+ echo Logging output to experiments/logs/rfcn_end2end_ResNet-50_.txt.2018-03-11_23-07-13
Logging output to experiments/logs/rfcn_end2end_ResNet-50_.txt.2018-03-11_23-07-13
+ ./tools/train_net.py --gpu 0 --solver models/pascal_voc/ResNet-50/rfcn_end2end/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_2007_trainval --iters 120000 --cfg experiments/cfgs/rfcn_end2end_ohem.yml
imagenet_train
<function <lambda> at 0x7fc518651aa0>
imagenet_val
<function <lambda> at 0x7fc518651b18>
Called with args:
Namespace(cfg_file='experiments/cfgs/rfcn_end2end_ohem.yml', gpu_id=0, imdb_name='voc_2007_trainval', max_iters=120000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/ResNet-50/rfcn_end2end/solver_ohem.prototxt')
Using config:
{'DATA_DIR': '/home/fan/Rfcn/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'rfcn_end2end_ohem',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fan/Rfcn/models/pascal_voc',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/fan/Rfcn',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2007_trainval gt roidb loaded from /home/fan/Rfcn/data/cache/voc_2007_trainval_gt_roidb.pkl
done
Preparing training data...
done
446740 roidb entries
Output will be saved to `/home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval`
Filtered 0 roidb entries: 446740 -> 446740
Computing bounding-box regression targets...
bbox target means:
[[ 0.  0.  0.  0.]
 [ 0.  0.  0.  0.]]
[ 0.  0.  0.  0.]
bbox target stdevs:
[[ 0.1  0.1  0.2  0.2]
 [ 0.1  0.1  0.2  0.2]]
[ 0.1  0.1  0.2  0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0311 23:08:51.166546 17663 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/ResNet-50/rfcn_end2end/train_agnostic_ohem.prototxt"
base_lr: 0.001
display: 100
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 10000
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 2
I0311 23:08:51.166679 17663 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/ResNet-50/rfcn_end2end/train_agnostic_ohem.prototxt
I0311 23:08:51.168937 17663 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0311 23:08:51.169728 17663 layer_factory.hpp:77] Creating layer input-data
I0311 23:08:51.229250 17663 net.cpp:100] Creating Layer input-data
I0311 23:08:51.229271 17663 net.cpp:418] input-data -> data
I0311 23:08:51.229281 17663 net.cpp:418] input-data -> im_info
I0311 23:08:51.229288 17663 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0311 23:08:53.694437 17663 net.cpp:150] Setting up input-data
I0311 23:08:53.694485 17663 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0311 23:08:53.694489 17663 net.cpp:157] Top shape: 1 3 (3)
I0311 23:08:53.694492 17663 net.cpp:157] Top shape: 1 4 (4)
I0311 23:08:53.694494 17663 net.cpp:165] Memory required for data: 7200028
I0311 23:08:53.694499 17663 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0311 23:08:53.694524 17663 net.cpp:100] Creating Layer data_input-data_0_split
I0311 23:08:53.694527 17663 net.cpp:444] data_input-data_0_split <- data
I0311 23:08:53.694545 17663 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0311 23:08:53.694567 17663 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0311 23:08:53.694619 17663 net.cpp:150] Setting up data_input-data_0_split
I0311 23:08:53.694639 17663 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0311 23:08:53.694643 17663 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0311 23:08:53.694658 17663 net.cpp:165] Memory required for data: 21600028
I0311 23:08:53.694659 17663 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0311 23:08:53.694664 17663 net.cpp:100] Creating Layer im_info_input-data_1_split
I0311 23:08:53.694665 17663 net.cpp:444] im_info_input-data_1_split <- im_info
I0311 23:08:53.694684 17663 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0311 23:08:53.694689 17663 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0311 23:08:53.694725 17663 net.cpp:150] Setting up im_info_input-data_1_split
I0311 23:08:53.694728 17663 net.cpp:157] Top shape: 1 3 (3)
I0311 23:08:53.694744 17663 net.cpp:157] Top shape: 1 3 (3)
I0311 23:08:53.694746 17663 net.cpp:165] Memory required for data: 21600052
I0311 23:08:53.694748 17663 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0311 23:08:53.694768 17663 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0311 23:08:53.694772 17663 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0311 23:08:53.694775 17663 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0311 23:08:53.694792 17663 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0311 23:08:53.694828 17663 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0311 23:08:53.694833 17663 net.cpp:157] Top shape: 1 4 (4)
I0311 23:08:53.694835 17663 net.cpp:157] Top shape: 1 4 (4)
I0311 23:08:53.694838 17663 net.cpp:165] Memory required for data: 21600084
I0311 23:08:53.694839 17663 layer_factory.hpp:77] Creating layer conv1
I0311 23:08:53.694847 17663 net.cpp:100] Creating Layer conv1
I0311 23:08:53.694850 17663 net.cpp:444] conv1 <- data_input-data_0_split_0
I0311 23:08:53.694854 17663 net.cpp:418] conv1 -> conv1
I0311 23:08:53.696303 17663 net.cpp:150] Setting up conv1
I0311 23:08:53.696316 17663 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0311 23:08:53.696318 17663 net.cpp:165] Memory required for data: 60000084
I0311 23:08:53.696341 17663 layer_factory.hpp:77] Creating layer bn_conv1
I0311 23:08:53.696348 17663 net.cpp:100] Creating Layer bn_conv1
I0311 23:08:53.696352 17663 net.cpp:444] bn_conv1 <- conv1
I0311 23:08:53.696357 17663 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0311 23:08:53.696669 17663 net.cpp:150] Setting up bn_conv1
I0311 23:08:53.696674 17663 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0311 23:08:53.696677 17663 net.cpp:165] Memory required for data: 98400084
I0311 23:08:53.696684 17663 layer_factory.hpp:77] Creating layer scale_conv1
I0311 23:08:53.696691 17663 net.cpp:100] Creating Layer scale_conv1
I0311 23:08:53.696708 17663 net.cpp:444] scale_conv1 <- conv1
I0311 23:08:53.696713 17663 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0311 23:08:53.696751 17663 layer_factory.hpp:77] Creating layer scale_conv1
I0311 23:08:53.697681 17663 net.cpp:150] Setting up scale_conv1
I0311 23:08:53.697692 17663 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0311 23:08:53.697695 17663 net.cpp:165] Memory required for data: 136800084
I0311 23:08:53.697701 17663 layer_factory.hpp:77] Creating layer conv1_relu
I0311 23:08:53.697722 17663 net.cpp:100] Creating Layer conv1_relu
I0311 23:08:53.697726 17663 net.cpp:444] conv1_relu <- conv1
I0311 23:08:53.697731 17663 net.cpp:405] conv1_relu -> conv1 (in-place)
I0311 23:08:53.697736 17663 net.cpp:150] Setting up conv1_relu
I0311 23:08:53.697739 17663 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0311 23:08:53.697741 17663 net.cpp:165] Memory required for data: 175200084
I0311 23:08:53.697744 17663 layer_factory.hpp:77] Creating layer pool1
I0311 23:08:53.697751 17663 net.cpp:100] Creating Layer pool1
I0311 23:08:53.697753 17663 net.cpp:444] pool1 <- conv1
I0311 23:08:53.697757 17663 net.cpp:418] pool1 -> pool1
I0311 23:08:53.697813 17663 net.cpp:150] Setting up pool1
I0311 23:08:53.697818 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.697819 17663 net.cpp:165] Memory required for data: 184800084
I0311 23:08:53.697823 17663 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0311 23:08:53.697826 17663 net.cpp:100] Creating Layer pool1_pool1_0_split
I0311 23:08:53.697829 17663 net.cpp:444] pool1_pool1_0_split <- pool1
I0311 23:08:53.697834 17663 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0311 23:08:53.697854 17663 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0311 23:08:53.697875 17663 net.cpp:150] Setting up pool1_pool1_0_split
I0311 23:08:53.697880 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.697916 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.697917 17663 net.cpp:165] Memory required for data: 204000084
I0311 23:08:53.697921 17663 layer_factory.hpp:77] Creating layer res2a_branch1
I0311 23:08:53.697942 17663 net.cpp:100] Creating Layer res2a_branch1
I0311 23:08:53.697944 17663 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0311 23:08:53.697962 17663 net.cpp:418] res2a_branch1 -> res2a_branch1
I0311 23:08:53.698112 17663 net.cpp:150] Setting up res2a_branch1
I0311 23:08:53.698117 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.698120 17663 net.cpp:165] Memory required for data: 242400084
I0311 23:08:53.698123 17663 layer_factory.hpp:77] Creating layer bn2a_branch1
I0311 23:08:53.698128 17663 net.cpp:100] Creating Layer bn2a_branch1
I0311 23:08:53.698132 17663 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0311 23:08:53.698150 17663 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0311 23:08:53.698917 17663 net.cpp:150] Setting up bn2a_branch1
I0311 23:08:53.698926 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.698930 17663 net.cpp:165] Memory required for data: 280800084
I0311 23:08:53.698936 17663 layer_factory.hpp:77] Creating layer scale2a_branch1
I0311 23:08:53.698956 17663 net.cpp:100] Creating Layer scale2a_branch1
I0311 23:08:53.698958 17663 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0311 23:08:53.698963 17663 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0311 23:08:53.699018 17663 layer_factory.hpp:77] Creating layer scale2a_branch1
I0311 23:08:53.699188 17663 net.cpp:150] Setting up scale2a_branch1
I0311 23:08:53.699193 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.699196 17663 net.cpp:165] Memory required for data: 319200084
I0311 23:08:53.699199 17663 layer_factory.hpp:77] Creating layer res2a_branch2a
I0311 23:08:53.699205 17663 net.cpp:100] Creating Layer res2a_branch2a
I0311 23:08:53.699208 17663 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0311 23:08:53.699213 17663 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0311 23:08:53.700048 17663 net.cpp:150] Setting up res2a_branch2a
I0311 23:08:53.700057 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.700060 17663 net.cpp:165] Memory required for data: 328800084
I0311 23:08:53.700064 17663 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0311 23:08:53.700070 17663 net.cpp:100] Creating Layer bn2a_branch2a
I0311 23:08:53.700088 17663 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0311 23:08:53.700093 17663 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0311 23:08:53.700270 17663 net.cpp:150] Setting up bn2a_branch2a
I0311 23:08:53.700274 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.700278 17663 net.cpp:165] Memory required for data: 338400084
I0311 23:08:53.700284 17663 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0311 23:08:53.700304 17663 net.cpp:100] Creating Layer scale2a_branch2a
I0311 23:08:53.700305 17663 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0311 23:08:53.700309 17663 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0311 23:08:53.700350 17663 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0311 23:08:53.700563 17663 net.cpp:150] Setting up scale2a_branch2a
I0311 23:08:53.700580 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.700583 17663 net.cpp:165] Memory required for data: 348000084
I0311 23:08:53.700587 17663 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0311 23:08:53.700593 17663 net.cpp:100] Creating Layer res2a_branch2a_relu
I0311 23:08:53.700614 17663 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0311 23:08:53.700618 17663 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0311 23:08:53.700623 17663 net.cpp:150] Setting up res2a_branch2a_relu
I0311 23:08:53.700637 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.700639 17663 net.cpp:165] Memory required for data: 357600084
I0311 23:08:53.700642 17663 layer_factory.hpp:77] Creating layer res2a_branch2b
I0311 23:08:53.700661 17663 net.cpp:100] Creating Layer res2a_branch2b
I0311 23:08:53.700666 17663 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0311 23:08:53.700685 17663 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0311 23:08:53.700845 17663 net.cpp:150] Setting up res2a_branch2b
I0311 23:08:53.700850 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.700851 17663 net.cpp:165] Memory required for data: 367200084
I0311 23:08:53.700855 17663 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0311 23:08:53.700858 17663 net.cpp:100] Creating Layer bn2a_branch2b
I0311 23:08:53.700861 17663 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0311 23:08:53.700865 17663 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0311 23:08:53.701046 17663 net.cpp:150] Setting up bn2a_branch2b
I0311 23:08:53.701051 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.701055 17663 net.cpp:165] Memory required for data: 376800084
I0311 23:08:53.701058 17663 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0311 23:08:53.701062 17663 net.cpp:100] Creating Layer scale2a_branch2b
I0311 23:08:53.701066 17663 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0311 23:08:53.701068 17663 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0311 23:08:53.701118 17663 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0311 23:08:53.701252 17663 net.cpp:150] Setting up scale2a_branch2b
I0311 23:08:53.701257 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.701259 17663 net.cpp:165] Memory required for data: 386400084
I0311 23:08:53.701263 17663 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0311 23:08:53.701268 17663 net.cpp:100] Creating Layer res2a_branch2b_relu
I0311 23:08:53.701272 17663 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0311 23:08:53.701289 17663 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0311 23:08:53.701294 17663 net.cpp:150] Setting up res2a_branch2b_relu
I0311 23:08:53.701297 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.701299 17663 net.cpp:165] Memory required for data: 396000084
I0311 23:08:53.701303 17663 layer_factory.hpp:77] Creating layer res2a_branch2c
I0311 23:08:53.701308 17663 net.cpp:100] Creating Layer res2a_branch2c
I0311 23:08:53.701310 17663 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0311 23:08:53.701314 17663 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0311 23:08:53.701501 17663 net.cpp:150] Setting up res2a_branch2c
I0311 23:08:53.701506 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.701508 17663 net.cpp:165] Memory required for data: 434400084
I0311 23:08:53.701511 17663 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0311 23:08:53.701517 17663 net.cpp:100] Creating Layer bn2a_branch2c
I0311 23:08:53.701534 17663 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0311 23:08:53.701537 17663 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0311 23:08:53.701704 17663 net.cpp:150] Setting up bn2a_branch2c
I0311 23:08:53.701709 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.701710 17663 net.cpp:165] Memory required for data: 472800084
I0311 23:08:53.701715 17663 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0311 23:08:53.701719 17663 net.cpp:100] Creating Layer scale2a_branch2c
I0311 23:08:53.701722 17663 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0311 23:08:53.701725 17663 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0311 23:08:53.701748 17663 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0311 23:08:53.701903 17663 net.cpp:150] Setting up scale2a_branch2c
I0311 23:08:53.701910 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.701912 17663 net.cpp:165] Memory required for data: 511200084
I0311 23:08:53.701915 17663 layer_factory.hpp:77] Creating layer res2a
I0311 23:08:53.701920 17663 net.cpp:100] Creating Layer res2a
I0311 23:08:53.701922 17663 net.cpp:444] res2a <- res2a_branch1
I0311 23:08:53.701925 17663 net.cpp:444] res2a <- res2a_branch2c
I0311 23:08:53.701928 17663 net.cpp:418] res2a -> res2a
I0311 23:08:53.701944 17663 net.cpp:150] Setting up res2a
I0311 23:08:53.701948 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.701951 17663 net.cpp:165] Memory required for data: 549600084
I0311 23:08:53.701952 17663 layer_factory.hpp:77] Creating layer res2a_relu
I0311 23:08:53.701956 17663 net.cpp:100] Creating Layer res2a_relu
I0311 23:08:53.701972 17663 net.cpp:444] res2a_relu <- res2a
I0311 23:08:53.701974 17663 net.cpp:405] res2a_relu -> res2a (in-place)
I0311 23:08:53.701978 17663 net.cpp:150] Setting up res2a_relu
I0311 23:08:53.701982 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.701984 17663 net.cpp:165] Memory required for data: 588000084
I0311 23:08:53.701987 17663 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0311 23:08:53.702008 17663 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0311 23:08:53.702009 17663 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0311 23:08:53.702026 17663 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0311 23:08:53.702031 17663 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0311 23:08:53.702081 17663 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0311 23:08:53.702086 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.702102 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.702105 17663 net.cpp:165] Memory required for data: 664800084
I0311 23:08:53.702108 17663 layer_factory.hpp:77] Creating layer res2b_branch2a
I0311 23:08:53.702112 17663 net.cpp:100] Creating Layer res2b_branch2a
I0311 23:08:53.702116 17663 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0311 23:08:53.702136 17663 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0311 23:08:53.702280 17663 net.cpp:150] Setting up res2b_branch2a
I0311 23:08:53.702286 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.702288 17663 net.cpp:165] Memory required for data: 674400084
I0311 23:08:53.702291 17663 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0311 23:08:53.702296 17663 net.cpp:100] Creating Layer bn2b_branch2a
I0311 23:08:53.702299 17663 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0311 23:08:53.702316 17663 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0311 23:08:53.703119 17663 net.cpp:150] Setting up bn2b_branch2a
I0311 23:08:53.703128 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.703131 17663 net.cpp:165] Memory required for data: 684000084
I0311 23:08:53.703140 17663 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0311 23:08:53.703161 17663 net.cpp:100] Creating Layer scale2b_branch2a
I0311 23:08:53.703164 17663 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0311 23:08:53.703168 17663 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0311 23:08:53.703236 17663 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0311 23:08:53.703418 17663 net.cpp:150] Setting up scale2b_branch2a
I0311 23:08:53.703423 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.703424 17663 net.cpp:165] Memory required for data: 693600084
I0311 23:08:53.703428 17663 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0311 23:08:53.703433 17663 net.cpp:100] Creating Layer res2b_branch2a_relu
I0311 23:08:53.703449 17663 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0311 23:08:53.703451 17663 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0311 23:08:53.703455 17663 net.cpp:150] Setting up res2b_branch2a_relu
I0311 23:08:53.703459 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.703460 17663 net.cpp:165] Memory required for data: 703200084
I0311 23:08:53.703464 17663 layer_factory.hpp:77] Creating layer res2b_branch2b
I0311 23:08:53.703481 17663 net.cpp:100] Creating Layer res2b_branch2b
I0311 23:08:53.703485 17663 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0311 23:08:53.703501 17663 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0311 23:08:53.703672 17663 net.cpp:150] Setting up res2b_branch2b
I0311 23:08:53.703678 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.703680 17663 net.cpp:165] Memory required for data: 712800084
I0311 23:08:53.703685 17663 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0311 23:08:53.703691 17663 net.cpp:100] Creating Layer bn2b_branch2b
I0311 23:08:53.703707 17663 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0311 23:08:53.703711 17663 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0311 23:08:53.703856 17663 net.cpp:150] Setting up bn2b_branch2b
I0311 23:08:53.703861 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.703864 17663 net.cpp:165] Memory required for data: 722400084
I0311 23:08:53.703868 17663 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0311 23:08:53.703873 17663 net.cpp:100] Creating Layer scale2b_branch2b
I0311 23:08:53.703876 17663 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0311 23:08:53.703893 17663 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0311 23:08:53.703943 17663 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0311 23:08:53.704077 17663 net.cpp:150] Setting up scale2b_branch2b
I0311 23:08:53.704082 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.704085 17663 net.cpp:165] Memory required for data: 732000084
I0311 23:08:53.704089 17663 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0311 23:08:53.704107 17663 net.cpp:100] Creating Layer res2b_branch2b_relu
I0311 23:08:53.704110 17663 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0311 23:08:53.704114 17663 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0311 23:08:53.704118 17663 net.cpp:150] Setting up res2b_branch2b_relu
I0311 23:08:53.704121 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.704123 17663 net.cpp:165] Memory required for data: 741600084
I0311 23:08:53.704126 17663 layer_factory.hpp:77] Creating layer res2b_branch2c
I0311 23:08:53.704130 17663 net.cpp:100] Creating Layer res2b_branch2c
I0311 23:08:53.704133 17663 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0311 23:08:53.704138 17663 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0311 23:08:53.704278 17663 net.cpp:150] Setting up res2b_branch2c
I0311 23:08:53.704283 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704285 17663 net.cpp:165] Memory required for data: 780000084
I0311 23:08:53.704288 17663 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0311 23:08:53.704293 17663 net.cpp:100] Creating Layer bn2b_branch2c
I0311 23:08:53.704309 17663 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0311 23:08:53.704313 17663 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0311 23:08:53.704459 17663 net.cpp:150] Setting up bn2b_branch2c
I0311 23:08:53.704465 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704468 17663 net.cpp:165] Memory required for data: 818400084
I0311 23:08:53.704473 17663 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0311 23:08:53.704478 17663 net.cpp:100] Creating Layer scale2b_branch2c
I0311 23:08:53.704481 17663 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0311 23:08:53.704485 17663 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0311 23:08:53.704535 17663 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0311 23:08:53.704689 17663 net.cpp:150] Setting up scale2b_branch2c
I0311 23:08:53.704694 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704696 17663 net.cpp:165] Memory required for data: 856800084
I0311 23:08:53.704699 17663 layer_factory.hpp:77] Creating layer res2b
I0311 23:08:53.704704 17663 net.cpp:100] Creating Layer res2b
I0311 23:08:53.704721 17663 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0311 23:08:53.704725 17663 net.cpp:444] res2b <- res2b_branch2c
I0311 23:08:53.704728 17663 net.cpp:418] res2b -> res2b
I0311 23:08:53.704743 17663 net.cpp:150] Setting up res2b
I0311 23:08:53.704763 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704766 17663 net.cpp:165] Memory required for data: 895200084
I0311 23:08:53.704768 17663 layer_factory.hpp:77] Creating layer res2b_relu
I0311 23:08:53.704784 17663 net.cpp:100] Creating Layer res2b_relu
I0311 23:08:53.704787 17663 net.cpp:444] res2b_relu <- res2b
I0311 23:08:53.704790 17663 net.cpp:405] res2b_relu -> res2b (in-place)
I0311 23:08:53.704808 17663 net.cpp:150] Setting up res2b_relu
I0311 23:08:53.704812 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704813 17663 net.cpp:165] Memory required for data: 933600084
I0311 23:08:53.704828 17663 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0311 23:08:53.704833 17663 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0311 23:08:53.704834 17663 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0311 23:08:53.704838 17663 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0311 23:08:53.704843 17663 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0311 23:08:53.704877 17663 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0311 23:08:53.704882 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704898 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.704900 17663 net.cpp:165] Memory required for data: 1010400084
I0311 23:08:53.704902 17663 layer_factory.hpp:77] Creating layer res2c_branch2a
I0311 23:08:53.704907 17663 net.cpp:100] Creating Layer res2c_branch2a
I0311 23:08:53.704922 17663 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0311 23:08:53.704926 17663 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0311 23:08:53.705087 17663 net.cpp:150] Setting up res2c_branch2a
I0311 23:08:53.705092 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.705094 17663 net.cpp:165] Memory required for data: 1020000084
I0311 23:08:53.705097 17663 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0311 23:08:53.705101 17663 net.cpp:100] Creating Layer bn2c_branch2a
I0311 23:08:53.705104 17663 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0311 23:08:53.705121 17663 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0311 23:08:53.705286 17663 net.cpp:150] Setting up bn2c_branch2a
I0311 23:08:53.705291 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.705293 17663 net.cpp:165] Memory required for data: 1029600084
I0311 23:08:53.705298 17663 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0311 23:08:53.705303 17663 net.cpp:100] Creating Layer scale2c_branch2a
I0311 23:08:53.705307 17663 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0311 23:08:53.705312 17663 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0311 23:08:53.705337 17663 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0311 23:08:53.705456 17663 net.cpp:150] Setting up scale2c_branch2a
I0311 23:08:53.705461 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.705463 17663 net.cpp:165] Memory required for data: 1039200084
I0311 23:08:53.705468 17663 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0311 23:08:53.705472 17663 net.cpp:100] Creating Layer res2c_branch2a_relu
I0311 23:08:53.705489 17663 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0311 23:08:53.705492 17663 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0311 23:08:53.705497 17663 net.cpp:150] Setting up res2c_branch2a_relu
I0311 23:08:53.705513 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.705515 17663 net.cpp:165] Memory required for data: 1048800084
I0311 23:08:53.705518 17663 layer_factory.hpp:77] Creating layer res2c_branch2b
I0311 23:08:53.705523 17663 net.cpp:100] Creating Layer res2c_branch2b
I0311 23:08:53.705524 17663 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0311 23:08:53.705528 17663 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0311 23:08:53.705687 17663 net.cpp:150] Setting up res2c_branch2b
I0311 23:08:53.705693 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.705695 17663 net.cpp:165] Memory required for data: 1058400084
I0311 23:08:53.705698 17663 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0311 23:08:53.705703 17663 net.cpp:100] Creating Layer bn2c_branch2b
I0311 23:08:53.705704 17663 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0311 23:08:53.705708 17663 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0311 23:08:53.706622 17663 net.cpp:150] Setting up bn2c_branch2b
I0311 23:08:53.706647 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.706650 17663 net.cpp:165] Memory required for data: 1068000084
I0311 23:08:53.706671 17663 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0311 23:08:53.706678 17663 net.cpp:100] Creating Layer scale2c_branch2b
I0311 23:08:53.706681 17663 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0311 23:08:53.706686 17663 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0311 23:08:53.706758 17663 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0311 23:08:53.706918 17663 net.cpp:150] Setting up scale2c_branch2b
I0311 23:08:53.706923 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.706926 17663 net.cpp:165] Memory required for data: 1077600084
I0311 23:08:53.706929 17663 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0311 23:08:53.706933 17663 net.cpp:100] Creating Layer res2c_branch2b_relu
I0311 23:08:53.706949 17663 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0311 23:08:53.706954 17663 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0311 23:08:53.706957 17663 net.cpp:150] Setting up res2c_branch2b_relu
I0311 23:08:53.706960 17663 net.cpp:157] Top shape: 1 64 150 250 (2400000)
I0311 23:08:53.706962 17663 net.cpp:165] Memory required for data: 1087200084
I0311 23:08:53.706965 17663 layer_factory.hpp:77] Creating layer res2c_branch2c
I0311 23:08:53.706984 17663 net.cpp:100] Creating Layer res2c_branch2c
I0311 23:08:53.706987 17663 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0311 23:08:53.706992 17663 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0311 23:08:53.707168 17663 net.cpp:150] Setting up res2c_branch2c
I0311 23:08:53.707175 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707176 17663 net.cpp:165] Memory required for data: 1125600084
I0311 23:08:53.707180 17663 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0311 23:08:53.707185 17663 net.cpp:100] Creating Layer bn2c_branch2c
I0311 23:08:53.707186 17663 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0311 23:08:53.707202 17663 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0311 23:08:53.707365 17663 net.cpp:150] Setting up bn2c_branch2c
I0311 23:08:53.707370 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707373 17663 net.cpp:165] Memory required for data: 1164000084
I0311 23:08:53.707381 17663 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0311 23:08:53.707401 17663 net.cpp:100] Creating Layer scale2c_branch2c
I0311 23:08:53.707403 17663 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0311 23:08:53.707407 17663 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0311 23:08:53.707468 17663 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0311 23:08:53.707595 17663 net.cpp:150] Setting up scale2c_branch2c
I0311 23:08:53.707600 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707602 17663 net.cpp:165] Memory required for data: 1202400084
I0311 23:08:53.707607 17663 layer_factory.hpp:77] Creating layer res2c
I0311 23:08:53.707612 17663 net.cpp:100] Creating Layer res2c
I0311 23:08:53.707630 17663 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0311 23:08:53.707633 17663 net.cpp:444] res2c <- res2c_branch2c
I0311 23:08:53.707638 17663 net.cpp:418] res2c -> res2c
I0311 23:08:53.707653 17663 net.cpp:150] Setting up res2c
I0311 23:08:53.707670 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707674 17663 net.cpp:165] Memory required for data: 1240800084
I0311 23:08:53.707675 17663 layer_factory.hpp:77] Creating layer res2c_relu
I0311 23:08:53.707679 17663 net.cpp:100] Creating Layer res2c_relu
I0311 23:08:53.707682 17663 net.cpp:444] res2c_relu <- res2c
I0311 23:08:53.707686 17663 net.cpp:405] res2c_relu -> res2c (in-place)
I0311 23:08:53.707705 17663 net.cpp:150] Setting up res2c_relu
I0311 23:08:53.707710 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707711 17663 net.cpp:165] Memory required for data: 1279200084
I0311 23:08:53.707715 17663 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0311 23:08:53.707717 17663 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0311 23:08:53.707720 17663 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0311 23:08:53.707725 17663 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0311 23:08:53.707729 17663 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0311 23:08:53.707767 17663 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0311 23:08:53.707770 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707774 17663 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0311 23:08:53.707777 17663 net.cpp:165] Memory required for data: 1356000084
I0311 23:08:53.707778 17663 layer_factory.hpp:77] Creating layer res3a_branch1
I0311 23:08:53.707783 17663 net.cpp:100] Creating Layer res3a_branch1
I0311 23:08:53.707787 17663 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0311 23:08:53.707792 17663 net.cpp:418] res3a_branch1 -> res3a_branch1
I0311 23:08:53.707993 17663 net.cpp:150] Setting up res3a_branch1
I0311 23:08:53.707999 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.708003 17663 net.cpp:165] Memory required for data: 1375200084
I0311 23:08:53.708006 17663 layer_factory.hpp:77] Creating layer bn3a_branch1
I0311 23:08:53.708010 17663 net.cpp:100] Creating Layer bn3a_branch1
I0311 23:08:53.708014 17663 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0311 23:08:53.708019 17663 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0311 23:08:53.708853 17663 net.cpp:150] Setting up bn3a_branch1
I0311 23:08:53.708863 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.708865 17663 net.cpp:165] Memory required for data: 1394400084
I0311 23:08:53.708873 17663 layer_factory.hpp:77] Creating layer scale3a_branch1
I0311 23:08:53.708878 17663 net.cpp:100] Creating Layer scale3a_branch1
I0311 23:08:53.708881 17663 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0311 23:08:53.708886 17663 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0311 23:08:53.708912 17663 layer_factory.hpp:77] Creating layer scale3a_branch1
I0311 23:08:53.709002 17663 net.cpp:150] Setting up scale3a_branch1
I0311 23:08:53.709008 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.709010 17663 net.cpp:165] Memory required for data: 1413600084
I0311 23:08:53.709015 17663 layer_factory.hpp:77] Creating layer res3a_branch2a
I0311 23:08:53.709020 17663 net.cpp:100] Creating Layer res3a_branch2a
I0311 23:08:53.709024 17663 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0311 23:08:53.709028 17663 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0311 23:08:53.709172 17663 net.cpp:150] Setting up res3a_branch2a
I0311 23:08:53.709178 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709180 17663 net.cpp:165] Memory required for data: 1418400084
I0311 23:08:53.709184 17663 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0311 23:08:53.709189 17663 net.cpp:100] Creating Layer bn3a_branch2a
I0311 23:08:53.709192 17663 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0311 23:08:53.709197 17663 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0311 23:08:53.709323 17663 net.cpp:150] Setting up bn3a_branch2a
I0311 23:08:53.709328 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709331 17663 net.cpp:165] Memory required for data: 1423200084
I0311 23:08:53.709336 17663 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0311 23:08:53.709341 17663 net.cpp:100] Creating Layer scale3a_branch2a
I0311 23:08:53.709344 17663 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0311 23:08:53.709348 17663 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0311 23:08:53.709373 17663 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0311 23:08:53.709470 17663 net.cpp:150] Setting up scale3a_branch2a
I0311 23:08:53.709475 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709478 17663 net.cpp:165] Memory required for data: 1428000084
I0311 23:08:53.709482 17663 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0311 23:08:53.709486 17663 net.cpp:100] Creating Layer res3a_branch2a_relu
I0311 23:08:53.709489 17663 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0311 23:08:53.709496 17663 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0311 23:08:53.709501 17663 net.cpp:150] Setting up res3a_branch2a_relu
I0311 23:08:53.709503 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709506 17663 net.cpp:165] Memory required for data: 1432800084
I0311 23:08:53.709508 17663 layer_factory.hpp:77] Creating layer res3a_branch2b
I0311 23:08:53.709513 17663 net.cpp:100] Creating Layer res3a_branch2b
I0311 23:08:53.709517 17663 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0311 23:08:53.709534 17663 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0311 23:08:53.709758 17663 net.cpp:150] Setting up res3a_branch2b
I0311 23:08:53.709764 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709765 17663 net.cpp:165] Memory required for data: 1437600084
I0311 23:08:53.709769 17663 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0311 23:08:53.709774 17663 net.cpp:100] Creating Layer bn3a_branch2b
I0311 23:08:53.709789 17663 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0311 23:08:53.709792 17663 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0311 23:08:53.709939 17663 net.cpp:150] Setting up bn3a_branch2b
I0311 23:08:53.709945 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.709947 17663 net.cpp:165] Memory required for data: 1442400084
I0311 23:08:53.709952 17663 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0311 23:08:53.709973 17663 net.cpp:100] Creating Layer scale3a_branch2b
I0311 23:08:53.709976 17663 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0311 23:08:53.709992 17663 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0311 23:08:53.710016 17663 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0311 23:08:53.710117 17663 net.cpp:150] Setting up scale3a_branch2b
I0311 23:08:53.710124 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.710140 17663 net.cpp:165] Memory required for data: 1447200084
I0311 23:08:53.710144 17663 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0311 23:08:53.710162 17663 net.cpp:100] Creating Layer res3a_branch2b_relu
I0311 23:08:53.710165 17663 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0311 23:08:53.710168 17663 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0311 23:08:53.710172 17663 net.cpp:150] Setting up res3a_branch2b_relu
I0311 23:08:53.710176 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.710180 17663 net.cpp:165] Memory required for data: 1452000084
I0311 23:08:53.710181 17663 layer_factory.hpp:77] Creating layer res3a_branch2c
I0311 23:08:53.710187 17663 net.cpp:100] Creating Layer res3a_branch2c
I0311 23:08:53.710203 17663 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0311 23:08:53.710207 17663 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0311 23:08:53.710398 17663 net.cpp:150] Setting up res3a_branch2c
I0311 23:08:53.710403 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710407 17663 net.cpp:165] Memory required for data: 1471200084
I0311 23:08:53.710410 17663 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0311 23:08:53.710414 17663 net.cpp:100] Creating Layer bn3a_branch2c
I0311 23:08:53.710417 17663 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0311 23:08:53.710422 17663 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0311 23:08:53.710568 17663 net.cpp:150] Setting up bn3a_branch2c
I0311 23:08:53.710573 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710575 17663 net.cpp:165] Memory required for data: 1490400084
I0311 23:08:53.710580 17663 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0311 23:08:53.710587 17663 net.cpp:100] Creating Layer scale3a_branch2c
I0311 23:08:53.710589 17663 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0311 23:08:53.710593 17663 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0311 23:08:53.710616 17663 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0311 23:08:53.710705 17663 net.cpp:150] Setting up scale3a_branch2c
I0311 23:08:53.710711 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710713 17663 net.cpp:165] Memory required for data: 1509600084
I0311 23:08:53.710717 17663 layer_factory.hpp:77] Creating layer res3a
I0311 23:08:53.710722 17663 net.cpp:100] Creating Layer res3a
I0311 23:08:53.710726 17663 net.cpp:444] res3a <- res3a_branch1
I0311 23:08:53.710729 17663 net.cpp:444] res3a <- res3a_branch2c
I0311 23:08:53.710734 17663 net.cpp:418] res3a -> res3a
I0311 23:08:53.710750 17663 net.cpp:150] Setting up res3a
I0311 23:08:53.710755 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710757 17663 net.cpp:165] Memory required for data: 1528800084
I0311 23:08:53.710760 17663 layer_factory.hpp:77] Creating layer res3a_relu
I0311 23:08:53.710765 17663 net.cpp:100] Creating Layer res3a_relu
I0311 23:08:53.710769 17663 net.cpp:444] res3a_relu <- res3a
I0311 23:08:53.710772 17663 net.cpp:405] res3a_relu -> res3a (in-place)
I0311 23:08:53.710777 17663 net.cpp:150] Setting up res3a_relu
I0311 23:08:53.710780 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710783 17663 net.cpp:165] Memory required for data: 1548000084
I0311 23:08:53.710785 17663 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0311 23:08:53.710789 17663 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0311 23:08:53.710791 17663 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0311 23:08:53.710795 17663 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0311 23:08:53.710799 17663 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0311 23:08:53.710824 17663 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0311 23:08:53.710829 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710831 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.710834 17663 net.cpp:165] Memory required for data: 1586400084
I0311 23:08:53.710835 17663 layer_factory.hpp:77] Creating layer res3b_branch2a
I0311 23:08:53.710841 17663 net.cpp:100] Creating Layer res3b_branch2a
I0311 23:08:53.710844 17663 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0311 23:08:53.710849 17663 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0311 23:08:53.711007 17663 net.cpp:150] Setting up res3b_branch2a
I0311 23:08:53.711012 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.711014 17663 net.cpp:165] Memory required for data: 1591200084
I0311 23:08:53.711017 17663 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0311 23:08:53.711021 17663 net.cpp:100] Creating Layer bn3b_branch2a
I0311 23:08:53.711024 17663 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0311 23:08:53.711027 17663 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0311 23:08:53.711156 17663 net.cpp:150] Setting up bn3b_branch2a
I0311 23:08:53.711160 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.711163 17663 net.cpp:165] Memory required for data: 1596000084
I0311 23:08:53.711167 17663 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0311 23:08:53.711172 17663 net.cpp:100] Creating Layer scale3b_branch2a
I0311 23:08:53.711175 17663 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0311 23:08:53.711179 17663 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0311 23:08:53.711203 17663 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0311 23:08:53.711290 17663 net.cpp:150] Setting up scale3b_branch2a
I0311 23:08:53.711295 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.711297 17663 net.cpp:165] Memory required for data: 1600800084
I0311 23:08:53.711302 17663 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0311 23:08:53.711307 17663 net.cpp:100] Creating Layer res3b_branch2a_relu
I0311 23:08:53.711309 17663 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0311 23:08:53.711313 17663 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0311 23:08:53.711318 17663 net.cpp:150] Setting up res3b_branch2a_relu
I0311 23:08:53.711320 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.711323 17663 net.cpp:165] Memory required for data: 1605600084
I0311 23:08:53.711325 17663 layer_factory.hpp:77] Creating layer res3b_branch2b
I0311 23:08:53.711329 17663 net.cpp:100] Creating Layer res3b_branch2b
I0311 23:08:53.711331 17663 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0311 23:08:53.711336 17663 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0311 23:08:53.712203 17663 net.cpp:150] Setting up res3b_branch2b
I0311 23:08:53.712211 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.712213 17663 net.cpp:165] Memory required for data: 1610400084
I0311 23:08:53.712218 17663 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0311 23:08:53.712224 17663 net.cpp:100] Creating Layer bn3b_branch2b
I0311 23:08:53.712226 17663 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0311 23:08:53.712231 17663 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0311 23:08:53.712369 17663 net.cpp:150] Setting up bn3b_branch2b
I0311 23:08:53.712374 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.712376 17663 net.cpp:165] Memory required for data: 1615200084
I0311 23:08:53.712381 17663 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0311 23:08:53.712386 17663 net.cpp:100] Creating Layer scale3b_branch2b
I0311 23:08:53.712389 17663 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0311 23:08:53.712393 17663 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0311 23:08:53.712419 17663 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0311 23:08:53.712503 17663 net.cpp:150] Setting up scale3b_branch2b
I0311 23:08:53.712508 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.712510 17663 net.cpp:165] Memory required for data: 1620000084
I0311 23:08:53.712514 17663 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0311 23:08:53.712519 17663 net.cpp:100] Creating Layer res3b_branch2b_relu
I0311 23:08:53.712522 17663 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0311 23:08:53.712525 17663 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0311 23:08:53.712529 17663 net.cpp:150] Setting up res3b_branch2b_relu
I0311 23:08:53.712532 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.712534 17663 net.cpp:165] Memory required for data: 1624800084
I0311 23:08:53.712537 17663 layer_factory.hpp:77] Creating layer res3b_branch2c
I0311 23:08:53.712543 17663 net.cpp:100] Creating Layer res3b_branch2c
I0311 23:08:53.712545 17663 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0311 23:08:53.712549 17663 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0311 23:08:53.712716 17663 net.cpp:150] Setting up res3b_branch2c
I0311 23:08:53.712721 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.712723 17663 net.cpp:165] Memory required for data: 1644000084
I0311 23:08:53.712726 17663 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0311 23:08:53.712730 17663 net.cpp:100] Creating Layer bn3b_branch2c
I0311 23:08:53.712733 17663 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0311 23:08:53.712736 17663 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0311 23:08:53.712870 17663 net.cpp:150] Setting up bn3b_branch2c
I0311 23:08:53.712874 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.712877 17663 net.cpp:165] Memory required for data: 1663200084
I0311 23:08:53.712882 17663 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0311 23:08:53.712888 17663 net.cpp:100] Creating Layer scale3b_branch2c
I0311 23:08:53.712889 17663 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0311 23:08:53.712893 17663 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0311 23:08:53.712916 17663 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0311 23:08:53.713006 17663 net.cpp:150] Setting up scale3b_branch2c
I0311 23:08:53.713011 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.713013 17663 net.cpp:165] Memory required for data: 1682400084
I0311 23:08:53.713017 17663 layer_factory.hpp:77] Creating layer res3b
I0311 23:08:53.713023 17663 net.cpp:100] Creating Layer res3b
I0311 23:08:53.713026 17663 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0311 23:08:53.713029 17663 net.cpp:444] res3b <- res3b_branch2c
I0311 23:08:53.713032 17663 net.cpp:418] res3b -> res3b
I0311 23:08:53.713049 17663 net.cpp:150] Setting up res3b
I0311 23:08:53.713053 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.713055 17663 net.cpp:165] Memory required for data: 1701600084
I0311 23:08:53.713057 17663 layer_factory.hpp:77] Creating layer res3b_relu
I0311 23:08:53.713062 17663 net.cpp:100] Creating Layer res3b_relu
I0311 23:08:53.713063 17663 net.cpp:444] res3b_relu <- res3b
I0311 23:08:53.713068 17663 net.cpp:405] res3b_relu -> res3b (in-place)
I0311 23:08:53.713070 17663 net.cpp:150] Setting up res3b_relu
I0311 23:08:53.713073 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.713076 17663 net.cpp:165] Memory required for data: 1720800084
I0311 23:08:53.713078 17663 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0311 23:08:53.713083 17663 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0311 23:08:53.713084 17663 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0311 23:08:53.713088 17663 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0311 23:08:53.713093 17663 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0311 23:08:53.713116 17663 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0311 23:08:53.713120 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.713124 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.713125 17663 net.cpp:165] Memory required for data: 1759200084
I0311 23:08:53.713129 17663 layer_factory.hpp:77] Creating layer res3c_branch2a
I0311 23:08:53.713135 17663 net.cpp:100] Creating Layer res3c_branch2a
I0311 23:08:53.713136 17663 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0311 23:08:53.713140 17663 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0311 23:08:53.713301 17663 net.cpp:150] Setting up res3c_branch2a
I0311 23:08:53.713305 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713309 17663 net.cpp:165] Memory required for data: 1764000084
I0311 23:08:53.713311 17663 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0311 23:08:53.713317 17663 net.cpp:100] Creating Layer bn3c_branch2a
I0311 23:08:53.713320 17663 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0311 23:08:53.713323 17663 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0311 23:08:53.713452 17663 net.cpp:150] Setting up bn3c_branch2a
I0311 23:08:53.713456 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713459 17663 net.cpp:165] Memory required for data: 1768800084
I0311 23:08:53.713464 17663 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0311 23:08:53.713469 17663 net.cpp:100] Creating Layer scale3c_branch2a
I0311 23:08:53.713472 17663 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0311 23:08:53.713475 17663 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0311 23:08:53.713500 17663 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0311 23:08:53.713585 17663 net.cpp:150] Setting up scale3c_branch2a
I0311 23:08:53.713589 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713591 17663 net.cpp:165] Memory required for data: 1773600084
I0311 23:08:53.713595 17663 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0311 23:08:53.713600 17663 net.cpp:100] Creating Layer res3c_branch2a_relu
I0311 23:08:53.713603 17663 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0311 23:08:53.713606 17663 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0311 23:08:53.713610 17663 net.cpp:150] Setting up res3c_branch2a_relu
I0311 23:08:53.713613 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713616 17663 net.cpp:165] Memory required for data: 1778400084
I0311 23:08:53.713618 17663 layer_factory.hpp:77] Creating layer res3c_branch2b
I0311 23:08:53.713624 17663 net.cpp:100] Creating Layer res3c_branch2b
I0311 23:08:53.713626 17663 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0311 23:08:53.713630 17663 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0311 23:08:53.713820 17663 net.cpp:150] Setting up res3c_branch2b
I0311 23:08:53.713825 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713827 17663 net.cpp:165] Memory required for data: 1783200084
I0311 23:08:53.713830 17663 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0311 23:08:53.713836 17663 net.cpp:100] Creating Layer bn3c_branch2b
I0311 23:08:53.713838 17663 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0311 23:08:53.713841 17663 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0311 23:08:53.713984 17663 net.cpp:150] Setting up bn3c_branch2b
I0311 23:08:53.713990 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.713992 17663 net.cpp:165] Memory required for data: 1788000084
I0311 23:08:53.713997 17663 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0311 23:08:53.714002 17663 net.cpp:100] Creating Layer scale3c_branch2b
I0311 23:08:53.714004 17663 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0311 23:08:53.714009 17663 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0311 23:08:53.714033 17663 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0311 23:08:53.714123 17663 net.cpp:150] Setting up scale3c_branch2b
I0311 23:08:53.714128 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.714130 17663 net.cpp:165] Memory required for data: 1792800084
I0311 23:08:53.714134 17663 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0311 23:08:53.714138 17663 net.cpp:100] Creating Layer res3c_branch2b_relu
I0311 23:08:53.714140 17663 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0311 23:08:53.714143 17663 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0311 23:08:53.714148 17663 net.cpp:150] Setting up res3c_branch2b_relu
I0311 23:08:53.714150 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.714154 17663 net.cpp:165] Memory required for data: 1797600084
I0311 23:08:53.714155 17663 layer_factory.hpp:77] Creating layer res3c_branch2c
I0311 23:08:53.714160 17663 net.cpp:100] Creating Layer res3c_branch2c
I0311 23:08:53.714164 17663 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0311 23:08:53.714169 17663 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0311 23:08:53.715004 17663 net.cpp:150] Setting up res3c_branch2c
I0311 23:08:53.715013 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715016 17663 net.cpp:165] Memory required for data: 1816800084
I0311 23:08:53.715020 17663 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0311 23:08:53.715026 17663 net.cpp:100] Creating Layer bn3c_branch2c
I0311 23:08:53.715029 17663 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0311 23:08:53.715034 17663 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0311 23:08:53.715173 17663 net.cpp:150] Setting up bn3c_branch2c
I0311 23:08:53.715178 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715180 17663 net.cpp:165] Memory required for data: 1836000084
I0311 23:08:53.715185 17663 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0311 23:08:53.715190 17663 net.cpp:100] Creating Layer scale3c_branch2c
I0311 23:08:53.715193 17663 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0311 23:08:53.715196 17663 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0311 23:08:53.715219 17663 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0311 23:08:53.715309 17663 net.cpp:150] Setting up scale3c_branch2c
I0311 23:08:53.715314 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715317 17663 net.cpp:165] Memory required for data: 1855200084
I0311 23:08:53.715320 17663 layer_factory.hpp:77] Creating layer res3c
I0311 23:08:53.715324 17663 net.cpp:100] Creating Layer res3c
I0311 23:08:53.715327 17663 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0311 23:08:53.715330 17663 net.cpp:444] res3c <- res3c_branch2c
I0311 23:08:53.715335 17663 net.cpp:418] res3c -> res3c
I0311 23:08:53.715351 17663 net.cpp:150] Setting up res3c
I0311 23:08:53.715355 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715358 17663 net.cpp:165] Memory required for data: 1874400084
I0311 23:08:53.715360 17663 layer_factory.hpp:77] Creating layer res3c_relu
I0311 23:08:53.715364 17663 net.cpp:100] Creating Layer res3c_relu
I0311 23:08:53.715366 17663 net.cpp:444] res3c_relu <- res3c
I0311 23:08:53.715369 17663 net.cpp:405] res3c_relu -> res3c (in-place)
I0311 23:08:53.715374 17663 net.cpp:150] Setting up res3c_relu
I0311 23:08:53.715378 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715379 17663 net.cpp:165] Memory required for data: 1893600084
I0311 23:08:53.715381 17663 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0311 23:08:53.715386 17663 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0311 23:08:53.715389 17663 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0311 23:08:53.715392 17663 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0311 23:08:53.715396 17663 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0311 23:08:53.715420 17663 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0311 23:08:53.715423 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715426 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.715430 17663 net.cpp:165] Memory required for data: 1932000084
I0311 23:08:53.715432 17663 layer_factory.hpp:77] Creating layer res3d_branch2a
I0311 23:08:53.715437 17663 net.cpp:100] Creating Layer res3d_branch2a
I0311 23:08:53.715440 17663 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0311 23:08:53.715445 17663 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0311 23:08:53.715600 17663 net.cpp:150] Setting up res3d_branch2a
I0311 23:08:53.715605 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.715606 17663 net.cpp:165] Memory required for data: 1936800084
I0311 23:08:53.715610 17663 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0311 23:08:53.715615 17663 net.cpp:100] Creating Layer bn3d_branch2a
I0311 23:08:53.715618 17663 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0311 23:08:53.715621 17663 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0311 23:08:53.715749 17663 net.cpp:150] Setting up bn3d_branch2a
I0311 23:08:53.715754 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.715756 17663 net.cpp:165] Memory required for data: 1941600084
I0311 23:08:53.715767 17663 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0311 23:08:53.715772 17663 net.cpp:100] Creating Layer scale3d_branch2a
I0311 23:08:53.715775 17663 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0311 23:08:53.715780 17663 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0311 23:08:53.715807 17663 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0311 23:08:53.715890 17663 net.cpp:150] Setting up scale3d_branch2a
I0311 23:08:53.715895 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.715898 17663 net.cpp:165] Memory required for data: 1946400084
I0311 23:08:53.715901 17663 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0311 23:08:53.715905 17663 net.cpp:100] Creating Layer res3d_branch2a_relu
I0311 23:08:53.715909 17663 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0311 23:08:53.715912 17663 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0311 23:08:53.715916 17663 net.cpp:150] Setting up res3d_branch2a_relu
I0311 23:08:53.715919 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.715921 17663 net.cpp:165] Memory required for data: 1951200084
I0311 23:08:53.715924 17663 layer_factory.hpp:77] Creating layer res3d_branch2b
I0311 23:08:53.715931 17663 net.cpp:100] Creating Layer res3d_branch2b
I0311 23:08:53.715934 17663 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0311 23:08:53.715939 17663 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0311 23:08:53.716140 17663 net.cpp:150] Setting up res3d_branch2b
I0311 23:08:53.716145 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.716147 17663 net.cpp:165] Memory required for data: 1956000084
I0311 23:08:53.716150 17663 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0311 23:08:53.716156 17663 net.cpp:100] Creating Layer bn3d_branch2b
I0311 23:08:53.716158 17663 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0311 23:08:53.716162 17663 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0311 23:08:53.716295 17663 net.cpp:150] Setting up bn3d_branch2b
I0311 23:08:53.716298 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.716300 17663 net.cpp:165] Memory required for data: 1960800084
I0311 23:08:53.716305 17663 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0311 23:08:53.716310 17663 net.cpp:100] Creating Layer scale3d_branch2b
I0311 23:08:53.716313 17663 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0311 23:08:53.716316 17663 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0311 23:08:53.716341 17663 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0311 23:08:53.716429 17663 net.cpp:150] Setting up scale3d_branch2b
I0311 23:08:53.716434 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.716436 17663 net.cpp:165] Memory required for data: 1965600084
I0311 23:08:53.716440 17663 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0311 23:08:53.716445 17663 net.cpp:100] Creating Layer res3d_branch2b_relu
I0311 23:08:53.716449 17663 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0311 23:08:53.716452 17663 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0311 23:08:53.716456 17663 net.cpp:150] Setting up res3d_branch2b_relu
I0311 23:08:53.716459 17663 net.cpp:157] Top shape: 1 128 75 125 (1200000)
I0311 23:08:53.716461 17663 net.cpp:165] Memory required for data: 1970400084
I0311 23:08:53.716464 17663 layer_factory.hpp:77] Creating layer res3d_branch2c
I0311 23:08:53.716470 17663 net.cpp:100] Creating Layer res3d_branch2c
I0311 23:08:53.716472 17663 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0311 23:08:53.716476 17663 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0311 23:08:53.716629 17663 net.cpp:150] Setting up res3d_branch2c
I0311 23:08:53.716634 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.716636 17663 net.cpp:165] Memory required for data: 1989600084
I0311 23:08:53.716639 17663 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0311 23:08:53.716644 17663 net.cpp:100] Creating Layer bn3d_branch2c
I0311 23:08:53.716645 17663 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0311 23:08:53.716650 17663 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0311 23:08:53.716785 17663 net.cpp:150] Setting up bn3d_branch2c
I0311 23:08:53.716789 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.716791 17663 net.cpp:165] Memory required for data: 2008800084
I0311 23:08:53.716796 17663 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0311 23:08:53.716800 17663 net.cpp:100] Creating Layer scale3d_branch2c
I0311 23:08:53.716804 17663 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0311 23:08:53.716809 17663 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0311 23:08:53.716832 17663 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0311 23:08:53.716920 17663 net.cpp:150] Setting up scale3d_branch2c
I0311 23:08:53.716926 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.716929 17663 net.cpp:165] Memory required for data: 2028000084
I0311 23:08:53.716933 17663 layer_factory.hpp:77] Creating layer res3d
I0311 23:08:53.716938 17663 net.cpp:100] Creating Layer res3d
I0311 23:08:53.716940 17663 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0311 23:08:53.716943 17663 net.cpp:444] res3d <- res3d_branch2c
I0311 23:08:53.716948 17663 net.cpp:418] res3d -> res3d
I0311 23:08:53.716962 17663 net.cpp:150] Setting up res3d
I0311 23:08:53.716966 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.716969 17663 net.cpp:165] Memory required for data: 2047200084
I0311 23:08:53.716971 17663 layer_factory.hpp:77] Creating layer res3d_relu
I0311 23:08:53.716975 17663 net.cpp:100] Creating Layer res3d_relu
I0311 23:08:53.716977 17663 net.cpp:444] res3d_relu <- res3d
I0311 23:08:53.716981 17663 net.cpp:405] res3d_relu -> res3d (in-place)
I0311 23:08:53.716985 17663 net.cpp:150] Setting up res3d_relu
I0311 23:08:53.716989 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.716990 17663 net.cpp:165] Memory required for data: 2066400084
I0311 23:08:53.716994 17663 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0311 23:08:53.716997 17663 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0311 23:08:53.717000 17663 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0311 23:08:53.717005 17663 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0311 23:08:53.717008 17663 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0311 23:08:53.717032 17663 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0311 23:08:53.717036 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.717038 17663 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0311 23:08:53.717041 17663 net.cpp:165] Memory required for data: 2104800084
I0311 23:08:53.717043 17663 layer_factory.hpp:77] Creating layer res4a_branch1
I0311 23:08:53.717048 17663 net.cpp:100] Creating Layer res4a_branch1
I0311 23:08:53.717051 17663 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0311 23:08:53.717054 17663 net.cpp:418] res4a_branch1 -> res4a_branch1
I0311 23:08:53.718144 17663 net.cpp:150] Setting up res4a_branch1
I0311 23:08:53.718158 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.718159 17663 net.cpp:165] Memory required for data: 2114605908
I0311 23:08:53.718164 17663 layer_factory.hpp:77] Creating layer bn4a_branch1
I0311 23:08:53.718170 17663 net.cpp:100] Creating Layer bn4a_branch1
I0311 23:08:53.718173 17663 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0311 23:08:53.718178 17663 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0311 23:08:53.718318 17663 net.cpp:150] Setting up bn4a_branch1
I0311 23:08:53.718323 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.718325 17663 net.cpp:165] Memory required for data: 2124411732
I0311 23:08:53.718330 17663 layer_factory.hpp:77] Creating layer scale4a_branch1
I0311 23:08:53.718335 17663 net.cpp:100] Creating Layer scale4a_branch1
I0311 23:08:53.718338 17663 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0311 23:08:53.718343 17663 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0311 23:08:53.718367 17663 layer_factory.hpp:77] Creating layer scale4a_branch1
I0311 23:08:53.718523 17663 net.cpp:150] Setting up scale4a_branch1
I0311 23:08:53.718528 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.718530 17663 net.cpp:165] Memory required for data: 2134217556
I0311 23:08:53.718534 17663 layer_factory.hpp:77] Creating layer res4a_branch2a
I0311 23:08:53.718540 17663 net.cpp:100] Creating Layer res4a_branch2a
I0311 23:08:53.718544 17663 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0311 23:08:53.718549 17663 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0311 23:08:53.719804 17663 net.cpp:150] Setting up res4a_branch2a
I0311 23:08:53.719818 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.719821 17663 net.cpp:165] Memory required for data: 2136669012
I0311 23:08:53.719826 17663 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0311 23:08:53.719848 17663 net.cpp:100] Creating Layer bn4a_branch2a
I0311 23:08:53.719851 17663 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0311 23:08:53.719856 17663 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0311 23:08:53.720021 17663 net.cpp:150] Setting up bn4a_branch2a
I0311 23:08:53.720026 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.720028 17663 net.cpp:165] Memory required for data: 2139120468
I0311 23:08:53.720033 17663 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0311 23:08:53.720038 17663 net.cpp:100] Creating Layer scale4a_branch2a
I0311 23:08:53.720055 17663 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0311 23:08:53.720060 17663 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0311 23:08:53.720099 17663 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0311 23:08:53.720182 17663 net.cpp:150] Setting up scale4a_branch2a
I0311 23:08:53.720188 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.720191 17663 net.cpp:165] Memory required for data: 2141571924
I0311 23:08:53.720196 17663 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0311 23:08:53.720199 17663 net.cpp:100] Creating Layer res4a_branch2a_relu
I0311 23:08:53.720203 17663 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0311 23:08:53.720206 17663 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0311 23:08:53.720211 17663 net.cpp:150] Setting up res4a_branch2a_relu
I0311 23:08:53.720214 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.720216 17663 net.cpp:165] Memory required for data: 2144023380
I0311 23:08:53.720219 17663 layer_factory.hpp:77] Creating layer res4a_branch2b
I0311 23:08:53.720227 17663 net.cpp:100] Creating Layer res4a_branch2b
I0311 23:08:53.720229 17663 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0311 23:08:53.720234 17663 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0311 23:08:53.721731 17663 net.cpp:150] Setting up res4a_branch2b
I0311 23:08:53.721771 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.721773 17663 net.cpp:165] Memory required for data: 2146474836
I0311 23:08:53.721782 17663 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0311 23:08:53.721791 17663 net.cpp:100] Creating Layer bn4a_branch2b
I0311 23:08:53.721799 17663 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0311 23:08:53.721807 17663 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0311 23:08:53.721990 17663 net.cpp:150] Setting up bn4a_branch2b
I0311 23:08:53.721999 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.722002 17663 net.cpp:165] Memory required for data: 2148926292
I0311 23:08:53.722009 17663 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0311 23:08:53.722018 17663 net.cpp:100] Creating Layer scale4a_branch2b
I0311 23:08:53.722021 17663 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0311 23:08:53.722025 17663 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0311 23:08:53.722060 17663 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0311 23:08:53.722154 17663 net.cpp:150] Setting up scale4a_branch2b
I0311 23:08:53.722160 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.722162 17663 net.cpp:165] Memory required for data: 2151377748
I0311 23:08:53.722167 17663 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0311 23:08:53.722173 17663 net.cpp:100] Creating Layer res4a_branch2b_relu
I0311 23:08:53.722177 17663 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0311 23:08:53.722183 17663 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0311 23:08:53.722189 17663 net.cpp:150] Setting up res4a_branch2b_relu
I0311 23:08:53.722193 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.722195 17663 net.cpp:165] Memory required for data: 2153829204
I0311 23:08:53.722198 17663 layer_factory.hpp:77] Creating layer res4a_branch2c
I0311 23:08:53.722208 17663 net.cpp:100] Creating Layer res4a_branch2c
I0311 23:08:53.722210 17663 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0311 23:08:53.722214 17663 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0311 23:08:53.722555 17663 net.cpp:150] Setting up res4a_branch2c
I0311 23:08:53.722563 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.722565 17663 net.cpp:165] Memory required for data: 2163635028
I0311 23:08:53.722569 17663 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0311 23:08:53.722575 17663 net.cpp:100] Creating Layer bn4a_branch2c
I0311 23:08:53.722579 17663 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0311 23:08:53.722584 17663 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0311 23:08:53.722738 17663 net.cpp:150] Setting up bn4a_branch2c
I0311 23:08:53.722744 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.722746 17663 net.cpp:165] Memory required for data: 2173440852
I0311 23:08:53.722751 17663 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0311 23:08:53.722759 17663 net.cpp:100] Creating Layer scale4a_branch2c
I0311 23:08:53.722761 17663 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0311 23:08:53.722765 17663 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0311 23:08:53.722792 17663 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0311 23:08:53.722885 17663 net.cpp:150] Setting up scale4a_branch2c
I0311 23:08:53.722892 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.722893 17663 net.cpp:165] Memory required for data: 2183246676
I0311 23:08:53.722898 17663 layer_factory.hpp:77] Creating layer res4a
I0311 23:08:53.722915 17663 net.cpp:100] Creating Layer res4a
I0311 23:08:53.722921 17663 net.cpp:444] res4a <- res4a_branch1
I0311 23:08:53.722924 17663 net.cpp:444] res4a <- res4a_branch2c
I0311 23:08:53.722929 17663 net.cpp:418] res4a -> res4a
I0311 23:08:53.722949 17663 net.cpp:150] Setting up res4a
I0311 23:08:53.722954 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.722957 17663 net.cpp:165] Memory required for data: 2193052500
I0311 23:08:53.722960 17663 layer_factory.hpp:77] Creating layer res4a_relu
I0311 23:08:53.722964 17663 net.cpp:100] Creating Layer res4a_relu
I0311 23:08:53.722967 17663 net.cpp:444] res4a_relu <- res4a
I0311 23:08:53.722971 17663 net.cpp:405] res4a_relu -> res4a (in-place)
I0311 23:08:53.722975 17663 net.cpp:150] Setting up res4a_relu
I0311 23:08:53.722980 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.722982 17663 net.cpp:165] Memory required for data: 2202858324
I0311 23:08:53.722985 17663 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0311 23:08:53.722990 17663 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0311 23:08:53.722992 17663 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0311 23:08:53.722996 17663 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0311 23:08:53.723001 17663 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0311 23:08:53.723029 17663 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0311 23:08:53.723037 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.723039 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.723042 17663 net.cpp:165] Memory required for data: 2222469972
I0311 23:08:53.723044 17663 layer_factory.hpp:77] Creating layer res4b_branch2a
I0311 23:08:53.723049 17663 net.cpp:100] Creating Layer res4b_branch2a
I0311 23:08:53.723053 17663 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0311 23:08:53.723058 17663 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0311 23:08:53.724725 17663 net.cpp:150] Setting up res4b_branch2a
I0311 23:08:53.724776 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.724778 17663 net.cpp:165] Memory required for data: 2224921428
I0311 23:08:53.724792 17663 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0311 23:08:53.724825 17663 net.cpp:100] Creating Layer bn4b_branch2a
I0311 23:08:53.724845 17663 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0311 23:08:53.724858 17663 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0311 23:08:53.725075 17663 net.cpp:150] Setting up bn4b_branch2a
I0311 23:08:53.725081 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.725083 17663 net.cpp:165] Memory required for data: 2227372884
I0311 23:08:53.725091 17663 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0311 23:08:53.725100 17663 net.cpp:100] Creating Layer scale4b_branch2a
I0311 23:08:53.725102 17663 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0311 23:08:53.725106 17663 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0311 23:08:53.725170 17663 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0311 23:08:53.725275 17663 net.cpp:150] Setting up scale4b_branch2a
I0311 23:08:53.725281 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.725282 17663 net.cpp:165] Memory required for data: 2229824340
I0311 23:08:53.725301 17663 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0311 23:08:53.725306 17663 net.cpp:100] Creating Layer res4b_branch2a_relu
I0311 23:08:53.725311 17663 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0311 23:08:53.725314 17663 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0311 23:08:53.725320 17663 net.cpp:150] Setting up res4b_branch2a_relu
I0311 23:08:53.725323 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.725325 17663 net.cpp:165] Memory required for data: 2232275796
I0311 23:08:53.725327 17663 layer_factory.hpp:77] Creating layer res4b_branch2b
I0311 23:08:53.725337 17663 net.cpp:100] Creating Layer res4b_branch2b
I0311 23:08:53.725339 17663 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0311 23:08:53.725343 17663 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0311 23:08:53.726855 17663 net.cpp:150] Setting up res4b_branch2b
I0311 23:08:53.726868 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.726871 17663 net.cpp:165] Memory required for data: 2234727252
I0311 23:08:53.726876 17663 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0311 23:08:53.726884 17663 net.cpp:100] Creating Layer bn4b_branch2b
I0311 23:08:53.726902 17663 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0311 23:08:53.726907 17663 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0311 23:08:53.727089 17663 net.cpp:150] Setting up bn4b_branch2b
I0311 23:08:53.727095 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.727097 17663 net.cpp:165] Memory required for data: 2237178708
I0311 23:08:53.727102 17663 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0311 23:08:53.727108 17663 net.cpp:100] Creating Layer scale4b_branch2b
I0311 23:08:53.727123 17663 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0311 23:08:53.727128 17663 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0311 23:08:53.727167 17663 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0311 23:08:53.727277 17663 net.cpp:150] Setting up scale4b_branch2b
I0311 23:08:53.727283 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.727285 17663 net.cpp:165] Memory required for data: 2239630164
I0311 23:08:53.727289 17663 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0311 23:08:53.727293 17663 net.cpp:100] Creating Layer res4b_branch2b_relu
I0311 23:08:53.727296 17663 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0311 23:08:53.727299 17663 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0311 23:08:53.727304 17663 net.cpp:150] Setting up res4b_branch2b_relu
I0311 23:08:53.727308 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.727309 17663 net.cpp:165] Memory required for data: 2242081620
I0311 23:08:53.727324 17663 layer_factory.hpp:77] Creating layer res4b_branch2c
I0311 23:08:53.727331 17663 net.cpp:100] Creating Layer res4b_branch2c
I0311 23:08:53.727334 17663 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0311 23:08:53.727339 17663 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0311 23:08:53.727608 17663 net.cpp:150] Setting up res4b_branch2c
I0311 23:08:53.727615 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.727617 17663 net.cpp:165] Memory required for data: 2251887444
I0311 23:08:53.727622 17663 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0311 23:08:53.727627 17663 net.cpp:100] Creating Layer bn4b_branch2c
I0311 23:08:53.727629 17663 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0311 23:08:53.727632 17663 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0311 23:08:53.727782 17663 net.cpp:150] Setting up bn4b_branch2c
I0311 23:08:53.727787 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.727789 17663 net.cpp:165] Memory required for data: 2261693268
I0311 23:08:53.727793 17663 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0311 23:08:53.727798 17663 net.cpp:100] Creating Layer scale4b_branch2c
I0311 23:08:53.727815 17663 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0311 23:08:53.727818 17663 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0311 23:08:53.727843 17663 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0311 23:08:53.727954 17663 net.cpp:150] Setting up scale4b_branch2c
I0311 23:08:53.727959 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.727962 17663 net.cpp:165] Memory required for data: 2271499092
I0311 23:08:53.727979 17663 layer_factory.hpp:77] Creating layer res4b
I0311 23:08:53.727984 17663 net.cpp:100] Creating Layer res4b
I0311 23:08:53.727988 17663 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0311 23:08:53.727991 17663 net.cpp:444] res4b <- res4b_branch2c
I0311 23:08:53.727995 17663 net.cpp:418] res4b -> res4b
I0311 23:08:53.728013 17663 net.cpp:150] Setting up res4b
I0311 23:08:53.728016 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.728018 17663 net.cpp:165] Memory required for data: 2281304916
I0311 23:08:53.728021 17663 layer_factory.hpp:77] Creating layer res4b_relu
I0311 23:08:53.728024 17663 net.cpp:100] Creating Layer res4b_relu
I0311 23:08:53.728027 17663 net.cpp:444] res4b_relu <- res4b
I0311 23:08:53.728032 17663 net.cpp:405] res4b_relu -> res4b (in-place)
I0311 23:08:53.728035 17663 net.cpp:150] Setting up res4b_relu
I0311 23:08:53.728039 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.728041 17663 net.cpp:165] Memory required for data: 2291110740
I0311 23:08:53.728044 17663 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0311 23:08:53.728047 17663 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0311 23:08:53.728050 17663 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0311 23:08:53.728055 17663 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0311 23:08:53.728058 17663 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0311 23:08:53.728083 17663 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0311 23:08:53.728087 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.728091 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.728093 17663 net.cpp:165] Memory required for data: 2310722388
I0311 23:08:53.728096 17663 layer_factory.hpp:77] Creating layer res4c_branch2a
I0311 23:08:53.728101 17663 net.cpp:100] Creating Layer res4c_branch2a
I0311 23:08:53.728104 17663 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0311 23:08:53.728108 17663 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0311 23:08:53.729137 17663 net.cpp:150] Setting up res4c_branch2a
I0311 23:08:53.729149 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.729152 17663 net.cpp:165] Memory required for data: 2313173844
I0311 23:08:53.729157 17663 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0311 23:08:53.729164 17663 net.cpp:100] Creating Layer bn4c_branch2a
I0311 23:08:53.729167 17663 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0311 23:08:53.729172 17663 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0311 23:08:53.729334 17663 net.cpp:150] Setting up bn4c_branch2a
I0311 23:08:53.729341 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.729342 17663 net.cpp:165] Memory required for data: 2315625300
I0311 23:08:53.729347 17663 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0311 23:08:53.729351 17663 net.cpp:100] Creating Layer scale4c_branch2a
I0311 23:08:53.729354 17663 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0311 23:08:53.729372 17663 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0311 23:08:53.729410 17663 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0311 23:08:53.729506 17663 net.cpp:150] Setting up scale4c_branch2a
I0311 23:08:53.729511 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.729513 17663 net.cpp:165] Memory required for data: 2318076756
I0311 23:08:53.729517 17663 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0311 23:08:53.729521 17663 net.cpp:100] Creating Layer res4c_branch2a_relu
I0311 23:08:53.729524 17663 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0311 23:08:53.729540 17663 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0311 23:08:53.729544 17663 net.cpp:150] Setting up res4c_branch2a_relu
I0311 23:08:53.729547 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.729563 17663 net.cpp:165] Memory required for data: 2320528212
I0311 23:08:53.729565 17663 layer_factory.hpp:77] Creating layer res4c_branch2b
I0311 23:08:53.729571 17663 net.cpp:100] Creating Layer res4c_branch2b
I0311 23:08:53.729574 17663 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0311 23:08:53.729579 17663 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0311 23:08:53.730788 17663 net.cpp:150] Setting up res4c_branch2b
I0311 23:08:53.730803 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.730806 17663 net.cpp:165] Memory required for data: 2322979668
I0311 23:08:53.730811 17663 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0311 23:08:53.730832 17663 net.cpp:100] Creating Layer bn4c_branch2b
I0311 23:08:53.730836 17663 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0311 23:08:53.730840 17663 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0311 23:08:53.731009 17663 net.cpp:150] Setting up bn4c_branch2b
I0311 23:08:53.731014 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.731016 17663 net.cpp:165] Memory required for data: 2325431124
I0311 23:08:53.731021 17663 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0311 23:08:53.731041 17663 net.cpp:100] Creating Layer scale4c_branch2b
I0311 23:08:53.731045 17663 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0311 23:08:53.731048 17663 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0311 23:08:53.731088 17663 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0311 23:08:53.731185 17663 net.cpp:150] Setting up scale4c_branch2b
I0311 23:08:53.731190 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.731192 17663 net.cpp:165] Memory required for data: 2327882580
I0311 23:08:53.731196 17663 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0311 23:08:53.731200 17663 net.cpp:100] Creating Layer res4c_branch2b_relu
I0311 23:08:53.731217 17663 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0311 23:08:53.731221 17663 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0311 23:08:53.731226 17663 net.cpp:150] Setting up res4c_branch2b_relu
I0311 23:08:53.731228 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.731231 17663 net.cpp:165] Memory required for data: 2330334036
I0311 23:08:53.731233 17663 layer_factory.hpp:77] Creating layer res4c_branch2c
I0311 23:08:53.731252 17663 net.cpp:100] Creating Layer res4c_branch2c
I0311 23:08:53.731256 17663 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0311 23:08:53.731261 17663 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0311 23:08:53.731598 17663 net.cpp:150] Setting up res4c_branch2c
I0311 23:08:53.731604 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.731606 17663 net.cpp:165] Memory required for data: 2340139860
I0311 23:08:53.731611 17663 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0311 23:08:53.731614 17663 net.cpp:100] Creating Layer bn4c_branch2c
I0311 23:08:53.731617 17663 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0311 23:08:53.731637 17663 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0311 23:08:53.731806 17663 net.cpp:150] Setting up bn4c_branch2c
I0311 23:08:53.731812 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.731814 17663 net.cpp:165] Memory required for data: 2349945684
I0311 23:08:53.731818 17663 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0311 23:08:53.731823 17663 net.cpp:100] Creating Layer scale4c_branch2c
I0311 23:08:53.731825 17663 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0311 23:08:53.731842 17663 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0311 23:08:53.731879 17663 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0311 23:08:53.731988 17663 net.cpp:150] Setting up scale4c_branch2c
I0311 23:08:53.731993 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.731997 17663 net.cpp:165] Memory required for data: 2359751508
I0311 23:08:53.731999 17663 layer_factory.hpp:77] Creating layer res4c
I0311 23:08:53.732004 17663 net.cpp:100] Creating Layer res4c
I0311 23:08:53.732019 17663 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0311 23:08:53.732023 17663 net.cpp:444] res4c <- res4c_branch2c
I0311 23:08:53.732028 17663 net.cpp:418] res4c -> res4c
I0311 23:08:53.732058 17663 net.cpp:150] Setting up res4c
I0311 23:08:53.732061 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.732064 17663 net.cpp:165] Memory required for data: 2369557332
I0311 23:08:53.732066 17663 layer_factory.hpp:77] Creating layer res4c_relu
I0311 23:08:53.732070 17663 net.cpp:100] Creating Layer res4c_relu
I0311 23:08:53.732074 17663 net.cpp:444] res4c_relu <- res4c
I0311 23:08:53.732077 17663 net.cpp:405] res4c_relu -> res4c (in-place)
I0311 23:08:53.732081 17663 net.cpp:150] Setting up res4c_relu
I0311 23:08:53.732084 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.732086 17663 net.cpp:165] Memory required for data: 2379363156
I0311 23:08:53.732089 17663 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0311 23:08:53.732092 17663 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0311 23:08:53.732095 17663 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0311 23:08:53.732098 17663 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0311 23:08:53.732103 17663 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0311 23:08:53.732127 17663 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0311 23:08:53.732131 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.732134 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.732136 17663 net.cpp:165] Memory required for data: 2398974804
I0311 23:08:53.732139 17663 layer_factory.hpp:77] Creating layer res4d_branch2a
I0311 23:08:53.732144 17663 net.cpp:100] Creating Layer res4d_branch2a
I0311 23:08:53.732148 17663 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0311 23:08:53.732151 17663 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0311 23:08:53.733172 17663 net.cpp:150] Setting up res4d_branch2a
I0311 23:08:53.733184 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.733187 17663 net.cpp:165] Memory required for data: 2401426260
I0311 23:08:53.733191 17663 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0311 23:08:53.733198 17663 net.cpp:100] Creating Layer bn4d_branch2a
I0311 23:08:53.733214 17663 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0311 23:08:53.733219 17663 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0311 23:08:53.733371 17663 net.cpp:150] Setting up bn4d_branch2a
I0311 23:08:53.733376 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.733377 17663 net.cpp:165] Memory required for data: 2403877716
I0311 23:08:53.733382 17663 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0311 23:08:53.733402 17663 net.cpp:100] Creating Layer scale4d_branch2a
I0311 23:08:53.733404 17663 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0311 23:08:53.733407 17663 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0311 23:08:53.733448 17663 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0311 23:08:53.733556 17663 net.cpp:150] Setting up scale4d_branch2a
I0311 23:08:53.733561 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.733562 17663 net.cpp:165] Memory required for data: 2406329172
I0311 23:08:53.733566 17663 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0311 23:08:53.733572 17663 net.cpp:100] Creating Layer res4d_branch2a_relu
I0311 23:08:53.733587 17663 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0311 23:08:53.733592 17663 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0311 23:08:53.733595 17663 net.cpp:150] Setting up res4d_branch2a_relu
I0311 23:08:53.733598 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.733602 17663 net.cpp:165] Memory required for data: 2408780628
I0311 23:08:53.733603 17663 layer_factory.hpp:77] Creating layer res4d_branch2b
I0311 23:08:53.733609 17663 net.cpp:100] Creating Layer res4d_branch2b
I0311 23:08:53.733611 17663 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0311 23:08:53.733615 17663 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0311 23:08:53.734802 17663 net.cpp:150] Setting up res4d_branch2b
I0311 23:08:53.734814 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.734817 17663 net.cpp:165] Memory required for data: 2411232084
I0311 23:08:53.734822 17663 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0311 23:08:53.734843 17663 net.cpp:100] Creating Layer bn4d_branch2b
I0311 23:08:53.734845 17663 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0311 23:08:53.734863 17663 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0311 23:08:53.735021 17663 net.cpp:150] Setting up bn4d_branch2b
I0311 23:08:53.735028 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.735029 17663 net.cpp:165] Memory required for data: 2413683540
I0311 23:08:53.735034 17663 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0311 23:08:53.735054 17663 net.cpp:100] Creating Layer scale4d_branch2b
I0311 23:08:53.735057 17663 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0311 23:08:53.735061 17663 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0311 23:08:53.735102 17663 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0311 23:08:53.735225 17663 net.cpp:150] Setting up scale4d_branch2b
I0311 23:08:53.735230 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.735234 17663 net.cpp:165] Memory required for data: 2416134996
I0311 23:08:53.735237 17663 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0311 23:08:53.735242 17663 net.cpp:100] Creating Layer res4d_branch2b_relu
I0311 23:08:53.735258 17663 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0311 23:08:53.735262 17663 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0311 23:08:53.735280 17663 net.cpp:150] Setting up res4d_branch2b_relu
I0311 23:08:53.735282 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.735285 17663 net.cpp:165] Memory required for data: 2418586452
I0311 23:08:53.735287 17663 layer_factory.hpp:77] Creating layer res4d_branch2c
I0311 23:08:53.735293 17663 net.cpp:100] Creating Layer res4d_branch2c
I0311 23:08:53.735296 17663 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0311 23:08:53.735301 17663 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0311 23:08:53.735589 17663 net.cpp:150] Setting up res4d_branch2c
I0311 23:08:53.735595 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.735597 17663 net.cpp:165] Memory required for data: 2428392276
I0311 23:08:53.735600 17663 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0311 23:08:53.735605 17663 net.cpp:100] Creating Layer bn4d_branch2c
I0311 23:08:53.735622 17663 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0311 23:08:53.735626 17663 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0311 23:08:53.735774 17663 net.cpp:150] Setting up bn4d_branch2c
I0311 23:08:53.735780 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.735782 17663 net.cpp:165] Memory required for data: 2438198100
I0311 23:08:53.735786 17663 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0311 23:08:53.735791 17663 net.cpp:100] Creating Layer scale4d_branch2c
I0311 23:08:53.735808 17663 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0311 23:08:53.735812 17663 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0311 23:08:53.735849 17663 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0311 23:08:53.735944 17663 net.cpp:150] Setting up scale4d_branch2c
I0311 23:08:53.735950 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.735954 17663 net.cpp:165] Memory required for data: 2448003924
I0311 23:08:53.735957 17663 layer_factory.hpp:77] Creating layer res4d
I0311 23:08:53.735961 17663 net.cpp:100] Creating Layer res4d
I0311 23:08:53.735977 17663 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0311 23:08:53.735980 17663 net.cpp:444] res4d <- res4d_branch2c
I0311 23:08:53.735997 17663 net.cpp:418] res4d -> res4d
I0311 23:08:53.736014 17663 net.cpp:150] Setting up res4d
I0311 23:08:53.736018 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.736021 17663 net.cpp:165] Memory required for data: 2457809748
I0311 23:08:53.736023 17663 layer_factory.hpp:77] Creating layer res4d_relu
I0311 23:08:53.736027 17663 net.cpp:100] Creating Layer res4d_relu
I0311 23:08:53.736029 17663 net.cpp:444] res4d_relu <- res4d
I0311 23:08:53.736034 17663 net.cpp:405] res4d_relu -> res4d (in-place)
I0311 23:08:53.736038 17663 net.cpp:150] Setting up res4d_relu
I0311 23:08:53.736042 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.736043 17663 net.cpp:165] Memory required for data: 2467615572
I0311 23:08:53.736045 17663 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0311 23:08:53.736049 17663 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0311 23:08:53.736052 17663 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0311 23:08:53.736057 17663 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0311 23:08:53.736063 17663 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0311 23:08:53.736085 17663 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0311 23:08:53.736089 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.736093 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.736094 17663 net.cpp:165] Memory required for data: 2487227220
I0311 23:08:53.736097 17663 layer_factory.hpp:77] Creating layer res4e_branch2a
I0311 23:08:53.736105 17663 net.cpp:100] Creating Layer res4e_branch2a
I0311 23:08:53.736109 17663 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0311 23:08:53.736112 17663 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0311 23:08:53.737093 17663 net.cpp:150] Setting up res4e_branch2a
I0311 23:08:53.737104 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.737107 17663 net.cpp:165] Memory required for data: 2489678676
I0311 23:08:53.737112 17663 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0311 23:08:53.737130 17663 net.cpp:100] Creating Layer bn4e_branch2a
I0311 23:08:53.737133 17663 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0311 23:08:53.737138 17663 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0311 23:08:53.737304 17663 net.cpp:150] Setting up bn4e_branch2a
I0311 23:08:53.737310 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.737313 17663 net.cpp:165] Memory required for data: 2492130132
I0311 23:08:53.737318 17663 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0311 23:08:53.737337 17663 net.cpp:100] Creating Layer scale4e_branch2a
I0311 23:08:53.737340 17663 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0311 23:08:53.737344 17663 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0311 23:08:53.737385 17663 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0311 23:08:53.737478 17663 net.cpp:150] Setting up scale4e_branch2a
I0311 23:08:53.737483 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.737485 17663 net.cpp:165] Memory required for data: 2494581588
I0311 23:08:53.737489 17663 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0311 23:08:53.737494 17663 net.cpp:100] Creating Layer res4e_branch2a_relu
I0311 23:08:53.737509 17663 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0311 23:08:53.737514 17663 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0311 23:08:53.737519 17663 net.cpp:150] Setting up res4e_branch2a_relu
I0311 23:08:53.737521 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.737537 17663 net.cpp:165] Memory required for data: 2497033044
I0311 23:08:53.737540 17663 layer_factory.hpp:77] Creating layer res4e_branch2b
I0311 23:08:53.737545 17663 net.cpp:100] Creating Layer res4e_branch2b
I0311 23:08:53.737546 17663 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0311 23:08:53.737551 17663 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0311 23:08:53.738899 17663 net.cpp:150] Setting up res4e_branch2b
I0311 23:08:53.738929 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.738932 17663 net.cpp:165] Memory required for data: 2499484500
I0311 23:08:53.738956 17663 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0311 23:08:53.738967 17663 net.cpp:100] Creating Layer bn4e_branch2b
I0311 23:08:53.738975 17663 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0311 23:08:53.738996 17663 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0311 23:08:53.739192 17663 net.cpp:150] Setting up bn4e_branch2b
I0311 23:08:53.739198 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.739202 17663 net.cpp:165] Memory required for data: 2501935956
I0311 23:08:53.739207 17663 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0311 23:08:53.739228 17663 net.cpp:100] Creating Layer scale4e_branch2b
I0311 23:08:53.739230 17663 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0311 23:08:53.739234 17663 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0311 23:08:53.739279 17663 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0311 23:08:53.739399 17663 net.cpp:150] Setting up scale4e_branch2b
I0311 23:08:53.739404 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.739408 17663 net.cpp:165] Memory required for data: 2504387412
I0311 23:08:53.739411 17663 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0311 23:08:53.739418 17663 net.cpp:100] Creating Layer res4e_branch2b_relu
I0311 23:08:53.739434 17663 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0311 23:08:53.739439 17663 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0311 23:08:53.739457 17663 net.cpp:150] Setting up res4e_branch2b_relu
I0311 23:08:53.739461 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.739476 17663 net.cpp:165] Memory required for data: 2506838868
I0311 23:08:53.739480 17663 layer_factory.hpp:77] Creating layer res4e_branch2c
I0311 23:08:53.739490 17663 net.cpp:100] Creating Layer res4e_branch2c
I0311 23:08:53.739491 17663 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0311 23:08:53.739495 17663 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0311 23:08:53.739898 17663 net.cpp:150] Setting up res4e_branch2c
I0311 23:08:53.739905 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.739908 17663 net.cpp:165] Memory required for data: 2516644692
I0311 23:08:53.739912 17663 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0311 23:08:53.739918 17663 net.cpp:100] Creating Layer bn4e_branch2c
I0311 23:08:53.739920 17663 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0311 23:08:53.739924 17663 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0311 23:08:53.740097 17663 net.cpp:150] Setting up bn4e_branch2c
I0311 23:08:53.740101 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740104 17663 net.cpp:165] Memory required for data: 2526450516
I0311 23:08:53.740108 17663 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0311 23:08:53.740113 17663 net.cpp:100] Creating Layer scale4e_branch2c
I0311 23:08:53.740116 17663 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0311 23:08:53.740121 17663 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0311 23:08:53.740145 17663 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0311 23:08:53.740236 17663 net.cpp:150] Setting up scale4e_branch2c
I0311 23:08:53.740242 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740243 17663 net.cpp:165] Memory required for data: 2536256340
I0311 23:08:53.740248 17663 layer_factory.hpp:77] Creating layer res4e
I0311 23:08:53.740252 17663 net.cpp:100] Creating Layer res4e
I0311 23:08:53.740257 17663 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0311 23:08:53.740260 17663 net.cpp:444] res4e <- res4e_branch2c
I0311 23:08:53.740265 17663 net.cpp:418] res4e -> res4e
I0311 23:08:53.740283 17663 net.cpp:150] Setting up res4e
I0311 23:08:53.740288 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740291 17663 net.cpp:165] Memory required for data: 2546062164
I0311 23:08:53.740293 17663 layer_factory.hpp:77] Creating layer res4e_relu
I0311 23:08:53.740298 17663 net.cpp:100] Creating Layer res4e_relu
I0311 23:08:53.740301 17663 net.cpp:444] res4e_relu <- res4e
I0311 23:08:53.740305 17663 net.cpp:405] res4e_relu -> res4e (in-place)
I0311 23:08:53.740309 17663 net.cpp:150] Setting up res4e_relu
I0311 23:08:53.740314 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740315 17663 net.cpp:165] Memory required for data: 2555867988
I0311 23:08:53.740319 17663 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0311 23:08:53.740322 17663 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0311 23:08:53.740325 17663 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0311 23:08:53.740329 17663 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0311 23:08:53.740334 17663 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0311 23:08:53.740360 17663 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0311 23:08:53.740365 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740367 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.740370 17663 net.cpp:165] Memory required for data: 2575479636
I0311 23:08:53.740372 17663 layer_factory.hpp:77] Creating layer res4f_branch2a
I0311 23:08:53.740377 17663 net.cpp:100] Creating Layer res4f_branch2a
I0311 23:08:53.740381 17663 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0311 23:08:53.740386 17663 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0311 23:08:53.741482 17663 net.cpp:150] Setting up res4f_branch2a
I0311 23:08:53.741506 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.741509 17663 net.cpp:165] Memory required for data: 2577931092
I0311 23:08:53.741518 17663 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0311 23:08:53.741524 17663 net.cpp:100] Creating Layer bn4f_branch2a
I0311 23:08:53.741529 17663 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0311 23:08:53.741536 17663 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0311 23:08:53.741698 17663 net.cpp:150] Setting up bn4f_branch2a
I0311 23:08:53.741704 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.741706 17663 net.cpp:165] Memory required for data: 2580382548
I0311 23:08:53.741713 17663 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0311 23:08:53.741719 17663 net.cpp:100] Creating Layer scale4f_branch2a
I0311 23:08:53.741722 17663 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0311 23:08:53.741725 17663 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0311 23:08:53.741755 17663 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0311 23:08:53.741842 17663 net.cpp:150] Setting up scale4f_branch2a
I0311 23:08:53.741847 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.741849 17663 net.cpp:165] Memory required for data: 2582834004
I0311 23:08:53.741853 17663 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0311 23:08:53.741858 17663 net.cpp:100] Creating Layer res4f_branch2a_relu
I0311 23:08:53.741861 17663 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0311 23:08:53.741866 17663 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0311 23:08:53.741870 17663 net.cpp:150] Setting up res4f_branch2a_relu
I0311 23:08:53.741874 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.741876 17663 net.cpp:165] Memory required for data: 2585285460
I0311 23:08:53.741878 17663 layer_factory.hpp:77] Creating layer res4f_branch2b
I0311 23:08:53.741885 17663 net.cpp:100] Creating Layer res4f_branch2b
I0311 23:08:53.741889 17663 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0311 23:08:53.741905 17663 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0311 23:08:53.743185 17663 net.cpp:150] Setting up res4f_branch2b
I0311 23:08:53.743209 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.743212 17663 net.cpp:165] Memory required for data: 2587736916
I0311 23:08:53.743233 17663 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0311 23:08:53.743259 17663 net.cpp:100] Creating Layer bn4f_branch2b
I0311 23:08:53.743264 17663 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0311 23:08:53.743271 17663 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0311 23:08:53.743449 17663 net.cpp:150] Setting up bn4f_branch2b
I0311 23:08:53.743454 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.743458 17663 net.cpp:165] Memory required for data: 2590188372
I0311 23:08:53.743463 17663 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0311 23:08:53.743482 17663 net.cpp:100] Creating Layer scale4f_branch2b
I0311 23:08:53.743484 17663 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0311 23:08:53.743489 17663 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0311 23:08:53.743533 17663 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0311 23:08:53.743638 17663 net.cpp:150] Setting up scale4f_branch2b
I0311 23:08:53.743644 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.743646 17663 net.cpp:165] Memory required for data: 2592639828
I0311 23:08:53.743650 17663 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0311 23:08:53.743655 17663 net.cpp:100] Creating Layer res4f_branch2b_relu
I0311 23:08:53.743672 17663 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0311 23:08:53.743676 17663 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0311 23:08:53.743680 17663 net.cpp:150] Setting up res4f_branch2b_relu
I0311 23:08:53.743683 17663 net.cpp:157] Top shape: 1 256 38 63 (612864)
I0311 23:08:53.743686 17663 net.cpp:165] Memory required for data: 2595091284
I0311 23:08:53.743688 17663 layer_factory.hpp:77] Creating layer res4f_branch2c
I0311 23:08:53.743695 17663 net.cpp:100] Creating Layer res4f_branch2c
I0311 23:08:53.743713 17663 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0311 23:08:53.743718 17663 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0311 23:08:53.744033 17663 net.cpp:150] Setting up res4f_branch2c
I0311 23:08:53.744040 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744042 17663 net.cpp:165] Memory required for data: 2604897108
I0311 23:08:53.744046 17663 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0311 23:08:53.744066 17663 net.cpp:100] Creating Layer bn4f_branch2c
I0311 23:08:53.744069 17663 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0311 23:08:53.744073 17663 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0311 23:08:53.744242 17663 net.cpp:150] Setting up bn4f_branch2c
I0311 23:08:53.744248 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744251 17663 net.cpp:165] Memory required for data: 2614702932
I0311 23:08:53.744282 17663 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0311 23:08:53.744287 17663 net.cpp:100] Creating Layer scale4f_branch2c
I0311 23:08:53.744289 17663 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0311 23:08:53.744293 17663 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0311 23:08:53.744335 17663 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0311 23:08:53.744436 17663 net.cpp:150] Setting up scale4f_branch2c
I0311 23:08:53.744441 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744443 17663 net.cpp:165] Memory required for data: 2624508756
I0311 23:08:53.744447 17663 layer_factory.hpp:77] Creating layer res4f
I0311 23:08:53.744452 17663 net.cpp:100] Creating Layer res4f
I0311 23:08:53.744468 17663 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0311 23:08:53.744472 17663 net.cpp:444] res4f <- res4f_branch2c
I0311 23:08:53.744475 17663 net.cpp:418] res4f -> res4f
I0311 23:08:53.744493 17663 net.cpp:150] Setting up res4f
I0311 23:08:53.744498 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744501 17663 net.cpp:165] Memory required for data: 2634314580
I0311 23:08:53.744503 17663 layer_factory.hpp:77] Creating layer res4f_relu
I0311 23:08:53.744508 17663 net.cpp:100] Creating Layer res4f_relu
I0311 23:08:53.744524 17663 net.cpp:444] res4f_relu <- res4f
I0311 23:08:53.744529 17663 net.cpp:405] res4f_relu -> res4f (in-place)
I0311 23:08:53.744535 17663 net.cpp:150] Setting up res4f_relu
I0311 23:08:53.744539 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744540 17663 net.cpp:165] Memory required for data: 2644120404
I0311 23:08:53.744544 17663 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0311 23:08:53.744547 17663 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0311 23:08:53.744549 17663 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0311 23:08:53.744555 17663 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0311 23:08:53.744560 17663 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0311 23:08:53.744566 17663 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0311 23:08:53.744602 17663 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0311 23:08:53.744606 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744609 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744612 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.744616 17663 net.cpp:165] Memory required for data: 2673537876
I0311 23:08:53.744617 17663 layer_factory.hpp:77] Creating layer res5a_branch1
I0311 23:08:53.744623 17663 net.cpp:100] Creating Layer res5a_branch1
I0311 23:08:53.744626 17663 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0311 23:08:53.744630 17663 net.cpp:418] res5a_branch1 -> res5a_branch1
I0311 23:08:53.749286 17663 net.cpp:150] Setting up res5a_branch1
I0311 23:08:53.749310 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.749313 17663 net.cpp:165] Memory required for data: 2693149524
I0311 23:08:53.749334 17663 layer_factory.hpp:77] Creating layer bn5a_branch1
I0311 23:08:53.749346 17663 net.cpp:100] Creating Layer bn5a_branch1
I0311 23:08:53.749351 17663 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0311 23:08:53.749357 17663 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0311 23:08:53.749549 17663 net.cpp:150] Setting up bn5a_branch1
I0311 23:08:53.749555 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.749557 17663 net.cpp:165] Memory required for data: 2712761172
I0311 23:08:53.749564 17663 layer_factory.hpp:77] Creating layer scale5a_branch1
I0311 23:08:53.749572 17663 net.cpp:100] Creating Layer scale5a_branch1
I0311 23:08:53.749577 17663 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0311 23:08:53.749581 17663 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0311 23:08:53.749632 17663 layer_factory.hpp:77] Creating layer scale5a_branch1
I0311 23:08:53.749732 17663 net.cpp:150] Setting up scale5a_branch1
I0311 23:08:53.749738 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.749742 17663 net.cpp:165] Memory required for data: 2732372820
I0311 23:08:53.749745 17663 layer_factory.hpp:77] Creating layer res5a_branch2a
I0311 23:08:53.749755 17663 net.cpp:100] Creating Layer res5a_branch2a
I0311 23:08:53.749758 17663 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0311 23:08:53.749763 17663 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0311 23:08:53.751158 17663 net.cpp:150] Setting up res5a_branch2a
I0311 23:08:53.751193 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.751195 17663 net.cpp:165] Memory required for data: 2737275732
I0311 23:08:53.751236 17663 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0311 23:08:53.751251 17663 net.cpp:100] Creating Layer bn5a_branch2a
I0311 23:08:53.751256 17663 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0311 23:08:53.751266 17663 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0311 23:08:53.751471 17663 net.cpp:150] Setting up bn5a_branch2a
I0311 23:08:53.751477 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.751480 17663 net.cpp:165] Memory required for data: 2742178644
I0311 23:08:53.751485 17663 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0311 23:08:53.751494 17663 net.cpp:100] Creating Layer scale5a_branch2a
I0311 23:08:53.751498 17663 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0311 23:08:53.751502 17663 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0311 23:08:53.751549 17663 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0311 23:08:53.751652 17663 net.cpp:150] Setting up scale5a_branch2a
I0311 23:08:53.751657 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.751659 17663 net.cpp:165] Memory required for data: 2747081556
I0311 23:08:53.751664 17663 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0311 23:08:53.751670 17663 net.cpp:100] Creating Layer res5a_branch2a_relu
I0311 23:08:53.751673 17663 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0311 23:08:53.751678 17663 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0311 23:08:53.751684 17663 net.cpp:150] Setting up res5a_branch2a_relu
I0311 23:08:53.751688 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.751690 17663 net.cpp:165] Memory required for data: 2751984468
I0311 23:08:53.751693 17663 layer_factory.hpp:77] Creating layer res5a_branch2b
I0311 23:08:53.751703 17663 net.cpp:100] Creating Layer res5a_branch2b
I0311 23:08:53.751705 17663 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0311 23:08:53.751709 17663 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0311 23:08:53.756763 17663 net.cpp:150] Setting up res5a_branch2b
I0311 23:08:53.756809 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.756813 17663 net.cpp:165] Memory required for data: 2756887380
I0311 23:08:53.756836 17663 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0311 23:08:53.756866 17663 net.cpp:100] Creating Layer bn5a_branch2b
I0311 23:08:53.756875 17663 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0311 23:08:53.756896 17663 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0311 23:08:53.757102 17663 net.cpp:150] Setting up bn5a_branch2b
I0311 23:08:53.757107 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.757110 17663 net.cpp:165] Memory required for data: 2761790292
I0311 23:08:53.757115 17663 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0311 23:08:53.757138 17663 net.cpp:100] Creating Layer scale5a_branch2b
I0311 23:08:53.757140 17663 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0311 23:08:53.757156 17663 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0311 23:08:53.757185 17663 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0311 23:08:53.757287 17663 net.cpp:150] Setting up scale5a_branch2b
I0311 23:08:53.757292 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.757294 17663 net.cpp:165] Memory required for data: 2766693204
I0311 23:08:53.757298 17663 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0311 23:08:53.757302 17663 net.cpp:100] Creating Layer res5a_branch2b_relu
I0311 23:08:53.757305 17663 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0311 23:08:53.757324 17663 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0311 23:08:53.757329 17663 net.cpp:150] Setting up res5a_branch2b_relu
I0311 23:08:53.757333 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.757334 17663 net.cpp:165] Memory required for data: 2771596116
I0311 23:08:53.757338 17663 layer_factory.hpp:77] Creating layer res5a_branch2c
I0311 23:08:53.757357 17663 net.cpp:100] Creating Layer res5a_branch2c
I0311 23:08:53.757359 17663 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0311 23:08:53.757364 17663 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0311 23:08:53.759482 17663 net.cpp:150] Setting up res5a_branch2c
I0311 23:08:53.759505 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.759508 17663 net.cpp:165] Memory required for data: 2791207764
I0311 23:08:53.759529 17663 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0311 23:08:53.759541 17663 net.cpp:100] Creating Layer bn5a_branch2c
I0311 23:08:53.759546 17663 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0311 23:08:53.759552 17663 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0311 23:08:53.759733 17663 net.cpp:150] Setting up bn5a_branch2c
I0311 23:08:53.759739 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.759742 17663 net.cpp:165] Memory required for data: 2810819412
I0311 23:08:53.759747 17663 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0311 23:08:53.759768 17663 net.cpp:100] Creating Layer scale5a_branch2c
I0311 23:08:53.759770 17663 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0311 23:08:53.759773 17663 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0311 23:08:53.759809 17663 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0311 23:08:53.759949 17663 net.cpp:150] Setting up scale5a_branch2c
I0311 23:08:53.759954 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.759956 17663 net.cpp:165] Memory required for data: 2830431060
I0311 23:08:53.759960 17663 layer_factory.hpp:77] Creating layer res5a
I0311 23:08:53.759965 17663 net.cpp:100] Creating Layer res5a
I0311 23:08:53.759984 17663 net.cpp:444] res5a <- res5a_branch1
I0311 23:08:53.759986 17663 net.cpp:444] res5a <- res5a_branch2c
I0311 23:08:53.759991 17663 net.cpp:418] res5a -> res5a
I0311 23:08:53.760009 17663 net.cpp:150] Setting up res5a
I0311 23:08:53.760012 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.760015 17663 net.cpp:165] Memory required for data: 2850042708
I0311 23:08:53.760017 17663 layer_factory.hpp:77] Creating layer res5a_relu
I0311 23:08:53.760023 17663 net.cpp:100] Creating Layer res5a_relu
I0311 23:08:53.760040 17663 net.cpp:444] res5a_relu <- res5a
I0311 23:08:53.760042 17663 net.cpp:405] res5a_relu -> res5a (in-place)
I0311 23:08:53.760046 17663 net.cpp:150] Setting up res5a_relu
I0311 23:08:53.760049 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.760052 17663 net.cpp:165] Memory required for data: 2869654356
I0311 23:08:53.760054 17663 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0311 23:08:53.760058 17663 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0311 23:08:53.760061 17663 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0311 23:08:53.760064 17663 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0311 23:08:53.760069 17663 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0311 23:08:53.760094 17663 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0311 23:08:53.760099 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.760102 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.760104 17663 net.cpp:165] Memory required for data: 2908877652
I0311 23:08:53.760107 17663 layer_factory.hpp:77] Creating layer res5b_branch2a
I0311 23:08:53.760113 17663 net.cpp:100] Creating Layer res5b_branch2a
I0311 23:08:53.760118 17663 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0311 23:08:53.760120 17663 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0311 23:08:53.762497 17663 net.cpp:150] Setting up res5b_branch2a
I0311 23:08:53.762519 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.762522 17663 net.cpp:165] Memory required for data: 2913780564
I0311 23:08:53.762544 17663 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0311 23:08:53.762562 17663 net.cpp:100] Creating Layer bn5b_branch2a
I0311 23:08:53.762567 17663 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0311 23:08:53.762578 17663 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0311 23:08:53.762778 17663 net.cpp:150] Setting up bn5b_branch2a
I0311 23:08:53.762784 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.762785 17663 net.cpp:165] Memory required for data: 2918683476
I0311 23:08:53.762791 17663 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0311 23:08:53.762796 17663 net.cpp:100] Creating Layer scale5b_branch2a
I0311 23:08:53.762799 17663 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0311 23:08:53.762818 17663 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0311 23:08:53.762861 17663 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0311 23:08:53.762995 17663 net.cpp:150] Setting up scale5b_branch2a
I0311 23:08:53.763001 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.763003 17663 net.cpp:165] Memory required for data: 2923586388
I0311 23:08:53.763008 17663 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0311 23:08:53.763012 17663 net.cpp:100] Creating Layer res5b_branch2a_relu
I0311 23:08:53.763029 17663 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0311 23:08:53.763032 17663 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0311 23:08:53.763037 17663 net.cpp:150] Setting up res5b_branch2a_relu
I0311 23:08:53.763041 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.763042 17663 net.cpp:165] Memory required for data: 2928489300
I0311 23:08:53.763046 17663 layer_factory.hpp:77] Creating layer res5b_branch2b
I0311 23:08:53.763052 17663 net.cpp:100] Creating Layer res5b_branch2b
I0311 23:08:53.763067 17663 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0311 23:08:53.763073 17663 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0311 23:08:53.768332 17663 net.cpp:150] Setting up res5b_branch2b
I0311 23:08:53.768395 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.768399 17663 net.cpp:165] Memory required for data: 2933392212
I0311 23:08:53.768431 17663 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0311 23:08:53.768455 17663 net.cpp:100] Creating Layer bn5b_branch2b
I0311 23:08:53.768463 17663 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0311 23:08:53.768476 17663 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0311 23:08:53.768734 17663 net.cpp:150] Setting up bn5b_branch2b
I0311 23:08:53.768741 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.768744 17663 net.cpp:165] Memory required for data: 2938295124
I0311 23:08:53.768750 17663 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0311 23:08:53.768776 17663 net.cpp:100] Creating Layer scale5b_branch2b
I0311 23:08:53.768779 17663 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0311 23:08:53.768785 17663 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0311 23:08:53.768833 17663 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0311 23:08:53.768951 17663 net.cpp:150] Setting up scale5b_branch2b
I0311 23:08:53.768959 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.768961 17663 net.cpp:165] Memory required for data: 2943198036
I0311 23:08:53.768965 17663 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0311 23:08:53.768970 17663 net.cpp:100] Creating Layer res5b_branch2b_relu
I0311 23:08:53.768988 17663 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0311 23:08:53.768992 17663 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0311 23:08:53.768997 17663 net.cpp:150] Setting up res5b_branch2b_relu
I0311 23:08:53.769001 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.769002 17663 net.cpp:165] Memory required for data: 2948100948
I0311 23:08:53.769018 17663 layer_factory.hpp:77] Creating layer res5b_branch2c
I0311 23:08:53.769031 17663 net.cpp:100] Creating Layer res5b_branch2c
I0311 23:08:53.769033 17663 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0311 23:08:53.769040 17663 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0311 23:08:53.771384 17663 net.cpp:150] Setting up res5b_branch2c
I0311 23:08:53.771407 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.771410 17663 net.cpp:165] Memory required for data: 2967712596
I0311 23:08:53.771431 17663 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0311 23:08:53.771443 17663 net.cpp:100] Creating Layer bn5b_branch2c
I0311 23:08:53.771447 17663 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0311 23:08:53.771456 17663 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0311 23:08:53.771646 17663 net.cpp:150] Setting up bn5b_branch2c
I0311 23:08:53.771651 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.771653 17663 net.cpp:165] Memory required for data: 2987324244
I0311 23:08:53.771659 17663 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0311 23:08:53.771679 17663 net.cpp:100] Creating Layer scale5b_branch2c
I0311 23:08:53.771682 17663 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0311 23:08:53.771687 17663 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0311 23:08:53.771731 17663 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0311 23:08:53.771847 17663 net.cpp:150] Setting up scale5b_branch2c
I0311 23:08:53.771865 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.771867 17663 net.cpp:165] Memory required for data: 3006935892
I0311 23:08:53.771872 17663 layer_factory.hpp:77] Creating layer res5b
I0311 23:08:53.771889 17663 net.cpp:100] Creating Layer res5b
I0311 23:08:53.771893 17663 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0311 23:08:53.771896 17663 net.cpp:444] res5b <- res5b_branch2c
I0311 23:08:53.771901 17663 net.cpp:418] res5b -> res5b
I0311 23:08:53.771919 17663 net.cpp:150] Setting up res5b
I0311 23:08:53.771924 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.771927 17663 net.cpp:165] Memory required for data: 3026547540
I0311 23:08:53.771929 17663 layer_factory.hpp:77] Creating layer res5b_relu
I0311 23:08:53.771934 17663 net.cpp:100] Creating Layer res5b_relu
I0311 23:08:53.771936 17663 net.cpp:444] res5b_relu <- res5b
I0311 23:08:53.771941 17663 net.cpp:405] res5b_relu -> res5b (in-place)
I0311 23:08:53.771947 17663 net.cpp:150] Setting up res5b_relu
I0311 23:08:53.771963 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.771966 17663 net.cpp:165] Memory required for data: 3046159188
I0311 23:08:53.771968 17663 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0311 23:08:53.771986 17663 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0311 23:08:53.771987 17663 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0311 23:08:53.771991 17663 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0311 23:08:53.772011 17663 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0311 23:08:53.772050 17663 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0311 23:08:53.772055 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.772058 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.772061 17663 net.cpp:165] Memory required for data: 3085382484
I0311 23:08:53.772063 17663 layer_factory.hpp:77] Creating layer res5c_branch2a
I0311 23:08:53.772070 17663 net.cpp:100] Creating Layer res5c_branch2a
I0311 23:08:53.772074 17663 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0311 23:08:53.772092 17663 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0311 23:08:53.774245 17663 net.cpp:150] Setting up res5c_branch2a
I0311 23:08:53.774264 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.774267 17663 net.cpp:165] Memory required for data: 3090285396
I0311 23:08:53.774273 17663 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0311 23:08:53.774298 17663 net.cpp:100] Creating Layer bn5c_branch2a
I0311 23:08:53.774317 17663 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0311 23:08:53.774323 17663 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0311 23:08:53.774513 17663 net.cpp:150] Setting up bn5c_branch2a
I0311 23:08:53.774518 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.774520 17663 net.cpp:165] Memory required for data: 3095188308
I0311 23:08:53.774525 17663 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0311 23:08:53.774530 17663 net.cpp:100] Creating Layer scale5c_branch2a
I0311 23:08:53.774533 17663 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0311 23:08:53.774536 17663 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0311 23:08:53.774580 17663 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0311 23:08:53.774750 17663 net.cpp:150] Setting up scale5c_branch2a
I0311 23:08:53.774755 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.774757 17663 net.cpp:165] Memory required for data: 3100091220
I0311 23:08:53.774761 17663 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0311 23:08:53.774765 17663 net.cpp:100] Creating Layer res5c_branch2a_relu
I0311 23:08:53.774767 17663 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0311 23:08:53.774772 17663 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0311 23:08:53.774776 17663 net.cpp:150] Setting up res5c_branch2a_relu
I0311 23:08:53.774780 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.774781 17663 net.cpp:165] Memory required for data: 3104994132
I0311 23:08:53.774783 17663 layer_factory.hpp:77] Creating layer res5c_branch2b
I0311 23:08:53.774790 17663 net.cpp:100] Creating Layer res5c_branch2b
I0311 23:08:53.774792 17663 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0311 23:08:53.774796 17663 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0311 23:08:53.779017 17663 net.cpp:150] Setting up res5c_branch2b
I0311 23:08:53.779045 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.779047 17663 net.cpp:165] Memory required for data: 3109897044
I0311 23:08:53.779054 17663 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0311 23:08:53.779063 17663 net.cpp:100] Creating Layer bn5c_branch2b
I0311 23:08:53.779068 17663 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0311 23:08:53.779078 17663 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0311 23:08:53.779309 17663 net.cpp:150] Setting up bn5c_branch2b
I0311 23:08:53.779314 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.779316 17663 net.cpp:165] Memory required for data: 3114799956
I0311 23:08:53.779321 17663 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0311 23:08:53.779327 17663 net.cpp:100] Creating Layer scale5c_branch2b
I0311 23:08:53.779330 17663 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0311 23:08:53.779333 17663 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0311 23:08:53.779376 17663 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0311 23:08:53.779511 17663 net.cpp:150] Setting up scale5c_branch2b
I0311 23:08:53.779516 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.779520 17663 net.cpp:165] Memory required for data: 3119702868
I0311 23:08:53.779523 17663 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0311 23:08:53.779527 17663 net.cpp:100] Creating Layer res5c_branch2b_relu
I0311 23:08:53.779531 17663 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0311 23:08:53.779534 17663 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0311 23:08:53.779539 17663 net.cpp:150] Setting up res5c_branch2b_relu
I0311 23:08:53.779542 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.779544 17663 net.cpp:165] Memory required for data: 3124605780
I0311 23:08:53.779547 17663 layer_factory.hpp:77] Creating layer res5c_branch2c
I0311 23:08:53.779553 17663 net.cpp:100] Creating Layer res5c_branch2c
I0311 23:08:53.779556 17663 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0311 23:08:53.779561 17663 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0311 23:08:53.781446 17663 net.cpp:150] Setting up res5c_branch2c
I0311 23:08:53.781466 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.781469 17663 net.cpp:165] Memory required for data: 3144217428
I0311 23:08:53.781474 17663 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0311 23:08:53.781497 17663 net.cpp:100] Creating Layer bn5c_branch2c
I0311 23:08:53.781502 17663 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0311 23:08:53.781507 17663 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0311 23:08:53.781741 17663 net.cpp:150] Setting up bn5c_branch2c
I0311 23:08:53.781747 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.781749 17663 net.cpp:165] Memory required for data: 3163829076
I0311 23:08:53.781754 17663 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0311 23:08:53.781759 17663 net.cpp:100] Creating Layer scale5c_branch2c
I0311 23:08:53.781774 17663 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0311 23:08:53.781780 17663 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0311 23:08:53.781824 17663 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0311 23:08:53.781954 17663 net.cpp:150] Setting up scale5c_branch2c
I0311 23:08:53.781961 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.781963 17663 net.cpp:165] Memory required for data: 3183440724
I0311 23:08:53.781967 17663 layer_factory.hpp:77] Creating layer res5c
I0311 23:08:53.781983 17663 net.cpp:100] Creating Layer res5c
I0311 23:08:53.781986 17663 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0311 23:08:53.782004 17663 net.cpp:444] res5c <- res5c_branch2c
I0311 23:08:53.782007 17663 net.cpp:418] res5c -> res5c
I0311 23:08:53.782027 17663 net.cpp:150] Setting up res5c
I0311 23:08:53.782045 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.782048 17663 net.cpp:165] Memory required for data: 3203052372
I0311 23:08:53.782050 17663 layer_factory.hpp:77] Creating layer res5c_relu
I0311 23:08:53.782055 17663 net.cpp:100] Creating Layer res5c_relu
I0311 23:08:53.782071 17663 net.cpp:444] res5c_relu <- res5c
I0311 23:08:53.782075 17663 net.cpp:405] res5c_relu -> res5c (in-place)
I0311 23:08:53.782079 17663 net.cpp:150] Setting up res5c_relu
I0311 23:08:53.782084 17663 net.cpp:157] Top shape: 1 2048 38 63 (4902912)
I0311 23:08:53.782088 17663 net.cpp:165] Memory required for data: 3222664020
I0311 23:08:53.782089 17663 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0311 23:08:53.782097 17663 net.cpp:100] Creating Layer rpn_conv/3x3
I0311 23:08:53.782100 17663 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0311 23:08:53.782105 17663 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0311 23:08:53.823802 17663 net.cpp:150] Setting up rpn_conv/3x3
I0311 23:08:53.823837 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.823839 17663 net.cpp:165] Memory required for data: 3227566932
I0311 23:08:53.823850 17663 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0311 23:08:53.823863 17663 net.cpp:100] Creating Layer rpn_relu/3x3
I0311 23:08:53.823868 17663 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0311 23:08:53.823874 17663 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0311 23:08:53.823884 17663 net.cpp:150] Setting up rpn_relu/3x3
I0311 23:08:53.823886 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.823889 17663 net.cpp:165] Memory required for data: 3232469844
I0311 23:08:53.823891 17663 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0311 23:08:53.823896 17663 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0311 23:08:53.823899 17663 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0311 23:08:53.823904 17663 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0311 23:08:53.823909 17663 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0311 23:08:53.823947 17663 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0311 23:08:53.823952 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.823956 17663 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0311 23:08:53.823957 17663 net.cpp:165] Memory required for data: 3242275668
I0311 23:08:53.823961 17663 layer_factory.hpp:77] Creating layer rpn_cls_score
I0311 23:08:53.823971 17663 net.cpp:100] Creating Layer rpn_cls_score
I0311 23:08:53.823976 17663 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0311 23:08:53.823979 17663 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0311 23:08:53.824268 17663 net.cpp:150] Setting up rpn_cls_score
I0311 23:08:53.824275 17663 net.cpp:157] Top shape: 1 18 38 63 (43092)
I0311 23:08:53.824277 17663 net.cpp:165] Memory required for data: 3242448036
I0311 23:08:53.824281 17663 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0311 23:08:53.824286 17663 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0311 23:08:53.824290 17663 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0311 23:08:53.824295 17663 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0311 23:08:53.824301 17663 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0311 23:08:53.824328 17663 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0311 23:08:53.824334 17663 net.cpp:157] Top shape: 1 18 38 63 (43092)
I0311 23:08:53.824337 17663 net.cpp:157] Top shape: 1 18 38 63 (43092)
I0311 23:08:53.824339 17663 net.cpp:165] Memory required for data: 3242792772
I0311 23:08:53.824342 17663 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0311 23:08:53.824352 17663 net.cpp:100] Creating Layer rpn_bbox_pred
I0311 23:08:53.824355 17663 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0311 23:08:53.824360 17663 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0311 23:08:53.824702 17663 net.cpp:150] Setting up rpn_bbox_pred
I0311 23:08:53.824708 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.824710 17663 net.cpp:165] Memory required for data: 3243137508
I0311 23:08:53.824715 17663 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0311 23:08:53.824719 17663 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0311 23:08:53.824723 17663 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0311 23:08:53.824728 17663 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0311 23:08:53.824733 17663 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0311 23:08:53.824764 17663 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0311 23:08:53.824769 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.824771 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.824774 17663 net.cpp:165] Memory required for data: 3243826980
I0311 23:08:53.824776 17663 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0311 23:08:53.824782 17663 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0311 23:08:53.824786 17663 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0311 23:08:53.824791 17663 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0311 23:08:53.824813 17663 net.cpp:150] Setting up rpn_cls_score_reshape
I0311 23:08:53.824820 17663 net.cpp:157] Top shape: 1 2 342 63 (43092)
I0311 23:08:53.824821 17663 net.cpp:165] Memory required for data: 3243999348
I0311 23:08:53.824825 17663 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0311 23:08:53.824828 17663 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0311 23:08:53.824832 17663 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0311 23:08:53.824837 17663 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0311 23:08:53.824842 17663 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0311 23:08:53.824870 17663 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0311 23:08:53.824875 17663 net.cpp:157] Top shape: 1 2 342 63 (43092)
I0311 23:08:53.824878 17663 net.cpp:157] Top shape: 1 2 342 63 (43092)
I0311 23:08:53.824880 17663 net.cpp:165] Memory required for data: 3244344084
I0311 23:08:53.824883 17663 layer_factory.hpp:77] Creating layer rpn-data
I0311 23:08:53.825249 17663 net.cpp:100] Creating Layer rpn-data
I0311 23:08:53.825258 17663 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0311 23:08:53.825263 17663 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0311 23:08:53.825268 17663 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0311 23:08:53.825271 17663 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0311 23:08:53.825276 17663 net.cpp:418] rpn-data -> rpn_labels
I0311 23:08:53.825282 17663 net.cpp:418] rpn-data -> rpn_bbox_targets
I0311 23:08:53.825289 17663 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0311 23:08:53.825294 17663 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0311 23:08:53.825889 17663 net.cpp:150] Setting up rpn-data
I0311 23:08:53.825923 17663 net.cpp:157] Top shape: 1 1 342 63 (21546)
I0311 23:08:53.825927 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.825930 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.825933 17663 net.cpp:157] Top shape: 1 36 38 63 (86184)
I0311 23:08:53.825937 17663 net.cpp:165] Memory required for data: 3245464476
I0311 23:08:53.825942 17663 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0311 23:08:53.825948 17663 net.cpp:100] Creating Layer rpn_loss_cls
I0311 23:08:53.825951 17663 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0311 23:08:53.825956 17663 net.cpp:444] rpn_loss_cls <- rpn_labels
I0311 23:08:53.825960 17663 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0311 23:08:53.825974 17663 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0311 23:08:53.826088 17663 net.cpp:150] Setting up rpn_loss_cls
I0311 23:08:53.826095 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.826098 17663 net.cpp:160]     with loss weight 1
I0311 23:08:53.826107 17663 net.cpp:165] Memory required for data: 3245464480
I0311 23:08:53.826109 17663 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0311 23:08:53.826124 17663 net.cpp:100] Creating Layer rpn_loss_bbox
I0311 23:08:53.826128 17663 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0311 23:08:53.826133 17663 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0311 23:08:53.826135 17663 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0311 23:08:53.826138 17663 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0311 23:08:53.826143 17663 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0311 23:08:53.826634 17663 net.cpp:150] Setting up rpn_loss_bbox
I0311 23:08:53.826642 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.826643 17663 net.cpp:160]     with loss weight 1
I0311 23:08:53.826647 17663 net.cpp:165] Memory required for data: 3245464484
I0311 23:08:53.826650 17663 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0311 23:08:53.826654 17663 net.cpp:100] Creating Layer rpn_cls_prob
I0311 23:08:53.826659 17663 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0311 23:08:53.826663 17663 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0311 23:08:53.826741 17663 net.cpp:150] Setting up rpn_cls_prob
I0311 23:08:53.826746 17663 net.cpp:157] Top shape: 1 2 342 63 (43092)
I0311 23:08:53.826748 17663 net.cpp:165] Memory required for data: 3245636852
I0311 23:08:53.826751 17663 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0311 23:08:53.826757 17663 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0311 23:08:53.826761 17663 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0311 23:08:53.826764 17663 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0311 23:08:53.826802 17663 net.cpp:150] Setting up rpn_cls_prob_reshape
I0311 23:08:53.826805 17663 net.cpp:157] Top shape: 1 18 38 63 (43092)
I0311 23:08:53.826807 17663 net.cpp:165] Memory required for data: 3245809220
I0311 23:08:53.826810 17663 layer_factory.hpp:77] Creating layer proposal
I0311 23:08:53.827535 17663 net.cpp:100] Creating Layer proposal
I0311 23:08:53.827551 17663 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0311 23:08:53.827558 17663 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0311 23:08:53.827563 17663 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0311 23:08:53.827569 17663 net.cpp:418] proposal -> rpn_rois
I0311 23:08:53.839603 17663 net.cpp:150] Setting up proposal
I0311 23:08:53.839635 17663 net.cpp:157] Top shape: 1 5 (5)
I0311 23:08:53.839638 17663 net.cpp:165] Memory required for data: 3245809240
I0311 23:08:53.839661 17663 layer_factory.hpp:77] Creating layer roi-data
I0311 23:08:53.839941 17663 net.cpp:100] Creating Layer roi-data
I0311 23:08:53.839964 17663 net.cpp:444] roi-data <- rpn_rois
I0311 23:08:53.839972 17663 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0311 23:08:53.839977 17663 net.cpp:418] roi-data -> rois
I0311 23:08:53.839987 17663 net.cpp:418] roi-data -> labels
I0311 23:08:53.839994 17663 net.cpp:418] roi-data -> bbox_targets
I0311 23:08:53.839998 17663 net.cpp:418] roi-data -> bbox_inside_weights
I0311 23:08:53.840004 17663 net.cpp:418] roi-data -> bbox_outside_weights
I0311 23:08:53.840510 17663 net.cpp:150] Setting up roi-data
I0311 23:08:53.840523 17663 net.cpp:157] Top shape: 1 5 1 1 (5)
I0311 23:08:53.840525 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.840528 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840531 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840534 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840536 17663 net.cpp:165] Memory required for data: 3245809360
I0311 23:08:53.840539 17663 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0311 23:08:53.840544 17663 net.cpp:100] Creating Layer rois_roi-data_0_split
I0311 23:08:53.840549 17663 net.cpp:444] rois_roi-data_0_split <- rois
I0311 23:08:53.840555 17663 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0311 23:08:53.840561 17663 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0311 23:08:53.840566 17663 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0311 23:08:53.840607 17663 net.cpp:150] Setting up rois_roi-data_0_split
I0311 23:08:53.840612 17663 net.cpp:157] Top shape: 1 5 1 1 (5)
I0311 23:08:53.840615 17663 net.cpp:157] Top shape: 1 5 1 1 (5)
I0311 23:08:53.840618 17663 net.cpp:157] Top shape: 1 5 1 1 (5)
I0311 23:08:53.840620 17663 net.cpp:165] Memory required for data: 3245809420
I0311 23:08:53.840622 17663 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0311 23:08:53.840626 17663 net.cpp:100] Creating Layer labels_roi-data_1_split
I0311 23:08:53.840629 17663 net.cpp:444] labels_roi-data_1_split <- labels
I0311 23:08:53.840633 17663 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0311 23:08:53.840638 17663 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0311 23:08:53.840663 17663 net.cpp:150] Setting up labels_roi-data_1_split
I0311 23:08:53.840668 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.840672 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.840673 17663 net.cpp:165] Memory required for data: 3245809428
I0311 23:08:53.840675 17663 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0311 23:08:53.840679 17663 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0311 23:08:53.840682 17663 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0311 23:08:53.840685 17663 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0311 23:08:53.840692 17663 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0311 23:08:53.840716 17663 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0311 23:08:53.840721 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840724 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840726 17663 net.cpp:165] Memory required for data: 3245809492
I0311 23:08:53.840728 17663 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0311 23:08:53.840732 17663 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0311 23:08:53.840734 17663 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0311 23:08:53.840739 17663 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0311 23:08:53.840744 17663 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0311 23:08:53.840768 17663 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0311 23:08:53.840773 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840776 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.840778 17663 net.cpp:165] Memory required for data: 3245809556
I0311 23:08:53.840780 17663 layer_factory.hpp:77] Creating layer conv_new_1
I0311 23:08:53.840792 17663 net.cpp:100] Creating Layer conv_new_1
I0311 23:08:53.840798 17663 net.cpp:444] conv_new_1 <- res5c
I0311 23:08:53.840802 17663 net.cpp:418] conv_new_1 -> conv_new_1
I0311 23:08:53.859946 17663 net.cpp:150] Setting up conv_new_1
I0311 23:08:53.859982 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.859984 17663 net.cpp:165] Memory required for data: 3255615380
I0311 23:08:53.860009 17663 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0311 23:08:53.860018 17663 net.cpp:100] Creating Layer conv_new_1_relu
I0311 23:08:53.860023 17663 net.cpp:444] conv_new_1_relu <- conv_new_1
I0311 23:08:53.860030 17663 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0311 23:08:53.860038 17663 net.cpp:150] Setting up conv_new_1_relu
I0311 23:08:53.860040 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.860043 17663 net.cpp:165] Memory required for data: 3265421204
I0311 23:08:53.860045 17663 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0311 23:08:53.860049 17663 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0311 23:08:53.860051 17663 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0311 23:08:53.860055 17663 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0311 23:08:53.860060 17663 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0311 23:08:53.860095 17663 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0311 23:08:53.860100 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.860103 17663 net.cpp:157] Top shape: 1 1024 38 63 (2451456)
I0311 23:08:53.860106 17663 net.cpp:165] Memory required for data: 3285032852
I0311 23:08:53.860108 17663 layer_factory.hpp:77] Creating layer rfcn_cls
I0311 23:08:53.860116 17663 net.cpp:100] Creating Layer rfcn_cls
I0311 23:08:53.860121 17663 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0311 23:08:53.860126 17663 net.cpp:418] rfcn_cls -> rfcn_cls
I0311 23:08:53.861960 17663 net.cpp:150] Setting up rfcn_cls
I0311 23:08:53.861989 17663 net.cpp:157] Top shape: 1 98 38 63 (234612)
I0311 23:08:53.861991 17663 net.cpp:165] Memory required for data: 3285971300
I0311 23:08:53.862000 17663 layer_factory.hpp:77] Creating layer rfcn_bbox
I0311 23:08:53.862011 17663 net.cpp:100] Creating Layer rfcn_bbox
I0311 23:08:53.862018 17663 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0311 23:08:53.862025 17663 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0311 23:08:53.865573 17663 net.cpp:150] Setting up rfcn_bbox
I0311 23:08:53.865617 17663 net.cpp:157] Top shape: 1 392 38 63 (938448)
I0311 23:08:53.865618 17663 net.cpp:165] Memory required for data: 3289725092
I0311 23:08:53.865626 17663 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0311 23:08:53.865638 17663 net.cpp:100] Creating Layer psroipooled_cls_rois
I0311 23:08:53.865643 17663 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0311 23:08:53.865648 17663 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0311 23:08:53.865670 17663 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0311 23:08:53.865681 17663 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0311 23:08:53.865746 17663 net.cpp:150] Setting up psroipooled_cls_rois
I0311 23:08:53.865752 17663 net.cpp:157] Top shape: 1 2 7 7 (98)
I0311 23:08:53.865754 17663 net.cpp:165] Memory required for data: 3289725484
I0311 23:08:53.865757 17663 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0311 23:08:53.865762 17663 net.cpp:100] Creating Layer ave_cls_score_rois
I0311 23:08:53.865766 17663 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0311 23:08:53.865769 17663 net.cpp:418] ave_cls_score_rois -> cls_score
I0311 23:08:53.865789 17663 net.cpp:150] Setting up ave_cls_score_rois
I0311 23:08:53.865794 17663 net.cpp:157] Top shape: 1 2 1 1 (2)
I0311 23:08:53.865797 17663 net.cpp:165] Memory required for data: 3289725492
I0311 23:08:53.865798 17663 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0311 23:08:53.865803 17663 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0311 23:08:53.865808 17663 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0311 23:08:53.865811 17663 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0311 23:08:53.865816 17663 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0311 23:08:53.865823 17663 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0311 23:08:53.865859 17663 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0311 23:08:53.865864 17663 net.cpp:157] Top shape: 1 2 1 1 (2)
I0311 23:08:53.865866 17663 net.cpp:157] Top shape: 1 2 1 1 (2)
I0311 23:08:53.865869 17663 net.cpp:157] Top shape: 1 2 1 1 (2)
I0311 23:08:53.865871 17663 net.cpp:165] Memory required for data: 3289725516
I0311 23:08:53.865873 17663 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0311 23:08:53.865878 17663 net.cpp:100] Creating Layer psroipooled_loc_rois
I0311 23:08:53.865883 17663 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0311 23:08:53.865887 17663 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0311 23:08:53.865902 17663 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0311 23:08:53.865908 17663 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0311 23:08:53.865936 17663 net.cpp:150] Setting up psroipooled_loc_rois
I0311 23:08:53.865942 17663 net.cpp:157] Top shape: 1 8 7 7 (392)
I0311 23:08:53.865944 17663 net.cpp:165] Memory required for data: 3289727084
I0311 23:08:53.865947 17663 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0311 23:08:53.865950 17663 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0311 23:08:53.865954 17663 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0311 23:08:53.865958 17663 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0311 23:08:53.865975 17663 net.cpp:150] Setting up ave_bbox_pred_rois
I0311 23:08:53.865980 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.865983 17663 net.cpp:165] Memory required for data: 3289727116
I0311 23:08:53.865984 17663 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0311 23:08:53.865988 17663 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0311 23:08:53.865991 17663 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0311 23:08:53.865995 17663 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0311 23:08:53.866000 17663 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0311 23:08:53.866025 17663 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0311 23:08:53.866030 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.866034 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.866035 17663 net.cpp:165] Memory required for data: 3289727180
I0311 23:08:53.866037 17663 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0311 23:08:53.866042 17663 net.cpp:100] Creating Layer per_roi_loss_cls
I0311 23:08:53.866046 17663 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0311 23:08:53.866050 17663 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0311 23:08:53.866055 17663 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0311 23:08:53.866060 17663 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0311 23:08:53.866066 17663 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0311 23:08:53.866075 17663 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0311 23:08:53.866154 17663 net.cpp:150] Setting up per_roi_loss_cls
I0311 23:08:53.866159 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.866163 17663 net.cpp:157] Top shape: 1 2 1 1 (2)
I0311 23:08:53.866165 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866168 17663 net.cpp:165] Memory required for data: 3289727196
I0311 23:08:53.866170 17663 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0311 23:08:53.866174 17663 net.cpp:100] Creating Layer per_roi_loss_bbox
I0311 23:08:53.866178 17663 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0311 23:08:53.866181 17663 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0311 23:08:53.866185 17663 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0311 23:08:53.866189 17663 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0311 23:08:53.866195 17663 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0311 23:08:53.866238 17663 net.cpp:150] Setting up per_roi_loss_bbox
I0311 23:08:53.866242 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.866245 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866247 17663 net.cpp:165] Memory required for data: 3289727204
I0311 23:08:53.866250 17663 layer_factory.hpp:77] Creating layer per_roi_loss
I0311 23:08:53.866255 17663 net.cpp:100] Creating Layer per_roi_loss
I0311 23:08:53.866257 17663 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0311 23:08:53.866261 17663 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0311 23:08:53.866264 17663 net.cpp:418] per_roi_loss -> per_roi_loss
I0311 23:08:53.866282 17663 net.cpp:150] Setting up per_roi_loss
I0311 23:08:53.866286 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866289 17663 net.cpp:165] Memory required for data: 3289727208
I0311 23:08:53.866291 17663 layer_factory.hpp:77] Creating layer annotator_detector
I0311 23:08:53.866297 17663 net.cpp:100] Creating Layer annotator_detector
I0311 23:08:53.866302 17663 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0311 23:08:53.866304 17663 net.cpp:444] annotator_detector <- per_roi_loss
I0311 23:08:53.866307 17663 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0311 23:08:53.866310 17663 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0311 23:08:53.866314 17663 net.cpp:418] annotator_detector -> labels_ohem
I0311 23:08:53.866319 17663 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0311 23:08:53.866349 17663 net.cpp:150] Setting up annotator_detector
I0311 23:08:53.866354 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866358 17663 net.cpp:157] Top shape: 1 8 1 1 (8)
I0311 23:08:53.866359 17663 net.cpp:165] Memory required for data: 3289727244
I0311 23:08:53.866361 17663 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0311 23:08:53.866365 17663 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0311 23:08:53.866367 17663 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0311 23:08:53.866371 17663 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0311 23:08:53.866377 17663 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0311 23:08:53.866402 17663 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0311 23:08:53.866406 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866410 17663 net.cpp:157] Top shape: 1 1 1 1 (1)
I0311 23:08:53.866411 17663 net.cpp:165] Memory required for data: 3289727252
I0311 23:08:53.866415 17663 layer_factory.hpp:77] Creating layer silence
I0311 23:08:53.866418 17663 net.cpp:100] Creating Layer silence
I0311 23:08:53.866420 17663 net.cpp:444] silence <- bbox_outside_weights
I0311 23:08:53.866425 17663 net.cpp:444] silence <- temp_loss_cls
I0311 23:08:53.866430 17663 net.cpp:444] silence <- temp_prob_cls
I0311 23:08:53.866432 17663 net.cpp:444] silence <- temp_loss_bbox
I0311 23:08:53.866436 17663 net.cpp:150] Setting up silence
I0311 23:08:53.866437 17663 net.cpp:165] Memory required for data: 3289727252
I0311 23:08:53.866439 17663 layer_factory.hpp:77] Creating layer loss
I0311 23:08:53.866443 17663 net.cpp:100] Creating Layer loss
I0311 23:08:53.866446 17663 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0311 23:08:53.866449 17663 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0311 23:08:53.866453 17663 net.cpp:418] loss -> loss_cls
I0311 23:08:53.866461 17663 layer_factory.hpp:77] Creating layer loss
I0311 23:08:53.866528 17663 net.cpp:150] Setting up loss
I0311 23:08:53.866533 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.866535 17663 net.cpp:160]     with loss weight 1
I0311 23:08:53.866539 17663 net.cpp:165] Memory required for data: 3289727256
I0311 23:08:53.866541 17663 layer_factory.hpp:77] Creating layer accuarcy
I0311 23:08:53.866545 17663 net.cpp:100] Creating Layer accuarcy
I0311 23:08:53.866549 17663 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0311 23:08:53.866552 17663 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0311 23:08:53.866556 17663 net.cpp:418] accuarcy -> accuarcy
I0311 23:08:53.866564 17663 net.cpp:150] Setting up accuarcy
I0311 23:08:53.866569 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.866570 17663 net.cpp:165] Memory required for data: 3289727260
I0311 23:08:53.866572 17663 layer_factory.hpp:77] Creating layer loss_bbox
I0311 23:08:53.866575 17663 net.cpp:100] Creating Layer loss_bbox
I0311 23:08:53.866580 17663 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0311 23:08:53.866583 17663 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0311 23:08:53.866586 17663 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0311 23:08:53.866590 17663 net.cpp:418] loss_bbox -> loss_bbox
I0311 23:08:53.866627 17663 net.cpp:150] Setting up loss_bbox
I0311 23:08:53.866632 17663 net.cpp:157] Top shape: (1)
I0311 23:08:53.866634 17663 net.cpp:160]     with loss weight 1
I0311 23:08:53.866637 17663 net.cpp:165] Memory required for data: 3289727264
I0311 23:08:53.866641 17663 net.cpp:226] loss_bbox needs backward computation.
I0311 23:08:53.866644 17663 net.cpp:228] accuarcy does not need backward computation.
I0311 23:08:53.866647 17663 net.cpp:226] loss needs backward computation.
I0311 23:08:53.866650 17663 net.cpp:228] silence does not need backward computation.
I0311 23:08:53.866654 17663 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0311 23:08:53.866657 17663 net.cpp:228] annotator_detector does not need backward computation.
I0311 23:08:53.866662 17663 net.cpp:228] per_roi_loss does not need backward computation.
I0311 23:08:53.866664 17663 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0311 23:08:53.866669 17663 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0311 23:08:53.866672 17663 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0311 23:08:53.866675 17663 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0311 23:08:53.866678 17663 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0311 23:08:53.866681 17663 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0311 23:08:53.866683 17663 net.cpp:226] ave_cls_score_rois needs backward computation.
I0311 23:08:53.866686 17663 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0311 23:08:53.866689 17663 net.cpp:226] rfcn_bbox needs backward computation.
I0311 23:08:53.866693 17663 net.cpp:226] rfcn_cls needs backward computation.
I0311 23:08:53.866695 17663 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0311 23:08:53.866698 17663 net.cpp:226] conv_new_1_relu needs backward computation.
I0311 23:08:53.866700 17663 net.cpp:226] conv_new_1 needs backward computation.
I0311 23:08:53.866703 17663 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0311 23:08:53.866708 17663 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0311 23:08:53.866714 17663 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0311 23:08:53.866716 17663 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0311 23:08:53.866720 17663 net.cpp:226] roi-data needs backward computation.
I0311 23:08:53.866724 17663 net.cpp:226] proposal needs backward computation.
I0311 23:08:53.866729 17663 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0311 23:08:53.866732 17663 net.cpp:226] rpn_cls_prob needs backward computation.
I0311 23:08:53.866736 17663 net.cpp:226] rpn_loss_bbox needs backward computation.
I0311 23:08:53.866740 17663 net.cpp:226] rpn_loss_cls needs backward computation.
I0311 23:08:53.866744 17663 net.cpp:226] rpn-data needs backward computation.
I0311 23:08:53.866749 17663 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0311 23:08:53.866751 17663 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0311 23:08:53.866755 17663 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0311 23:08:53.866757 17663 net.cpp:226] rpn_bbox_pred needs backward computation.
I0311 23:08:53.866760 17663 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0311 23:08:53.866763 17663 net.cpp:226] rpn_cls_score needs backward computation.
I0311 23:08:53.866766 17663 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0311 23:08:53.866768 17663 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0311 23:08:53.866771 17663 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0311 23:08:53.866775 17663 net.cpp:226] res5c_relu needs backward computation.
I0311 23:08:53.866777 17663 net.cpp:226] res5c needs backward computation.
I0311 23:08:53.866781 17663 net.cpp:226] scale5c_branch2c needs backward computation.
I0311 23:08:53.866785 17663 net.cpp:226] bn5c_branch2c needs backward computation.
I0311 23:08:53.866787 17663 net.cpp:226] res5c_branch2c needs backward computation.
I0311 23:08:53.866791 17663 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0311 23:08:53.866793 17663 net.cpp:226] scale5c_branch2b needs backward computation.
I0311 23:08:53.866796 17663 net.cpp:226] bn5c_branch2b needs backward computation.
I0311 23:08:53.866798 17663 net.cpp:226] res5c_branch2b needs backward computation.
I0311 23:08:53.866801 17663 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0311 23:08:53.866804 17663 net.cpp:226] scale5c_branch2a needs backward computation.
I0311 23:08:53.866806 17663 net.cpp:226] bn5c_branch2a needs backward computation.
I0311 23:08:53.866809 17663 net.cpp:226] res5c_branch2a needs backward computation.
I0311 23:08:53.866812 17663 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0311 23:08:53.866816 17663 net.cpp:226] res5b_relu needs backward computation.
I0311 23:08:53.866818 17663 net.cpp:226] res5b needs backward computation.
I0311 23:08:53.866822 17663 net.cpp:226] scale5b_branch2c needs backward computation.
I0311 23:08:53.866824 17663 net.cpp:226] bn5b_branch2c needs backward computation.
I0311 23:08:53.866827 17663 net.cpp:226] res5b_branch2c needs backward computation.
I0311 23:08:53.866830 17663 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0311 23:08:53.866832 17663 net.cpp:226] scale5b_branch2b needs backward computation.
I0311 23:08:53.866835 17663 net.cpp:226] bn5b_branch2b needs backward computation.
I0311 23:08:53.866838 17663 net.cpp:226] res5b_branch2b needs backward computation.
I0311 23:08:53.866840 17663 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0311 23:08:53.866843 17663 net.cpp:226] scale5b_branch2a needs backward computation.
I0311 23:08:53.866845 17663 net.cpp:226] bn5b_branch2a needs backward computation.
I0311 23:08:53.866847 17663 net.cpp:226] res5b_branch2a needs backward computation.
I0311 23:08:53.866850 17663 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0311 23:08:53.866853 17663 net.cpp:226] res5a_relu needs backward computation.
I0311 23:08:53.866855 17663 net.cpp:226] res5a needs backward computation.
I0311 23:08:53.866859 17663 net.cpp:226] scale5a_branch2c needs backward computation.
I0311 23:08:53.866861 17663 net.cpp:226] bn5a_branch2c needs backward computation.
I0311 23:08:53.866864 17663 net.cpp:226] res5a_branch2c needs backward computation.
I0311 23:08:53.866866 17663 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0311 23:08:53.866871 17663 net.cpp:226] scale5a_branch2b needs backward computation.
I0311 23:08:53.866873 17663 net.cpp:226] bn5a_branch2b needs backward computation.
I0311 23:08:53.866876 17663 net.cpp:226] res5a_branch2b needs backward computation.
I0311 23:08:53.866879 17663 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0311 23:08:53.866881 17663 net.cpp:226] scale5a_branch2a needs backward computation.
I0311 23:08:53.866884 17663 net.cpp:226] bn5a_branch2a needs backward computation.
I0311 23:08:53.866886 17663 net.cpp:226] res5a_branch2a needs backward computation.
I0311 23:08:53.866889 17663 net.cpp:226] scale5a_branch1 needs backward computation.
I0311 23:08:53.866892 17663 net.cpp:226] bn5a_branch1 needs backward computation.
I0311 23:08:53.866894 17663 net.cpp:226] res5a_branch1 needs backward computation.
I0311 23:08:53.866899 17663 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0311 23:08:53.866901 17663 net.cpp:226] res4f_relu needs backward computation.
I0311 23:08:53.866904 17663 net.cpp:226] res4f needs backward computation.
I0311 23:08:53.866909 17663 net.cpp:226] scale4f_branch2c needs backward computation.
I0311 23:08:53.866911 17663 net.cpp:226] bn4f_branch2c needs backward computation.
I0311 23:08:53.866914 17663 net.cpp:226] res4f_branch2c needs backward computation.
I0311 23:08:53.866916 17663 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0311 23:08:53.866919 17663 net.cpp:226] scale4f_branch2b needs backward computation.
I0311 23:08:53.866922 17663 net.cpp:226] bn4f_branch2b needs backward computation.
I0311 23:08:53.866925 17663 net.cpp:226] res4f_branch2b needs backward computation.
I0311 23:08:53.866927 17663 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0311 23:08:53.866930 17663 net.cpp:226] scale4f_branch2a needs backward computation.
I0311 23:08:53.866932 17663 net.cpp:226] bn4f_branch2a needs backward computation.
I0311 23:08:53.866935 17663 net.cpp:226] res4f_branch2a needs backward computation.
I0311 23:08:53.866937 17663 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0311 23:08:53.866940 17663 net.cpp:226] res4e_relu needs backward computation.
I0311 23:08:53.866942 17663 net.cpp:226] res4e needs backward computation.
I0311 23:08:53.866945 17663 net.cpp:226] scale4e_branch2c needs backward computation.
I0311 23:08:53.866948 17663 net.cpp:226] bn4e_branch2c needs backward computation.
I0311 23:08:53.866950 17663 net.cpp:226] res4e_branch2c needs backward computation.
I0311 23:08:53.866953 17663 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0311 23:08:53.866956 17663 net.cpp:226] scale4e_branch2b needs backward computation.
I0311 23:08:53.866958 17663 net.cpp:226] bn4e_branch2b needs backward computation.
I0311 23:08:53.866961 17663 net.cpp:226] res4e_branch2b needs backward computation.
I0311 23:08:53.866963 17663 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0311 23:08:53.866966 17663 net.cpp:226] scale4e_branch2a needs backward computation.
I0311 23:08:53.866968 17663 net.cpp:226] bn4e_branch2a needs backward computation.
I0311 23:08:53.866971 17663 net.cpp:226] res4e_branch2a needs backward computation.
I0311 23:08:53.866973 17663 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0311 23:08:53.866976 17663 net.cpp:226] res4d_relu needs backward computation.
I0311 23:08:53.866978 17663 net.cpp:226] res4d needs backward computation.
I0311 23:08:53.866981 17663 net.cpp:226] scale4d_branch2c needs backward computation.
I0311 23:08:53.866984 17663 net.cpp:226] bn4d_branch2c needs backward computation.
I0311 23:08:53.866986 17663 net.cpp:226] res4d_branch2c needs backward computation.
I0311 23:08:53.866989 17663 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0311 23:08:53.866991 17663 net.cpp:226] scale4d_branch2b needs backward computation.
I0311 23:08:53.866996 17663 net.cpp:226] bn4d_branch2b needs backward computation.
I0311 23:08:53.866997 17663 net.cpp:226] res4d_branch2b needs backward computation.
I0311 23:08:53.867000 17663 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0311 23:08:53.867003 17663 net.cpp:226] scale4d_branch2a needs backward computation.
I0311 23:08:53.867007 17663 net.cpp:226] bn4d_branch2a needs backward computation.
I0311 23:08:53.867009 17663 net.cpp:226] res4d_branch2a needs backward computation.
I0311 23:08:53.867012 17663 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0311 23:08:53.867014 17663 net.cpp:226] res4c_relu needs backward computation.
I0311 23:08:53.867017 17663 net.cpp:226] res4c needs backward computation.
I0311 23:08:53.867019 17663 net.cpp:226] scale4c_branch2c needs backward computation.
I0311 23:08:53.867022 17663 net.cpp:226] bn4c_branch2c needs backward computation.
I0311 23:08:53.867024 17663 net.cpp:226] res4c_branch2c needs backward computation.
I0311 23:08:53.867027 17663 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0311 23:08:53.867029 17663 net.cpp:226] scale4c_branch2b needs backward computation.
I0311 23:08:53.867033 17663 net.cpp:226] bn4c_branch2b needs backward computation.
I0311 23:08:53.867034 17663 net.cpp:226] res4c_branch2b needs backward computation.
I0311 23:08:53.867038 17663 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0311 23:08:53.867039 17663 net.cpp:226] scale4c_branch2a needs backward computation.
I0311 23:08:53.867043 17663 net.cpp:226] bn4c_branch2a needs backward computation.
I0311 23:08:53.867044 17663 net.cpp:226] res4c_branch2a needs backward computation.
I0311 23:08:53.867048 17663 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0311 23:08:53.867050 17663 net.cpp:226] res4b_relu needs backward computation.
I0311 23:08:53.867053 17663 net.cpp:226] res4b needs backward computation.
I0311 23:08:53.867056 17663 net.cpp:226] scale4b_branch2c needs backward computation.
I0311 23:08:53.867058 17663 net.cpp:226] bn4b_branch2c needs backward computation.
I0311 23:08:53.867061 17663 net.cpp:226] res4b_branch2c needs backward computation.
I0311 23:08:53.867063 17663 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0311 23:08:53.867066 17663 net.cpp:226] scale4b_branch2b needs backward computation.
I0311 23:08:53.867069 17663 net.cpp:226] bn4b_branch2b needs backward computation.
I0311 23:08:53.867071 17663 net.cpp:226] res4b_branch2b needs backward computation.
I0311 23:08:53.867074 17663 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0311 23:08:53.867076 17663 net.cpp:226] scale4b_branch2a needs backward computation.
I0311 23:08:53.867079 17663 net.cpp:226] bn4b_branch2a needs backward computation.
I0311 23:08:53.867081 17663 net.cpp:226] res4b_branch2a needs backward computation.
I0311 23:08:53.867084 17663 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0311 23:08:53.867086 17663 net.cpp:226] res4a_relu needs backward computation.
I0311 23:08:53.867090 17663 net.cpp:226] res4a needs backward computation.
I0311 23:08:53.867094 17663 net.cpp:226] scale4a_branch2c needs backward computation.
I0311 23:08:53.867096 17663 net.cpp:226] bn4a_branch2c needs backward computation.
I0311 23:08:53.867100 17663 net.cpp:226] res4a_branch2c needs backward computation.
I0311 23:08:53.867102 17663 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0311 23:08:53.867105 17663 net.cpp:226] scale4a_branch2b needs backward computation.
I0311 23:08:53.867107 17663 net.cpp:226] bn4a_branch2b needs backward computation.
I0311 23:08:53.867110 17663 net.cpp:226] res4a_branch2b needs backward computation.
I0311 23:08:53.867113 17663 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0311 23:08:53.867115 17663 net.cpp:226] scale4a_branch2a needs backward computation.
I0311 23:08:53.867117 17663 net.cpp:226] bn4a_branch2a needs backward computation.
I0311 23:08:53.867120 17663 net.cpp:226] res4a_branch2a needs backward computation.
I0311 23:08:53.867123 17663 net.cpp:226] scale4a_branch1 needs backward computation.
I0311 23:08:53.867125 17663 net.cpp:226] bn4a_branch1 needs backward computation.
I0311 23:08:53.867128 17663 net.cpp:226] res4a_branch1 needs backward computation.
I0311 23:08:53.867131 17663 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0311 23:08:53.867133 17663 net.cpp:226] res3d_relu needs backward computation.
I0311 23:08:53.867136 17663 net.cpp:226] res3d needs backward computation.
I0311 23:08:53.867139 17663 net.cpp:226] scale3d_branch2c needs backward computation.
I0311 23:08:53.867141 17663 net.cpp:226] bn3d_branch2c needs backward computation.
I0311 23:08:53.867144 17663 net.cpp:226] res3d_branch2c needs backward computation.
I0311 23:08:53.867147 17663 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0311 23:08:53.867149 17663 net.cpp:226] scale3d_branch2b needs backward computation.
I0311 23:08:53.867151 17663 net.cpp:226] bn3d_branch2b needs backward computation.
I0311 23:08:53.867156 17663 net.cpp:226] res3d_branch2b needs backward computation.
I0311 23:08:53.867158 17663 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0311 23:08:53.867161 17663 net.cpp:226] scale3d_branch2a needs backward computation.
I0311 23:08:53.867163 17663 net.cpp:226] bn3d_branch2a needs backward computation.
I0311 23:08:53.867166 17663 net.cpp:226] res3d_branch2a needs backward computation.
I0311 23:08:53.867168 17663 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0311 23:08:53.867171 17663 net.cpp:226] res3c_relu needs backward computation.
I0311 23:08:53.867185 17663 net.cpp:226] res3c needs backward computation.
I0311 23:08:53.867189 17663 net.cpp:226] scale3c_branch2c needs backward computation.
I0311 23:08:53.867192 17663 net.cpp:226] bn3c_branch2c needs backward computation.
I0311 23:08:53.867193 17663 net.cpp:226] res3c_branch2c needs backward computation.
I0311 23:08:53.867210 17663 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0311 23:08:53.867213 17663 net.cpp:226] scale3c_branch2b needs backward computation.
I0311 23:08:53.867215 17663 net.cpp:226] bn3c_branch2b needs backward computation.
I0311 23:08:53.867230 17663 net.cpp:226] res3c_branch2b needs backward computation.
I0311 23:08:53.867233 17663 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0311 23:08:53.867236 17663 net.cpp:226] scale3c_branch2a needs backward computation.
I0311 23:08:53.867238 17663 net.cpp:226] bn3c_branch2a needs backward computation.
I0311 23:08:53.867241 17663 net.cpp:226] res3c_branch2a needs backward computation.
I0311 23:08:53.867244 17663 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0311 23:08:53.867246 17663 net.cpp:226] res3b_relu needs backward computation.
I0311 23:08:53.867249 17663 net.cpp:226] res3b needs backward computation.
I0311 23:08:53.867252 17663 net.cpp:226] scale3b_branch2c needs backward computation.
I0311 23:08:53.867255 17663 net.cpp:226] bn3b_branch2c needs backward computation.
I0311 23:08:53.867259 17663 net.cpp:226] res3b_branch2c needs backward computation.
I0311 23:08:53.867261 17663 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0311 23:08:53.867264 17663 net.cpp:226] scale3b_branch2b needs backward computation.
I0311 23:08:53.867267 17663 net.cpp:226] bn3b_branch2b needs backward computation.
I0311 23:08:53.867270 17663 net.cpp:226] res3b_branch2b needs backward computation.
I0311 23:08:53.867272 17663 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0311 23:08:53.867275 17663 net.cpp:226] scale3b_branch2a needs backward computation.
I0311 23:08:53.867277 17663 net.cpp:226] bn3b_branch2a needs backward computation.
I0311 23:08:53.867280 17663 net.cpp:226] res3b_branch2a needs backward computation.
I0311 23:08:53.867282 17663 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0311 23:08:53.867285 17663 net.cpp:226] res3a_relu needs backward computation.
I0311 23:08:53.867287 17663 net.cpp:226] res3a needs backward computation.
I0311 23:08:53.867290 17663 net.cpp:226] scale3a_branch2c needs backward computation.
I0311 23:08:53.867292 17663 net.cpp:226] bn3a_branch2c needs backward computation.
I0311 23:08:53.867295 17663 net.cpp:226] res3a_branch2c needs backward computation.
I0311 23:08:53.867297 17663 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0311 23:08:53.867300 17663 net.cpp:226] scale3a_branch2b needs backward computation.
I0311 23:08:53.867303 17663 net.cpp:226] bn3a_branch2b needs backward computation.
I0311 23:08:53.867305 17663 net.cpp:226] res3a_branch2b needs backward computation.
I0311 23:08:53.867307 17663 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0311 23:08:53.867311 17663 net.cpp:226] scale3a_branch2a needs backward computation.
I0311 23:08:53.867313 17663 net.cpp:226] bn3a_branch2a needs backward computation.
I0311 23:08:53.867316 17663 net.cpp:226] res3a_branch2a needs backward computation.
I0311 23:08:53.867318 17663 net.cpp:226] scale3a_branch1 needs backward computation.
I0311 23:08:53.867321 17663 net.cpp:226] bn3a_branch1 needs backward computation.
I0311 23:08:53.867324 17663 net.cpp:226] res3a_branch1 needs backward computation.
I0311 23:08:53.867341 17663 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0311 23:08:53.867343 17663 net.cpp:228] res2c_relu does not need backward computation.
I0311 23:08:53.867347 17663 net.cpp:228] res2c does not need backward computation.
I0311 23:08:53.867350 17663 net.cpp:228] scale2c_branch2c does not need backward computation.
I0311 23:08:53.867353 17663 net.cpp:228] bn2c_branch2c does not need backward computation.
I0311 23:08:53.867357 17663 net.cpp:228] res2c_branch2c does not need backward computation.
I0311 23:08:53.867362 17663 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0311 23:08:53.867364 17663 net.cpp:228] scale2c_branch2b does not need backward computation.
I0311 23:08:53.867382 17663 net.cpp:228] bn2c_branch2b does not need backward computation.
I0311 23:08:53.867383 17663 net.cpp:228] res2c_branch2b does not need backward computation.
I0311 23:08:53.867388 17663 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0311 23:08:53.867390 17663 net.cpp:228] scale2c_branch2a does not need backward computation.
I0311 23:08:53.867393 17663 net.cpp:228] bn2c_branch2a does not need backward computation.
I0311 23:08:53.867395 17663 net.cpp:228] res2c_branch2a does not need backward computation.
I0311 23:08:53.867398 17663 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0311 23:08:53.867401 17663 net.cpp:228] res2b_relu does not need backward computation.
I0311 23:08:53.867404 17663 net.cpp:228] res2b does not need backward computation.
I0311 23:08:53.867408 17663 net.cpp:228] scale2b_branch2c does not need backward computation.
I0311 23:08:53.867410 17663 net.cpp:228] bn2b_branch2c does not need backward computation.
I0311 23:08:53.867413 17663 net.cpp:228] res2b_branch2c does not need backward computation.
I0311 23:08:53.867415 17663 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0311 23:08:53.867417 17663 net.cpp:228] scale2b_branch2b does not need backward computation.
I0311 23:08:53.867420 17663 net.cpp:228] bn2b_branch2b does not need backward computation.
I0311 23:08:53.867422 17663 net.cpp:228] res2b_branch2b does not need backward computation.
I0311 23:08:53.867425 17663 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0311 23:08:53.867429 17663 net.cpp:228] scale2b_branch2a does not need backward computation.
I0311 23:08:53.867430 17663 net.cpp:228] bn2b_branch2a does not need backward computation.
I0311 23:08:53.867434 17663 net.cpp:228] res2b_branch2a does not need backward computation.
I0311 23:08:53.867449 17663 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0311 23:08:53.867452 17663 net.cpp:228] res2a_relu does not need backward computation.
I0311 23:08:53.867455 17663 net.cpp:228] res2a does not need backward computation.
I0311 23:08:53.867458 17663 net.cpp:228] scale2a_branch2c does not need backward computation.
I0311 23:08:53.867461 17663 net.cpp:228] bn2a_branch2c does not need backward computation.
I0311 23:08:53.867465 17663 net.cpp:228] res2a_branch2c does not need backward computation.
I0311 23:08:53.867467 17663 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0311 23:08:53.867470 17663 net.cpp:228] scale2a_branch2b does not need backward computation.
I0311 23:08:53.867472 17663 net.cpp:228] bn2a_branch2b does not need backward computation.
I0311 23:08:53.867488 17663 net.cpp:228] res2a_branch2b does not need backward computation.
I0311 23:08:53.867491 17663 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0311 23:08:53.867494 17663 net.cpp:228] scale2a_branch2a does not need backward computation.
I0311 23:08:53.867498 17663 net.cpp:228] bn2a_branch2a does not need backward computation.
I0311 23:08:53.867501 17663 net.cpp:228] res2a_branch2a does not need backward computation.
I0311 23:08:53.867504 17663 net.cpp:228] scale2a_branch1 does not need backward computation.
I0311 23:08:53.867507 17663 net.cpp:228] bn2a_branch1 does not need backward computation.
I0311 23:08:53.867511 17663 net.cpp:228] res2a_branch1 does not need backward computation.
I0311 23:08:53.867514 17663 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0311 23:08:53.867517 17663 net.cpp:228] pool1 does not need backward computation.
I0311 23:08:53.867521 17663 net.cpp:228] conv1_relu does not need backward computation.
I0311 23:08:53.867523 17663 net.cpp:228] scale_conv1 does not need backward computation.
I0311 23:08:53.867525 17663 net.cpp:228] bn_conv1 does not need backward computation.
I0311 23:08:53.867528 17663 net.cpp:228] conv1 does not need backward computation.
I0311 23:08:53.867532 17663 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0311 23:08:53.867535 17663 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0311 23:08:53.867552 17663 net.cpp:228] data_input-data_0_split does not need backward computation.
I0311 23:08:53.867557 17663 net.cpp:228] input-data does not need backward computation.
I0311 23:08:53.867558 17663 net.cpp:270] This network produces output accuarcy
I0311 23:08:53.867561 17663 net.cpp:270] This network produces output loss_bbox
I0311 23:08:53.867564 17663 net.cpp:270] This network produces output loss_cls
I0311 23:08:53.867566 17663 net.cpp:270] This network produces output rpn_cls_loss
I0311 23:08:53.867569 17663 net.cpp:270] This network produces output rpn_loss_bbox
I0311 23:08:53.867705 17663 net.cpp:283] Network initialization done.
I0311 23:08:53.868551 17663 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0311 23:08:53.945646 17663 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0311 23:08:53.945672 17663 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0311 23:08:53.945677 17663 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0311 23:08:53.945679 17663 net.cpp:774] Copying source layer conv1
I0311 23:08:53.945699 17663 net.cpp:774] Copying source layer bn_conv1
I0311 23:08:53.945703 17663 net.cpp:774] Copying source layer scale_conv1
I0311 23:08:53.945708 17663 net.cpp:774] Copying source layer conv1_relu
I0311 23:08:53.945710 17663 net.cpp:774] Copying source layer pool1
I0311 23:08:53.945713 17663 net.cpp:774] Copying source layer pool1_pool1_0_split
I0311 23:08:53.945714 17663 net.cpp:774] Copying source layer res2a_branch1
I0311 23:08:53.945740 17663 net.cpp:774] Copying source layer bn2a_branch1
I0311 23:08:53.945747 17663 net.cpp:774] Copying source layer scale2a_branch1
I0311 23:08:53.945766 17663 net.cpp:774] Copying source layer res2a_branch2a
I0311 23:08:53.945777 17663 net.cpp:774] Copying source layer bn2a_branch2a
I0311 23:08:53.945781 17663 net.cpp:774] Copying source layer scale2a_branch2a
I0311 23:08:53.945785 17663 net.cpp:774] Copying source layer res2a_branch2a_relu
I0311 23:08:53.945787 17663 net.cpp:774] Copying source layer res2a_branch2b
I0311 23:08:53.945837 17663 net.cpp:774] Copying source layer bn2a_branch2b
I0311 23:08:53.945842 17663 net.cpp:774] Copying source layer scale2a_branch2b
I0311 23:08:53.945845 17663 net.cpp:774] Copying source layer res2a_branch2b_relu
I0311 23:08:53.945848 17663 net.cpp:774] Copying source layer res2a_branch2c
I0311 23:08:53.945870 17663 net.cpp:774] Copying source layer bn2a_branch2c
I0311 23:08:53.945876 17663 net.cpp:774] Copying source layer scale2a_branch2c
I0311 23:08:53.945880 17663 net.cpp:774] Copying source layer res2a
I0311 23:08:53.945883 17663 net.cpp:774] Copying source layer res2a_relu
I0311 23:08:53.945885 17663 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0311 23:08:53.945888 17663 net.cpp:774] Copying source layer res2b_branch2a
I0311 23:08:53.945922 17663 net.cpp:774] Copying source layer bn2b_branch2a
I0311 23:08:53.945927 17663 net.cpp:774] Copying source layer scale2b_branch2a
I0311 23:08:53.945931 17663 net.cpp:774] Copying source layer res2b_branch2a_relu
I0311 23:08:53.945933 17663 net.cpp:774] Copying source layer res2b_branch2b
I0311 23:08:53.945981 17663 net.cpp:774] Copying source layer bn2b_branch2b
I0311 23:08:53.945986 17663 net.cpp:774] Copying source layer scale2b_branch2b
I0311 23:08:53.945991 17663 net.cpp:774] Copying source layer res2b_branch2b_relu
I0311 23:08:53.945992 17663 net.cpp:774] Copying source layer res2b_branch2c
I0311 23:08:53.946022 17663 net.cpp:774] Copying source layer bn2b_branch2c
I0311 23:08:53.946027 17663 net.cpp:774] Copying source layer scale2b_branch2c
I0311 23:08:53.946033 17663 net.cpp:774] Copying source layer res2b
I0311 23:08:53.946034 17663 net.cpp:774] Copying source layer res2b_relu
I0311 23:08:53.946036 17663 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0311 23:08:53.946039 17663 net.cpp:774] Copying source layer res2c_branch2a
I0311 23:08:53.946060 17663 net.cpp:774] Copying source layer bn2c_branch2a
I0311 23:08:53.946065 17663 net.cpp:774] Copying source layer scale2c_branch2a
I0311 23:08:53.946069 17663 net.cpp:774] Copying source layer res2c_branch2a_relu
I0311 23:08:53.946071 17663 net.cpp:774] Copying source layer res2c_branch2b
I0311 23:08:53.946113 17663 net.cpp:774] Copying source layer bn2c_branch2b
I0311 23:08:53.946120 17663 net.cpp:774] Copying source layer scale2c_branch2b
I0311 23:08:53.946122 17663 net.cpp:774] Copying source layer res2c_branch2b_relu
I0311 23:08:53.946125 17663 net.cpp:774] Copying source layer res2c_branch2c
I0311 23:08:53.946148 17663 net.cpp:774] Copying source layer bn2c_branch2c
I0311 23:08:53.946153 17663 net.cpp:774] Copying source layer scale2c_branch2c
I0311 23:08:53.946157 17663 net.cpp:774] Copying source layer res2c
I0311 23:08:53.946161 17663 net.cpp:774] Copying source layer res2c_relu
I0311 23:08:53.946164 17663 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0311 23:08:53.946166 17663 net.cpp:774] Copying source layer res3a_branch1
I0311 23:08:53.946326 17663 net.cpp:774] Copying source layer bn3a_branch1
I0311 23:08:53.946334 17663 net.cpp:774] Copying source layer scale3a_branch1
I0311 23:08:53.946339 17663 net.cpp:774] Copying source layer res3a_branch2a
I0311 23:08:53.946382 17663 net.cpp:774] Copying source layer bn3a_branch2a
I0311 23:08:53.946386 17663 net.cpp:774] Copying source layer scale3a_branch2a
I0311 23:08:53.946390 17663 net.cpp:774] Copying source layer res3a_branch2a_relu
I0311 23:08:53.946393 17663 net.cpp:774] Copying source layer res3a_branch2b
I0311 23:08:53.946588 17663 net.cpp:774] Copying source layer bn3a_branch2b
I0311 23:08:53.946594 17663 net.cpp:774] Copying source layer scale3a_branch2b
I0311 23:08:53.946599 17663 net.cpp:774] Copying source layer res3a_branch2b_relu
I0311 23:08:53.946602 17663 net.cpp:774] Copying source layer res3a_branch2c
I0311 23:08:53.946682 17663 net.cpp:774] Copying source layer bn3a_branch2c
I0311 23:08:53.946689 17663 net.cpp:774] Copying source layer scale3a_branch2c
I0311 23:08:53.946694 17663 net.cpp:774] Copying source layer res3a
I0311 23:08:53.946697 17663 net.cpp:774] Copying source layer res3a_relu
I0311 23:08:53.946701 17663 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0311 23:08:53.946702 17663 net.cpp:774] Copying source layer res3b_branch2a
I0311 23:08:53.946782 17663 net.cpp:774] Copying source layer bn3b_branch2a
I0311 23:08:53.946789 17663 net.cpp:774] Copying source layer scale3b_branch2a
I0311 23:08:53.946792 17663 net.cpp:774] Copying source layer res3b_branch2a_relu
I0311 23:08:53.946795 17663 net.cpp:774] Copying source layer res3b_branch2b
I0311 23:08:53.946979 17663 net.cpp:774] Copying source layer bn3b_branch2b
I0311 23:08:53.946985 17663 net.cpp:774] Copying source layer scale3b_branch2b
I0311 23:08:53.946990 17663 net.cpp:774] Copying source layer res3b_branch2b_relu
I0311 23:08:53.946991 17663 net.cpp:774] Copying source layer res3b_branch2c
I0311 23:08:53.947067 17663 net.cpp:774] Copying source layer bn3b_branch2c
I0311 23:08:53.947074 17663 net.cpp:774] Copying source layer scale3b_branch2c
I0311 23:08:53.947079 17663 net.cpp:774] Copying source layer res3b
I0311 23:08:53.947082 17663 net.cpp:774] Copying source layer res3b_relu
I0311 23:08:53.947085 17663 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0311 23:08:53.947088 17663 net.cpp:774] Copying source layer res3c_branch2a
I0311 23:08:53.947162 17663 net.cpp:774] Copying source layer bn3c_branch2a
I0311 23:08:53.947170 17663 net.cpp:774] Copying source layer scale3c_branch2a
I0311 23:08:53.947172 17663 net.cpp:774] Copying source layer res3c_branch2a_relu
I0311 23:08:53.947175 17663 net.cpp:774] Copying source layer res3c_branch2b
I0311 23:08:53.947347 17663 net.cpp:774] Copying source layer bn3c_branch2b
I0311 23:08:53.947353 17663 net.cpp:774] Copying source layer scale3c_branch2b
I0311 23:08:53.947357 17663 net.cpp:774] Copying source layer res3c_branch2b_relu
I0311 23:08:53.947360 17663 net.cpp:774] Copying source layer res3c_branch2c
I0311 23:08:53.947438 17663 net.cpp:774] Copying source layer bn3c_branch2c
I0311 23:08:53.947443 17663 net.cpp:774] Copying source layer scale3c_branch2c
I0311 23:08:53.947448 17663 net.cpp:774] Copying source layer res3c
I0311 23:08:53.947453 17663 net.cpp:774] Copying source layer res3c_relu
I0311 23:08:53.947455 17663 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0311 23:08:53.947458 17663 net.cpp:774] Copying source layer res3d_branch2a
I0311 23:08:53.947531 17663 net.cpp:774] Copying source layer bn3d_branch2a
I0311 23:08:53.947537 17663 net.cpp:774] Copying source layer scale3d_branch2a
I0311 23:08:53.947541 17663 net.cpp:774] Copying source layer res3d_branch2a_relu
I0311 23:08:53.947544 17663 net.cpp:774] Copying source layer res3d_branch2b
I0311 23:08:53.947721 17663 net.cpp:774] Copying source layer bn3d_branch2b
I0311 23:08:53.947726 17663 net.cpp:774] Copying source layer scale3d_branch2b
I0311 23:08:53.947731 17663 net.cpp:774] Copying source layer res3d_branch2b_relu
I0311 23:08:53.947732 17663 net.cpp:774] Copying source layer res3d_branch2c
I0311 23:08:53.947810 17663 net.cpp:774] Copying source layer bn3d_branch2c
I0311 23:08:53.947818 17663 net.cpp:774] Copying source layer scale3d_branch2c
I0311 23:08:53.947823 17663 net.cpp:774] Copying source layer res3d
I0311 23:08:53.947825 17663 net.cpp:774] Copying source layer res3d_relu
I0311 23:08:53.947829 17663 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0311 23:08:53.947831 17663 net.cpp:774] Copying source layer res4a_branch1
I0311 23:08:53.948485 17663 net.cpp:774] Copying source layer bn4a_branch1
I0311 23:08:53.948495 17663 net.cpp:774] Copying source layer scale4a_branch1
I0311 23:08:53.948500 17663 net.cpp:774] Copying source layer res4a_branch2a
I0311 23:08:53.948658 17663 net.cpp:774] Copying source layer bn4a_branch2a
I0311 23:08:53.948665 17663 net.cpp:774] Copying source layer scale4a_branch2a
I0311 23:08:53.948670 17663 net.cpp:774] Copying source layer res4a_branch2a_relu
I0311 23:08:53.948674 17663 net.cpp:774] Copying source layer res4a_branch2b
I0311 23:08:53.949396 17663 net.cpp:774] Copying source layer bn4a_branch2b
I0311 23:08:53.949407 17663 net.cpp:774] Copying source layer scale4a_branch2b
I0311 23:08:53.949412 17663 net.cpp:774] Copying source layer res4a_branch2b_relu
I0311 23:08:53.949415 17663 net.cpp:774] Copying source layer res4a_branch2c
I0311 23:08:53.949728 17663 net.cpp:774] Copying source layer bn4a_branch2c
I0311 23:08:53.949736 17663 net.cpp:774] Copying source layer scale4a_branch2c
I0311 23:08:53.949741 17663 net.cpp:774] Copying source layer res4a
I0311 23:08:53.949745 17663 net.cpp:774] Copying source layer res4a_relu
I0311 23:08:53.949749 17663 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0311 23:08:53.949751 17663 net.cpp:774] Copying source layer res4b_branch2a
I0311 23:08:53.950072 17663 net.cpp:774] Copying source layer bn4b_branch2a
I0311 23:08:53.950079 17663 net.cpp:774] Copying source layer scale4b_branch2a
I0311 23:08:53.950084 17663 net.cpp:774] Copying source layer res4b_branch2a_relu
I0311 23:08:53.950088 17663 net.cpp:774] Copying source layer res4b_branch2b
I0311 23:08:53.950803 17663 net.cpp:774] Copying source layer bn4b_branch2b
I0311 23:08:53.950814 17663 net.cpp:774] Copying source layer scale4b_branch2b
I0311 23:08:53.950819 17663 net.cpp:774] Copying source layer res4b_branch2b_relu
I0311 23:08:53.950821 17663 net.cpp:774] Copying source layer res4b_branch2c
I0311 23:08:53.951150 17663 net.cpp:774] Copying source layer bn4b_branch2c
I0311 23:08:53.951159 17663 net.cpp:774] Copying source layer scale4b_branch2c
I0311 23:08:53.951165 17663 net.cpp:774] Copying source layer res4b
I0311 23:08:53.951169 17663 net.cpp:774] Copying source layer res4b_relu
I0311 23:08:53.951174 17663 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0311 23:08:53.951175 17663 net.cpp:774] Copying source layer res4c_branch2a
I0311 23:08:53.951493 17663 net.cpp:774] Copying source layer bn4c_branch2a
I0311 23:08:53.951500 17663 net.cpp:774] Copying source layer scale4c_branch2a
I0311 23:08:53.951505 17663 net.cpp:774] Copying source layer res4c_branch2a_relu
I0311 23:08:53.951509 17663 net.cpp:774] Copying source layer res4c_branch2b
I0311 23:08:53.952198 17663 net.cpp:774] Copying source layer bn4c_branch2b
I0311 23:08:53.952206 17663 net.cpp:774] Copying source layer scale4c_branch2b
I0311 23:08:53.952210 17663 net.cpp:774] Copying source layer res4c_branch2b_relu
I0311 23:08:53.952214 17663 net.cpp:774] Copying source layer res4c_branch2c
I0311 23:08:53.952473 17663 net.cpp:774] Copying source layer bn4c_branch2c
I0311 23:08:53.952481 17663 net.cpp:774] Copying source layer scale4c_branch2c
I0311 23:08:53.952486 17663 net.cpp:774] Copying source layer res4c
I0311 23:08:53.952491 17663 net.cpp:774] Copying source layer res4c_relu
I0311 23:08:53.952493 17663 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0311 23:08:53.952495 17663 net.cpp:774] Copying source layer res4d_branch2a
I0311 23:08:53.952775 17663 net.cpp:774] Copying source layer bn4d_branch2a
I0311 23:08:53.952781 17663 net.cpp:774] Copying source layer scale4d_branch2a
I0311 23:08:53.952787 17663 net.cpp:774] Copying source layer res4d_branch2a_relu
I0311 23:08:53.952790 17663 net.cpp:774] Copying source layer res4d_branch2b
I0311 23:08:53.953433 17663 net.cpp:774] Copying source layer bn4d_branch2b
I0311 23:08:53.953440 17663 net.cpp:774] Copying source layer scale4d_branch2b
I0311 23:08:53.953445 17663 net.cpp:774] Copying source layer res4d_branch2b_relu
I0311 23:08:53.953449 17663 net.cpp:774] Copying source layer res4d_branch2c
I0311 23:08:53.953770 17663 net.cpp:774] Copying source layer bn4d_branch2c
I0311 23:08:53.953778 17663 net.cpp:774] Copying source layer scale4d_branch2c
I0311 23:08:53.953784 17663 net.cpp:774] Copying source layer res4d
I0311 23:08:53.953788 17663 net.cpp:774] Copying source layer res4d_relu
I0311 23:08:53.953790 17663 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0311 23:08:53.953794 17663 net.cpp:774] Copying source layer res4e_branch2a
I0311 23:08:53.954126 17663 net.cpp:774] Copying source layer bn4e_branch2a
I0311 23:08:53.954134 17663 net.cpp:774] Copying source layer scale4e_branch2a
I0311 23:08:53.954140 17663 net.cpp:774] Copying source layer res4e_branch2a_relu
I0311 23:08:53.954144 17663 net.cpp:774] Copying source layer res4e_branch2b
I0311 23:08:53.954881 17663 net.cpp:774] Copying source layer bn4e_branch2b
I0311 23:08:53.954890 17663 net.cpp:774] Copying source layer scale4e_branch2b
I0311 23:08:53.954895 17663 net.cpp:774] Copying source layer res4e_branch2b_relu
I0311 23:08:53.954896 17663 net.cpp:774] Copying source layer res4e_branch2c
I0311 23:08:53.955233 17663 net.cpp:774] Copying source layer bn4e_branch2c
I0311 23:08:53.955242 17663 net.cpp:774] Copying source layer scale4e_branch2c
I0311 23:08:53.955248 17663 net.cpp:774] Copying source layer res4e
I0311 23:08:53.955251 17663 net.cpp:774] Copying source layer res4e_relu
I0311 23:08:53.955255 17663 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0311 23:08:53.955257 17663 net.cpp:774] Copying source layer res4f_branch2a
I0311 23:08:53.955588 17663 net.cpp:774] Copying source layer bn4f_branch2a
I0311 23:08:53.955595 17663 net.cpp:774] Copying source layer scale4f_branch2a
I0311 23:08:53.955600 17663 net.cpp:774] Copying source layer res4f_branch2a_relu
I0311 23:08:53.955602 17663 net.cpp:774] Copying source layer res4f_branch2b
I0311 23:08:53.956333 17663 net.cpp:774] Copying source layer bn4f_branch2b
I0311 23:08:53.956341 17663 net.cpp:774] Copying source layer scale4f_branch2b
I0311 23:08:53.956346 17663 net.cpp:774] Copying source layer res4f_branch2b_relu
I0311 23:08:53.956349 17663 net.cpp:774] Copying source layer res4f_branch2c
I0311 23:08:53.956723 17663 net.cpp:774] Copying source layer bn4f_branch2c
I0311 23:08:53.956733 17663 net.cpp:774] Copying source layer scale4f_branch2c
I0311 23:08:53.956739 17663 net.cpp:774] Copying source layer res4f
I0311 23:08:53.956743 17663 net.cpp:774] Copying source layer res4f_relu
I0311 23:08:53.956746 17663 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0311 23:08:53.956749 17663 net.cpp:774] Copying source layer res5a_branch1
I0311 23:08:53.959738 17663 net.cpp:774] Copying source layer bn5a_branch1
I0311 23:08:53.959760 17663 net.cpp:774] Copying source layer scale5a_branch1
I0311 23:08:53.959796 17663 net.cpp:774] Copying source layer res5a_branch2a
I0311 23:08:53.960448 17663 net.cpp:774] Copying source layer bn5a_branch2a
I0311 23:08:53.960463 17663 net.cpp:774] Copying source layer scale5a_branch2a
I0311 23:08:53.960469 17663 net.cpp:774] Copying source layer res5a_branch2a_relu
I0311 23:08:53.960472 17663 net.cpp:774] Copying source layer res5a_branch2b
I0311 23:08:53.963491 17663 net.cpp:774] Copying source layer bn5a_branch2b
I0311 23:08:53.963503 17663 net.cpp:774] Copying source layer scale5a_branch2b
I0311 23:08:53.963510 17663 net.cpp:774] Copying source layer res5a_branch2b_relu
I0311 23:08:53.963511 17663 net.cpp:774] Copying source layer res5a_branch2c
I0311 23:08:53.964367 17663 net.cpp:774] Copying source layer bn5a_branch2c
I0311 23:08:53.964385 17663 net.cpp:774] Copying source layer scale5a_branch2c
I0311 23:08:53.964392 17663 net.cpp:774] Copying source layer res5a
I0311 23:08:53.964395 17663 net.cpp:774] Copying source layer res5a_relu
I0311 23:08:53.964399 17663 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0311 23:08:53.964402 17663 net.cpp:774] Copying source layer res5b_branch2a
I0311 23:08:53.965611 17663 net.cpp:774] Copying source layer bn5b_branch2a
I0311 23:08:53.965629 17663 net.cpp:774] Copying source layer scale5b_branch2a
I0311 23:08:53.965636 17663 net.cpp:774] Copying source layer res5b_branch2a_relu
I0311 23:08:53.965638 17663 net.cpp:774] Copying source layer res5b_branch2b
I0311 23:08:53.969074 17663 net.cpp:774] Copying source layer bn5b_branch2b
I0311 23:08:53.969117 17663 net.cpp:774] Copying source layer scale5b_branch2b
I0311 23:08:53.969130 17663 net.cpp:774] Copying source layer res5b_branch2b_relu
I0311 23:08:53.969135 17663 net.cpp:774] Copying source layer res5b_branch2c
I0311 23:08:53.970911 17663 net.cpp:774] Copying source layer bn5b_branch2c
I0311 23:08:53.970927 17663 net.cpp:774] Copying source layer scale5b_branch2c
I0311 23:08:53.970935 17663 net.cpp:774] Copying source layer res5b
I0311 23:08:53.970938 17663 net.cpp:774] Copying source layer res5b_relu
I0311 23:08:53.970942 17663 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0311 23:08:53.970945 17663 net.cpp:774] Copying source layer res5c_branch2a
I0311 23:08:53.971897 17663 net.cpp:774] Copying source layer bn5c_branch2a
I0311 23:08:53.971909 17663 net.cpp:774] Copying source layer scale5c_branch2a
I0311 23:08:53.971915 17663 net.cpp:774] Copying source layer res5c_branch2a_relu
I0311 23:08:53.971918 17663 net.cpp:774] Copying source layer res5c_branch2b
I0311 23:08:53.974706 17663 net.cpp:774] Copying source layer bn5c_branch2b
I0311 23:08:53.974721 17663 net.cpp:774] Copying source layer scale5c_branch2b
I0311 23:08:53.974727 17663 net.cpp:774] Copying source layer res5c_branch2b_relu
I0311 23:08:53.974730 17663 net.cpp:774] Copying source layer res5c_branch2c
I0311 23:08:53.975831 17663 net.cpp:774] Copying source layer bn5c_branch2c
I0311 23:08:53.975845 17663 net.cpp:774] Copying source layer scale5c_branch2c
I0311 23:08:53.975853 17663 net.cpp:774] Copying source layer res5c
I0311 23:08:53.975857 17663 net.cpp:774] Copying source layer res5c_relu
I0311 23:08:53.975860 17663 net.cpp:771] Ignoring source layer pool5
I0311 23:08:53.975862 17663 net.cpp:771] Ignoring source layer fc1000
I0311 23:08:53.975865 17663 net.cpp:771] Ignoring source layer prob
Solving...
I0311 23:08:55.270756 17663 solver.cpp:228] Iteration 0, loss = 1.64045
I0311 23:08:55.270794 17663 solver.cpp:244]     Train net output #0: accuarcy = 0
I0311 23:08:55.270802 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0 (* 1 = 0 loss)
I0311 23:08:55.270820 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.704975 (* 1 = 0.704975 loss)
I0311 23:08:55.270824 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.681106 (* 1 = 0.681106 loss)
I0311 23:08:55.270843 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.504879 (* 1 = 0.504879 loss)
I0311 23:08:55.270846 17663 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0311 23:09:45.692140 17663 solver.cpp:228] Iteration 100, loss = 0.450747
I0311 23:09:45.692162 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0311 23:09:45.692169 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815578 (* 1 = 0.0815578 loss)
I0311 23:09:45.692188 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183416 (* 1 = 0.183416 loss)
I0311 23:09:45.692193 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0886878 (* 1 = 0.0886878 loss)
I0311 23:09:45.692196 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.166019 (* 1 = 0.166019 loss)
I0311 23:09:45.692214 17663 sgd_solver.cpp:106] Iteration 100, lr = 0.001
/home/fan/Rfcn/tools/../lib/fast_rcnn/bbox_transform.py:24: RuntimeWarning: invalid value encountered in log
  targets_dh = np.log(gt_heights / ex_heights)
I0311 23:10:36.851258 17663 solver.cpp:228] Iteration 200, loss = 0.600524
I0311 23:10:36.851279 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0311 23:10:36.851286 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.137779 (* 1 = 0.137779 loss)
I0311 23:10:36.851305 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.273674 (* 1 = 0.273674 loss)
I0311 23:10:36.851310 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.113765 (* 1 = 0.113765 loss)
I0311 23:10:36.851315 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.163972 (* 1 = 0.163972 loss)
I0311 23:10:36.851318 17663 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0311 23:11:28.981912 17663 solver.cpp:228] Iteration 300, loss = 0.963879
I0311 23:11:28.981933 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0311 23:11:28.981941 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.504475 (* 1 = 0.504475 loss)
I0311 23:11:28.981959 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.50715 (* 1 = 0.50715 loss)
I0311 23:11:28.981964 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0368159 (* 1 = 0.0368159 loss)
I0311 23:11:28.981981 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.154816 (* 1 = 0.154816 loss)
I0311 23:11:28.981986 17663 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0311 23:12:21.197043 17663 solver.cpp:228] Iteration 400, loss = 1.25409
I0311 23:12:21.197064 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0311 23:12:21.197072 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.222237 (* 1 = 0.222237 loss)
I0311 23:12:21.197091 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.329853 (* 1 = 0.329853 loss)
I0311 23:12:21.197095 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.116619 (* 1 = 0.116619 loss)
I0311 23:12:21.197099 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110178 (* 1 = 0.110178 loss)
I0311 23:12:21.197116 17663 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0311 23:13:13.519073 17663 solver.cpp:228] Iteration 500, loss = 0.263039
I0311 23:13:13.519096 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0311 23:13:13.519104 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0789601 (* 1 = 0.0789601 loss)
I0311 23:13:13.519122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123687 (* 1 = 0.123687 loss)
I0311 23:13:13.519126 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296307 (* 1 = 0.0296307 loss)
I0311 23:13:13.519130 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0845895 (* 1 = 0.0845895 loss)
I0311 23:13:13.519135 17663 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0311 23:14:04.978900 17663 solver.cpp:228] Iteration 600, loss = 0.515698
I0311 23:14:04.978924 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0311 23:14:04.978931 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13488 (* 1 = 0.13488 loss)
I0311 23:14:04.978950 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.240421 (* 1 = 0.240421 loss)
I0311 23:14:04.978955 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0945649 (* 1 = 0.0945649 loss)
I0311 23:14:04.978960 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.077115 (* 1 = 0.077115 loss)
I0311 23:14:04.978963 17663 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0311 23:14:57.317665 17663 solver.cpp:228] Iteration 700, loss = 1.88881
I0311 23:14:57.317687 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0311 23:14:57.317694 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.253885 (* 1 = 0.253885 loss)
I0311 23:14:57.317713 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.5502 (* 1 = 0.5502 loss)
I0311 23:14:57.317716 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.261752 (* 1 = 0.261752 loss)
I0311 23:14:57.317720 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 1.88079 (* 1 = 1.88079 loss)
I0311 23:14:57.317739 17663 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0311 23:15:49.577730 17663 solver.cpp:228] Iteration 800, loss = 0.963125
I0311 23:15:49.577751 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0311 23:15:49.577759 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0158012 (* 1 = 0.0158012 loss)
I0311 23:15:49.577778 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0930454 (* 1 = 0.0930454 loss)
I0311 23:15:49.577782 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.400634 (* 1 = 0.400634 loss)
I0311 23:15:49.577786 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.997041 (* 1 = 0.997041 loss)
I0311 23:15:49.577803 17663 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0311 23:16:41.651257 17663 solver.cpp:228] Iteration 900, loss = 0.558287
I0311 23:16:41.651278 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0311 23:16:41.651285 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124014 (* 1 = 0.124014 loss)
I0311 23:16:41.651289 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102603 (* 1 = 0.102603 loss)
I0311 23:16:41.651309 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0278595 (* 1 = 0.0278595 loss)
I0311 23:16:41.651312 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.078764 (* 1 = 0.078764 loss)
I0311 23:16:41.651316 17663 sgd_solver.cpp:106] Iteration 900, lr = 0.001
speed: 0.519s / iter
I0311 23:17:33.950712 17663 solver.cpp:228] Iteration 1000, loss = 0.468153
I0311 23:17:33.950861 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:17:33.950919 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.255898 (* 1 = 0.255898 loss)
I0311 23:17:33.950966 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.254366 (* 1 = 0.254366 loss)
I0311 23:17:33.951014 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024522 (* 1 = 0.024522 loss)
I0311 23:17:33.951061 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0607642 (* 1 = 0.0607642 loss)
I0311 23:17:33.951107 17663 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0311 23:18:26.935708 17663 solver.cpp:228] Iteration 1100, loss = 0.494801
I0311 23:18:26.935730 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0311 23:18:26.935739 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.216101 (* 1 = 0.216101 loss)
I0311 23:18:26.935742 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.292445 (* 1 = 0.292445 loss)
I0311 23:18:26.935760 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0283534 (* 1 = 0.0283534 loss)
I0311 23:18:26.935765 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113093 (* 1 = 0.113093 loss)
I0311 23:18:26.935770 17663 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0311 23:19:19.517439 17663 solver.cpp:228] Iteration 1200, loss = 0.438179
I0311 23:19:19.517462 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0311 23:19:19.517470 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574893 (* 1 = 0.0574893 loss)
I0311 23:19:19.517489 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133373 (* 1 = 0.133373 loss)
I0311 23:19:19.517494 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0500311 (* 1 = 0.0500311 loss)
I0311 23:19:19.517511 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0932314 (* 1 = 0.0932314 loss)
I0311 23:19:19.517515 17663 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0311 23:20:12.220904 17663 solver.cpp:228] Iteration 1300, loss = 0.802531
I0311 23:20:12.220927 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0311 23:20:12.220933 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.31702 (* 1 = 0.31702 loss)
I0311 23:20:12.220950 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.448306 (* 1 = 0.448306 loss)
I0311 23:20:12.220955 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.115175 (* 1 = 0.115175 loss)
I0311 23:20:12.220959 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.322919 (* 1 = 0.322919 loss)
I0311 23:20:12.220964 17663 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0311 23:21:04.325371 17663 solver.cpp:228] Iteration 1400, loss = 0.792662
I0311 23:21:04.325393 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0311 23:21:04.325400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.213308 (* 1 = 0.213308 loss)
I0311 23:21:04.325405 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.324196 (* 1 = 0.324196 loss)
I0311 23:21:04.325408 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0733426 (* 1 = 0.0733426 loss)
I0311 23:21:04.325413 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109962 (* 1 = 0.109962 loss)
I0311 23:21:04.325431 17663 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0311 23:21:56.912204 17663 solver.cpp:228] Iteration 1500, loss = 0.508745
I0311 23:21:56.912226 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0311 23:21:56.912233 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.086503 (* 1 = 0.086503 loss)
I0311 23:21:56.912253 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149382 (* 1 = 0.149382 loss)
I0311 23:21:56.912257 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.073763 (* 1 = 0.073763 loss)
I0311 23:21:56.912276 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0986807 (* 1 = 0.0986807 loss)
I0311 23:21:56.912281 17663 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0311 23:22:49.515326 17663 solver.cpp:228] Iteration 1600, loss = 0.333038
I0311 23:22:49.515348 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0311 23:22:49.515357 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758197 (* 1 = 0.0758197 loss)
I0311 23:22:49.515375 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.205088 (* 1 = 0.205088 loss)
I0311 23:22:49.515379 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0386133 (* 1 = 0.0386133 loss)
I0311 23:22:49.515384 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00970013 (* 1 = 0.00970013 loss)
I0311 23:22:49.515388 17663 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0311 23:23:41.569924 17663 solver.cpp:228] Iteration 1700, loss = 0.309488
I0311 23:23:41.569962 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:23:41.569968 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657014 (* 1 = 0.0657014 loss)
I0311 23:23:41.569988 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.206691 (* 1 = 0.206691 loss)
I0311 23:23:41.569993 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00902063 (* 1 = 0.00902063 loss)
I0311 23:23:41.569996 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102333 (* 1 = 0.0102333 loss)
I0311 23:23:41.570014 17663 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0311 23:24:33.297822 17663 solver.cpp:228] Iteration 1800, loss = 0.427702
I0311 23:24:33.297843 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0311 23:24:33.297852 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627477 (* 1 = 0.0627477 loss)
I0311 23:24:33.297870 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.119121 (* 1 = 0.119121 loss)
I0311 23:24:33.297874 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0572289 (* 1 = 0.0572289 loss)
I0311 23:24:33.297878 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102065 (* 1 = 0.102065 loss)
I0311 23:24:33.297883 17663 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0311 23:25:25.401355 17663 solver.cpp:228] Iteration 1900, loss = 0.410164
I0311 23:25:25.401376 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0311 23:25:25.401383 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.138278 (* 1 = 0.138278 loss)
I0311 23:25:25.401402 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.246984 (* 1 = 0.246984 loss)
I0311 23:25:25.401407 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.126735 (* 1 = 0.126735 loss)
I0311 23:25:25.401410 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0674662 (* 1 = 0.0674662 loss)
I0311 23:25:25.401415 17663 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
speed: 0.521s / iter
I0311 23:26:17.145424 17663 solver.cpp:228] Iteration 2000, loss = 0.273247
I0311 23:26:17.145447 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0311 23:26:17.145454 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0507159 (* 1 = 0.0507159 loss)
I0311 23:26:17.145458 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0505667 (* 1 = 0.0505667 loss)
I0311 23:26:17.145463 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0359661 (* 1 = 0.0359661 loss)
I0311 23:26:17.145480 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117986 (* 1 = 0.117986 loss)
I0311 23:26:17.145485 17663 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0311 23:27:09.920001 17663 solver.cpp:228] Iteration 2100, loss = 0.287713
I0311 23:27:09.920023 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0311 23:27:09.920030 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.129815 (* 1 = 0.129815 loss)
I0311 23:27:09.920050 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121576 (* 1 = 0.121576 loss)
I0311 23:27:09.920054 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241664 (* 1 = 0.0241664 loss)
I0311 23:27:09.920058 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198712 (* 1 = 0.0198712 loss)
I0311 23:27:09.920063 17663 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0311 23:28:02.850554 17663 solver.cpp:228] Iteration 2200, loss = 0.581487
I0311 23:28:02.850575 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0311 23:28:02.850582 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822746 (* 1 = 0.0822746 loss)
I0311 23:28:02.850587 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.230835 (* 1 = 0.230835 loss)
I0311 23:28:02.850606 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0815507 (* 1 = 0.0815507 loss)
I0311 23:28:02.850610 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.468404 (* 1 = 0.468404 loss)
I0311 23:28:02.850615 17663 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0311 23:28:55.290837 17663 solver.cpp:228] Iteration 2300, loss = 0.325062
I0311 23:28:55.290858 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0311 23:28:55.290865 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.146245 (* 1 = 0.146245 loss)
I0311 23:28:55.290884 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121066 (* 1 = 0.121066 loss)
I0311 23:28:55.290887 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105016 (* 1 = 0.0105016 loss)
I0311 23:28:55.290892 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421811 (* 1 = 0.0421811 loss)
I0311 23:28:55.290910 17663 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0311 23:29:47.874414 17663 solver.cpp:228] Iteration 2400, loss = 0.613086
I0311 23:29:47.874436 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:29:47.874444 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.174488 (* 1 = 0.174488 loss)
I0311 23:29:47.874464 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.325453 (* 1 = 0.325453 loss)
I0311 23:29:47.874467 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.137765 (* 1 = 0.137765 loss)
I0311 23:29:47.874471 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153855 (* 1 = 0.153855 loss)
I0311 23:29:47.874475 17663 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0311 23:30:40.477032 17663 solver.cpp:228] Iteration 2500, loss = 0.439803
I0311 23:30:40.477053 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0311 23:30:40.477061 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.120861 (* 1 = 0.120861 loss)
I0311 23:30:40.477080 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165222 (* 1 = 0.165222 loss)
I0311 23:30:40.477085 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245386 (* 1 = 0.0245386 loss)
I0311 23:30:40.477089 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117141 (* 1 = 0.117141 loss)
I0311 23:30:40.477093 17663 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0311 23:31:33.153782 17663 solver.cpp:228] Iteration 2600, loss = 0.633449
I0311 23:31:33.153805 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:31:33.153812 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116022 (* 1 = 0.116022 loss)
I0311 23:31:33.153831 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.230442 (* 1 = 0.230442 loss)
I0311 23:31:33.153836 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167316 (* 1 = 0.0167316 loss)
I0311 23:31:33.153852 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430832 (* 1 = 0.0430832 loss)
I0311 23:31:33.153856 17663 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0311 23:32:25.208618 17663 solver.cpp:228] Iteration 2700, loss = 0.486848
I0311 23:32:25.208638 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0311 23:32:25.208647 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.158262 (* 1 = 0.158262 loss)
I0311 23:32:25.208664 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.302702 (* 1 = 0.302702 loss)
I0311 23:32:25.208668 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274067 (* 1 = 0.0274067 loss)
I0311 23:32:25.208673 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0498163 (* 1 = 0.0498163 loss)
I0311 23:32:25.208690 17663 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0311 23:33:18.562471 17663 solver.cpp:228] Iteration 2800, loss = 0.425486
I0311 23:33:18.562494 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:33:18.562501 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.132414 (* 1 = 0.132414 loss)
I0311 23:33:18.562521 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196777 (* 1 = 0.196777 loss)
I0311 23:33:18.562525 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.041029 (* 1 = 0.041029 loss)
I0311 23:33:18.562530 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.275987 (* 1 = 0.275987 loss)
I0311 23:33:18.562533 17663 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0311 23:34:11.359453 17663 solver.cpp:228] Iteration 2900, loss = 0.582916
I0311 23:34:11.359475 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0311 23:34:11.359483 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.172431 (* 1 = 0.172431 loss)
I0311 23:34:11.359500 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.239844 (* 1 = 0.239844 loss)
I0311 23:34:11.359505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0496342 (* 1 = 0.0496342 loss)
I0311 23:34:11.359508 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.206665 (* 1 = 0.206665 loss)
I0311 23:34:11.359513 17663 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
speed: 0.523s / iter
I0311 23:35:03.472626 17663 solver.cpp:228] Iteration 3000, loss = 0.40577
I0311 23:35:03.472784 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0311 23:35:03.472841 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.198522 (* 1 = 0.198522 loss)
I0311 23:35:03.472888 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.286306 (* 1 = 0.286306 loss)
I0311 23:35:03.472935 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201722 (* 1 = 0.0201722 loss)
I0311 23:35:03.472981 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143604 (* 1 = 0.0143604 loss)
I0311 23:35:03.473027 17663 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0311 23:35:55.665050 17663 solver.cpp:228] Iteration 3100, loss = 0.589092
I0311 23:35:55.665091 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0311 23:35:55.665100 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.285402 (* 1 = 0.285402 loss)
I0311 23:35:55.665107 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.439479 (* 1 = 0.439479 loss)
I0311 23:35:55.665110 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.136331 (* 1 = 0.136331 loss)
I0311 23:35:55.665114 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.130311 (* 1 = 0.130311 loss)
I0311 23:35:55.665120 17663 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0311 23:36:48.263325 17663 solver.cpp:228] Iteration 3200, loss = 0.666633
I0311 23:36:48.263351 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0311 23:36:48.263358 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.205889 (* 1 = 0.205889 loss)
I0311 23:36:48.263377 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.337873 (* 1 = 0.337873 loss)
I0311 23:36:48.263382 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.138025 (* 1 = 0.138025 loss)
I0311 23:36:48.263386 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.142987 (* 1 = 0.142987 loss)
I0311 23:36:48.263391 17663 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0311 23:37:41.070236 17663 solver.cpp:228] Iteration 3300, loss = 1.34302
I0311 23:37:41.070260 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0311 23:37:41.070267 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.483874 (* 1 = 0.483874 loss)
I0311 23:37:41.070286 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.54449 (* 1 = 0.54449 loss)
I0311 23:37:41.070291 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.150999 (* 1 = 0.150999 loss)
I0311 23:37:41.070294 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124179 (* 1 = 0.124179 loss)
I0311 23:37:41.070299 17663 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0311 23:38:33.475790 17663 solver.cpp:228] Iteration 3400, loss = 0.491905
I0311 23:38:33.475811 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:38:33.475818 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.16281 (* 1 = 0.16281 loss)
I0311 23:38:33.475838 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219985 (* 1 = 0.219985 loss)
I0311 23:38:33.475842 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0376537 (* 1 = 0.0376537 loss)
I0311 23:38:33.475859 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.298776 (* 1 = 0.298776 loss)
I0311 23:38:33.475864 17663 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0311 23:39:26.212611 17663 solver.cpp:228] Iteration 3500, loss = 0.309929
I0311 23:39:26.212633 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0311 23:39:26.212641 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105805 (* 1 = 0.105805 loss)
I0311 23:39:26.212659 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135692 (* 1 = 0.135692 loss)
I0311 23:39:26.212663 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204494 (* 1 = 0.0204494 loss)
I0311 23:39:26.212667 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318311 (* 1 = 0.0318311 loss)
I0311 23:39:26.212671 17663 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0311 23:40:19.440194 17663 solver.cpp:228] Iteration 3600, loss = 0.309963
I0311 23:40:19.440214 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0311 23:40:19.440222 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0875148 (* 1 = 0.0875148 loss)
I0311 23:40:19.440240 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.119674 (* 1 = 0.119674 loss)
I0311 23:40:19.440244 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241824 (* 1 = 0.0241824 loss)
I0311 23:40:19.440249 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0462235 (* 1 = 0.0462235 loss)
I0311 23:40:19.440253 17663 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0311 23:41:11.919364 17663 solver.cpp:228] Iteration 3700, loss = 0.416091
I0311 23:41:11.919387 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0311 23:41:11.919395 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.047313 (* 1 = 0.047313 loss)
I0311 23:41:11.919414 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100131 (* 1 = 0.100131 loss)
I0311 23:41:11.919419 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00513496 (* 1 = 0.00513496 loss)
I0311 23:41:11.919422 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213883 (* 1 = 0.0213883 loss)
I0311 23:41:11.919427 17663 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0311 23:42:04.009593 17663 solver.cpp:228] Iteration 3800, loss = 0.442636
I0311 23:42:04.009616 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0311 23:42:04.009624 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0910725 (* 1 = 0.0910725 loss)
I0311 23:42:04.009644 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157932 (* 1 = 0.157932 loss)
I0311 23:42:04.009649 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00741842 (* 1 = 0.00741842 loss)
I0311 23:42:04.009666 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140688 (* 1 = 0.0140688 loss)
I0311 23:42:04.009671 17663 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0311 23:42:56.576817 17663 solver.cpp:228] Iteration 3900, loss = 0.57927
I0311 23:42:56.576841 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0311 23:42:56.576848 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.167157 (* 1 = 0.167157 loss)
I0311 23:42:56.576869 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.24347 (* 1 = 0.24347 loss)
I0311 23:42:56.576874 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323568 (* 1 = 0.0323568 loss)
I0311 23:42:56.576877 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102406 (* 1 = 0.102406 loss)
I0311 23:42:56.576882 17663 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
speed: 0.524s / iter
I0311 23:43:49.149358 17663 solver.cpp:228] Iteration 4000, loss = 1.06433
I0311 23:43:49.149523 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0311 23:43:49.149580 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.538345 (* 1 = 0.538345 loss)
I0311 23:43:49.149627 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.378822 (* 1 = 0.378822 loss)
I0311 23:43:49.149673 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.062002 (* 1 = 0.062002 loss)
I0311 23:43:49.149731 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0690434 (* 1 = 0.0690434 loss)
I0311 23:43:49.149780 17663 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0311 23:44:41.576887 17663 solver.cpp:228] Iteration 4100, loss = 0.333287
I0311 23:44:41.576915 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0311 23:44:41.576925 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815599 (* 1 = 0.0815599 loss)
I0311 23:44:41.576944 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146854 (* 1 = 0.146854 loss)
I0311 23:44:41.576948 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0428945 (* 1 = 0.0428945 loss)
I0311 23:44:41.576952 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100312 (* 1 = 0.100312 loss)
I0311 23:44:41.576958 17663 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0311 23:45:33.612713 17663 solver.cpp:228] Iteration 4200, loss = 0.366432
I0311 23:45:33.612735 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0311 23:45:33.612743 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0583853 (* 1 = 0.0583853 loss)
I0311 23:45:33.612761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.224026 (* 1 = 0.224026 loss)
I0311 23:45:33.612766 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148075 (* 1 = 0.0148075 loss)
I0311 23:45:33.612769 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116699 (* 1 = 0.0116699 loss)
I0311 23:45:33.612787 17663 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0311 23:46:26.354354 17663 solver.cpp:228] Iteration 4300, loss = 0.309727
I0311 23:46:26.354377 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0311 23:46:26.354384 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.095469 (* 1 = 0.095469 loss)
I0311 23:46:26.354388 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.290344 (* 1 = 0.290344 loss)
I0311 23:46:26.354408 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258554 (* 1 = 0.0258554 loss)
I0311 23:46:26.354411 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344875 (* 1 = 0.0344875 loss)
I0311 23:46:26.354416 17663 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0311 23:47:18.898697 17663 solver.cpp:228] Iteration 4400, loss = 0.63845
I0311 23:47:18.898721 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0311 23:47:18.898728 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.198867 (* 1 = 0.198867 loss)
I0311 23:47:18.898747 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.345582 (* 1 = 0.345582 loss)
I0311 23:47:18.898751 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0539515 (* 1 = 0.0539515 loss)
I0311 23:47:18.898756 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149187 (* 1 = 0.149187 loss)
I0311 23:47:18.898761 17663 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0311 23:48:11.468216 17663 solver.cpp:228] Iteration 4500, loss = 0.972425
I0311 23:48:11.468240 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0311 23:48:11.468247 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0978031 (* 1 = 0.0978031 loss)
I0311 23:48:11.468252 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.164753 (* 1 = 0.164753 loss)
I0311 23:48:11.468271 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0078585 (* 1 = 0.0078585 loss)
I0311 23:48:11.468274 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0634002 (* 1 = 0.0634002 loss)
I0311 23:48:11.468279 17663 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0311 23:49:04.409626 17663 solver.cpp:228] Iteration 4600, loss = 1.06324
I0311 23:49:04.409647 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0311 23:49:04.409656 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.510615 (* 1 = 0.510615 loss)
I0311 23:49:04.409659 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.688935 (* 1 = 0.688935 loss)
I0311 23:49:04.409678 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0715522 (* 1 = 0.0715522 loss)
I0311 23:49:04.409682 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117234 (* 1 = 0.117234 loss)
I0311 23:49:04.409687 17663 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0311 23:49:56.581341 17663 solver.cpp:228] Iteration 4700, loss = 0.406542
I0311 23:49:56.581362 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0311 23:49:56.581369 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.061634 (* 1 = 0.061634 loss)
I0311 23:49:56.581387 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165457 (* 1 = 0.165457 loss)
I0311 23:49:56.581393 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0072683 (* 1 = 0.0072683 loss)
I0311 23:49:56.581396 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0988156 (* 1 = 0.0988156 loss)
I0311 23:49:56.581401 17663 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0311 23:50:48.304778 17663 solver.cpp:228] Iteration 4800, loss = 0.662526
I0311 23:50:48.304802 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0311 23:50:48.304811 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.082265 (* 1 = 0.082265 loss)
I0311 23:50:48.304829 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106825 (* 1 = 0.106825 loss)
I0311 23:50:48.304833 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202501 (* 1 = 0.00202501 loss)
I0311 23:50:48.304850 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00378421 (* 1 = 0.00378421 loss)
I0311 23:50:48.304857 17663 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0311 23:51:41.065788 17663 solver.cpp:228] Iteration 4900, loss = 1.0365
I0311 23:51:41.065809 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0311 23:51:41.065816 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.496499 (* 1 = 0.496499 loss)
I0311 23:51:41.065821 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.546264 (* 1 = 0.546264 loss)
I0311 23:51:41.065840 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.225279 (* 1 = 0.225279 loss)
I0311 23:51:41.065843 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.451752 (* 1 = 0.451752 loss)
I0311 23:51:41.065847 17663 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
speed: 0.524s / iter
I0311 23:52:33.395216 17663 solver.cpp:228] Iteration 5000, loss = 0.386586
I0311 23:52:33.395364 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0311 23:52:33.395418 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355513 (* 1 = 0.0355513 loss)
I0311 23:52:33.395467 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168366 (* 1 = 0.168366 loss)
I0311 23:52:33.395514 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474117 (* 1 = 0.00474117 loss)
I0311 23:52:33.395560 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00493671 (* 1 = 0.00493671 loss)
I0311 23:52:33.395606 17663 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0311 23:53:25.661471 17663 solver.cpp:228] Iteration 5100, loss = 0.782093
I0311 23:53:25.661494 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0311 23:53:25.661502 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.408349 (* 1 = 0.408349 loss)
I0311 23:53:25.661521 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.485641 (* 1 = 0.485641 loss)
I0311 23:53:25.661525 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0936804 (* 1 = 0.0936804 loss)
I0311 23:53:25.661542 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.146221 (* 1 = 0.146221 loss)
I0311 23:53:25.661547 17663 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0311 23:54:18.166286 17663 solver.cpp:228] Iteration 5200, loss = 0.36858
I0311 23:54:18.166308 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0311 23:54:18.166316 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589649 (* 1 = 0.0589649 loss)
I0311 23:54:18.166335 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.154272 (* 1 = 0.154272 loss)
I0311 23:54:18.166339 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016242 (* 1 = 0.016242 loss)
I0311 23:54:18.166343 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293809 (* 1 = 0.0293809 loss)
I0311 23:54:18.166362 17663 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0311 23:55:10.378458 17663 solver.cpp:228] Iteration 5300, loss = 0.274003
I0311 23:55:10.378481 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0311 23:55:10.378489 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0785369 (* 1 = 0.0785369 loss)
I0311 23:55:10.378494 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180674 (* 1 = 0.180674 loss)
I0311 23:55:10.378512 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0467433 (* 1 = 0.0467433 loss)
I0311 23:55:10.378516 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0954353 (* 1 = 0.0954353 loss)
I0311 23:55:10.378521 17663 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0311 23:56:03.582799 17663 solver.cpp:228] Iteration 5400, loss = 0.49627
I0311 23:56:03.582820 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0311 23:56:03.582828 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855645 (* 1 = 0.0855645 loss)
I0311 23:56:03.582847 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.14083 (* 1 = 0.14083 loss)
I0311 23:56:03.582851 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172793 (* 1 = 0.0172793 loss)
I0311 23:56:03.582855 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0919394 (* 1 = 0.0919394 loss)
I0311 23:56:03.582860 17663 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0311 23:56:55.755311 17663 solver.cpp:228] Iteration 5500, loss = 1.20111
I0311 23:56:55.755347 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0311 23:56:55.755355 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10088 (* 1 = 0.10088 loss)
I0311 23:56:55.755374 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.257952 (* 1 = 0.257952 loss)
I0311 23:56:55.755378 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227207 (* 1 = 0.0227207 loss)
I0311 23:56:55.755394 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.169876 (* 1 = 0.169876 loss)
I0311 23:56:55.755400 17663 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0311 23:57:48.238294 17663 solver.cpp:228] Iteration 5600, loss = 0.833841
I0311 23:57:48.238315 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0311 23:57:48.238322 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.436107 (* 1 = 0.436107 loss)
I0311 23:57:48.238327 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.626365 (* 1 = 0.626365 loss)
I0311 23:57:48.238346 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.192378 (* 1 = 0.192378 loss)
I0311 23:57:48.238350 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168201 (* 1 = 0.168201 loss)
I0311 23:57:48.238355 17663 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0311 23:58:40.320489 17663 solver.cpp:228] Iteration 5700, loss = 0.56197
I0311 23:58:40.320510 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0311 23:58:40.320518 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0504934 (* 1 = 0.0504934 loss)
I0311 23:58:40.320536 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17351 (* 1 = 0.17351 loss)
I0311 23:58:40.320540 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276178 (* 1 = 0.0276178 loss)
I0311 23:58:40.320544 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.162438 (* 1 = 0.162438 loss)
I0311 23:58:40.320561 17663 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0311 23:59:32.456578 17663 solver.cpp:228] Iteration 5800, loss = 0.464501
I0311 23:59:32.456598 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0311 23:59:32.456606 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116972 (* 1 = 0.116972 loss)
I0311 23:59:32.456625 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.220636 (* 1 = 0.220636 loss)
I0311 23:59:32.456629 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0396511 (* 1 = 0.0396511 loss)
I0311 23:59:32.456646 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0835864 (* 1 = 0.0835864 loss)
I0311 23:59:32.456650 17663 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0312 00:00:24.977041 17663 solver.cpp:228] Iteration 5900, loss = 0.485433
I0312 00:00:24.977064 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 00:00:24.977084 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.23185 (* 1 = 0.23185 loss)
I0312 00:00:24.977089 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.256425 (* 1 = 0.256425 loss)
I0312 00:00:24.977093 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180771 (* 1 = 0.0180771 loss)
I0312 00:00:24.977113 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119834 (* 1 = 0.119834 loss)
I0312 00:00:24.977116 17663 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
speed: 0.524s / iter
I0312 00:01:18.098588 17663 solver.cpp:228] Iteration 6000, loss = 0.608091
I0312 00:01:18.098763 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 00:01:18.098820 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.284784 (* 1 = 0.284784 loss)
I0312 00:01:18.098870 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.405014 (* 1 = 0.405014 loss)
I0312 00:01:18.098917 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0475732 (* 1 = 0.0475732 loss)
I0312 00:01:18.098963 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.391815 (* 1 = 0.391815 loss)
I0312 00:01:18.099010 17663 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0312 00:02:10.581773 17663 solver.cpp:228] Iteration 6100, loss = 0.289286
I0312 00:02:10.581796 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 00:02:10.581804 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.100366 (* 1 = 0.100366 loss)
I0312 00:02:10.581823 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156642 (* 1 = 0.156642 loss)
I0312 00:02:10.581827 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111774 (* 1 = 0.0111774 loss)
I0312 00:02:10.581831 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300956 (* 1 = 0.0300956 loss)
I0312 00:02:10.581836 17663 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0312 00:03:03.253105 17663 solver.cpp:228] Iteration 6200, loss = 0.331881
I0312 00:03:03.253126 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 00:03:03.253134 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.14708 (* 1 = 0.14708 loss)
I0312 00:03:03.253152 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125276 (* 1 = 0.125276 loss)
I0312 00:03:03.253156 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0283665 (* 1 = 0.0283665 loss)
I0312 00:03:03.253160 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048365 (* 1 = 0.048365 loss)
I0312 00:03:03.253165 17663 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0312 00:03:55.414386 17663 solver.cpp:228] Iteration 6300, loss = 0.468176
I0312 00:03:55.414407 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 00:03:55.414413 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.162394 (* 1 = 0.162394 loss)
I0312 00:03:55.414433 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.27437 (* 1 = 0.27437 loss)
I0312 00:03:55.414438 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00735228 (* 1 = 0.00735228 loss)
I0312 00:03:55.414454 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0659601 (* 1 = 0.0659601 loss)
I0312 00:03:55.414458 17663 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0312 00:04:47.462345 17663 solver.cpp:228] Iteration 6400, loss = 0.458559
I0312 00:04:47.462365 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 00:04:47.462373 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.127604 (* 1 = 0.127604 loss)
I0312 00:04:47.462376 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.225598 (* 1 = 0.225598 loss)
I0312 00:04:47.462394 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0584567 (* 1 = 0.0584567 loss)
I0312 00:04:47.462399 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0831307 (* 1 = 0.0831307 loss)
I0312 00:04:47.462404 17663 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0312 00:05:39.627121 17663 solver.cpp:228] Iteration 6500, loss = 0.421745
I0312 00:05:39.627146 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 00:05:39.627153 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.145018 (* 1 = 0.145018 loss)
I0312 00:05:39.627158 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.175061 (* 1 = 0.175061 loss)
I0312 00:05:39.627162 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.028557 (* 1 = 0.028557 loss)
I0312 00:05:39.627166 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0684515 (* 1 = 0.0684515 loss)
I0312 00:05:39.627187 17663 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0312 00:06:32.109063 17663 solver.cpp:228] Iteration 6600, loss = 0.541071
I0312 00:06:32.109084 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 00:06:32.109091 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.174777 (* 1 = 0.174777 loss)
I0312 00:06:32.109110 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.324691 (* 1 = 0.324691 loss)
I0312 00:06:32.109114 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328253 (* 1 = 0.0328253 loss)
I0312 00:06:32.109118 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0694635 (* 1 = 0.0694635 loss)
I0312 00:06:32.109135 17663 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0312 00:07:25.288987 17663 solver.cpp:228] Iteration 6700, loss = 0.39453
I0312 00:07:25.289010 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:07:25.289016 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0859135 (* 1 = 0.0859135 loss)
I0312 00:07:25.289034 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144514 (* 1 = 0.144514 loss)
I0312 00:07:25.289039 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0457438 (* 1 = 0.0457438 loss)
I0312 00:07:25.289043 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.086186 (* 1 = 0.086186 loss)
I0312 00:07:25.289047 17663 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0312 00:08:18.501071 17663 solver.cpp:228] Iteration 6800, loss = 0.465767
I0312 00:08:18.501096 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:08:18.501103 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119628 (* 1 = 0.119628 loss)
I0312 00:08:18.501122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.212006 (* 1 = 0.212006 loss)
I0312 00:08:18.501127 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210504 (* 1 = 0.0210504 loss)
I0312 00:08:18.501132 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.074866 (* 1 = 0.074866 loss)
I0312 00:08:18.501135 17663 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0312 00:09:10.922205 17663 solver.cpp:228] Iteration 6900, loss = 0.387192
I0312 00:09:10.922226 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:09:10.922235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.075608 (* 1 = 0.075608 loss)
I0312 00:09:10.922253 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.166234 (* 1 = 0.166234 loss)
I0312 00:09:10.922257 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122492 (* 1 = 0.0122492 loss)
I0312 00:09:10.922261 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0540897 (* 1 = 0.0540897 loss)
I0312 00:09:10.922266 17663 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
speed: 0.524s / iter
I0312 00:10:03.017489 17663 solver.cpp:228] Iteration 7000, loss = 0.243187
I0312 00:10:03.017638 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:10:03.017695 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0695544 (* 1 = 0.0695544 loss)
I0312 00:10:03.017745 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.129842 (* 1 = 0.129842 loss)
I0312 00:10:03.017791 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196247 (* 1 = 0.0196247 loss)
I0312 00:10:03.017838 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0765421 (* 1 = 0.0765421 loss)
I0312 00:10:03.017884 17663 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0312 00:10:55.839138 17663 solver.cpp:228] Iteration 7100, loss = 0.280602
I0312 00:10:55.839159 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 00:10:55.839167 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0938299 (* 1 = 0.0938299 loss)
I0312 00:10:55.839186 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0789434 (* 1 = 0.0789434 loss)
I0312 00:10:55.839191 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018198 (* 1 = 0.018198 loss)
I0312 00:10:55.839195 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015112 (* 1 = 0.015112 loss)
I0312 00:10:55.839200 17663 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0312 00:11:48.074494 17663 solver.cpp:228] Iteration 7200, loss = 0.454922
I0312 00:11:48.074518 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:11:48.074525 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.127731 (* 1 = 0.127731 loss)
I0312 00:11:48.074544 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188493 (* 1 = 0.188493 loss)
I0312 00:11:48.074548 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0097405 (* 1 = 0.0097405 loss)
I0312 00:11:48.074553 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179303 (* 1 = 0.0179303 loss)
I0312 00:11:48.074558 17663 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0312 00:12:40.718830 17663 solver.cpp:228] Iteration 7300, loss = 0.699988
I0312 00:12:40.718852 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 00:12:40.718858 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.157739 (* 1 = 0.157739 loss)
I0312 00:12:40.718863 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.272318 (* 1 = 0.272318 loss)
I0312 00:12:40.718881 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0349643 (* 1 = 0.0349643 loss)
I0312 00:12:40.718885 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144186 (* 1 = 0.144186 loss)
I0312 00:12:40.718890 17663 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0312 00:13:33.221679 17663 solver.cpp:228] Iteration 7400, loss = 0.970654
I0312 00:13:33.221701 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 00:13:33.221709 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.117422 (* 1 = 0.117422 loss)
I0312 00:13:33.221729 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.209248 (* 1 = 0.209248 loss)
I0312 00:13:33.221732 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131809 (* 1 = 0.0131809 loss)
I0312 00:13:33.221736 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035541 (* 1 = 0.035541 loss)
I0312 00:13:33.221741 17663 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0312 00:14:25.176200 17663 solver.cpp:228] Iteration 7500, loss = 0.548077
I0312 00:14:25.176223 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 00:14:25.176230 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.204273 (* 1 = 0.204273 loss)
I0312 00:14:25.176234 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.214094 (* 1 = 0.214094 loss)
I0312 00:14:25.176254 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0520297 (* 1 = 0.0520297 loss)
I0312 00:14:25.176257 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0676999 (* 1 = 0.0676999 loss)
I0312 00:14:25.176262 17663 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0312 00:15:17.706359 17663 solver.cpp:228] Iteration 7600, loss = 0.440218
I0312 00:15:17.706382 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 00:15:17.706400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277579 (* 1 = 0.0277579 loss)
I0312 00:15:17.706419 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0398282 (* 1 = 0.0398282 loss)
I0312 00:15:17.706423 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164451 (* 1 = 0.0164451 loss)
I0312 00:15:17.706427 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.224871 (* 1 = 0.224871 loss)
I0312 00:15:17.706445 17663 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0312 00:16:10.091043 17663 solver.cpp:228] Iteration 7700, loss = 0.598089
I0312 00:16:10.091065 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 00:16:10.091073 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691423 (* 1 = 0.0691423 loss)
I0312 00:16:10.091091 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.24166 (* 1 = 0.24166 loss)
I0312 00:16:10.091095 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0773091 (* 1 = 0.0773091 loss)
I0312 00:16:10.091111 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0912005 (* 1 = 0.0912005 loss)
I0312 00:16:10.091116 17663 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0312 00:17:03.216315 17663 solver.cpp:228] Iteration 7800, loss = 0.312272
I0312 00:17:03.216336 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:17:03.216343 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.104286 (* 1 = 0.104286 loss)
I0312 00:17:03.216362 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13255 (* 1 = 0.13255 loss)
I0312 00:17:03.216367 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139167 (* 1 = 0.0139167 loss)
I0312 00:17:03.216370 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103368 (* 1 = 0.103368 loss)
I0312 00:17:03.216375 17663 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0312 00:17:55.533059 17663 solver.cpp:228] Iteration 7900, loss = 0.273359
I0312 00:17:55.533083 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:17:55.533090 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549391 (* 1 = 0.0549391 loss)
I0312 00:17:55.533110 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0755849 (* 1 = 0.0755849 loss)
I0312 00:17:55.533114 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.053106 (* 1 = 0.053106 loss)
I0312 00:17:55.533118 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0814759 (* 1 = 0.0814759 loss)
I0312 00:17:55.533123 17663 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
speed: 0.524s / iter
I0312 00:18:48.469482 17663 solver.cpp:228] Iteration 8000, loss = 0.484511
I0312 00:18:48.469633 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:18:48.469691 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.113912 (* 1 = 0.113912 loss)
I0312 00:18:48.469738 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.140498 (* 1 = 0.140498 loss)
I0312 00:18:48.469785 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210141 (* 1 = 0.0210141 loss)
I0312 00:18:48.469831 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113737 (* 1 = 0.113737 loss)
I0312 00:18:48.469878 17663 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0312 00:19:41.503067 17663 solver.cpp:228] Iteration 8100, loss = 0.442839
I0312 00:19:41.503087 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 00:19:41.503094 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.21674 (* 1 = 0.21674 loss)
I0312 00:19:41.503113 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.309368 (* 1 = 0.309368 loss)
I0312 00:19:41.503118 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018578 (* 1 = 0.018578 loss)
I0312 00:19:41.503121 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127369 (* 1 = 0.127369 loss)
I0312 00:19:41.503139 17663 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0312 00:20:33.775475 17663 solver.cpp:228] Iteration 8200, loss = 0.428006
I0312 00:20:33.775498 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 00:20:33.775506 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.083185 (* 1 = 0.083185 loss)
I0312 00:20:33.775509 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.179074 (* 1 = 0.179074 loss)
I0312 00:20:33.775528 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00573933 (* 1 = 0.00573933 loss)
I0312 00:20:33.775533 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0715172 (* 1 = 0.0715172 loss)
I0312 00:20:33.775538 17663 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0312 00:21:25.903865 17663 solver.cpp:228] Iteration 8300, loss = 0.313338
I0312 00:21:25.903888 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 00:21:25.903897 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245477 (* 1 = 0.0245477 loss)
I0312 00:21:25.903915 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0252415 (* 1 = 0.0252415 loss)
I0312 00:21:25.903919 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198488 (* 1 = 0.0198488 loss)
I0312 00:21:25.903923 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405184 (* 1 = 0.0405184 loss)
I0312 00:21:25.903928 17663 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0312 00:22:17.672904 17663 solver.cpp:228] Iteration 8400, loss = 0.591588
I0312 00:22:17.672940 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 00:22:17.672947 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.120274 (* 1 = 0.120274 loss)
I0312 00:22:17.672967 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161601 (* 1 = 0.161601 loss)
I0312 00:22:17.672972 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241544 (* 1 = 0.0241544 loss)
I0312 00:22:17.672988 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0425162 (* 1 = 0.0425162 loss)
I0312 00:22:17.672992 17663 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0312 00:23:10.822548 17663 solver.cpp:228] Iteration 8500, loss = 0.280935
I0312 00:23:10.822571 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:23:10.822578 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.138494 (* 1 = 0.138494 loss)
I0312 00:23:10.822582 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180905 (* 1 = 0.180905 loss)
I0312 00:23:10.822602 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989657 (* 1 = 0.00989657 loss)
I0312 00:23:10.822607 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0577972 (* 1 = 0.0577972 loss)
I0312 00:23:10.822610 17663 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0312 00:24:03.396375 17663 solver.cpp:228] Iteration 8600, loss = 0.475517
I0312 00:24:03.396397 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 00:24:03.396405 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0656877 (* 1 = 0.0656877 loss)
I0312 00:24:03.396425 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.316067 (* 1 = 0.316067 loss)
I0312 00:24:03.396428 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.162121 (* 1 = 0.162121 loss)
I0312 00:24:03.396432 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.173642 (* 1 = 0.173642 loss)
I0312 00:24:03.396450 17663 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0312 00:24:55.842013 17663 solver.cpp:228] Iteration 8700, loss = 0.435182
I0312 00:24:55.842036 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 00:24:55.842043 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141815 (* 1 = 0.141815 loss)
I0312 00:24:55.842062 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.301158 (* 1 = 0.301158 loss)
I0312 00:24:55.842067 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106056 (* 1 = 0.0106056 loss)
I0312 00:24:55.842084 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.188748 (* 1 = 0.188748 loss)
I0312 00:24:55.842088 17663 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0312 00:25:48.928619 17663 solver.cpp:228] Iteration 8800, loss = 1.17718
I0312 00:25:48.928642 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0312 00:25:48.928648 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.287612 (* 1 = 0.287612 loss)
I0312 00:25:48.928668 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.623201 (* 1 = 0.623201 loss)
I0312 00:25:48.928671 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.440136 (* 1 = 0.440136 loss)
I0312 00:25:48.928675 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.6069 (* 1 = 0.6069 loss)
I0312 00:25:48.928680 17663 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0312 00:26:41.451478 17663 solver.cpp:228] Iteration 8900, loss = 0.508635
I0312 00:26:41.451508 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 00:26:41.451529 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13512 (* 1 = 0.13512 loss)
I0312 00:26:41.451534 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.251971 (* 1 = 0.251971 loss)
I0312 00:26:41.451539 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0223998 (* 1 = 0.0223998 loss)
I0312 00:26:41.451542 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.178031 (* 1 = 0.178031 loss)
I0312 00:26:41.451548 17663 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
/home/fan/Rfcn/tools/../lib/fast_rcnn/bbox_transform.py:23: RuntimeWarning: invalid value encountered in log
  targets_dw = np.log(gt_widths / ex_widths)
speed: 0.524s / iter
I0312 00:27:33.514284 17663 solver.cpp:228] Iteration 9000, loss = 0.706091
I0312 00:27:33.514475 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 00:27:33.514535 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.175666 (* 1 = 0.175666 loss)
I0312 00:27:33.514585 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.32275 (* 1 = 0.32275 loss)
I0312 00:27:33.514631 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123403 (* 1 = 0.0123403 loss)
I0312 00:27:33.514678 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0782308 (* 1 = 0.0782308 loss)
I0312 00:27:33.514726 17663 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0312 00:28:25.474179 17663 solver.cpp:228] Iteration 9100, loss = 0.329342
I0312 00:28:25.474229 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:28:25.474251 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.102111 (* 1 = 0.102111 loss)
I0312 00:28:25.474256 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.160568 (* 1 = 0.160568 loss)
I0312 00:28:25.474261 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0487848 (* 1 = 0.0487848 loss)
I0312 00:28:25.474265 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342072 (* 1 = 0.0342072 loss)
I0312 00:28:25.474270 17663 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0312 00:29:17.415904 17663 solver.cpp:228] Iteration 9200, loss = 0.185037
I0312 00:29:17.415927 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:29:17.415935 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0361456 (* 1 = 0.0361456 loss)
I0312 00:29:17.415940 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.075488 (* 1 = 0.075488 loss)
I0312 00:29:17.415958 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162613 (* 1 = 0.0162613 loss)
I0312 00:29:17.415962 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751395 (* 1 = 0.0751395 loss)
I0312 00:29:17.415967 17663 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0312 00:30:09.528123 17663 solver.cpp:228] Iteration 9300, loss = 1.03712
I0312 00:30:09.528144 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 00:30:09.528152 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.172715 (* 1 = 0.172715 loss)
I0312 00:30:09.528172 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.29138 (* 1 = 0.29138 loss)
I0312 00:30:09.528175 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.357353 (* 1 = 0.357353 loss)
I0312 00:30:09.528192 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.474782 (* 1 = 0.474782 loss)
I0312 00:30:09.528197 17663 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0312 00:31:01.841168 17663 solver.cpp:228] Iteration 9400, loss = 0.296372
I0312 00:31:01.841197 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 00:31:01.841204 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0828375 (* 1 = 0.0828375 loss)
I0312 00:31:01.841210 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.152251 (* 1 = 0.152251 loss)
I0312 00:31:01.841217 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359592 (* 1 = 0.00359592 loss)
I0312 00:31:01.841220 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0328437 (* 1 = 0.0328437 loss)
I0312 00:31:01.841226 17663 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0312 00:31:54.201098 17663 solver.cpp:228] Iteration 9500, loss = 0.355146
I0312 00:31:54.201119 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 00:31:54.201126 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.121057 (* 1 = 0.121057 loss)
I0312 00:31:54.201131 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.204461 (* 1 = 0.204461 loss)
I0312 00:31:54.201149 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204851 (* 1 = 0.0204851 loss)
I0312 00:31:54.201153 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.094803 (* 1 = 0.094803 loss)
I0312 00:31:54.201159 17663 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0312 00:32:47.341208 17663 solver.cpp:228] Iteration 9600, loss = 0.617114
I0312 00:32:47.341230 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 00:32:47.341238 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.139837 (* 1 = 0.139837 loss)
I0312 00:32:47.341256 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196262 (* 1 = 0.196262 loss)
I0312 00:32:47.341260 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0683984 (* 1 = 0.0683984 loss)
I0312 00:32:47.341264 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013518 (* 1 = 0.013518 loss)
I0312 00:32:47.341269 17663 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0312 00:33:39.378433 17663 solver.cpp:228] Iteration 9700, loss = 0.192181
I0312 00:33:39.378455 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 00:33:39.378463 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136538 (* 1 = 0.0136538 loss)
I0312 00:33:39.378468 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106832 (* 1 = 0.106832 loss)
I0312 00:33:39.378471 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286433 (* 1 = 0.00286433 loss)
I0312 00:33:39.378475 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164755 (* 1 = 0.0164755 loss)
I0312 00:33:39.378480 17663 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0312 00:34:32.304787 17663 solver.cpp:228] Iteration 9800, loss = 0.37214
I0312 00:34:32.304811 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:34:32.304818 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.104238 (* 1 = 0.104238 loss)
I0312 00:34:32.304822 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.110085 (* 1 = 0.110085 loss)
I0312 00:34:32.304841 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123996 (* 1 = 0.0123996 loss)
I0312 00:34:32.304846 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.197902 (* 1 = 0.197902 loss)
I0312 00:34:32.304850 17663 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0312 00:35:24.485252 17663 solver.cpp:228] Iteration 9900, loss = 0.317923
I0312 00:35:24.485275 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 00:35:24.485283 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0753051 (* 1 = 0.0753051 loss)
I0312 00:35:24.485302 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.173587 (* 1 = 0.173587 loss)
I0312 00:35:24.485306 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0376533 (* 1 = 0.0376533 loss)
I0312 00:35:24.485311 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0811609 (* 1 = 0.0811609 loss)
I0312 00:35:24.485316 17663 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0312 00:36:16.062906 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_10000.caffemodel
I0312 00:36:16.482537 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_10000.solverstate
speed: 0.524s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_10000.caffemodel
I0312 00:36:17.560092 17663 solver.cpp:228] Iteration 10000, loss = 0.974055
I0312 00:36:17.560117 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 00:36:17.560123 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00244976 (* 1 = 0.00244976 loss)
I0312 00:36:17.560142 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0403754 (* 1 = 0.0403754 loss)
I0312 00:36:17.560147 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.149174 (* 1 = 0.149174 loss)
I0312 00:36:17.560151 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 1.43638 (* 1 = 1.43638 loss)
I0312 00:36:17.560156 17663 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0312 00:37:10.326289 17663 solver.cpp:228] Iteration 10100, loss = 0.256685
I0312 00:37:10.326310 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 00:37:10.326318 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00189915 (* 1 = 0.00189915 loss)
I0312 00:37:10.326337 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.04788 (* 1 = 0.04788 loss)
I0312 00:37:10.326341 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.155207 (* 1 = 0.155207 loss)
I0312 00:37:10.326359 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0633849 (* 1 = 0.0633849 loss)
I0312 00:37:10.326362 17663 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0312 00:38:03.536669 17663 solver.cpp:228] Iteration 10200, loss = 0.196075
I0312 00:38:03.536689 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:38:03.536696 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174709 (* 1 = 0.0174709 loss)
I0312 00:38:03.536701 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.081915 (* 1 = 0.081915 loss)
I0312 00:38:03.536720 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00523993 (* 1 = 0.00523993 loss)
I0312 00:38:03.536725 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284447 (* 1 = 0.0284447 loss)
I0312 00:38:03.536728 17663 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0312 00:38:55.695546 17663 solver.cpp:228] Iteration 10300, loss = 0.603772
I0312 00:38:55.695569 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 00:38:55.695576 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.187485 (* 1 = 0.187485 loss)
I0312 00:38:55.695595 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.23579 (* 1 = 0.23579 loss)
I0312 00:38:55.695600 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0363232 (* 1 = 0.0363232 loss)
I0312 00:38:55.695603 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.203318 (* 1 = 0.203318 loss)
I0312 00:38:55.695608 17663 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0312 00:39:47.453491 17663 solver.cpp:228] Iteration 10400, loss = 0.684396
I0312 00:39:47.453513 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 00:39:47.453521 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.212304 (* 1 = 0.212304 loss)
I0312 00:39:47.453539 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.293818 (* 1 = 0.293818 loss)
I0312 00:39:47.453543 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189812 (* 1 = 0.0189812 loss)
I0312 00:39:47.453547 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126454 (* 1 = 0.126454 loss)
I0312 00:39:47.453565 17663 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0312 00:40:40.252328 17663 solver.cpp:228] Iteration 10500, loss = 0.800508
I0312 00:40:40.252351 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:40:40.252357 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590741 (* 1 = 0.0590741 loss)
I0312 00:40:40.252377 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.203456 (* 1 = 0.203456 loss)
I0312 00:40:40.252380 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438881 (* 1 = 0.00438881 loss)
I0312 00:40:40.252385 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035343 (* 1 = 0.035343 loss)
I0312 00:40:40.252389 17663 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0312 00:41:32.356103 17663 solver.cpp:228] Iteration 10600, loss = 0.766939
I0312 00:41:32.356127 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 00:41:32.356133 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.296513 (* 1 = 0.296513 loss)
I0312 00:41:32.356153 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.414606 (* 1 = 0.414606 loss)
I0312 00:41:32.356156 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171873 (* 1 = 0.0171873 loss)
I0312 00:41:32.356160 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.337869 (* 1 = 0.337869 loss)
I0312 00:41:32.356165 17663 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0312 00:42:24.183804 17663 solver.cpp:228] Iteration 10700, loss = 0.624376
I0312 00:42:24.183828 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 00:42:24.183836 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13954 (* 1 = 0.13954 loss)
I0312 00:42:24.183856 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.160221 (* 1 = 0.160221 loss)
I0312 00:42:24.183859 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.118129 (* 1 = 0.118129 loss)
I0312 00:42:24.183863 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.211311 (* 1 = 0.211311 loss)
I0312 00:42:24.183868 17663 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0312 00:43:16.078744 17663 solver.cpp:228] Iteration 10800, loss = 0.293124
I0312 00:43:16.078765 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:43:16.078773 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346789 (* 1 = 0.0346789 loss)
I0312 00:43:16.078778 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147342 (* 1 = 0.147342 loss)
I0312 00:43:16.078796 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0397671 (* 1 = 0.0397671 loss)
I0312 00:43:16.078800 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00763907 (* 1 = 0.00763907 loss)
I0312 00:43:16.078805 17663 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0312 00:44:08.058841 17663 solver.cpp:228] Iteration 10900, loss = 0.413137
I0312 00:44:08.058862 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 00:44:08.058869 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334627 (* 1 = 0.0334627 loss)
I0312 00:44:08.058874 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170147 (* 1 = 0.170147 loss)
I0312 00:44:08.058892 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226129 (* 1 = 0.0226129 loss)
I0312 00:44:08.058897 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106931 (* 1 = 0.0106931 loss)
I0312 00:44:08.058902 17663 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
speed: 0.524s / iter
I0312 00:45:01.303234 17663 solver.cpp:228] Iteration 11000, loss = 0.124465
I0312 00:45:01.303354 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:45:01.303405 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106178 (* 1 = 0.0106178 loss)
I0312 00:45:01.303434 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0736606 (* 1 = 0.0736606 loss)
I0312 00:45:01.303442 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206948 (* 1 = 0.00206948 loss)
I0312 00:45:01.303447 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112412 (* 1 = 0.0112412 loss)
I0312 00:45:01.303452 17663 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0312 00:45:54.066296 17663 solver.cpp:228] Iteration 11100, loss = 0.329559
I0312 00:45:54.066319 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 00:45:54.066328 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.163 (* 1 = 0.163 loss)
I0312 00:45:54.066332 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.187391 (* 1 = 0.187391 loss)
I0312 00:45:54.066350 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0237357 (* 1 = 0.0237357 loss)
I0312 00:45:54.066355 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0720166 (* 1 = 0.0720166 loss)
I0312 00:45:54.066360 17663 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0312 00:46:46.637009 17663 solver.cpp:228] Iteration 11200, loss = 0.153775
I0312 00:46:46.637032 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:46:46.637038 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168408 (* 1 = 0.0168408 loss)
I0312 00:46:46.637058 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.108096 (* 1 = 0.108096 loss)
I0312 00:46:46.637063 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0090699 (* 1 = 0.0090699 loss)
I0312 00:46:46.637066 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00681009 (* 1 = 0.00681009 loss)
I0312 00:46:46.637071 17663 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0312 00:47:38.357942 17663 solver.cpp:228] Iteration 11300, loss = 0.44921
I0312 00:47:38.357988 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 00:47:38.357996 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115037 (* 1 = 0.0115037 loss)
I0312 00:47:38.358016 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0590797 (* 1 = 0.0590797 loss)
I0312 00:47:38.358021 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132026 (* 1 = 0.0132026 loss)
I0312 00:47:38.358024 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395568 (* 1 = 0.0395568 loss)
I0312 00:47:38.358029 17663 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0312 00:48:29.690634 17663 solver.cpp:228] Iteration 11400, loss = 0.273874
I0312 00:48:29.690660 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 00:48:29.690667 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0221113 (* 1 = 0.0221113 loss)
I0312 00:48:29.690687 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0684754 (* 1 = 0.0684754 loss)
I0312 00:48:29.690692 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149483 (* 1 = 0.0149483 loss)
I0312 00:48:29.690697 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00686182 (* 1 = 0.00686182 loss)
I0312 00:48:29.690702 17663 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0312 00:49:22.043799 17663 solver.cpp:228] Iteration 11500, loss = 0.342324
I0312 00:49:22.043820 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 00:49:22.043828 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0905751 (* 1 = 0.0905751 loss)
I0312 00:49:22.043848 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.143304 (* 1 = 0.143304 loss)
I0312 00:49:22.043851 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00437684 (* 1 = 0.00437684 loss)
I0312 00:49:22.043855 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160071 (* 1 = 0.0160071 loss)
I0312 00:49:22.043860 17663 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0312 00:50:14.166800 17663 solver.cpp:228] Iteration 11600, loss = 0.937412
I0312 00:50:14.166822 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 00:50:14.166829 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.176147 (* 1 = 0.176147 loss)
I0312 00:50:14.166848 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.396281 (* 1 = 0.396281 loss)
I0312 00:50:14.166852 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.291675 (* 1 = 0.291675 loss)
I0312 00:50:14.166857 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.233224 (* 1 = 0.233224 loss)
I0312 00:50:14.166860 17663 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0312 00:51:06.153086 17663 solver.cpp:228] Iteration 11700, loss = 0.390924
I0312 00:51:06.153108 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 00:51:06.153115 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173194 (* 1 = 0.0173194 loss)
I0312 00:51:06.153134 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.081978 (* 1 = 0.081978 loss)
I0312 00:51:06.153141 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00433059 (* 1 = 0.00433059 loss)
I0312 00:51:06.153144 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195656 (* 1 = 0.0195656 loss)
I0312 00:51:06.153149 17663 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0312 00:51:57.794986 17663 solver.cpp:228] Iteration 11800, loss = 0.436665
I0312 00:51:57.795008 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:51:57.795017 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990967 (* 1 = 0.0990967 loss)
I0312 00:51:57.795022 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111275 (* 1 = 0.111275 loss)
I0312 00:51:57.795024 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227116 (* 1 = 0.0227116 loss)
I0312 00:51:57.795028 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121137 (* 1 = 0.121137 loss)
I0312 00:51:57.795033 17663 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0312 00:52:50.720572 17663 solver.cpp:228] Iteration 11900, loss = 0.444497
I0312 00:52:50.720595 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 00:52:50.720602 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.128596 (* 1 = 0.128596 loss)
I0312 00:52:50.720621 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.234024 (* 1 = 0.234024 loss)
I0312 00:52:50.720626 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0716999 (* 1 = 0.0716999 loss)
I0312 00:52:50.720630 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0982344 (* 1 = 0.0982344 loss)
I0312 00:52:50.720635 17663 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
speed: 0.524s / iter
I0312 00:53:43.840073 17663 solver.cpp:228] Iteration 12000, loss = 0.32055
I0312 00:53:43.840212 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 00:53:43.840270 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00139687 (* 1 = 0.00139687 loss)
I0312 00:53:43.840318 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149228 (* 1 = 0.149228 loss)
I0312 00:53:43.840366 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.123013 (* 1 = 0.123013 loss)
I0312 00:53:43.840414 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400696 (* 1 = 0.0400696 loss)
I0312 00:53:43.840447 17663 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0312 00:54:35.955526 17663 solver.cpp:228] Iteration 12100, loss = 0.122704
I0312 00:54:35.955549 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 00:54:35.955557 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172187 (* 1 = 0.0172187 loss)
I0312 00:54:35.955575 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0712072 (* 1 = 0.0712072 loss)
I0312 00:54:35.955580 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00544947 (* 1 = 0.00544947 loss)
I0312 00:54:35.955585 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102269 (* 1 = 0.0102269 loss)
I0312 00:54:35.955590 17663 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0312 00:55:28.199481 17663 solver.cpp:228] Iteration 12200, loss = 0.916563
I0312 00:55:28.199501 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 00:55:28.199508 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.309957 (* 1 = 0.309957 loss)
I0312 00:55:28.199527 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.368682 (* 1 = 0.368682 loss)
I0312 00:55:28.199532 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.477432 (* 1 = 0.477432 loss)
I0312 00:55:28.199535 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.443575 (* 1 = 0.443575 loss)
I0312 00:55:28.199540 17663 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0312 00:56:21.029763 17663 solver.cpp:228] Iteration 12300, loss = 0.43367
I0312 00:56:21.029788 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:56:21.029794 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340584 (* 1 = 0.0340584 loss)
I0312 00:56:21.029814 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0891979 (* 1 = 0.0891979 loss)
I0312 00:56:21.029819 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144554 (* 1 = 0.0144554 loss)
I0312 00:56:21.029836 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035071 (* 1 = 0.035071 loss)
I0312 00:56:21.029840 17663 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0312 00:57:14.372776 17663 solver.cpp:228] Iteration 12400, loss = 0.332003
I0312 00:57:14.372828 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 00:57:14.372835 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0941944 (* 1 = 0.0941944 loss)
I0312 00:57:14.372853 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.184384 (* 1 = 0.184384 loss)
I0312 00:57:14.372859 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00475399 (* 1 = 0.00475399 loss)
I0312 00:57:14.372875 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111426 (* 1 = 0.0111426 loss)
I0312 00:57:14.372880 17663 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0312 00:58:06.742746 17663 solver.cpp:228] Iteration 12500, loss = 0.402317
I0312 00:58:06.742769 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 00:58:06.742777 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.139473 (* 1 = 0.139473 loss)
I0312 00:58:06.742796 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.223998 (* 1 = 0.223998 loss)
I0312 00:58:06.742800 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0385724 (* 1 = 0.0385724 loss)
I0312 00:58:06.742818 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185108 (* 1 = 0.185108 loss)
I0312 00:58:06.742822 17663 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0312 00:58:59.259681 17663 solver.cpp:228] Iteration 12600, loss = 0.368754
I0312 00:58:59.259704 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 00:58:59.259711 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291905 (* 1 = 0.0291905 loss)
I0312 00:58:59.259730 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0845778 (* 1 = 0.0845778 loss)
I0312 00:58:59.259735 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265752 (* 1 = 0.00265752 loss)
I0312 00:58:59.259754 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00869146 (* 1 = 0.00869146 loss)
I0312 00:58:59.259759 17663 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0312 00:59:51.862123 17663 solver.cpp:228] Iteration 12700, loss = 0.170495
I0312 00:59:51.862149 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 00:59:51.862155 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259746 (* 1 = 0.0259746 loss)
I0312 00:59:51.862174 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0716612 (* 1 = 0.0716612 loss)
I0312 00:59:51.862179 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178596 (* 1 = 0.00178596 loss)
I0312 00:59:51.862185 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.007858 (* 1 = 0.007858 loss)
I0312 00:59:51.862190 17663 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0312 01:00:44.959635 17663 solver.cpp:228] Iteration 12800, loss = 0.229479
I0312 01:00:44.959662 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:00:44.959671 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0623491 (* 1 = 0.0623491 loss)
I0312 01:00:44.959689 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.187474 (* 1 = 0.187474 loss)
I0312 01:00:44.959694 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0351075 (* 1 = 0.0351075 loss)
I0312 01:00:44.959712 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00581021 (* 1 = 0.00581021 loss)
I0312 01:00:44.959717 17663 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0312 01:01:37.902016 17663 solver.cpp:228] Iteration 12900, loss = 0.663357
I0312 01:01:37.902037 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:01:37.902045 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0891646 (* 1 = 0.0891646 loss)
I0312 01:01:37.902065 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137244 (* 1 = 0.137244 loss)
I0312 01:01:37.902070 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00859037 (* 1 = 0.00859037 loss)
I0312 01:01:37.902073 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0562454 (* 1 = 0.0562454 loss)
I0312 01:01:37.902078 17663 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
speed: 0.524s / iter
I0312 01:02:30.868149 17663 solver.cpp:228] Iteration 13000, loss = 0.415635
I0312 01:02:30.868172 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:02:30.868180 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0635362 (* 1 = 0.0635362 loss)
I0312 01:02:30.868199 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.130702 (* 1 = 0.130702 loss)
I0312 01:02:30.868203 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.130386 (* 1 = 0.130386 loss)
I0312 01:02:30.868208 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11746 (* 1 = 0.11746 loss)
I0312 01:02:30.868212 17663 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0312 01:03:23.548743 17663 solver.cpp:228] Iteration 13100, loss = 0.419462
I0312 01:03:23.548765 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:03:23.548773 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0850943 (* 1 = 0.0850943 loss)
I0312 01:03:23.548791 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188084 (* 1 = 0.188084 loss)
I0312 01:03:23.548795 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648376 (* 1 = 0.00648376 loss)
I0312 01:03:23.548800 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339232 (* 1 = 0.0339232 loss)
I0312 01:03:23.548804 17663 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0312 01:04:16.077982 17663 solver.cpp:228] Iteration 13200, loss = 0.517654
I0312 01:04:16.078004 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:04:16.078011 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0011261 (* 1 = 0.0011261 loss)
I0312 01:04:16.078030 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0624967 (* 1 = 0.0624967 loss)
I0312 01:04:16.078035 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.114823 (* 1 = 0.114823 loss)
I0312 01:04:16.078039 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.566998 (* 1 = 0.566998 loss)
I0312 01:04:16.078043 17663 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0312 01:05:08.919286 17663 solver.cpp:228] Iteration 13300, loss = 0.11385
I0312 01:05:08.919312 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 01:05:08.919318 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293722 (* 1 = 0.0293722 loss)
I0312 01:05:08.919338 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0750533 (* 1 = 0.0750533 loss)
I0312 01:05:08.919342 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00679948 (* 1 = 0.00679948 loss)
I0312 01:05:08.919348 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380434 (* 1 = 0.0380434 loss)
I0312 01:05:08.919353 17663 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0312 01:06:01.428342 17663 solver.cpp:228] Iteration 13400, loss = 0.764904
I0312 01:06:01.428364 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 01:06:01.428370 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.42074 (* 1 = 0.42074 loss)
I0312 01:06:01.428388 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.492829 (* 1 = 0.492829 loss)
I0312 01:06:01.428393 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.24551 (* 1 = 0.24551 loss)
I0312 01:06:01.428397 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.230921 (* 1 = 0.230921 loss)
I0312 01:06:01.428401 17663 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0312 01:06:53.924072 17663 solver.cpp:228] Iteration 13500, loss = 0.367269
I0312 01:06:53.924093 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 01:06:53.924100 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00188801 (* 1 = 0.00188801 loss)
I0312 01:06:53.924119 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.00950042 (* 1 = 0.00950042 loss)
I0312 01:06:53.924124 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188644 (* 1 = 0.0188644 loss)
I0312 01:06:53.924129 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.374045 (* 1 = 0.374045 loss)
I0312 01:06:53.924145 17663 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0312 01:07:46.196734 17663 solver.cpp:228] Iteration 13600, loss = 0.400025
I0312 01:07:46.196763 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 01:07:46.196770 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0995573 (* 1 = 0.0995573 loss)
I0312 01:07:46.196790 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.230426 (* 1 = 0.230426 loss)
I0312 01:07:46.196794 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203711 (* 1 = 0.0203711 loss)
I0312 01:07:46.196799 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323397 (* 1 = 0.0323397 loss)
I0312 01:07:46.196804 17663 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0312 01:08:38.601450 17663 solver.cpp:228] Iteration 13700, loss = 0.560891
I0312 01:08:38.601471 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 01:08:38.601478 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.231119 (* 1 = 0.231119 loss)
I0312 01:08:38.601497 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.423519 (* 1 = 0.423519 loss)
I0312 01:08:38.601502 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0286714 (* 1 = 0.0286714 loss)
I0312 01:08:38.601506 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.176367 (* 1 = 0.176367 loss)
I0312 01:08:38.601511 17663 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0312 01:09:31.179880 17663 solver.cpp:228] Iteration 13800, loss = 0.427713
I0312 01:09:31.179903 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 01:09:31.179910 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739476 (* 1 = 0.0739476 loss)
I0312 01:09:31.179929 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.091573 (* 1 = 0.091573 loss)
I0312 01:09:31.179934 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0307182 (* 1 = 0.0307182 loss)
I0312 01:09:31.179937 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0382337 (* 1 = 0.0382337 loss)
I0312 01:09:31.179941 17663 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0312 01:10:23.225731 17663 solver.cpp:228] Iteration 13900, loss = 0.162671
I0312 01:10:23.225754 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:10:23.225775 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.041927 (* 1 = 0.041927 loss)
I0312 01:10:23.225780 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105938 (* 1 = 0.105938 loss)
I0312 01:10:23.225783 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011209 (* 1 = 0.011209 loss)
I0312 01:10:23.225787 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044471 (* 1 = 0.044471 loss)
I0312 01:10:23.225806 17663 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
speed: 0.524s / iter
I0312 01:11:15.777706 17663 solver.cpp:228] Iteration 14000, loss = 0.207398
I0312 01:11:15.777925 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:11:15.777987 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457949 (* 1 = 0.0457949 loss)
I0312 01:11:15.778036 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114537 (* 1 = 0.114537 loss)
I0312 01:11:15.778084 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00649442 (* 1 = 0.00649442 loss)
I0312 01:11:15.778132 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254856 (* 1 = 0.0254856 loss)
I0312 01:11:15.778182 17663 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0312 01:12:08.245177 17663 solver.cpp:228] Iteration 14100, loss = 0.421841
I0312 01:12:08.245200 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:12:08.245208 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523627 (* 1 = 0.0523627 loss)
I0312 01:12:08.245227 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181518 (* 1 = 0.181518 loss)
I0312 01:12:08.245231 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139551 (* 1 = 0.0139551 loss)
I0312 01:12:08.245235 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163534 (* 1 = 0.0163534 loss)
I0312 01:12:08.245240 17663 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0312 01:13:00.369815 17663 solver.cpp:228] Iteration 14200, loss = 0.219441
I0312 01:13:00.369838 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 01:13:00.369845 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247892 (* 1 = 0.0247892 loss)
I0312 01:13:00.369865 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.10467 (* 1 = 0.10467 loss)
I0312 01:13:00.369870 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108571 (* 1 = 0.0108571 loss)
I0312 01:13:00.369874 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00585288 (* 1 = 0.00585288 loss)
I0312 01:13:00.369879 17663 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0312 01:13:52.620798 17663 solver.cpp:228] Iteration 14300, loss = 0.150935
I0312 01:13:52.620820 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 01:13:52.620826 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.018167 (* 1 = 0.018167 loss)
I0312 01:13:52.620846 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0554561 (* 1 = 0.0554561 loss)
I0312 01:13:52.620849 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00879787 (* 1 = 0.00879787 loss)
I0312 01:13:52.620854 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195772 (* 1 = 0.0195772 loss)
I0312 01:13:52.620858 17663 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0312 01:14:45.208655 17663 solver.cpp:228] Iteration 14400, loss = 0.552533
I0312 01:14:45.208676 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:14:45.208683 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.039634 (* 1 = 0.039634 loss)
I0312 01:14:45.208688 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.141449 (* 1 = 0.141449 loss)
I0312 01:14:45.208693 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00459682 (* 1 = 0.00459682 loss)
I0312 01:14:45.208710 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229171 (* 1 = 0.0229171 loss)
I0312 01:14:45.208715 17663 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0312 01:15:37.713464 17663 solver.cpp:228] Iteration 14500, loss = 0.468718
I0312 01:15:37.713486 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:15:37.713495 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690162 (* 1 = 0.0690162 loss)
I0312 01:15:37.713513 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147445 (* 1 = 0.147445 loss)
I0312 01:15:37.713517 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00991907 (* 1 = 0.00991907 loss)
I0312 01:15:37.713522 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117909 (* 1 = 0.117909 loss)
I0312 01:15:37.713527 17663 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0312 01:16:30.772313 17663 solver.cpp:228] Iteration 14600, loss = 0.222604
I0312 01:16:30.772336 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 01:16:30.772344 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448984 (* 1 = 0.0448984 loss)
I0312 01:16:30.772349 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.138241 (* 1 = 0.138241 loss)
I0312 01:16:30.772353 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0309881 (* 1 = 0.0309881 loss)
I0312 01:16:30.772357 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352927 (* 1 = 0.0352927 loss)
I0312 01:16:30.772377 17663 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0312 01:17:23.253720 17663 solver.cpp:228] Iteration 14700, loss = 0.200743
I0312 01:17:23.253742 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 01:17:23.253749 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574291 (* 1 = 0.0574291 loss)
I0312 01:17:23.253768 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137174 (* 1 = 0.137174 loss)
I0312 01:17:23.253773 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00349405 (* 1 = 0.00349405 loss)
I0312 01:17:23.253777 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00250389 (* 1 = 0.00250389 loss)
I0312 01:17:23.253782 17663 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0312 01:18:15.451719 17663 solver.cpp:228] Iteration 14800, loss = 0.220701
I0312 01:18:15.451743 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:18:15.451751 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0380543 (* 1 = 0.0380543 loss)
I0312 01:18:15.451771 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0951049 (* 1 = 0.0951049 loss)
I0312 01:18:15.451776 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363043 (* 1 = 0.00363043 loss)
I0312 01:18:15.451779 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00659111 (* 1 = 0.00659111 loss)
I0312 01:18:15.451784 17663 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0312 01:19:07.796237 17663 solver.cpp:228] Iteration 14900, loss = 0.255467
I0312 01:19:07.796258 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 01:19:07.796265 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437077 (* 1 = 0.0437077 loss)
I0312 01:19:07.796284 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156348 (* 1 = 0.156348 loss)
I0312 01:19:07.796289 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209951 (* 1 = 0.0209951 loss)
I0312 01:19:07.796305 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303932 (* 1 = 0.0303932 loss)
I0312 01:19:07.796310 17663 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
speed: 0.524s / iter
I0312 01:20:00.835355 17663 solver.cpp:228] Iteration 15000, loss = 0.263217
I0312 01:20:00.835377 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 01:20:00.835384 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125269 (* 1 = 0.125269 loss)
I0312 01:20:00.835403 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198466 (* 1 = 0.198466 loss)
I0312 01:20:00.835408 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485256 (* 1 = 0.00485256 loss)
I0312 01:20:00.835412 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224131 (* 1 = 0.0224131 loss)
I0312 01:20:00.835417 17663 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0312 01:20:53.336632 17663 solver.cpp:228] Iteration 15100, loss = 0.337739
I0312 01:20:53.336653 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 01:20:53.336661 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.106877 (* 1 = 0.106877 loss)
I0312 01:20:53.336665 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.254334 (* 1 = 0.254334 loss)
I0312 01:20:53.336684 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112647 (* 1 = 0.0112647 loss)
I0312 01:20:53.336688 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1246 (* 1 = 0.1246 loss)
I0312 01:20:53.336694 17663 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0312 01:21:45.854794 17663 solver.cpp:228] Iteration 15200, loss = 0.293898
I0312 01:21:45.854816 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:21:45.854823 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0704437 (* 1 = 0.0704437 loss)
I0312 01:21:45.854842 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.108941 (* 1 = 0.108941 loss)
I0312 01:21:45.854847 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00984773 (* 1 = 0.00984773 loss)
I0312 01:21:45.854851 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322044 (* 1 = 0.0322044 loss)
I0312 01:21:45.854856 17663 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0312 01:22:37.719986 17663 solver.cpp:228] Iteration 15300, loss = 0.613859
I0312 01:22:37.720007 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 01:22:37.720015 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18028 (* 1 = 0.18028 loss)
I0312 01:22:37.720033 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.26249 (* 1 = 0.26249 loss)
I0312 01:22:37.720038 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281275 (* 1 = 0.0281275 loss)
I0312 01:22:37.720042 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555723 (* 1 = 0.0555723 loss)
I0312 01:22:37.720059 17663 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0312 01:23:30.174482 17663 solver.cpp:228] Iteration 15400, loss = 0.563365
I0312 01:23:30.174504 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 01:23:30.174511 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.154227 (* 1 = 0.154227 loss)
I0312 01:23:30.174530 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.21821 (* 1 = 0.21821 loss)
I0312 01:23:30.174535 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0466345 (* 1 = 0.0466345 loss)
I0312 01:23:30.174538 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0836932 (* 1 = 0.0836932 loss)
I0312 01:23:30.174543 17663 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0312 01:24:22.343261 17663 solver.cpp:228] Iteration 15500, loss = 0.46121
I0312 01:24:22.343281 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 01:24:22.343288 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.201211 (* 1 = 0.201211 loss)
I0312 01:24:22.343307 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.325643 (* 1 = 0.325643 loss)
I0312 01:24:22.343312 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188441 (* 1 = 0.0188441 loss)
I0312 01:24:22.343315 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0766241 (* 1 = 0.0766241 loss)
I0312 01:24:22.343319 17663 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0312 01:25:15.382750 17663 solver.cpp:228] Iteration 15600, loss = 0.260555
I0312 01:25:15.382771 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:25:15.382778 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.121333 (* 1 = 0.121333 loss)
I0312 01:25:15.382783 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.221691 (* 1 = 0.221691 loss)
I0312 01:25:15.382787 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162627 (* 1 = 0.0162627 loss)
I0312 01:25:15.382791 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369031 (* 1 = 0.0369031 loss)
I0312 01:25:15.382796 17663 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0312 01:26:07.900915 17663 solver.cpp:228] Iteration 15700, loss = 0.24997
I0312 01:26:07.900938 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:26:07.900944 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.058948 (* 1 = 0.058948 loss)
I0312 01:26:07.900964 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.131551 (* 1 = 0.131551 loss)
I0312 01:26:07.900967 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142571 (* 1 = 0.0142571 loss)
I0312 01:26:07.900972 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0528837 (* 1 = 0.0528837 loss)
I0312 01:26:07.900976 17663 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0312 01:26:59.937963 17663 solver.cpp:228] Iteration 15800, loss = 0.402224
I0312 01:26:59.937983 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 01:26:59.937990 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141284 (* 1 = 0.141284 loss)
I0312 01:26:59.938009 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183146 (* 1 = 0.183146 loss)
I0312 01:26:59.938014 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126291 (* 1 = 0.0126291 loss)
I0312 01:26:59.938030 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02261 (* 1 = 0.02261 loss)
I0312 01:26:59.938035 17663 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0312 01:27:52.132519 17663 solver.cpp:228] Iteration 15900, loss = 0.26435
I0312 01:27:52.132541 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:27:52.132550 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0645392 (* 1 = 0.0645392 loss)
I0312 01:27:52.132570 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.129675 (* 1 = 0.129675 loss)
I0312 01:27:52.132573 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281302 (* 1 = 0.00281302 loss)
I0312 01:27:52.132578 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192094 (* 1 = 0.0192094 loss)
I0312 01:27:52.132596 17663 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
speed: 0.524s / iter
I0312 01:28:44.740705 17663 solver.cpp:228] Iteration 16000, loss = 0.400598
I0312 01:28:44.740741 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:28:44.740752 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0736891 (* 1 = 0.0736891 loss)
I0312 01:28:44.740758 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0915284 (* 1 = 0.0915284 loss)
I0312 01:28:44.740762 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297408 (* 1 = 0.0297408 loss)
I0312 01:28:44.740768 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13306 (* 1 = 0.13306 loss)
I0312 01:28:44.740773 17663 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0312 01:29:37.721204 17663 solver.cpp:228] Iteration 16100, loss = 0.427718
I0312 01:29:37.721226 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 01:29:37.721233 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708364 (* 1 = 0.0708364 loss)
I0312 01:29:37.721252 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0905566 (* 1 = 0.0905566 loss)
I0312 01:29:37.721257 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012409 (* 1 = 0.012409 loss)
I0312 01:29:37.721261 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0542129 (* 1 = 0.0542129 loss)
I0312 01:29:37.721266 17663 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0312 01:30:29.444254 17663 solver.cpp:228] Iteration 16200, loss = 0.487996
I0312 01:30:29.444274 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:30:29.444283 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0948559 (* 1 = 0.0948559 loss)
I0312 01:30:29.444286 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181972 (* 1 = 0.181972 loss)
I0312 01:30:29.444304 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170828 (* 1 = 0.0170828 loss)
I0312 01:30:29.444309 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10584 (* 1 = 0.10584 loss)
I0312 01:30:29.444314 17663 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0312 01:31:21.502923 17663 solver.cpp:228] Iteration 16300, loss = 0.462194
I0312 01:31:21.502943 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 01:31:21.502950 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337247 (* 1 = 0.0337247 loss)
I0312 01:31:21.502954 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.09468 (* 1 = 0.09468 loss)
I0312 01:31:21.502974 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302233 (* 1 = 0.00302233 loss)
I0312 01:31:21.502977 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112406 (* 1 = 0.0112406 loss)
I0312 01:31:21.502982 17663 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0312 01:32:13.599418 17663 solver.cpp:228] Iteration 16400, loss = 0.447296
I0312 01:32:13.599439 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 01:32:13.599447 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.247809 (* 1 = 0.247809 loss)
I0312 01:32:13.599465 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.225867 (* 1 = 0.225867 loss)
I0312 01:32:13.599469 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031229 (* 1 = 0.031229 loss)
I0312 01:32:13.599473 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.27664 (* 1 = 0.27664 loss)
I0312 01:32:13.599478 17663 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0312 01:33:06.476893 17663 solver.cpp:228] Iteration 16500, loss = 0.619881
I0312 01:33:06.476917 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 01:33:06.476923 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.110574 (* 1 = 0.110574 loss)
I0312 01:33:06.476943 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123989 (* 1 = 0.123989 loss)
I0312 01:33:06.476948 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0849796 (* 1 = 0.0849796 loss)
I0312 01:33:06.476951 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0842285 (* 1 = 0.0842285 loss)
I0312 01:33:06.476956 17663 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0312 01:33:58.994384 17663 solver.cpp:228] Iteration 16600, loss = 0.251961
I0312 01:33:58.994406 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 01:33:58.994413 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0904326 (* 1 = 0.0904326 loss)
I0312 01:33:58.994432 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.171862 (* 1 = 0.171862 loss)
I0312 01:33:58.994437 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305692 (* 1 = 0.00305692 loss)
I0312 01:33:58.994441 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173149 (* 1 = 0.0173149 loss)
I0312 01:33:58.994446 17663 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0312 01:34:51.825276 17663 solver.cpp:228] Iteration 16700, loss = 0.31084
I0312 01:34:51.825299 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 01:34:51.825306 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0495846 (* 1 = 0.0495846 loss)
I0312 01:34:51.825325 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0540415 (* 1 = 0.0540415 loss)
I0312 01:34:51.825330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00460516 (* 1 = 0.00460516 loss)
I0312 01:34:51.825333 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0492242 (* 1 = 0.0492242 loss)
I0312 01:34:51.825338 17663 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0312 01:35:43.988041 17663 solver.cpp:228] Iteration 16800, loss = 0.231109
I0312 01:35:43.988063 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:35:43.988070 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.067222 (* 1 = 0.067222 loss)
I0312 01:35:43.988090 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0684253 (* 1 = 0.0684253 loss)
I0312 01:35:43.988093 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383653 (* 1 = 0.00383653 loss)
I0312 01:35:43.988097 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241694 (* 1 = 0.0241694 loss)
I0312 01:35:43.988101 17663 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0312 01:36:36.237870 17663 solver.cpp:228] Iteration 16900, loss = 0.168022
I0312 01:36:36.237896 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:36:36.237920 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0489608 (* 1 = 0.0489608 loss)
I0312 01:36:36.237923 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104795 (* 1 = 0.104795 loss)
I0312 01:36:36.237928 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00579701 (* 1 = 0.00579701 loss)
I0312 01:36:36.237932 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206431 (* 1 = 0.0206431 loss)
I0312 01:36:36.237937 17663 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
speed: 0.524s / iter
I0312 01:37:28.988842 17663 solver.cpp:228] Iteration 17000, loss = 0.319385
I0312 01:37:28.988867 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 01:37:28.988873 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105679 (* 1 = 0.105679 loss)
I0312 01:37:28.988893 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111679 (* 1 = 0.111679 loss)
I0312 01:37:28.988898 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0362143 (* 1 = 0.0362143 loss)
I0312 01:37:28.988914 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0511222 (* 1 = 0.0511222 loss)
I0312 01:37:28.988919 17663 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0312 01:38:21.421121 17663 solver.cpp:228] Iteration 17100, loss = 0.591599
I0312 01:38:21.421145 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 01:38:21.421152 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.130603 (* 1 = 0.130603 loss)
I0312 01:38:21.421172 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.247139 (* 1 = 0.247139 loss)
I0312 01:38:21.421176 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211026 (* 1 = 0.0211026 loss)
I0312 01:38:21.421193 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148713 (* 1 = 0.148713 loss)
I0312 01:38:21.421198 17663 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0312 01:39:14.035820 17663 solver.cpp:228] Iteration 17200, loss = 0.66085
I0312 01:39:14.035842 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 01:39:14.035851 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.186225 (* 1 = 0.186225 loss)
I0312 01:39:14.035869 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.259214 (* 1 = 0.259214 loss)
I0312 01:39:14.035874 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115325 (* 1 = 0.0115325 loss)
I0312 01:39:14.035879 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370013 (* 1 = 0.0370013 loss)
I0312 01:39:14.035897 17663 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0312 01:40:06.176167 17663 solver.cpp:228] Iteration 17300, loss = 0.770009
I0312 01:40:06.176190 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:40:06.176198 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587805 (* 1 = 0.0587805 loss)
I0312 01:40:06.176216 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114881 (* 1 = 0.114881 loss)
I0312 01:40:06.176221 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0423965 (* 1 = 0.0423965 loss)
I0312 01:40:06.176225 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307829 (* 1 = 0.0307829 loss)
I0312 01:40:06.176229 17663 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0312 01:40:58.646828 17663 solver.cpp:228] Iteration 17400, loss = 0.212301
I0312 01:40:58.646852 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 01:40:58.646859 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273714 (* 1 = 0.0273714 loss)
I0312 01:40:58.646878 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0755835 (* 1 = 0.0755835 loss)
I0312 01:40:58.646883 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429863 (* 1 = 0.00429863 loss)
I0312 01:40:58.646888 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402072 (* 1 = 0.0402072 loss)
I0312 01:40:58.646893 17663 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0312 01:41:51.512559 17663 solver.cpp:228] Iteration 17500, loss = 0.442052
I0312 01:41:51.512581 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 01:41:51.512589 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240448 (* 1 = 0.0240448 loss)
I0312 01:41:51.512594 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12951 (* 1 = 0.12951 loss)
I0312 01:41:51.512598 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00317639 (* 1 = 0.00317639 loss)
I0312 01:41:51.512603 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443631 (* 1 = 0.0443631 loss)
I0312 01:41:51.512621 17663 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0312 01:42:44.006332 17663 solver.cpp:228] Iteration 17600, loss = 0.62814
I0312 01:42:44.006355 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 01:42:44.006361 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.113247 (* 1 = 0.113247 loss)
I0312 01:42:44.006381 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.286688 (* 1 = 0.286688 loss)
I0312 01:42:44.006386 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0496631 (* 1 = 0.0496631 loss)
I0312 01:42:44.006389 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13274 (* 1 = 0.13274 loss)
I0312 01:42:44.006394 17663 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0312 01:43:37.105557 17663 solver.cpp:228] Iteration 17700, loss = 0.483375
I0312 01:43:37.105581 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 01:43:37.105588 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703417 (* 1 = 0.0703417 loss)
I0312 01:43:37.105592 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.201228 (* 1 = 0.201228 loss)
I0312 01:43:37.105597 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636295 (* 1 = 0.00636295 loss)
I0312 01:43:37.105602 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324271 (* 1 = 0.0324271 loss)
I0312 01:43:37.105620 17663 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0312 01:44:30.072346 17663 solver.cpp:228] Iteration 17800, loss = 0.379166
I0312 01:44:30.072369 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 01:44:30.072376 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18304 (* 1 = 0.18304 loss)
I0312 01:44:30.072381 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.287455 (* 1 = 0.287455 loss)
I0312 01:44:30.072399 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176414 (* 1 = 0.0176414 loss)
I0312 01:44:30.072404 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452654 (* 1 = 0.0452654 loss)
I0312 01:44:30.072409 17663 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0312 01:45:23.336277 17663 solver.cpp:228] Iteration 17900, loss = 0.563509
I0312 01:45:23.336299 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 01:45:23.336308 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.123641 (* 1 = 0.123641 loss)
I0312 01:45:23.336326 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.288954 (* 1 = 0.288954 loss)
I0312 01:45:23.336330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0882637 (* 1 = 0.0882637 loss)
I0312 01:45:23.336347 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.294813 (* 1 = 0.294813 loss)
I0312 01:45:23.336352 17663 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
speed: 0.524s / iter
I0312 01:46:15.507578 17663 solver.cpp:228] Iteration 18000, loss = 0.665514
I0312 01:46:15.507756 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 01:46:15.507815 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.286011 (* 1 = 0.286011 loss)
I0312 01:46:15.507863 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.316557 (* 1 = 0.316557 loss)
I0312 01:46:15.507910 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0407319 (* 1 = 0.0407319 loss)
I0312 01:46:15.507957 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0551496 (* 1 = 0.0551496 loss)
I0312 01:46:15.508005 17663 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0312 01:47:07.715198 17663 solver.cpp:228] Iteration 18100, loss = 0.849036
I0312 01:47:07.715219 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 01:47:07.715226 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.232008 (* 1 = 0.232008 loss)
I0312 01:47:07.715245 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.327786 (* 1 = 0.327786 loss)
I0312 01:47:07.715250 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508794 (* 1 = 0.00508794 loss)
I0312 01:47:07.715255 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496424 (* 1 = 0.0496424 loss)
I0312 01:47:07.715271 17663 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0312 01:48:00.463907 17663 solver.cpp:228] Iteration 18200, loss = 0.48777
I0312 01:48:00.463930 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 01:48:00.463937 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.187709 (* 1 = 0.187709 loss)
I0312 01:48:00.463956 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.323122 (* 1 = 0.323122 loss)
I0312 01:48:00.463961 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205288 (* 1 = 0.0205288 loss)
I0312 01:48:00.463965 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0440895 (* 1 = 0.0440895 loss)
I0312 01:48:00.463970 17663 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0312 01:48:52.838601 17663 solver.cpp:228] Iteration 18300, loss = 0.263062
I0312 01:48:52.838624 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 01:48:52.838630 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0603481 (* 1 = 0.0603481 loss)
I0312 01:48:52.838649 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.108169 (* 1 = 0.108169 loss)
I0312 01:48:52.838654 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140549 (* 1 = 0.0140549 loss)
I0312 01:48:52.838657 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651541 (* 1 = 0.0651541 loss)
I0312 01:48:52.838662 17663 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0312 01:49:45.499358 17663 solver.cpp:228] Iteration 18400, loss = 0.560408
I0312 01:49:45.499379 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0312 01:49:45.499385 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.129099 (* 1 = 0.129099 loss)
I0312 01:49:45.499390 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.619261 (* 1 = 0.619261 loss)
I0312 01:49:45.499409 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0311792 (* 1 = 0.0311792 loss)
I0312 01:49:45.499413 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0550073 (* 1 = 0.0550073 loss)
I0312 01:49:45.499418 17663 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0312 01:50:37.451529 17663 solver.cpp:228] Iteration 18500, loss = 0.317431
I0312 01:50:37.451551 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 01:50:37.451560 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352312 (* 1 = 0.0352312 loss)
I0312 01:50:37.451565 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.16297 (* 1 = 0.16297 loss)
I0312 01:50:37.451570 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011555 (* 1 = 0.011555 loss)
I0312 01:50:37.451573 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246962 (* 1 = 0.0246962 loss)
I0312 01:50:37.451592 17663 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0312 01:51:30.087530 17663 solver.cpp:228] Iteration 18600, loss = 0.413373
I0312 01:51:30.087553 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 01:51:30.087559 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244345 (* 1 = 0.0244345 loss)
I0312 01:51:30.087579 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0780605 (* 1 = 0.0780605 loss)
I0312 01:51:30.087582 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191764 (* 1 = 0.00191764 loss)
I0312 01:51:30.087587 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0764877 (* 1 = 0.0764877 loss)
I0312 01:51:30.087591 17663 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0312 01:52:22.772276 17663 solver.cpp:228] Iteration 18700, loss = 0.657313
I0312 01:52:22.772298 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 01:52:22.772305 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.305098 (* 1 = 0.305098 loss)
I0312 01:52:22.772323 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.491864 (* 1 = 0.491864 loss)
I0312 01:52:22.772328 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0732338 (* 1 = 0.0732338 loss)
I0312 01:52:22.772346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.178427 (* 1 = 0.178427 loss)
I0312 01:52:22.772351 17663 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0312 01:53:14.688865 17663 solver.cpp:228] Iteration 18800, loss = 0.235505
I0312 01:53:14.688889 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 01:53:14.688896 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0603382 (* 1 = 0.0603382 loss)
I0312 01:53:14.688901 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0908499 (* 1 = 0.0908499 loss)
I0312 01:53:14.688905 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280007 (* 1 = 0.0280007 loss)
I0312 01:53:14.688910 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13306 (* 1 = 0.13306 loss)
I0312 01:53:14.688930 17663 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0312 01:54:06.700551 17663 solver.cpp:228] Iteration 18900, loss = 0.68462
I0312 01:54:06.700573 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 01:54:06.700582 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0307161 (* 1 = 0.0307161 loss)
I0312 01:54:06.700587 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13338 (* 1 = 0.13338 loss)
I0312 01:54:06.700605 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826558 (* 1 = 0.00826558 loss)
I0312 01:54:06.700609 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281099 (* 1 = 0.0281099 loss)
I0312 01:54:06.700614 17663 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
speed: 0.524s / iter
I0312 01:54:58.359235 17663 solver.cpp:228] Iteration 19000, loss = 0.12401
I0312 01:54:58.359385 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 01:54:58.359442 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275385 (* 1 = 0.0275385 loss)
I0312 01:54:58.359491 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11531 (* 1 = 0.11531 loss)
I0312 01:54:58.359539 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00455512 (* 1 = 0.00455512 loss)
I0312 01:54:58.359586 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00477748 (* 1 = 0.00477748 loss)
I0312 01:54:58.359633 17663 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0312 01:55:51.252995 17663 solver.cpp:228] Iteration 19100, loss = 0.330469
I0312 01:55:51.253018 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 01:55:51.253026 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0607719 (* 1 = 0.0607719 loss)
I0312 01:55:51.253046 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1578 (* 1 = 0.1578 loss)
I0312 01:55:51.253049 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00435032 (* 1 = 0.00435032 loss)
I0312 01:55:51.253054 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0996445 (* 1 = 0.0996445 loss)
I0312 01:55:51.253059 17663 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0312 01:56:43.655457 17663 solver.cpp:228] Iteration 19200, loss = 0.632453
I0312 01:56:43.655478 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 01:56:43.655486 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240409 (* 1 = 0.0240409 loss)
I0312 01:56:43.655491 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103019 (* 1 = 0.103019 loss)
I0312 01:56:43.655495 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.569964 (* 1 = 0.569964 loss)
I0312 01:56:43.655499 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.411464 (* 1 = 0.411464 loss)
I0312 01:56:43.655504 17663 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0312 01:57:37.193320 17663 solver.cpp:228] Iteration 19300, loss = 0.496177
I0312 01:57:37.193342 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 01:57:37.193349 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.11737 (* 1 = 0.11737 loss)
I0312 01:57:37.193368 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.241878 (* 1 = 0.241878 loss)
I0312 01:57:37.193373 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112857 (* 1 = 0.0112857 loss)
I0312 01:57:37.193377 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304102 (* 1 = 0.0304102 loss)
I0312 01:57:37.193382 17663 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0312 01:58:29.343309 17663 solver.cpp:228] Iteration 19400, loss = 0.772246
I0312 01:58:29.343333 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 01:58:29.343343 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.241252 (* 1 = 0.241252 loss)
I0312 01:58:29.343348 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.472047 (* 1 = 0.472047 loss)
I0312 01:58:29.343351 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0811607 (* 1 = 0.0811607 loss)
I0312 01:58:29.343355 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0841251 (* 1 = 0.0841251 loss)
I0312 01:58:29.343376 17663 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0312 01:59:21.969624 17663 solver.cpp:228] Iteration 19500, loss = 0.255689
I0312 01:59:21.969645 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 01:59:21.969652 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.038514 (* 1 = 0.038514 loss)
I0312 01:59:21.969671 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0900633 (* 1 = 0.0900633 loss)
I0312 01:59:21.969676 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251438 (* 1 = 0.0251438 loss)
I0312 01:59:21.969679 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0588329 (* 1 = 0.0588329 loss)
I0312 01:59:21.969683 17663 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0312 02:00:13.878489 17663 solver.cpp:228] Iteration 19600, loss = 0.254737
I0312 02:00:13.878509 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 02:00:13.878516 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310069 (* 1 = 0.0310069 loss)
I0312 02:00:13.878535 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151904 (* 1 = 0.151904 loss)
I0312 02:00:13.878540 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366945 (* 1 = 0.0366945 loss)
I0312 02:00:13.878556 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358689 (* 1 = 0.0358689 loss)
I0312 02:00:13.878561 17663 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0312 02:01:06.624442 17663 solver.cpp:228] Iteration 19700, loss = 0.374995
I0312 02:01:06.624464 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:01:06.624471 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.025551 (* 1 = 0.025551 loss)
I0312 02:01:06.624490 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114879 (* 1 = 0.114879 loss)
I0312 02:01:06.624495 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292124 (* 1 = 0.00292124 loss)
I0312 02:01:06.624500 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0609044 (* 1 = 0.0609044 loss)
I0312 02:01:06.624505 17663 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0312 02:01:58.909811 17663 solver.cpp:228] Iteration 19800, loss = 0.130039
I0312 02:01:58.909832 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 02:01:58.909840 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236064 (* 1 = 0.0236064 loss)
I0312 02:01:58.909845 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0674799 (* 1 = 0.0674799 loss)
I0312 02:01:58.909864 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266392 (* 1 = 0.00266392 loss)
I0312 02:01:58.909868 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0030909 (* 1 = 0.0030909 loss)
I0312 02:01:58.909874 17663 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0312 02:02:51.072803 17663 solver.cpp:228] Iteration 19900, loss = 0.585667
I0312 02:02:51.072825 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:02:51.072832 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0622616 (* 1 = 0.0622616 loss)
I0312 02:02:51.072851 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.175198 (* 1 = 0.175198 loss)
I0312 02:02:51.072856 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266563 (* 1 = 0.0266563 loss)
I0312 02:02:51.072860 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351997 (* 1 = 0.0351997 loss)
I0312 02:02:51.072865 17663 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0312 02:03:43.337783 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_20000.caffemodel
I0312 02:03:43.710520 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_20000.solverstate
speed: 0.524s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_20000.caffemodel
I0312 02:03:45.021697 17663 solver.cpp:228] Iteration 20000, loss = 0.287067
I0312 02:03:45.021720 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 02:03:45.021728 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644135 (* 1 = 0.0644135 loss)
I0312 02:03:45.021747 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157261 (* 1 = 0.157261 loss)
I0312 02:03:45.021752 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289392 (* 1 = 0.0289392 loss)
I0312 02:03:45.021756 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434149 (* 1 = 0.0434149 loss)
I0312 02:03:45.021761 17663 sgd_solver.cpp:106] Iteration 20000, lr = 1e-05
I0312 02:04:37.900029 17663 solver.cpp:228] Iteration 20100, loss = 0.346587
I0312 02:04:37.900051 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 02:04:37.900058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179995 (* 1 = 0.0179995 loss)
I0312 02:04:37.900063 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0862079 (* 1 = 0.0862079 loss)
I0312 02:04:37.900081 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416425 (* 1 = 0.00416425 loss)
I0312 02:04:37.900086 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173943 (* 1 = 0.0173943 loss)
I0312 02:04:37.900091 17663 sgd_solver.cpp:106] Iteration 20100, lr = 1e-05
I0312 02:05:30.358711 17663 solver.cpp:228] Iteration 20200, loss = 0.401191
I0312 02:05:30.358732 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 02:05:30.358741 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.11717 (* 1 = 0.11717 loss)
I0312 02:05:30.358744 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183231 (* 1 = 0.183231 loss)
I0312 02:05:30.358763 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0641877 (* 1 = 0.0641877 loss)
I0312 02:05:30.358767 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.350305 (* 1 = 0.350305 loss)
I0312 02:05:30.358772 17663 sgd_solver.cpp:106] Iteration 20200, lr = 1e-05
I0312 02:06:23.677407 17663 solver.cpp:228] Iteration 20300, loss = 0.222038
I0312 02:06:23.677428 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 02:06:23.677435 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0626312 (* 1 = 0.0626312 loss)
I0312 02:06:23.677454 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.191587 (* 1 = 0.191587 loss)
I0312 02:06:23.677459 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125419 (* 1 = 0.0125419 loss)
I0312 02:06:23.677476 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0739614 (* 1 = 0.0739614 loss)
I0312 02:06:23.677480 17663 sgd_solver.cpp:106] Iteration 20300, lr = 1e-05
I0312 02:07:15.985776 17663 solver.cpp:228] Iteration 20400, loss = 0.324343
I0312 02:07:15.985800 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 02:07:15.985806 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0803889 (* 1 = 0.0803889 loss)
I0312 02:07:15.985826 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.187179 (* 1 = 0.187179 loss)
I0312 02:07:15.985831 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222349 (* 1 = 0.00222349 loss)
I0312 02:07:15.985847 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0422198 (* 1 = 0.0422198 loss)
I0312 02:07:15.985852 17663 sgd_solver.cpp:106] Iteration 20400, lr = 1e-05
I0312 02:08:08.289067 17663 solver.cpp:228] Iteration 20500, loss = 0.550999
I0312 02:08:08.289088 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 02:08:08.289094 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.20802 (* 1 = 0.20802 loss)
I0312 02:08:08.289114 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.395535 (* 1 = 0.395535 loss)
I0312 02:08:08.289119 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0752472 (* 1 = 0.0752472 loss)
I0312 02:08:08.289122 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566266 (* 1 = 0.0566266 loss)
I0312 02:08:08.289126 17663 sgd_solver.cpp:106] Iteration 20500, lr = 1e-05
I0312 02:09:00.459408 17663 solver.cpp:228] Iteration 20600, loss = 0.351384
I0312 02:09:00.459430 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:09:00.459437 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.1083 (* 1 = 0.1083 loss)
I0312 02:09:00.459456 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17924 (* 1 = 0.17924 loss)
I0312 02:09:00.459460 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596104 (* 1 = 0.00596104 loss)
I0312 02:09:00.459465 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239505 (* 1 = 0.0239505 loss)
I0312 02:09:00.459470 17663 sgd_solver.cpp:106] Iteration 20600, lr = 1e-05
I0312 02:09:52.427706 17663 solver.cpp:228] Iteration 20700, loss = 0.282902
I0312 02:09:52.427727 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 02:09:52.427734 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.173866 (* 1 = 0.173866 loss)
I0312 02:09:52.427753 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.22106 (* 1 = 0.22106 loss)
I0312 02:09:52.427757 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125751 (* 1 = 0.0125751 loss)
I0312 02:09:52.427762 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401105 (* 1 = 0.0401105 loss)
I0312 02:09:52.427767 17663 sgd_solver.cpp:106] Iteration 20700, lr = 1e-05
I0312 02:10:44.235543 17663 solver.cpp:228] Iteration 20800, loss = 0.289848
I0312 02:10:44.235568 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 02:10:44.235575 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625544 (* 1 = 0.0625544 loss)
I0312 02:10:44.235594 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.197964 (* 1 = 0.197964 loss)
I0312 02:10:44.235599 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013469 (* 1 = 0.013469 loss)
I0312 02:10:44.235602 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0797781 (* 1 = 0.0797781 loss)
I0312 02:10:44.235607 17663 sgd_solver.cpp:106] Iteration 20800, lr = 1e-05
I0312 02:11:37.021541 17663 solver.cpp:228] Iteration 20900, loss = 0.214912
I0312 02:11:37.021564 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:11:37.021571 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00511019 (* 1 = 0.00511019 loss)
I0312 02:11:37.021577 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.14283 (* 1 = 0.14283 loss)
I0312 02:11:37.021581 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103047 (* 1 = 0.103047 loss)
I0312 02:11:37.021585 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353396 (* 1 = 0.0353396 loss)
I0312 02:11:37.021605 17663 sgd_solver.cpp:106] Iteration 20900, lr = 1e-05
speed: 0.524s / iter
I0312 02:12:28.975215 17663 solver.cpp:228] Iteration 21000, loss = 0.328055
I0312 02:12:28.975252 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 02:12:28.975260 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0677092 (* 1 = 0.0677092 loss)
I0312 02:12:28.975265 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125793 (* 1 = 0.125793 loss)
I0312 02:12:28.975283 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00346702 (* 1 = 0.00346702 loss)
I0312 02:12:28.975288 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00985547 (* 1 = 0.00985547 loss)
I0312 02:12:28.975293 17663 sgd_solver.cpp:106] Iteration 21000, lr = 1e-05
I0312 02:13:20.879765 17663 solver.cpp:228] Iteration 21100, loss = 0.301696
I0312 02:13:20.879787 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 02:13:20.879794 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0751464 (* 1 = 0.0751464 loss)
I0312 02:13:20.879799 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.192289 (* 1 = 0.192289 loss)
I0312 02:13:20.879803 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0549113 (* 1 = 0.0549113 loss)
I0312 02:13:20.879807 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0795898 (* 1 = 0.0795898 loss)
I0312 02:13:20.879812 17663 sgd_solver.cpp:106] Iteration 21100, lr = 1e-05
I0312 02:14:13.515959 17663 solver.cpp:228] Iteration 21200, loss = 0.234781
I0312 02:14:13.515980 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 02:14:13.515986 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.11388 (* 1 = 0.11388 loss)
I0312 02:14:13.515991 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183555 (* 1 = 0.183555 loss)
I0312 02:14:13.516010 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00528309 (* 1 = 0.00528309 loss)
I0312 02:14:13.516014 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0747062 (* 1 = 0.0747062 loss)
I0312 02:14:13.516031 17663 sgd_solver.cpp:106] Iteration 21200, lr = 1e-05
I0312 02:15:05.889953 17663 solver.cpp:228] Iteration 21300, loss = 0.300198
I0312 02:15:05.889979 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 02:15:05.889986 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334341 (* 1 = 0.0334341 loss)
I0312 02:15:05.889991 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.129444 (* 1 = 0.129444 loss)
I0312 02:15:05.890010 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604356 (* 1 = 0.00604356 loss)
I0312 02:15:05.890015 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00946239 (* 1 = 0.00946239 loss)
I0312 02:15:05.890033 17663 sgd_solver.cpp:106] Iteration 21300, lr = 1e-05
I0312 02:15:57.915416 17663 solver.cpp:228] Iteration 21400, loss = 0.126093
I0312 02:15:57.915437 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:15:57.915446 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316732 (* 1 = 0.0316732 loss)
I0312 02:15:57.915464 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0867709 (* 1 = 0.0867709 loss)
I0312 02:15:57.915469 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271466 (* 1 = 0.00271466 loss)
I0312 02:15:57.915473 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199718 (* 1 = 0.0199718 loss)
I0312 02:15:57.915477 17663 sgd_solver.cpp:106] Iteration 21400, lr = 1e-05
I0312 02:16:50.728031 17663 solver.cpp:228] Iteration 21500, loss = 0.309645
I0312 02:16:50.728056 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 02:16:50.728065 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333649 (* 1 = 0.0333649 loss)
I0312 02:16:50.728083 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137045 (* 1 = 0.137045 loss)
I0312 02:16:50.728087 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0392654 (* 1 = 0.0392654 loss)
I0312 02:16:50.728092 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00468796 (* 1 = 0.00468796 loss)
I0312 02:16:50.728097 17663 sgd_solver.cpp:106] Iteration 21500, lr = 1e-05
I0312 02:17:43.309434 17663 solver.cpp:228] Iteration 21600, loss = 1.09589
I0312 02:17:43.309455 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 02:17:43.309463 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.161699 (* 1 = 0.161699 loss)
I0312 02:17:43.309482 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.210436 (* 1 = 0.210436 loss)
I0312 02:17:43.309487 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604173 (* 1 = 0.00604173 loss)
I0312 02:17:43.309491 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0655359 (* 1 = 0.0655359 loss)
I0312 02:17:43.309496 17663 sgd_solver.cpp:106] Iteration 21600, lr = 1e-05
I0312 02:18:35.322875 17663 solver.cpp:228] Iteration 21700, loss = 0.166929
I0312 02:18:35.322898 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:18:35.322906 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434039 (* 1 = 0.0434039 loss)
I0312 02:18:35.322924 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0922549 (* 1 = 0.0922549 loss)
I0312 02:18:35.322929 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194254 (* 1 = 0.00194254 loss)
I0312 02:18:35.322933 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00552057 (* 1 = 0.00552057 loss)
I0312 02:18:35.322938 17663 sgd_solver.cpp:106] Iteration 21700, lr = 1e-05
I0312 02:19:28.502935 17663 solver.cpp:228] Iteration 21800, loss = 0.316428
I0312 02:19:28.502959 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 02:19:28.502965 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337619 (* 1 = 0.0337619 loss)
I0312 02:19:28.502970 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0794149 (* 1 = 0.0794149 loss)
I0312 02:19:28.502990 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00821459 (* 1 = 0.00821459 loss)
I0312 02:19:28.502993 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388613 (* 1 = 0.0388613 loss)
I0312 02:19:28.503012 17663 sgd_solver.cpp:106] Iteration 21800, lr = 1e-05
I0312 02:20:20.658377 17663 solver.cpp:228] Iteration 21900, loss = 0.287633
I0312 02:20:20.658399 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:20:20.658407 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0543031 (* 1 = 0.0543031 loss)
I0312 02:20:20.658411 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112121 (* 1 = 0.112121 loss)
I0312 02:20:20.658430 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00794204 (* 1 = 0.00794204 loss)
I0312 02:20:20.658435 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0529561 (* 1 = 0.0529561 loss)
I0312 02:20:20.658440 17663 sgd_solver.cpp:106] Iteration 21900, lr = 1e-05
speed: 0.524s / iter
I0312 02:21:13.495892 17663 solver.cpp:228] Iteration 22000, loss = 0.274754
I0312 02:21:13.495914 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:21:13.495923 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702113 (* 1 = 0.0702113 loss)
I0312 02:21:13.495941 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165485 (* 1 = 0.165485 loss)
I0312 02:21:13.495945 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021663 (* 1 = 0.021663 loss)
I0312 02:21:13.495949 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0565044 (* 1 = 0.0565044 loss)
I0312 02:21:13.495954 17663 sgd_solver.cpp:106] Iteration 22000, lr = 1e-05
I0312 02:22:05.833827 17663 solver.cpp:228] Iteration 22100, loss = 0.234196
I0312 02:22:05.833848 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:22:05.833855 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692805 (* 1 = 0.0692805 loss)
I0312 02:22:05.833860 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116421 (* 1 = 0.116421 loss)
I0312 02:22:05.833879 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103822 (* 1 = 0.0103822 loss)
I0312 02:22:05.833884 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176623 (* 1 = 0.0176623 loss)
I0312 02:22:05.833887 17663 sgd_solver.cpp:106] Iteration 22100, lr = 1e-05
I0312 02:22:57.835718 17663 solver.cpp:228] Iteration 22200, loss = 0.544378
I0312 02:22:57.835739 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:22:57.835747 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.100735 (* 1 = 0.100735 loss)
I0312 02:22:57.835767 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0969424 (* 1 = 0.0969424 loss)
I0312 02:22:57.835770 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109413 (* 1 = 0.0109413 loss)
I0312 02:22:57.835774 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.209883 (* 1 = 0.209883 loss)
I0312 02:22:57.835779 17663 sgd_solver.cpp:106] Iteration 22200, lr = 1e-05
I0312 02:23:49.189404 17663 solver.cpp:228] Iteration 22300, loss = 0.278602
I0312 02:23:49.189426 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 02:23:49.189435 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0709814 (* 1 = 0.0709814 loss)
I0312 02:23:49.189440 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0784806 (* 1 = 0.0784806 loss)
I0312 02:23:49.189443 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122455 (* 1 = 0.0122455 loss)
I0312 02:23:49.189447 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154642 (* 1 = 0.0154642 loss)
I0312 02:23:49.189466 17663 sgd_solver.cpp:106] Iteration 22300, lr = 1e-05
I0312 02:24:41.768034 17663 solver.cpp:228] Iteration 22400, loss = 0.235801
I0312 02:24:41.768057 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:24:41.768064 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0354908 (* 1 = 0.0354908 loss)
I0312 02:24:41.768084 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0659081 (* 1 = 0.0659081 loss)
I0312 02:24:41.768088 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00753635 (* 1 = 0.00753635 loss)
I0312 02:24:41.768092 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390494 (* 1 = 0.0390494 loss)
I0312 02:24:41.768097 17663 sgd_solver.cpp:106] Iteration 22400, lr = 1e-05
I0312 02:25:34.353849 17663 solver.cpp:228] Iteration 22500, loss = 0.485621
I0312 02:25:34.353873 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 02:25:34.353879 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.175781 (* 1 = 0.175781 loss)
I0312 02:25:34.353904 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.333987 (* 1 = 0.333987 loss)
I0312 02:25:34.353909 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00728606 (* 1 = 0.00728606 loss)
I0312 02:25:34.353927 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0725832 (* 1 = 0.0725832 loss)
I0312 02:25:34.353934 17663 sgd_solver.cpp:106] Iteration 22500, lr = 1e-05
I0312 02:26:26.547721 17663 solver.cpp:228] Iteration 22600, loss = 0.229632
I0312 02:26:26.547742 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:26:26.547750 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391633 (* 1 = 0.0391633 loss)
I0312 02:26:26.547755 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.136221 (* 1 = 0.136221 loss)
I0312 02:26:26.547760 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00212535 (* 1 = 0.00212535 loss)
I0312 02:26:26.547763 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00306056 (* 1 = 0.00306056 loss)
I0312 02:26:26.547768 17663 sgd_solver.cpp:106] Iteration 22600, lr = 1e-05
I0312 02:27:19.075366 17663 solver.cpp:228] Iteration 22700, loss = 0.689215
I0312 02:27:19.075387 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:27:19.075394 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.174436 (* 1 = 0.174436 loss)
I0312 02:27:19.075399 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170055 (* 1 = 0.170055 loss)
I0312 02:27:19.075403 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0432355 (* 1 = 0.0432355 loss)
I0312 02:27:19.075407 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128771 (* 1 = 0.128771 loss)
I0312 02:27:19.075412 17663 sgd_solver.cpp:106] Iteration 22700, lr = 1e-05
I0312 02:28:12.397259 17663 solver.cpp:228] Iteration 22800, loss = 0.5249
I0312 02:28:12.397281 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 02:28:12.397289 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125545 (* 1 = 0.125545 loss)
I0312 02:28:12.397307 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17459 (* 1 = 0.17459 loss)
I0312 02:28:12.397312 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262687 (* 1 = 0.0262687 loss)
I0312 02:28:12.397317 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.176508 (* 1 = 0.176508 loss)
I0312 02:28:12.397321 17663 sgd_solver.cpp:106] Iteration 22800, lr = 1e-05
I0312 02:29:04.990080 17663 solver.cpp:228] Iteration 22900, loss = 0.297294
I0312 02:29:04.990101 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:29:04.990108 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0408213 (* 1 = 0.0408213 loss)
I0312 02:29:04.990113 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.140545 (* 1 = 0.140545 loss)
I0312 02:29:04.990131 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00914058 (* 1 = 0.00914058 loss)
I0312 02:29:04.990136 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.263766 (* 1 = 0.263766 loss)
I0312 02:29:04.990141 17663 sgd_solver.cpp:106] Iteration 22900, lr = 1e-05
speed: 0.524s / iter
I0312 02:29:57.465728 17663 solver.cpp:228] Iteration 23000, loss = 0.444731
I0312 02:29:57.465888 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 02:29:57.465966 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.21757 (* 1 = 0.21757 loss)
I0312 02:29:57.466014 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.325495 (* 1 = 0.325495 loss)
I0312 02:29:57.466061 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172287 (* 1 = 0.0172287 loss)
I0312 02:29:57.466107 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103115 (* 1 = 0.103115 loss)
I0312 02:29:57.466154 17663 sgd_solver.cpp:106] Iteration 23000, lr = 1e-05
I0312 02:30:49.676353 17663 solver.cpp:228] Iteration 23100, loss = 0.127809
I0312 02:30:49.676375 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 02:30:49.676383 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0301268 (* 1 = 0.0301268 loss)
I0312 02:30:49.676403 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0578922 (* 1 = 0.0578922 loss)
I0312 02:30:49.676406 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00623324 (* 1 = 0.00623324 loss)
I0312 02:30:49.676410 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00503239 (* 1 = 0.00503239 loss)
I0312 02:30:49.676415 17663 sgd_solver.cpp:106] Iteration 23100, lr = 1e-05
I0312 02:31:41.487751 17663 solver.cpp:228] Iteration 23200, loss = 0.645285
I0312 02:31:41.487776 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 02:31:41.487782 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.138711 (* 1 = 0.138711 loss)
I0312 02:31:41.487800 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.150181 (* 1 = 0.150181 loss)
I0312 02:31:41.487805 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.142509 (* 1 = 0.142509 loss)
I0312 02:31:41.487809 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.670257 (* 1 = 0.670257 loss)
I0312 02:31:41.487814 17663 sgd_solver.cpp:106] Iteration 23200, lr = 1e-05
I0312 02:32:34.165729 17663 solver.cpp:228] Iteration 23300, loss = 0.363663
I0312 02:32:34.165752 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:32:34.165760 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0620254 (* 1 = 0.0620254 loss)
I0312 02:32:34.165778 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0869587 (* 1 = 0.0869587 loss)
I0312 02:32:34.165783 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146776 (* 1 = 0.0146776 loss)
I0312 02:32:34.165787 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172132 (* 1 = 0.0172132 loss)
I0312 02:32:34.165792 17663 sgd_solver.cpp:106] Iteration 23300, lr = 1e-05
I0312 02:33:26.578999 17663 solver.cpp:228] Iteration 23400, loss = 0.265232
I0312 02:33:26.579021 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:33:26.579030 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0745115 (* 1 = 0.0745115 loss)
I0312 02:33:26.579048 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.124073 (* 1 = 0.124073 loss)
I0312 02:33:26.579052 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0456332 (* 1 = 0.0456332 loss)
I0312 02:33:26.579056 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0745784 (* 1 = 0.0745784 loss)
I0312 02:33:26.579061 17663 sgd_solver.cpp:106] Iteration 23400, lr = 1e-05
I0312 02:34:19.063071 17663 solver.cpp:228] Iteration 23500, loss = 0.203743
I0312 02:34:19.063091 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 02:34:19.063099 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381559 (* 1 = 0.0381559 loss)
I0312 02:34:19.063118 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0514283 (* 1 = 0.0514283 loss)
I0312 02:34:19.063122 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361624 (* 1 = 0.00361624 loss)
I0312 02:34:19.063127 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318439 (* 1 = 0.0318439 loss)
I0312 02:34:19.063132 17663 sgd_solver.cpp:106] Iteration 23500, lr = 1e-05
I0312 02:35:11.244285 17663 solver.cpp:228] Iteration 23600, loss = 0.257536
I0312 02:35:11.244309 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:35:11.244316 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105319 (* 1 = 0.105319 loss)
I0312 02:35:11.244335 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.138076 (* 1 = 0.138076 loss)
I0312 02:35:11.244339 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0702237 (* 1 = 0.0702237 loss)
I0312 02:35:11.244343 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0412901 (* 1 = 0.0412901 loss)
I0312 02:35:11.244349 17663 sgd_solver.cpp:106] Iteration 23600, lr = 1e-05
I0312 02:36:03.882405 17663 solver.cpp:228] Iteration 23700, loss = 0.37083
I0312 02:36:03.882428 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 02:36:03.882436 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.19599 (* 1 = 0.19599 loss)
I0312 02:36:03.882454 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.261356 (* 1 = 0.261356 loss)
I0312 02:36:03.882459 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159777 (* 1 = 0.0159777 loss)
I0312 02:36:03.882463 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375594 (* 1 = 0.0375594 loss)
I0312 02:36:03.882468 17663 sgd_solver.cpp:106] Iteration 23700, lr = 1e-05
I0312 02:36:56.732087 17663 solver.cpp:228] Iteration 23800, loss = 0.221991
I0312 02:36:56.732110 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:36:56.732117 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0315529 (* 1 = 0.0315529 loss)
I0312 02:36:56.732136 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0881601 (* 1 = 0.0881601 loss)
I0312 02:36:56.732141 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00610401 (* 1 = 0.00610401 loss)
I0312 02:36:56.732144 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0570824 (* 1 = 0.0570824 loss)
I0312 02:36:56.732149 17663 sgd_solver.cpp:106] Iteration 23800, lr = 1e-05
I0312 02:37:49.488036 17663 solver.cpp:228] Iteration 23900, loss = 0.483545
I0312 02:37:49.488065 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 02:37:49.488087 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499385 (* 1 = 0.0499385 loss)
I0312 02:37:49.488093 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149392 (* 1 = 0.149392 loss)
I0312 02:37:49.488097 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298226 (* 1 = 0.00298226 loss)
I0312 02:37:49.488102 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120502 (* 1 = 0.120502 loss)
I0312 02:37:49.488109 17663 sgd_solver.cpp:106] Iteration 23900, lr = 1e-05
speed: 0.524s / iter
I0312 02:38:41.544677 17663 solver.cpp:228] Iteration 24000, loss = 0.469837
I0312 02:38:41.544822 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 02:38:41.544878 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0480925 (* 1 = 0.0480925 loss)
I0312 02:38:41.544927 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.158388 (* 1 = 0.158388 loss)
I0312 02:38:41.544975 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00895486 (* 1 = 0.00895486 loss)
I0312 02:38:41.545022 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0974156 (* 1 = 0.0974156 loss)
I0312 02:38:41.545068 17663 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0312 02:39:34.370347 17663 solver.cpp:228] Iteration 24100, loss = 0.466712
I0312 02:39:34.370368 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:39:34.370375 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524498 (* 1 = 0.0524498 loss)
I0312 02:39:34.370380 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0713946 (* 1 = 0.0713946 loss)
I0312 02:39:34.370398 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293465 (* 1 = 0.0293465 loss)
I0312 02:39:34.370402 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885428 (* 1 = 0.0885428 loss)
I0312 02:39:34.370407 17663 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0312 02:40:27.298040 17663 solver.cpp:228] Iteration 24200, loss = 0.269749
I0312 02:40:27.298063 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 02:40:27.298071 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0991604 (* 1 = 0.0991604 loss)
I0312 02:40:27.298090 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.167263 (* 1 = 0.167263 loss)
I0312 02:40:27.298094 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112927 (* 1 = 0.0112927 loss)
I0312 02:40:27.298099 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663753 (* 1 = 0.0663753 loss)
I0312 02:40:27.298116 17663 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0312 02:41:19.913020 17663 solver.cpp:228] Iteration 24300, loss = 0.346053
I0312 02:41:19.913043 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:41:19.913049 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.163948 (* 1 = 0.163948 loss)
I0312 02:41:19.913069 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.199781 (* 1 = 0.199781 loss)
I0312 02:41:19.913074 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00726119 (* 1 = 0.00726119 loss)
I0312 02:41:19.913077 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0476317 (* 1 = 0.0476317 loss)
I0312 02:41:19.913081 17663 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0312 02:42:12.169785 17663 solver.cpp:228] Iteration 24400, loss = 0.254292
I0312 02:42:12.169806 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 02:42:12.169813 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0710673 (* 1 = 0.0710673 loss)
I0312 02:42:12.169832 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.162219 (* 1 = 0.162219 loss)
I0312 02:42:12.169837 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00823557 (* 1 = 0.00823557 loss)
I0312 02:42:12.169842 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243707 (* 1 = 0.0243707 loss)
I0312 02:42:12.169847 17663 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0312 02:43:05.381502 17663 solver.cpp:228] Iteration 24500, loss = 0.294512
I0312 02:43:05.381525 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:43:05.381532 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0922076 (* 1 = 0.0922076 loss)
I0312 02:43:05.381551 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.182816 (* 1 = 0.182816 loss)
I0312 02:43:05.381556 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008817 (* 1 = 0.008817 loss)
I0312 02:43:05.381559 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244565 (* 1 = 0.0244565 loss)
I0312 02:43:05.381564 17663 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0312 02:43:58.063453 17663 solver.cpp:228] Iteration 24600, loss = 0.196693
I0312 02:43:58.063474 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 02:43:58.063482 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476125 (* 1 = 0.0476125 loss)
I0312 02:43:58.063486 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116194 (* 1 = 0.116194 loss)
I0312 02:43:58.063505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377381 (* 1 = 0.00377381 loss)
I0312 02:43:58.063509 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244037 (* 1 = 0.0244037 loss)
I0312 02:43:58.063514 17663 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0312 02:44:50.322818 17663 solver.cpp:228] Iteration 24700, loss = 0.474274
I0312 02:44:50.322841 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:44:50.322849 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.104352 (* 1 = 0.104352 loss)
I0312 02:44:50.322868 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.136499 (* 1 = 0.136499 loss)
I0312 02:44:50.322873 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137825 (* 1 = 0.0137825 loss)
I0312 02:44:50.322890 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289388 (* 1 = 0.0289388 loss)
I0312 02:44:50.322895 17663 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0312 02:45:42.633620 17663 solver.cpp:228] Iteration 24800, loss = 0.78778
I0312 02:45:42.633641 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 02:45:42.633648 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.450181 (* 1 = 0.450181 loss)
I0312 02:45:42.633667 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.534632 (* 1 = 0.534632 loss)
I0312 02:45:42.633671 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.100442 (* 1 = 0.100442 loss)
I0312 02:45:42.633675 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.308782 (* 1 = 0.308782 loss)
I0312 02:45:42.633680 17663 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0312 02:46:34.913712 17663 solver.cpp:228] Iteration 24900, loss = 0.335933
I0312 02:46:34.913735 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 02:46:34.913743 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459558 (* 1 = 0.0459558 loss)
I0312 02:46:34.913763 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0524518 (* 1 = 0.0524518 loss)
I0312 02:46:34.913766 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131716 (* 1 = 0.0131716 loss)
I0312 02:46:34.913770 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.058876 (* 1 = 0.058876 loss)
I0312 02:46:34.913775 17663 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
speed: 0.524s / iter
I0312 02:47:27.038336 17663 solver.cpp:228] Iteration 25000, loss = 0.325991
I0312 02:47:27.038480 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 02:47:27.038534 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707276 (* 1 = 0.0707276 loss)
I0312 02:47:27.038583 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0817999 (* 1 = 0.0817999 loss)
I0312 02:47:27.038631 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00431547 (* 1 = 0.00431547 loss)
I0312 02:47:27.038678 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0610624 (* 1 = 0.0610624 loss)
I0312 02:47:27.038725 17663 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0312 02:48:19.434293 17663 solver.cpp:228] Iteration 25100, loss = 0.168588
I0312 02:48:19.434314 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:48:19.434320 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0538217 (* 1 = 0.0538217 loss)
I0312 02:48:19.434340 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156522 (* 1 = 0.156522 loss)
I0312 02:48:19.434345 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171983 (* 1 = 0.0171983 loss)
I0312 02:48:19.434348 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00734904 (* 1 = 0.00734904 loss)
I0312 02:48:19.434352 17663 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0312 02:49:12.323094 17663 solver.cpp:228] Iteration 25200, loss = 0.328207
I0312 02:49:12.323117 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 02:49:12.323124 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.172957 (* 1 = 0.172957 loss)
I0312 02:49:12.323128 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1499 (* 1 = 0.1499 loss)
I0312 02:49:12.323132 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196435 (* 1 = 0.0196435 loss)
I0312 02:49:12.323137 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.130038 (* 1 = 0.130038 loss)
I0312 02:49:12.323141 17663 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0312 02:50:04.797505 17663 solver.cpp:228] Iteration 25300, loss = 0.232996
I0312 02:50:04.797529 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:50:04.797536 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422499 (* 1 = 0.0422499 loss)
I0312 02:50:04.797555 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1251 (* 1 = 0.1251 loss)
I0312 02:50:04.797560 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00721003 (* 1 = 0.00721003 loss)
I0312 02:50:04.797564 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313425 (* 1 = 0.0313425 loss)
I0312 02:50:04.797569 17663 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0312 02:50:57.698060 17663 solver.cpp:228] Iteration 25400, loss = 0.23427
I0312 02:50:57.698081 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 02:50:57.698087 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0661027 (* 1 = 0.0661027 loss)
I0312 02:50:57.698107 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107097 (* 1 = 0.107097 loss)
I0312 02:50:57.698110 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630234 (* 1 = 0.00630234 loss)
I0312 02:50:57.698115 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196207 (* 1 = 0.0196207 loss)
I0312 02:50:57.698119 17663 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0312 02:51:49.437608 17663 solver.cpp:228] Iteration 25500, loss = 0.427734
I0312 02:51:49.437631 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 02:51:49.437639 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.132983 (* 1 = 0.132983 loss)
I0312 02:51:49.437659 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.296093 (* 1 = 0.296093 loss)
I0312 02:51:49.437662 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119851 (* 1 = 0.0119851 loss)
I0312 02:51:49.437666 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.220166 (* 1 = 0.220166 loss)
I0312 02:51:49.437671 17663 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0312 02:52:41.567713 17663 solver.cpp:228] Iteration 25600, loss = 0.654419
I0312 02:52:41.567736 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 02:52:41.567744 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634315 (* 1 = 0.0634315 loss)
I0312 02:52:41.567762 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144762 (* 1 = 0.144762 loss)
I0312 02:52:41.567767 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00572494 (* 1 = 0.00572494 loss)
I0312 02:52:41.567771 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0977162 (* 1 = 0.0977162 loss)
I0312 02:52:41.567776 17663 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0312 02:53:34.713696 17663 solver.cpp:228] Iteration 25700, loss = 0.310093
I0312 02:53:34.713718 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 02:53:34.713726 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477019 (* 1 = 0.0477019 loss)
I0312 02:53:34.713730 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.042447 (* 1 = 0.042447 loss)
I0312 02:53:34.713750 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00842006 (* 1 = 0.00842006 loss)
I0312 02:53:34.713755 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.141111 (* 1 = 0.141111 loss)
I0312 02:53:34.713760 17663 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0312 02:54:27.298825 17663 solver.cpp:228] Iteration 25800, loss = 0.548447
I0312 02:54:27.298849 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0312 02:54:27.298856 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.24897 (* 1 = 0.24897 loss)
I0312 02:54:27.298876 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.568079 (* 1 = 0.568079 loss)
I0312 02:54:27.298879 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0943069 (* 1 = 0.0943069 loss)
I0312 02:54:27.298884 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158599 (* 1 = 0.0158599 loss)
I0312 02:54:27.298888 17663 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0312 02:55:19.855018 17663 solver.cpp:228] Iteration 25900, loss = 0.241071
I0312 02:55:19.855041 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 02:55:19.855049 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.017003 (* 1 = 0.017003 loss)
I0312 02:55:19.855068 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105574 (* 1 = 0.105574 loss)
I0312 02:55:19.855072 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336765 (* 1 = 0.00336765 loss)
I0312 02:55:19.855077 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116369 (* 1 = 0.116369 loss)
I0312 02:55:19.855096 17663 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
speed: 0.524s / iter
I0312 02:56:11.763470 17663 solver.cpp:228] Iteration 26000, loss = 0.413197
I0312 02:56:11.763492 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:56:11.763499 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.129561 (* 1 = 0.129561 loss)
I0312 02:56:11.763519 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181904 (* 1 = 0.181904 loss)
I0312 02:56:11.763523 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00941487 (* 1 = 0.00941487 loss)
I0312 02:56:11.763527 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030911 (* 1 = 0.030911 loss)
I0312 02:56:11.763532 17663 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0312 02:57:04.130630 17663 solver.cpp:228] Iteration 26100, loss = 0.26686
I0312 02:57:04.130650 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 02:57:04.130658 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.020182 (* 1 = 0.020182 loss)
I0312 02:57:04.130677 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103457 (* 1 = 0.103457 loss)
I0312 02:57:04.130681 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00333757 (* 1 = 0.00333757 loss)
I0312 02:57:04.130686 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0607221 (* 1 = 0.0607221 loss)
I0312 02:57:04.130690 17663 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0312 02:57:56.505739 17663 solver.cpp:228] Iteration 26200, loss = 0.413701
I0312 02:57:56.505761 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 02:57:56.505769 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.207784 (* 1 = 0.207784 loss)
I0312 02:57:56.505787 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.403416 (* 1 = 0.403416 loss)
I0312 02:57:56.505792 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00560216 (* 1 = 0.00560216 loss)
I0312 02:57:56.505796 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314098 (* 1 = 0.0314098 loss)
I0312 02:57:56.505800 17663 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0312 02:58:48.658841 17663 solver.cpp:228] Iteration 26300, loss = 0.482943
I0312 02:58:48.658866 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 02:58:48.658874 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.117138 (* 1 = 0.117138 loss)
I0312 02:58:48.658893 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.298101 (* 1 = 0.298101 loss)
I0312 02:58:48.658898 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105094 (* 1 = 0.0105094 loss)
I0312 02:58:48.658902 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0730429 (* 1 = 0.0730429 loss)
I0312 02:58:48.658907 17663 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0312 02:59:41.798583 17663 solver.cpp:228] Iteration 26400, loss = 0.523323
I0312 02:59:41.798607 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 02:59:41.798615 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443601 (* 1 = 0.0443601 loss)
I0312 02:59:41.798635 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0786941 (* 1 = 0.0786941 loss)
I0312 02:59:41.798638 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157282 (* 1 = 0.00157282 loss)
I0312 02:59:41.798643 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118684 (* 1 = 0.0118684 loss)
I0312 02:59:41.798648 17663 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0312 03:00:34.566637 17663 solver.cpp:228] Iteration 26500, loss = 0.248672
I0312 03:00:34.566659 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 03:00:34.566666 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119351 (* 1 = 0.119351 loss)
I0312 03:00:34.566685 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135544 (* 1 = 0.135544 loss)
I0312 03:00:34.566689 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0318789 (* 1 = 0.0318789 loss)
I0312 03:00:34.566694 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327943 (* 1 = 0.0327943 loss)
I0312 03:00:34.566699 17663 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0312 03:01:26.919296 17663 solver.cpp:228] Iteration 26600, loss = 0.287237
I0312 03:01:26.919324 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:01:26.919333 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.157865 (* 1 = 0.157865 loss)
I0312 03:01:26.919353 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.272779 (* 1 = 0.272779 loss)
I0312 03:01:26.919358 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118767 (* 1 = 0.0118767 loss)
I0312 03:01:26.919363 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289154 (* 1 = 0.0289154 loss)
I0312 03:01:26.919368 17663 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0312 03:02:19.505450 17663 solver.cpp:228] Iteration 26700, loss = 0.211756
I0312 03:02:19.505477 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 03:02:19.505486 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571049 (* 1 = 0.0571049 loss)
I0312 03:02:19.505506 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165356 (* 1 = 0.165356 loss)
I0312 03:02:19.505511 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434635 (* 1 = 0.00434635 loss)
I0312 03:02:19.505515 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158843 (* 1 = 0.0158843 loss)
I0312 03:02:19.505522 17663 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0312 03:03:12.211736 17663 solver.cpp:228] Iteration 26800, loss = 0.580985
I0312 03:03:12.211760 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 03:03:12.211766 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.107038 (* 1 = 0.107038 loss)
I0312 03:03:12.211787 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.214899 (* 1 = 0.214899 loss)
I0312 03:03:12.211791 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00910235 (* 1 = 0.00910235 loss)
I0312 03:03:12.211796 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0767258 (* 1 = 0.0767258 loss)
I0312 03:03:12.211800 17663 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0312 03:04:05.098635 17663 solver.cpp:228] Iteration 26900, loss = 0.174038
I0312 03:04:05.098672 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 03:04:05.098695 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.035809 (* 1 = 0.035809 loss)
I0312 03:04:05.098714 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0916168 (* 1 = 0.0916168 loss)
I0312 03:04:05.098719 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00423745 (* 1 = 0.00423745 loss)
I0312 03:04:05.098724 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00571276 (* 1 = 0.00571276 loss)
I0312 03:04:05.098729 17663 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
speed: 0.525s / iter
I0312 03:04:58.265401 17663 solver.cpp:228] Iteration 27000, loss = 0.182635
I0312 03:04:58.265424 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:04:58.265430 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188383 (* 1 = 0.0188383 loss)
I0312 03:04:58.265450 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0661336 (* 1 = 0.0661336 loss)
I0312 03:04:58.265453 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0331131 (* 1 = 0.0331131 loss)
I0312 03:04:58.265457 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600494 (* 1 = 0.0600494 loss)
I0312 03:04:58.265462 17663 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0312 03:05:50.532542 17663 solver.cpp:228] Iteration 27100, loss = 0.326859
I0312 03:05:50.532567 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 03:05:50.532575 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982237 (* 1 = 0.0982237 loss)
I0312 03:05:50.532595 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165009 (* 1 = 0.165009 loss)
I0312 03:05:50.532600 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0357228 (* 1 = 0.0357228 loss)
I0312 03:05:50.532616 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0484684 (* 1 = 0.0484684 loss)
I0312 03:05:50.532622 17663 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0312 03:06:42.838392 17663 solver.cpp:228] Iteration 27200, loss = 0.889473
I0312 03:06:42.838413 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:06:42.838420 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.202164 (* 1 = 0.202164 loss)
I0312 03:06:42.838440 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.33478 (* 1 = 0.33478 loss)
I0312 03:06:42.838444 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.208451 (* 1 = 0.208451 loss)
I0312 03:06:42.838449 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.376773 (* 1 = 0.376773 loss)
I0312 03:06:42.838465 17663 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0312 03:07:35.225728 17663 solver.cpp:228] Iteration 27300, loss = 0.183363
I0312 03:07:35.225750 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:07:35.225757 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.031553 (* 1 = 0.031553 loss)
I0312 03:07:35.225761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.088327 (* 1 = 0.088327 loss)
I0312 03:07:35.225780 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0054436 (* 1 = 0.0054436 loss)
I0312 03:07:35.225785 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00591834 (* 1 = 0.00591834 loss)
I0312 03:07:35.225790 17663 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0312 03:08:27.683413 17663 solver.cpp:228] Iteration 27400, loss = 0.230592
I0312 03:08:27.683435 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 03:08:27.683444 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0782481 (* 1 = 0.0782481 loss)
I0312 03:08:27.683462 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198035 (* 1 = 0.198035 loss)
I0312 03:08:27.683466 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00432446 (* 1 = 0.00432446 loss)
I0312 03:08:27.683471 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434773 (* 1 = 0.0434773 loss)
I0312 03:08:27.683476 17663 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0312 03:09:19.588174 17663 solver.cpp:228] Iteration 27500, loss = 0.707059
I0312 03:09:19.588196 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 03:09:19.588202 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.248754 (* 1 = 0.248754 loss)
I0312 03:09:19.588222 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.439883 (* 1 = 0.439883 loss)
I0312 03:09:19.588225 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0536539 (* 1 = 0.0536539 loss)
I0312 03:09:19.588229 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.488454 (* 1 = 0.488454 loss)
I0312 03:09:19.588246 17663 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0312 03:10:12.244230 17663 solver.cpp:228] Iteration 27600, loss = 0.632838
I0312 03:10:12.244252 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:10:12.244259 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.080231 (* 1 = 0.080231 loss)
I0312 03:10:12.244278 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.191001 (* 1 = 0.191001 loss)
I0312 03:10:12.244282 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131806 (* 1 = 0.0131806 loss)
I0312 03:10:12.244287 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0593834 (* 1 = 0.0593834 loss)
I0312 03:10:12.244290 17663 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0312 03:11:04.074857 17663 solver.cpp:228] Iteration 27700, loss = 0.24356
I0312 03:11:04.074879 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:11:04.074887 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.114337 (* 1 = 0.114337 loss)
I0312 03:11:04.074906 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.148366 (* 1 = 0.148366 loss)
I0312 03:11:04.074911 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116383 (* 1 = 0.0116383 loss)
I0312 03:11:04.074915 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00356141 (* 1 = 0.00356141 loss)
I0312 03:11:04.074920 17663 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0312 03:11:56.303216 17663 solver.cpp:228] Iteration 27800, loss = 0.188258
I0312 03:11:56.303238 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 03:11:56.303246 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163065 (* 1 = 0.0163065 loss)
I0312 03:11:56.303264 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0807705 (* 1 = 0.0807705 loss)
I0312 03:11:56.303268 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00866693 (* 1 = 0.00866693 loss)
I0312 03:11:56.303272 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111576 (* 1 = 0.0111576 loss)
I0312 03:11:56.303277 17663 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0312 03:12:49.072928 17663 solver.cpp:228] Iteration 27900, loss = 0.245327
I0312 03:12:49.073024 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:12:49.073046 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.024581 (* 1 = 0.024581 loss)
I0312 03:12:49.073053 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0518978 (* 1 = 0.0518978 loss)
I0312 03:12:49.073060 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208975 (* 1 = 0.00208975 loss)
I0312 03:12:49.073065 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01724 (* 1 = 0.01724 loss)
I0312 03:12:49.073070 17663 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
speed: 0.524s / iter
I0312 03:13:41.208701 17663 solver.cpp:228] Iteration 28000, loss = 0.220713
I0312 03:13:41.208848 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 03:13:41.208904 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437782 (* 1 = 0.0437782 loss)
I0312 03:13:41.208953 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0576855 (* 1 = 0.0576855 loss)
I0312 03:13:41.209000 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127927 (* 1 = 0.00127927 loss)
I0312 03:13:41.209048 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267947 (* 1 = 0.0267947 loss)
I0312 03:13:41.209095 17663 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0312 03:14:34.251709 17663 solver.cpp:228] Iteration 28100, loss = 0.450899
I0312 03:14:34.251735 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:14:34.251744 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268156 (* 1 = 0.0268156 loss)
I0312 03:14:34.251762 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0869025 (* 1 = 0.0869025 loss)
I0312 03:14:34.251767 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167288 (* 1 = 0.00167288 loss)
I0312 03:14:34.251771 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00675863 (* 1 = 0.00675863 loss)
I0312 03:14:34.251776 17663 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0312 03:15:27.198521 17663 solver.cpp:228] Iteration 28200, loss = 0.267711
I0312 03:15:27.198544 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:15:27.198550 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0862436 (* 1 = 0.0862436 loss)
I0312 03:15:27.198570 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189241 (* 1 = 0.189241 loss)
I0312 03:15:27.198575 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674042 (* 1 = 0.00674042 loss)
I0312 03:15:27.198578 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413683 (* 1 = 0.0413683 loss)
I0312 03:15:27.198582 17663 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0312 03:16:19.784953 17663 solver.cpp:228] Iteration 28300, loss = 0.142056
I0312 03:16:19.784976 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:16:19.784982 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0573785 (* 1 = 0.0573785 loss)
I0312 03:16:19.784986 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0845117 (* 1 = 0.0845117 loss)
I0312 03:16:19.785006 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434561 (* 1 = 0.00434561 loss)
I0312 03:16:19.785010 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109508 (* 1 = 0.0109508 loss)
I0312 03:16:19.785027 17663 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0312 03:17:12.790164 17663 solver.cpp:228] Iteration 28400, loss = 0.387427
I0312 03:17:12.790186 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:17:12.790194 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.140409 (* 1 = 0.140409 loss)
I0312 03:17:12.790197 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.236687 (* 1 = 0.236687 loss)
I0312 03:17:12.790215 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0301244 (* 1 = 0.0301244 loss)
I0312 03:17:12.790220 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.223162 (* 1 = 0.223162 loss)
I0312 03:17:12.790225 17663 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0312 03:18:05.007366 17663 solver.cpp:228] Iteration 28500, loss = 0.120283
I0312 03:18:05.007390 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 03:18:05.007397 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183786 (* 1 = 0.0183786 loss)
I0312 03:18:05.007417 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0347061 (* 1 = 0.0347061 loss)
I0312 03:18:05.007422 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00565274 (* 1 = 0.00565274 loss)
I0312 03:18:05.007427 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0489255 (* 1 = 0.0489255 loss)
I0312 03:18:05.007432 17663 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0312 03:18:57.758047 17663 solver.cpp:228] Iteration 28600, loss = 0.347503
I0312 03:18:57.758070 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:18:57.758077 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235914 (* 1 = 0.0235914 loss)
I0312 03:18:57.758082 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111219 (* 1 = 0.111219 loss)
I0312 03:18:57.758101 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260981 (* 1 = 0.00260981 loss)
I0312 03:18:57.758106 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161052 (* 1 = 0.0161052 loss)
I0312 03:18:57.758111 17663 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0312 03:19:50.146229 17663 solver.cpp:228] Iteration 28700, loss = 0.23424
I0312 03:19:50.146250 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 03:19:50.146257 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241685 (* 1 = 0.0241685 loss)
I0312 03:19:50.146276 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120063 (* 1 = 0.120063 loss)
I0312 03:19:50.146281 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00447964 (* 1 = 0.00447964 loss)
I0312 03:19:50.146297 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0573498 (* 1 = 0.0573498 loss)
I0312 03:19:50.146302 17663 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0312 03:20:42.693157 17663 solver.cpp:228] Iteration 28800, loss = 0.345556
I0312 03:20:42.693178 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:20:42.693186 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0700899 (* 1 = 0.0700899 loss)
I0312 03:20:42.693204 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0857177 (* 1 = 0.0857177 loss)
I0312 03:20:42.693209 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00761431 (* 1 = 0.00761431 loss)
I0312 03:20:42.693226 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0764298 (* 1 = 0.0764298 loss)
I0312 03:20:42.693231 17663 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0312 03:21:35.630014 17663 solver.cpp:228] Iteration 28900, loss = 0.397411
I0312 03:21:35.630038 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:21:35.630046 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690669 (* 1 = 0.0690669 loss)
I0312 03:21:35.630065 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181257 (* 1 = 0.181257 loss)
I0312 03:21:35.630069 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294119 (* 1 = 0.0294119 loss)
I0312 03:21:35.630086 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044695 (* 1 = 0.044695 loss)
I0312 03:21:35.630091 17663 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
speed: 0.525s / iter
I0312 03:22:28.619662 17663 solver.cpp:228] Iteration 29000, loss = 0.507212
I0312 03:22:28.619825 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 03:22:28.619882 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.106605 (* 1 = 0.106605 loss)
I0312 03:22:28.619930 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161121 (* 1 = 0.161121 loss)
I0312 03:22:28.619977 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206023 (* 1 = 0.0206023 loss)
I0312 03:22:28.620023 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0384182 (* 1 = 0.0384182 loss)
I0312 03:22:28.620069 17663 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0312 03:23:20.338287 17663 solver.cpp:228] Iteration 29100, loss = 0.359773
I0312 03:23:20.338310 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:23:20.338317 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0741657 (* 1 = 0.0741657 loss)
I0312 03:23:20.338322 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.21728 (* 1 = 0.21728 loss)
I0312 03:23:20.338341 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0485845 (* 1 = 0.0485845 loss)
I0312 03:23:20.338346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11355 (* 1 = 0.11355 loss)
I0312 03:23:20.338351 17663 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0312 03:24:12.475896 17663 solver.cpp:228] Iteration 29200, loss = 0.726799
I0312 03:24:12.475919 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 03:24:12.475926 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.208264 (* 1 = 0.208264 loss)
I0312 03:24:12.475945 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.243742 (* 1 = 0.243742 loss)
I0312 03:24:12.475950 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0561267 (* 1 = 0.0561267 loss)
I0312 03:24:12.475966 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.163655 (* 1 = 0.163655 loss)
I0312 03:24:12.475971 17663 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0312 03:25:05.360041 17663 solver.cpp:228] Iteration 29300, loss = 0.477768
I0312 03:25:05.360069 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:25:05.360075 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.151145 (* 1 = 0.151145 loss)
I0312 03:25:05.360095 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183987 (* 1 = 0.183987 loss)
I0312 03:25:05.360100 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.111607 (* 1 = 0.111607 loss)
I0312 03:25:05.360117 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129168 (* 1 = 0.129168 loss)
I0312 03:25:05.360122 17663 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0312 03:25:57.246587 17663 solver.cpp:228] Iteration 29400, loss = 0.882046
I0312 03:25:57.246608 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:25:57.246616 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.127022 (* 1 = 0.127022 loss)
I0312 03:25:57.246634 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.228628 (* 1 = 0.228628 loss)
I0312 03:25:57.246639 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0915283 (* 1 = 0.0915283 loss)
I0312 03:25:57.246644 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.475486 (* 1 = 0.475486 loss)
I0312 03:25:57.246647 17663 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0312 03:26:49.790705 17663 solver.cpp:228] Iteration 29500, loss = 0.368365
I0312 03:26:49.790729 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:26:49.790735 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.032527 (* 1 = 0.032527 loss)
I0312 03:26:49.790755 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0882734 (* 1 = 0.0882734 loss)
I0312 03:26:49.790758 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130299 (* 1 = 0.0130299 loss)
I0312 03:26:49.790763 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138035 (* 1 = 0.0138035 loss)
I0312 03:26:49.790768 17663 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0312 03:27:41.482631 17663 solver.cpp:228] Iteration 29600, loss = 0.988114
I0312 03:27:41.482652 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 03:27:41.482659 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.240735 (* 1 = 0.240735 loss)
I0312 03:27:41.482678 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.283494 (* 1 = 0.283494 loss)
I0312 03:27:41.482682 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126255 (* 1 = 0.0126255 loss)
I0312 03:27:41.482686 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0672805 (* 1 = 0.0672805 loss)
I0312 03:27:41.482703 17663 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0312 03:28:33.903237 17663 solver.cpp:228] Iteration 29700, loss = 0.137406
I0312 03:28:33.903259 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:28:33.903267 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468745 (* 1 = 0.0468745 loss)
I0312 03:28:33.903272 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106635 (* 1 = 0.106635 loss)
I0312 03:28:33.903276 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00516979 (* 1 = 0.00516979 loss)
I0312 03:28:33.903295 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204074 (* 1 = 0.0204074 loss)
I0312 03:28:33.903300 17663 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0312 03:29:26.204514 17663 solver.cpp:228] Iteration 29800, loss = 0.323722
I0312 03:29:26.204537 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 03:29:26.204545 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.056623 (* 1 = 0.056623 loss)
I0312 03:29:26.204550 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.15849 (* 1 = 0.15849 loss)
I0312 03:29:26.204555 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0284923 (* 1 = 0.0284923 loss)
I0312 03:29:26.204558 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0945638 (* 1 = 0.0945638 loss)
I0312 03:29:26.204562 17663 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0312 03:30:18.819754 17663 solver.cpp:228] Iteration 29900, loss = 0.319907
I0312 03:30:18.819777 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:30:18.819783 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234344 (* 1 = 0.0234344 loss)
I0312 03:30:18.819802 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103784 (* 1 = 0.103784 loss)
I0312 03:30:18.819806 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00756062 (* 1 = 0.00756062 loss)
I0312 03:30:18.819823 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185092 (* 1 = 0.0185092 loss)
I0312 03:30:18.819828 17663 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0312 03:31:10.115641 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_30000.caffemodel
I0312 03:31:10.501703 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_30000.solverstate
speed: 0.524s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_30000.caffemodel
I0312 03:31:11.723819 17663 solver.cpp:228] Iteration 30000, loss = 0.425327
I0312 03:31:11.723840 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:31:11.723847 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690611 (* 1 = 0.0690611 loss)
I0312 03:31:11.723851 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0933736 (* 1 = 0.0933736 loss)
I0312 03:31:11.723870 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0363063 (* 1 = 0.0363063 loss)
I0312 03:31:11.723875 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0932564 (* 1 = 0.0932564 loss)
I0312 03:31:11.723879 17663 sgd_solver.cpp:106] Iteration 30000, lr = 1e-06
I0312 03:32:04.717190 17663 solver.cpp:228] Iteration 30100, loss = 0.1651
I0312 03:32:04.717213 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 03:32:04.717221 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197786 (* 1 = 0.0197786 loss)
I0312 03:32:04.717226 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.080889 (* 1 = 0.080889 loss)
I0312 03:32:04.717244 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00203497 (* 1 = 0.00203497 loss)
I0312 03:32:04.717248 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273227 (* 1 = 0.0273227 loss)
I0312 03:32:04.717253 17663 sgd_solver.cpp:106] Iteration 30100, lr = 1e-06
I0312 03:32:57.160356 17663 solver.cpp:228] Iteration 30200, loss = 0.290554
I0312 03:32:57.160379 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:32:57.160387 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0646858 (* 1 = 0.0646858 loss)
I0312 03:32:57.160405 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.213746 (* 1 = 0.213746 loss)
I0312 03:32:57.160410 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00352935 (* 1 = 0.00352935 loss)
I0312 03:32:57.160414 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0382879 (* 1 = 0.0382879 loss)
I0312 03:32:57.160419 17663 sgd_solver.cpp:106] Iteration 30200, lr = 1e-06
I0312 03:33:49.468202 17663 solver.cpp:228] Iteration 30300, loss = 0.589097
I0312 03:33:49.468225 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:33:49.468233 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.159671 (* 1 = 0.159671 loss)
I0312 03:33:49.468238 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149106 (* 1 = 0.149106 loss)
I0312 03:33:49.468256 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00808157 (* 1 = 0.00808157 loss)
I0312 03:33:49.468262 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.176042 (* 1 = 0.176042 loss)
I0312 03:33:49.468267 17663 sgd_solver.cpp:106] Iteration 30300, lr = 1e-06
I0312 03:34:41.843964 17663 solver.cpp:228] Iteration 30400, loss = 0.382359
I0312 03:34:41.843986 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 03:34:41.843993 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.079423 (* 1 = 0.079423 loss)
I0312 03:34:41.844012 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186895 (* 1 = 0.186895 loss)
I0312 03:34:41.844017 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161967 (* 1 = 0.0161967 loss)
I0312 03:34:41.844020 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0943942 (* 1 = 0.0943942 loss)
I0312 03:34:41.844024 17663 sgd_solver.cpp:106] Iteration 30400, lr = 1e-06
I0312 03:35:33.874377 17663 solver.cpp:228] Iteration 30500, loss = 0.131157
I0312 03:35:33.874398 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 03:35:33.874405 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189774 (* 1 = 0.0189774 loss)
I0312 03:35:33.874424 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0524006 (* 1 = 0.0524006 loss)
I0312 03:35:33.874428 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247054 (* 1 = 0.00247054 loss)
I0312 03:35:33.874433 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00833751 (* 1 = 0.00833751 loss)
I0312 03:35:33.874438 17663 sgd_solver.cpp:106] Iteration 30500, lr = 1e-06
I0312 03:36:26.554194 17663 solver.cpp:228] Iteration 30600, loss = 0.43681
I0312 03:36:26.554217 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:36:26.554225 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0522102 (* 1 = 0.0522102 loss)
I0312 03:36:26.554230 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.208422 (* 1 = 0.208422 loss)
I0312 03:36:26.554249 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0303282 (* 1 = 0.0303282 loss)
I0312 03:36:26.554252 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.140922 (* 1 = 0.140922 loss)
I0312 03:36:26.554258 17663 sgd_solver.cpp:106] Iteration 30600, lr = 1e-06
I0312 03:37:19.486021 17663 solver.cpp:228] Iteration 30700, loss = 0.391441
I0312 03:37:19.486042 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 03:37:19.486049 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0428252 (* 1 = 0.0428252 loss)
I0312 03:37:19.486068 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11432 (* 1 = 0.11432 loss)
I0312 03:37:19.486073 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484097 (* 1 = 0.00484097 loss)
I0312 03:37:19.486078 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329457 (* 1 = 0.0329457 loss)
I0312 03:37:19.486081 17663 sgd_solver.cpp:106] Iteration 30700, lr = 1e-06
I0312 03:38:11.590008 17663 solver.cpp:228] Iteration 30800, loss = 0.390239
I0312 03:38:11.590029 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 03:38:11.590036 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0210002 (* 1 = 0.0210002 loss)
I0312 03:38:11.590040 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0803052 (* 1 = 0.0803052 loss)
I0312 03:38:11.590059 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00404441 (* 1 = 0.00404441 loss)
I0312 03:38:11.590064 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0904068 (* 1 = 0.0904068 loss)
I0312 03:38:11.590081 17663 sgd_solver.cpp:106] Iteration 30800, lr = 1e-06
I0312 03:39:03.937628 17663 solver.cpp:228] Iteration 30900, loss = 0.787433
I0312 03:39:03.937649 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0312 03:39:03.937657 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.229893 (* 1 = 0.229893 loss)
I0312 03:39:03.937675 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.536753 (* 1 = 0.536753 loss)
I0312 03:39:03.937680 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0439019 (* 1 = 0.0439019 loss)
I0312 03:39:03.937685 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0745577 (* 1 = 0.0745577 loss)
I0312 03:39:03.937690 17663 sgd_solver.cpp:106] Iteration 30900, lr = 1e-06
speed: 0.524s / iter
I0312 03:39:55.947245 17663 solver.cpp:228] Iteration 31000, loss = 0.444568
I0312 03:39:55.947382 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:39:55.947438 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807958 (* 1 = 0.0807958 loss)
I0312 03:39:55.947485 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.193502 (* 1 = 0.193502 loss)
I0312 03:39:55.947533 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00647918 (* 1 = 0.00647918 loss)
I0312 03:39:55.947579 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337339 (* 1 = 0.0337339 loss)
I0312 03:39:55.947626 17663 sgd_solver.cpp:106] Iteration 31000, lr = 1e-06
I0312 03:40:48.813479 17663 solver.cpp:228] Iteration 31100, loss = 0.783168
I0312 03:40:48.813501 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 03:40:48.813508 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.112486 (* 1 = 0.112486 loss)
I0312 03:40:48.813529 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0883058 (* 1 = 0.0883058 loss)
I0312 03:40:48.813532 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293357 (* 1 = 0.0293357 loss)
I0312 03:40:48.813536 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.415007 (* 1 = 0.415007 loss)
I0312 03:40:48.813541 17663 sgd_solver.cpp:106] Iteration 31100, lr = 1e-06
I0312 03:41:41.624349 17663 solver.cpp:228] Iteration 31200, loss = 0.24157
I0312 03:41:41.624372 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 03:41:41.624379 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437485 (* 1 = 0.0437485 loss)
I0312 03:41:41.624399 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0864252 (* 1 = 0.0864252 loss)
I0312 03:41:41.624404 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315513 (* 1 = 0.00315513 loss)
I0312 03:41:41.624408 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0706751 (* 1 = 0.0706751 loss)
I0312 03:41:41.624414 17663 sgd_solver.cpp:106] Iteration 31200, lr = 1e-06
I0312 03:42:34.494510 17663 solver.cpp:228] Iteration 31300, loss = 0.708062
I0312 03:42:34.494532 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 03:42:34.494539 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587453 (* 1 = 0.0587453 loss)
I0312 03:42:34.494559 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.152912 (* 1 = 0.152912 loss)
I0312 03:42:34.494562 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0526611 (* 1 = 0.0526611 loss)
I0312 03:42:34.494566 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.156661 (* 1 = 0.156661 loss)
I0312 03:42:34.494571 17663 sgd_solver.cpp:106] Iteration 31300, lr = 1e-06
I0312 03:43:26.972440 17663 solver.cpp:228] Iteration 31400, loss = 0.448671
I0312 03:43:26.972463 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:43:26.972471 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336405 (* 1 = 0.0336405 loss)
I0312 03:43:26.972476 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0746388 (* 1 = 0.0746388 loss)
I0312 03:43:26.972494 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122073 (* 1 = 0.00122073 loss)
I0312 03:43:26.972498 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00547099 (* 1 = 0.00547099 loss)
I0312 03:43:26.972504 17663 sgd_solver.cpp:106] Iteration 31400, lr = 1e-06
I0312 03:44:20.026455 17663 solver.cpp:228] Iteration 31500, loss = 0.248416
I0312 03:44:20.026479 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 03:44:20.026485 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631874 (* 1 = 0.0631874 loss)
I0312 03:44:20.026504 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.126015 (* 1 = 0.126015 loss)
I0312 03:44:20.026509 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113144 (* 1 = 0.0113144 loss)
I0312 03:44:20.026512 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304203 (* 1 = 0.0304203 loss)
I0312 03:44:20.026517 17663 sgd_solver.cpp:106] Iteration 31500, lr = 1e-06
I0312 03:45:12.684197 17663 solver.cpp:228] Iteration 31600, loss = 0.271374
I0312 03:45:12.684221 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:45:12.684227 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.111855 (* 1 = 0.111855 loss)
I0312 03:45:12.684247 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.190613 (* 1 = 0.190613 loss)
I0312 03:45:12.684250 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109964 (* 1 = 0.0109964 loss)
I0312 03:45:12.684254 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303348 (* 1 = 0.0303348 loss)
I0312 03:45:12.684259 17663 sgd_solver.cpp:106] Iteration 31600, lr = 1e-06
I0312 03:46:04.878994 17663 solver.cpp:228] Iteration 31700, loss = 0.995967
I0312 03:46:04.879015 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:46:04.879022 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0484063 (* 1 = 0.0484063 loss)
I0312 03:46:04.879041 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123715 (* 1 = 0.123715 loss)
I0312 03:46:04.879045 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00196936 (* 1 = 0.00196936 loss)
I0312 03:46:04.879050 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00923269 (* 1 = 0.00923269 loss)
I0312 03:46:04.879055 17663 sgd_solver.cpp:106] Iteration 31700, lr = 1e-06
I0312 03:46:58.170532 17663 solver.cpp:228] Iteration 31800, loss = 0.352973
I0312 03:46:58.170732 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 03:46:58.170794 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0888955 (* 1 = 0.0888955 loss)
I0312 03:46:58.170842 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.234647 (* 1 = 0.234647 loss)
I0312 03:46:58.170889 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186146 (* 1 = 0.0186146 loss)
I0312 03:46:58.170948 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103385 (* 1 = 0.103385 loss)
I0312 03:46:58.170996 17663 sgd_solver.cpp:106] Iteration 31800, lr = 1e-06
I0312 03:47:50.767936 17663 solver.cpp:228] Iteration 31900, loss = 0.244462
I0312 03:47:50.767959 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:47:50.767967 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0824586 (* 1 = 0.0824586 loss)
I0312 03:47:50.767987 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.190209 (* 1 = 0.190209 loss)
I0312 03:47:50.767990 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103202 (* 1 = 0.0103202 loss)
I0312 03:47:50.767994 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029653 (* 1 = 0.029653 loss)
I0312 03:47:50.768013 17663 sgd_solver.cpp:106] Iteration 31900, lr = 1e-06
speed: 0.525s / iter
I0312 03:48:43.423825 17663 solver.cpp:228] Iteration 32000, loss = 0.447943
I0312 03:48:43.423964 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 03:48:43.424021 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147775 (* 1 = 0.0147775 loss)
I0312 03:48:43.424070 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0653527 (* 1 = 0.0653527 loss)
I0312 03:48:43.424118 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0426678 (* 1 = 0.0426678 loss)
I0312 03:48:43.424165 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133297 (* 1 = 0.0133297 loss)
I0312 03:48:43.424211 17663 sgd_solver.cpp:106] Iteration 32000, lr = 1e-06
I0312 03:49:36.242388 17663 solver.cpp:228] Iteration 32100, loss = 0.386645
I0312 03:49:36.242409 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:49:36.242416 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309591 (* 1 = 0.0309591 loss)
I0312 03:49:36.242435 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0714598 (* 1 = 0.0714598 loss)
I0312 03:49:36.242439 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027371 (* 1 = 0.027371 loss)
I0312 03:49:36.242444 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00809955 (* 1 = 0.00809955 loss)
I0312 03:49:36.242461 17663 sgd_solver.cpp:106] Iteration 32100, lr = 1e-06
I0312 03:50:28.947386 17663 solver.cpp:228] Iteration 32200, loss = 0.221503
I0312 03:50:28.947408 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 03:50:28.947417 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971273 (* 1 = 0.0971273 loss)
I0312 03:50:28.947435 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.159847 (* 1 = 0.159847 loss)
I0312 03:50:28.947439 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485008 (* 1 = 0.00485008 loss)
I0312 03:50:28.947443 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0818177 (* 1 = 0.0818177 loss)
I0312 03:50:28.947448 17663 sgd_solver.cpp:106] Iteration 32200, lr = 1e-06
I0312 03:51:20.546576 17663 solver.cpp:228] Iteration 32300, loss = 0.187681
I0312 03:51:20.546597 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 03:51:20.546604 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126234 (* 1 = 0.0126234 loss)
I0312 03:51:20.546623 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0663083 (* 1 = 0.0663083 loss)
I0312 03:51:20.546627 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00994779 (* 1 = 0.00994779 loss)
I0312 03:51:20.546631 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289084 (* 1 = 0.0289084 loss)
I0312 03:51:20.546636 17663 sgd_solver.cpp:106] Iteration 32300, lr = 1e-06
I0312 03:52:13.438334 17663 solver.cpp:228] Iteration 32400, loss = 0.30234
I0312 03:52:13.438357 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 03:52:13.438364 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386463 (* 1 = 0.0386463 loss)
I0312 03:52:13.438383 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.122947 (* 1 = 0.122947 loss)
I0312 03:52:13.438387 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.146253 (* 1 = 0.146253 loss)
I0312 03:52:13.438391 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.161376 (* 1 = 0.161376 loss)
I0312 03:52:13.438396 17663 sgd_solver.cpp:106] Iteration 32400, lr = 1e-06
I0312 03:53:06.413813 17663 solver.cpp:228] Iteration 32500, loss = 0.403404
I0312 03:53:06.413836 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 03:53:06.413843 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.183423 (* 1 = 0.183423 loss)
I0312 03:53:06.413862 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.350392 (* 1 = 0.350392 loss)
I0312 03:53:06.413866 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0676281 (* 1 = 0.0676281 loss)
I0312 03:53:06.413872 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0946778 (* 1 = 0.0946778 loss)
I0312 03:53:06.413877 17663 sgd_solver.cpp:106] Iteration 32500, lr = 1e-06
I0312 03:53:58.824676 17663 solver.cpp:228] Iteration 32600, loss = 0.556337
I0312 03:53:58.824698 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 03:53:58.824705 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.280482 (* 1 = 0.280482 loss)
I0312 03:53:58.824724 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.466978 (* 1 = 0.466978 loss)
I0312 03:53:58.824728 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0457692 (* 1 = 0.0457692 loss)
I0312 03:53:58.824733 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.165086 (* 1 = 0.165086 loss)
I0312 03:53:58.824738 17663 sgd_solver.cpp:106] Iteration 32600, lr = 1e-06
I0312 03:54:50.801120 17663 solver.cpp:228] Iteration 32700, loss = 0.70913
I0312 03:54:50.801142 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 03:54:50.801149 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.163924 (* 1 = 0.163924 loss)
I0312 03:54:50.801153 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.397753 (* 1 = 0.397753 loss)
I0312 03:54:50.801172 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.107249 (* 1 = 0.107249 loss)
I0312 03:54:50.801177 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.207794 (* 1 = 0.207794 loss)
I0312 03:54:50.801193 17663 sgd_solver.cpp:106] Iteration 32700, lr = 1e-06
I0312 03:55:42.987598 17663 solver.cpp:228] Iteration 32800, loss = 0.443312
I0312 03:55:42.987620 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 03:55:42.987628 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278817 (* 1 = 0.0278817 loss)
I0312 03:55:42.987632 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106403 (* 1 = 0.106403 loss)
I0312 03:55:42.987651 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00620406 (* 1 = 0.00620406 loss)
I0312 03:55:42.987655 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117336 (* 1 = 0.0117336 loss)
I0312 03:55:42.987660 17663 sgd_solver.cpp:106] Iteration 32800, lr = 1e-06
I0312 03:56:35.979699 17663 solver.cpp:228] Iteration 32900, loss = 0.392126
I0312 03:56:35.979720 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 03:56:35.979728 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729719 (* 1 = 0.0729719 loss)
I0312 03:56:35.979732 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.148993 (* 1 = 0.148993 loss)
I0312 03:56:35.979750 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104638 (* 1 = 0.0104638 loss)
I0312 03:56:35.979755 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129154 (* 1 = 0.129154 loss)
I0312 03:56:35.979760 17663 sgd_solver.cpp:106] Iteration 32900, lr = 1e-06
speed: 0.525s / iter
I0312 03:57:28.719806 17663 solver.cpp:228] Iteration 33000, loss = 0.423251
I0312 03:57:28.719840 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 03:57:28.719847 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.139714 (* 1 = 0.139714 loss)
I0312 03:57:28.719867 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.233323 (* 1 = 0.233323 loss)
I0312 03:57:28.719873 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106603 (* 1 = 0.0106603 loss)
I0312 03:57:28.719877 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701174 (* 1 = 0.0701174 loss)
I0312 03:57:28.719883 17663 sgd_solver.cpp:106] Iteration 33000, lr = 1e-06
I0312 03:58:20.953063 17663 solver.cpp:228] Iteration 33100, loss = 0.4008
I0312 03:58:20.953085 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 03:58:20.953094 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0767491 (* 1 = 0.0767491 loss)
I0312 03:58:20.953111 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.152264 (* 1 = 0.152264 loss)
I0312 03:58:20.953116 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024877 (* 1 = 0.024877 loss)
I0312 03:58:20.953120 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0892202 (* 1 = 0.0892202 loss)
I0312 03:58:20.953125 17663 sgd_solver.cpp:106] Iteration 33100, lr = 1e-06
I0312 03:59:13.308668 17663 solver.cpp:228] Iteration 33200, loss = 0.55634
I0312 03:59:13.308692 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 03:59:13.308701 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.140506 (* 1 = 0.140506 loss)
I0312 03:59:13.308704 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196465 (* 1 = 0.196465 loss)
I0312 03:59:13.308708 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0613527 (* 1 = 0.0613527 loss)
I0312 03:59:13.308713 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.175994 (* 1 = 0.175994 loss)
I0312 03:59:13.308732 17663 sgd_solver.cpp:106] Iteration 33200, lr = 1e-06
I0312 04:00:05.363750 17663 solver.cpp:228] Iteration 33300, loss = 0.292724
I0312 04:00:05.363777 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:00:05.363785 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.113923 (* 1 = 0.113923 loss)
I0312 04:00:05.363804 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180683 (* 1 = 0.180683 loss)
I0312 04:00:05.363808 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202647 (* 1 = 0.0202647 loss)
I0312 04:00:05.363813 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0732633 (* 1 = 0.0732633 loss)
I0312 04:00:05.363818 17663 sgd_solver.cpp:106] Iteration 33300, lr = 1e-06
I0312 04:00:58.088062 17663 solver.cpp:228] Iteration 33400, loss = 0.230911
I0312 04:00:58.088258 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 04:00:58.088274 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308471 (* 1 = 0.0308471 loss)
I0312 04:00:58.088280 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0591295 (* 1 = 0.0591295 loss)
I0312 04:00:58.088285 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124658 (* 1 = 0.00124658 loss)
I0312 04:00:58.088291 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133362 (* 1 = 0.0133362 loss)
I0312 04:00:58.088301 17663 sgd_solver.cpp:106] Iteration 33400, lr = 1e-06
I0312 04:01:50.552713 17663 solver.cpp:228] Iteration 33500, loss = 0.335856
I0312 04:01:50.552736 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:01:50.552742 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.123058 (* 1 = 0.123058 loss)
I0312 04:01:50.552762 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.184526 (* 1 = 0.184526 loss)
I0312 04:01:50.552765 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00798514 (* 1 = 0.00798514 loss)
I0312 04:01:50.552770 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0576812 (* 1 = 0.0576812 loss)
I0312 04:01:50.552774 17663 sgd_solver.cpp:106] Iteration 33500, lr = 1e-06
I0312 04:02:43.038377 17663 solver.cpp:228] Iteration 33600, loss = 0.367373
I0312 04:02:43.038398 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 04:02:43.038404 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.147918 (* 1 = 0.147918 loss)
I0312 04:02:43.038424 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.256406 (* 1 = 0.256406 loss)
I0312 04:02:43.038427 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0615123 (* 1 = 0.0615123 loss)
I0312 04:02:43.038431 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148915 (* 1 = 0.148915 loss)
I0312 04:02:43.038436 17663 sgd_solver.cpp:106] Iteration 33600, lr = 1e-06
I0312 04:03:35.562908 17663 solver.cpp:228] Iteration 33700, loss = 0.306618
I0312 04:03:35.562930 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 04:03:35.562938 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.179994 (* 1 = 0.179994 loss)
I0312 04:03:35.562957 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.217067 (* 1 = 0.217067 loss)
I0312 04:03:35.562961 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.038568 (* 1 = 0.038568 loss)
I0312 04:03:35.562965 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0828311 (* 1 = 0.0828311 loss)
I0312 04:03:35.562970 17663 sgd_solver.cpp:106] Iteration 33700, lr = 1e-06
I0312 04:04:28.002406 17663 solver.cpp:228] Iteration 33800, loss = 0.220573
I0312 04:04:28.002429 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 04:04:28.002436 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475977 (* 1 = 0.0475977 loss)
I0312 04:04:28.002455 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0995018 (* 1 = 0.0995018 loss)
I0312 04:04:28.002460 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144342 (* 1 = 0.0144342 loss)
I0312 04:04:28.002463 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434964 (* 1 = 0.0434964 loss)
I0312 04:04:28.002468 17663 sgd_solver.cpp:106] Iteration 33800, lr = 1e-06
I0312 04:05:20.564548 17663 solver.cpp:228] Iteration 33900, loss = 0.180082
I0312 04:05:20.564571 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:05:20.564579 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0655515 (* 1 = 0.0655515 loss)
I0312 04:05:20.564599 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120008 (* 1 = 0.120008 loss)
I0312 04:05:20.564604 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00893619 (* 1 = 0.00893619 loss)
I0312 04:05:20.564607 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030913 (* 1 = 0.030913 loss)
I0312 04:05:20.564612 17663 sgd_solver.cpp:106] Iteration 33900, lr = 1e-06
speed: 0.525s / iter
I0312 04:06:12.699784 17663 solver.cpp:228] Iteration 34000, loss = 0.170628
I0312 04:06:12.699810 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:06:12.699816 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0659838 (* 1 = 0.0659838 loss)
I0312 04:06:12.699836 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144256 (* 1 = 0.144256 loss)
I0312 04:06:12.699839 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199958 (* 1 = 0.0199958 loss)
I0312 04:06:12.699843 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00621103 (* 1 = 0.00621103 loss)
I0312 04:06:12.699848 17663 sgd_solver.cpp:106] Iteration 34000, lr = 1e-06
I0312 04:07:05.299865 17663 solver.cpp:228] Iteration 34100, loss = 0.451684
I0312 04:07:05.299888 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 04:07:05.299896 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0209407 (* 1 = 0.0209407 loss)
I0312 04:07:05.299916 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0855447 (* 1 = 0.0855447 loss)
I0312 04:07:05.299919 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.185408 (* 1 = 0.185408 loss)
I0312 04:07:05.299937 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.196921 (* 1 = 0.196921 loss)
I0312 04:07:05.299942 17663 sgd_solver.cpp:106] Iteration 34100, lr = 1e-06
I0312 04:07:57.630832 17663 solver.cpp:228] Iteration 34200, loss = 0.316127
I0312 04:07:57.630853 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 04:07:57.630861 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.154396 (* 1 = 0.154396 loss)
I0312 04:07:57.630865 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.289724 (* 1 = 0.289724 loss)
I0312 04:07:57.630884 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163536 (* 1 = 0.0163536 loss)
I0312 04:07:57.630889 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430639 (* 1 = 0.0430639 loss)
I0312 04:07:57.630894 17663 sgd_solver.cpp:106] Iteration 34200, lr = 1e-06
I0312 04:08:50.001665 17663 solver.cpp:228] Iteration 34300, loss = 0.166673
I0312 04:08:50.001688 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 04:08:50.001695 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168259 (* 1 = 0.0168259 loss)
I0312 04:08:50.001714 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0879692 (* 1 = 0.0879692 loss)
I0312 04:08:50.001719 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00651435 (* 1 = 0.00651435 loss)
I0312 04:08:50.001724 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115969 (* 1 = 0.0115969 loss)
I0312 04:08:50.001741 17663 sgd_solver.cpp:106] Iteration 34300, lr = 1e-06
I0312 04:09:42.188798 17663 solver.cpp:228] Iteration 34400, loss = 0.194525
I0312 04:09:42.188820 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 04:09:42.188828 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0114189 (* 1 = 0.0114189 loss)
I0312 04:09:42.188848 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.051292 (* 1 = 0.051292 loss)
I0312 04:09:42.188853 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195272 (* 1 = 0.0195272 loss)
I0312 04:09:42.188856 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156457 (* 1 = 0.0156457 loss)
I0312 04:09:42.188863 17663 sgd_solver.cpp:106] Iteration 34400, lr = 1e-06
I0312 04:10:34.380272 17663 solver.cpp:228] Iteration 34500, loss = 0.601038
I0312 04:10:34.380295 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 04:10:34.380302 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855812 (* 1 = 0.0855812 loss)
I0312 04:10:34.380321 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.178209 (* 1 = 0.178209 loss)
I0312 04:10:34.380326 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.128966 (* 1 = 0.128966 loss)
I0312 04:10:34.380328 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.683462 (* 1 = 0.683462 loss)
I0312 04:10:34.380334 17663 sgd_solver.cpp:106] Iteration 34500, lr = 1e-06
I0312 04:11:26.344300 17663 solver.cpp:228] Iteration 34600, loss = 0.255497
I0312 04:11:26.344322 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:11:26.344331 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237552 (* 1 = 0.0237552 loss)
I0312 04:11:26.344349 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103501 (* 1 = 0.103501 loss)
I0312 04:11:26.344353 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180674 (* 1 = 0.0180674 loss)
I0312 04:11:26.344357 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236918 (* 1 = 0.0236918 loss)
I0312 04:11:26.344362 17663 sgd_solver.cpp:106] Iteration 34600, lr = 1e-06
I0312 04:12:18.027178 17663 solver.cpp:228] Iteration 34700, loss = 0.289181
I0312 04:12:18.027199 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 04:12:18.027206 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475152 (* 1 = 0.0475152 loss)
I0312 04:12:18.027211 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116649 (* 1 = 0.116649 loss)
I0312 04:12:18.027230 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305824 (* 1 = 0.00305824 loss)
I0312 04:12:18.027235 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00977911 (* 1 = 0.00977911 loss)
I0312 04:12:18.027240 17663 sgd_solver.cpp:106] Iteration 34700, lr = 1e-06
I0312 04:13:10.417804 17663 solver.cpp:228] Iteration 34800, loss = 1.07067
I0312 04:13:10.417826 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 04:13:10.417834 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10454 (* 1 = 0.10454 loss)
I0312 04:13:10.417852 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.281809 (* 1 = 0.281809 loss)
I0312 04:13:10.417857 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.612358 (* 1 = 0.612358 loss)
I0312 04:13:10.417861 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.409713 (* 1 = 0.409713 loss)
I0312 04:13:10.417866 17663 sgd_solver.cpp:106] Iteration 34800, lr = 1e-06
I0312 04:14:02.715803 17663 solver.cpp:228] Iteration 34900, loss = 0.295012
I0312 04:14:02.715826 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 04:14:02.715832 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0665165 (* 1 = 0.0665165 loss)
I0312 04:14:02.715852 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111739 (* 1 = 0.111739 loss)
I0312 04:14:02.715855 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019724 (* 1 = 0.019724 loss)
I0312 04:14:02.715873 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0630804 (* 1 = 0.0630804 loss)
I0312 04:14:02.715878 17663 sgd_solver.cpp:106] Iteration 34900, lr = 1e-06
speed: 0.525s / iter
I0312 04:14:55.606647 17663 solver.cpp:228] Iteration 35000, loss = 0.351501
I0312 04:14:55.606669 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:14:55.606676 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0718356 (* 1 = 0.0718356 loss)
I0312 04:14:55.606680 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151883 (* 1 = 0.151883 loss)
I0312 04:14:55.606699 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123371 (* 1 = 0.0123371 loss)
I0312 04:14:55.606703 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0846035 (* 1 = 0.0846035 loss)
I0312 04:14:55.606709 17663 sgd_solver.cpp:106] Iteration 35000, lr = 1e-06
I0312 04:15:48.556044 17663 solver.cpp:228] Iteration 35100, loss = 0.418567
I0312 04:15:48.556066 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 04:15:48.556074 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0427139 (* 1 = 0.0427139 loss)
I0312 04:15:48.556093 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100326 (* 1 = 0.100326 loss)
I0312 04:15:48.556097 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107142 (* 1 = 0.0107142 loss)
I0312 04:15:48.556102 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183072 (* 1 = 0.0183072 loss)
I0312 04:15:48.556107 17663 sgd_solver.cpp:106] Iteration 35100, lr = 1e-06
I0312 04:16:41.553023 17663 solver.cpp:228] Iteration 35200, loss = 0.606879
I0312 04:16:41.553046 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 04:16:41.553053 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.197042 (* 1 = 0.197042 loss)
I0312 04:16:41.553072 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.179197 (* 1 = 0.179197 loss)
I0312 04:16:41.553076 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183843 (* 1 = 0.0183843 loss)
I0312 04:16:41.553081 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.29995 (* 1 = 0.29995 loss)
I0312 04:16:41.553086 17663 sgd_solver.cpp:106] Iteration 35200, lr = 1e-06
I0312 04:17:33.607877 17663 solver.cpp:228] Iteration 35300, loss = 0.223737
I0312 04:17:33.607899 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:17:33.607906 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0794717 (* 1 = 0.0794717 loss)
I0312 04:17:33.607911 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121717 (* 1 = 0.121717 loss)
I0312 04:17:33.607929 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109604 (* 1 = 0.0109604 loss)
I0312 04:17:33.607933 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124594 (* 1 = 0.124594 loss)
I0312 04:17:33.607951 17663 sgd_solver.cpp:106] Iteration 35300, lr = 1e-06
I0312 04:18:26.596845 17663 solver.cpp:228] Iteration 35400, loss = 0.6284
I0312 04:18:26.596868 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 04:18:26.596876 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.161499 (* 1 = 0.161499 loss)
I0312 04:18:26.596881 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.216712 (* 1 = 0.216712 loss)
I0312 04:18:26.596885 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139717 (* 1 = 0.0139717 loss)
I0312 04:18:26.596889 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405951 (* 1 = 0.0405951 loss)
I0312 04:18:26.596909 17663 sgd_solver.cpp:106] Iteration 35400, lr = 1e-06
I0312 04:19:19.046643 17663 solver.cpp:228] Iteration 35500, loss = 0.244076
I0312 04:19:19.046666 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:19:19.046674 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474677 (* 1 = 0.0474677 loss)
I0312 04:19:19.046692 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.126523 (* 1 = 0.126523 loss)
I0312 04:19:19.046696 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887439 (* 1 = 0.00887439 loss)
I0312 04:19:19.046701 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338165 (* 1 = 0.0338165 loss)
I0312 04:19:19.046706 17663 sgd_solver.cpp:106] Iteration 35500, lr = 1e-06
I0312 04:20:11.773223 17663 solver.cpp:228] Iteration 35600, loss = 0.570829
I0312 04:20:11.773246 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 04:20:11.773253 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.169257 (* 1 = 0.169257 loss)
I0312 04:20:11.773272 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.194554 (* 1 = 0.194554 loss)
I0312 04:20:11.773277 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276344 (* 1 = 0.0276344 loss)
I0312 04:20:11.773280 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.26577 (* 1 = 0.26577 loss)
I0312 04:20:11.773285 17663 sgd_solver.cpp:106] Iteration 35600, lr = 1e-06
I0312 04:21:04.294203 17663 solver.cpp:228] Iteration 35700, loss = 0.344647
I0312 04:21:04.294224 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 04:21:04.294231 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692258 (* 1 = 0.0692258 loss)
I0312 04:21:04.294236 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168245 (* 1 = 0.168245 loss)
I0312 04:21:04.294240 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00832466 (* 1 = 0.00832466 loss)
I0312 04:21:04.294245 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0424001 (* 1 = 0.0424001 loss)
I0312 04:21:04.294250 17663 sgd_solver.cpp:106] Iteration 35700, lr = 1e-06
I0312 04:21:57.118005 17663 solver.cpp:228] Iteration 35800, loss = 0.559977
I0312 04:21:57.118028 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 04:21:57.118036 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.175886 (* 1 = 0.175886 loss)
I0312 04:21:57.118054 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.3421 (* 1 = 0.3421 loss)
I0312 04:21:57.118058 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.106887 (* 1 = 0.106887 loss)
I0312 04:21:57.118062 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.311874 (* 1 = 0.311874 loss)
I0312 04:21:57.118067 17663 sgd_solver.cpp:106] Iteration 35800, lr = 1e-06
I0312 04:22:50.651540 17663 solver.cpp:228] Iteration 35900, loss = 0.303214
I0312 04:22:50.651563 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 04:22:50.651571 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.150299 (* 1 = 0.150299 loss)
I0312 04:22:50.651574 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157889 (* 1 = 0.157889 loss)
I0312 04:22:50.651578 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273381 (* 1 = 0.00273381 loss)
I0312 04:22:50.651583 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0483431 (* 1 = 0.0483431 loss)
I0312 04:22:50.651602 17663 sgd_solver.cpp:106] Iteration 35900, lr = 1e-06
speed: 0.525s / iter
I0312 04:23:43.386310 17663 solver.cpp:228] Iteration 36000, loss = 0.325744
I0312 04:23:43.386431 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 04:23:43.386454 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371517 (* 1 = 0.0371517 loss)
I0312 04:23:43.386461 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0965227 (* 1 = 0.0965227 loss)
I0312 04:23:43.386466 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0243775 (* 1 = 0.0243775 loss)
I0312 04:23:43.386471 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0962458 (* 1 = 0.0962458 loss)
I0312 04:23:43.386477 17663 sgd_solver.cpp:106] Iteration 36000, lr = 1e-06
I0312 04:24:35.955896 17663 solver.cpp:228] Iteration 36100, loss = 0.15338
I0312 04:24:35.955917 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:24:35.955924 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486392 (* 1 = 0.0486392 loss)
I0312 04:24:35.955943 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12691 (* 1 = 0.12691 loss)
I0312 04:24:35.955947 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0065324 (* 1 = 0.0065324 loss)
I0312 04:24:35.955965 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344358 (* 1 = 0.0344358 loss)
I0312 04:24:35.955970 17663 sgd_solver.cpp:106] Iteration 36100, lr = 1e-06
I0312 04:25:28.510033 17663 solver.cpp:228] Iteration 36200, loss = 0.970694
I0312 04:25:28.510054 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:25:28.510061 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0783424 (* 1 = 0.0783424 loss)
I0312 04:25:28.510080 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125056 (* 1 = 0.125056 loss)
I0312 04:25:28.510084 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00659597 (* 1 = 0.00659597 loss)
I0312 04:25:28.510089 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01675 (* 1 = 0.01675 loss)
I0312 04:25:28.510107 17663 sgd_solver.cpp:106] Iteration 36200, lr = 1e-06
I0312 04:26:20.471662 17663 solver.cpp:228] Iteration 36300, loss = 0.44307
I0312 04:26:20.471684 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 04:26:20.471693 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356287 (* 1 = 0.0356287 loss)
I0312 04:26:20.471711 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0803083 (* 1 = 0.0803083 loss)
I0312 04:26:20.471716 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00464499 (* 1 = 0.00464499 loss)
I0312 04:26:20.471720 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298935 (* 1 = 0.0298935 loss)
I0312 04:26:20.471725 17663 sgd_solver.cpp:106] Iteration 36300, lr = 1e-06
I0312 04:27:12.944602 17663 solver.cpp:228] Iteration 36400, loss = 0.321748
I0312 04:27:12.944624 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 04:27:12.944631 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00872877 (* 1 = 0.00872877 loss)
I0312 04:27:12.944651 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0206135 (* 1 = 0.0206135 loss)
I0312 04:27:12.944655 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191803 (* 1 = 0.0191803 loss)
I0312 04:27:12.944659 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0787876 (* 1 = 0.0787876 loss)
I0312 04:27:12.944664 17663 sgd_solver.cpp:106] Iteration 36400, lr = 1e-06
I0312 04:28:05.055271 17663 solver.cpp:228] Iteration 36500, loss = 0.434986
I0312 04:28:05.055294 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 04:28:05.055300 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.241398 (* 1 = 0.241398 loss)
I0312 04:28:05.055320 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.255859 (* 1 = 0.255859 loss)
I0312 04:28:05.055325 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00862598 (* 1 = 0.00862598 loss)
I0312 04:28:05.055328 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0771979 (* 1 = 0.0771979 loss)
I0312 04:28:05.055333 17663 sgd_solver.cpp:106] Iteration 36500, lr = 1e-06
I0312 04:28:58.336447 17663 solver.cpp:228] Iteration 36600, loss = 0.406513
I0312 04:28:58.336467 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 04:28:58.336475 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0583699 (* 1 = 0.0583699 loss)
I0312 04:28:58.336479 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.274655 (* 1 = 0.274655 loss)
I0312 04:28:58.336483 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00955439 (* 1 = 0.00955439 loss)
I0312 04:28:58.336488 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0792322 (* 1 = 0.0792322 loss)
I0312 04:28:58.336493 17663 sgd_solver.cpp:106] Iteration 36600, lr = 1e-06
I0312 04:29:50.940835 17663 solver.cpp:228] Iteration 36700, loss = 0.622049
I0312 04:29:50.940857 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 04:29:50.940865 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.140872 (* 1 = 0.140872 loss)
I0312 04:29:50.940884 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.341813 (* 1 = 0.341813 loss)
I0312 04:29:50.940888 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0506356 (* 1 = 0.0506356 loss)
I0312 04:29:50.940891 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.130037 (* 1 = 0.130037 loss)
I0312 04:29:50.940896 17663 sgd_solver.cpp:106] Iteration 36700, lr = 1e-06
I0312 04:30:43.379027 17663 solver.cpp:228] Iteration 36800, loss = 0.376071
I0312 04:30:43.379050 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 04:30:43.379056 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.190408 (* 1 = 0.190408 loss)
I0312 04:30:43.379061 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.273151 (* 1 = 0.273151 loss)
I0312 04:30:43.379065 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0063145 (* 1 = 0.0063145 loss)
I0312 04:30:43.379070 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0500256 (* 1 = 0.0500256 loss)
I0312 04:30:43.379075 17663 sgd_solver.cpp:106] Iteration 36800, lr = 1e-06
I0312 04:31:35.035393 17663 solver.cpp:228] Iteration 36900, loss = 0.226384
I0312 04:31:35.035414 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 04:31:35.035421 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365031 (* 1 = 0.0365031 loss)
I0312 04:31:35.035439 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151106 (* 1 = 0.151106 loss)
I0312 04:31:35.035444 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00402244 (* 1 = 0.00402244 loss)
I0312 04:31:35.035449 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0587831 (* 1 = 0.0587831 loss)
I0312 04:31:35.035454 17663 sgd_solver.cpp:106] Iteration 36900, lr = 1e-06
speed: 0.525s / iter
I0312 04:32:27.979084 17663 solver.cpp:228] Iteration 37000, loss = 0.295535
I0312 04:32:27.979241 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:32:27.979297 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.092889 (* 1 = 0.092889 loss)
I0312 04:32:27.979346 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.122062 (* 1 = 0.122062 loss)
I0312 04:32:27.979393 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0239676 (* 1 = 0.0239676 loss)
I0312 04:32:27.979439 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236256 (* 1 = 0.0236256 loss)
I0312 04:32:27.979486 17663 sgd_solver.cpp:106] Iteration 37000, lr = 1e-06
I0312 04:33:21.230648 17663 solver.cpp:228] Iteration 37100, loss = 0.208294
I0312 04:33:21.230669 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 04:33:21.230677 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00957247 (* 1 = 0.00957247 loss)
I0312 04:33:21.230682 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.109079 (* 1 = 0.109079 loss)
I0312 04:33:21.230687 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00937305 (* 1 = 0.00937305 loss)
I0312 04:33:21.230691 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152843 (* 1 = 0.0152843 loss)
I0312 04:33:21.230696 17663 sgd_solver.cpp:106] Iteration 37100, lr = 1e-06
I0312 04:34:13.785145 17663 solver.cpp:228] Iteration 37200, loss = 0.19045
I0312 04:34:13.785166 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:34:13.785174 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119709 (* 1 = 0.0119709 loss)
I0312 04:34:13.785193 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0828399 (* 1 = 0.0828399 loss)
I0312 04:34:13.785197 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00556885 (* 1 = 0.00556885 loss)
I0312 04:34:13.785202 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00490308 (* 1 = 0.00490308 loss)
I0312 04:34:13.785207 17663 sgd_solver.cpp:106] Iteration 37200, lr = 1e-06
I0312 04:35:05.682075 17663 solver.cpp:228] Iteration 37300, loss = 0.396776
I0312 04:35:05.682097 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 04:35:05.682106 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0862322 (* 1 = 0.0862322 loss)
I0312 04:35:05.682124 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0560878 (* 1 = 0.0560878 loss)
I0312 04:35:05.682128 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177391 (* 1 = 0.0177391 loss)
I0312 04:35:05.682132 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.195966 (* 1 = 0.195966 loss)
I0312 04:35:05.682138 17663 sgd_solver.cpp:106] Iteration 37300, lr = 1e-06
I0312 04:35:59.638348 17663 solver.cpp:228] Iteration 37400, loss = 0.236956
I0312 04:35:59.638370 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 04:35:59.638378 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0619666 (* 1 = 0.0619666 loss)
I0312 04:35:59.638397 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.171838 (* 1 = 0.171838 loss)
I0312 04:35:59.638401 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020873 (* 1 = 0.020873 loss)
I0312 04:35:59.638406 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373263 (* 1 = 0.0373263 loss)
I0312 04:35:59.638411 17663 sgd_solver.cpp:106] Iteration 37400, lr = 1e-06
I0312 04:36:52.547016 17663 solver.cpp:228] Iteration 37500, loss = 0.227555
I0312 04:36:52.547039 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 04:36:52.547045 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195933 (* 1 = 0.0195933 loss)
I0312 04:36:52.547065 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0734583 (* 1 = 0.0734583 loss)
I0312 04:36:52.547070 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248674 (* 1 = 0.00248674 loss)
I0312 04:36:52.547073 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00551355 (* 1 = 0.00551355 loss)
I0312 04:36:52.547078 17663 sgd_solver.cpp:106] Iteration 37500, lr = 1e-06
I0312 04:37:45.843683 17663 solver.cpp:228] Iteration 37600, loss = 0.547555
I0312 04:37:45.843704 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 04:37:45.843711 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.108764 (* 1 = 0.108764 loss)
I0312 04:37:45.843731 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151568 (* 1 = 0.151568 loss)
I0312 04:37:45.843735 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0901302 (* 1 = 0.0901302 loss)
I0312 04:37:45.843739 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0800979 (* 1 = 0.0800979 loss)
I0312 04:37:45.843757 17663 sgd_solver.cpp:106] Iteration 37600, lr = 1e-06
I0312 04:38:37.947540 17663 solver.cpp:228] Iteration 37700, loss = 0.999634
I0312 04:38:37.947561 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 04:38:37.947569 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.197754 (* 1 = 0.197754 loss)
I0312 04:38:37.947587 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.329604 (* 1 = 0.329604 loss)
I0312 04:38:37.947592 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.221257 (* 1 = 0.221257 loss)
I0312 04:38:37.947595 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.352098 (* 1 = 0.352098 loss)
I0312 04:38:37.947600 17663 sgd_solver.cpp:106] Iteration 37700, lr = 1e-06
I0312 04:39:30.395241 17663 solver.cpp:228] Iteration 37800, loss = 0.729294
I0312 04:39:30.395263 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 04:39:30.395270 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.06703 (* 1 = 0.06703 loss)
I0312 04:39:30.395290 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157316 (* 1 = 0.157316 loss)
I0312 04:39:30.395293 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141293 (* 1 = 0.0141293 loss)
I0312 04:39:30.395298 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122375 (* 1 = 0.122375 loss)
I0312 04:39:30.395303 17663 sgd_solver.cpp:106] Iteration 37800, lr = 1e-06
I0312 04:40:22.927220 17663 solver.cpp:228] Iteration 37900, loss = 0.860589
I0312 04:40:22.927242 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 04:40:22.927249 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481335 (* 1 = 0.0481335 loss)
I0312 04:40:22.927268 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.167655 (* 1 = 0.167655 loss)
I0312 04:40:22.927273 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.582005 (* 1 = 0.582005 loss)
I0312 04:40:22.927290 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.71269 (* 1 = 0.71269 loss)
I0312 04:40:22.927295 17663 sgd_solver.cpp:106] Iteration 37900, lr = 1e-06
speed: 0.525s / iter
I0312 04:41:15.527751 17663 solver.cpp:228] Iteration 38000, loss = 0.168322
I0312 04:41:15.527789 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 04:41:15.527799 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.000958854 (* 1 = 0.000958854 loss)
I0312 04:41:15.527804 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0420916 (* 1 = 0.0420916 loss)
I0312 04:41:15.527808 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0950811 (* 1 = 0.0950811 loss)
I0312 04:41:15.527813 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116423 (* 1 = 0.116423 loss)
I0312 04:41:15.527819 17663 sgd_solver.cpp:106] Iteration 38000, lr = 1e-06
I0312 04:42:07.569710 17663 solver.cpp:228] Iteration 38100, loss = 0.154954
I0312 04:42:07.569733 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 04:42:07.569741 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294107 (* 1 = 0.0294107 loss)
I0312 04:42:07.569761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0578371 (* 1 = 0.0578371 loss)
I0312 04:42:07.569766 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106442 (* 1 = 0.00106442 loss)
I0312 04:42:07.569769 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00686522 (* 1 = 0.00686522 loss)
I0312 04:42:07.569774 17663 sgd_solver.cpp:106] Iteration 38100, lr = 1e-06
I0312 04:43:00.854218 17663 solver.cpp:228] Iteration 38200, loss = 0.471032
I0312 04:43:00.854243 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 04:43:00.854250 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.127034 (* 1 = 0.127034 loss)
I0312 04:43:00.854255 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.328872 (* 1 = 0.328872 loss)
I0312 04:43:00.854259 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00949686 (* 1 = 0.00949686 loss)
I0312 04:43:00.854264 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0823281 (* 1 = 0.0823281 loss)
I0312 04:43:00.854285 17663 sgd_solver.cpp:106] Iteration 38200, lr = 1e-06
I0312 04:43:52.931656 17663 solver.cpp:228] Iteration 38300, loss = 0.278221
I0312 04:43:52.931679 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 04:43:52.931686 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.122058 (* 1 = 0.122058 loss)
I0312 04:43:52.931690 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181062 (* 1 = 0.181062 loss)
I0312 04:43:52.931710 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00632986 (* 1 = 0.00632986 loss)
I0312 04:43:52.931715 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0504715 (* 1 = 0.0504715 loss)
I0312 04:43:52.931720 17663 sgd_solver.cpp:106] Iteration 38300, lr = 1e-06
I0312 04:44:44.901825 17663 solver.cpp:228] Iteration 38400, loss = 0.233513
I0312 04:44:44.901847 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:44:44.901854 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0742951 (* 1 = 0.0742951 loss)
I0312 04:44:44.901873 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151856 (* 1 = 0.151856 loss)
I0312 04:44:44.901877 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574928 (* 1 = 0.00574928 loss)
I0312 04:44:44.901881 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0750614 (* 1 = 0.0750614 loss)
I0312 04:44:44.901886 17663 sgd_solver.cpp:106] Iteration 38400, lr = 1e-06
I0312 04:45:37.441963 17663 solver.cpp:228] Iteration 38500, loss = 0.293337
I0312 04:45:37.441987 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 04:45:37.441994 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0995054 (* 1 = 0.0995054 loss)
I0312 04:45:37.441999 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189715 (* 1 = 0.189715 loss)
I0312 04:45:37.442003 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0483745 (* 1 = 0.0483745 loss)
I0312 04:45:37.442008 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0437194 (* 1 = 0.0437194 loss)
I0312 04:45:37.442026 17663 sgd_solver.cpp:106] Iteration 38500, lr = 1e-06
I0312 04:46:29.852522 17663 solver.cpp:228] Iteration 38600, loss = 0.304644
I0312 04:46:29.852548 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 04:46:29.852555 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199879 (* 1 = 0.0199879 loss)
I0312 04:46:29.852560 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.142237 (* 1 = 0.142237 loss)
I0312 04:46:29.852578 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.035307 (* 1 = 0.035307 loss)
I0312 04:46:29.852582 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162094 (* 1 = 0.0162094 loss)
I0312 04:46:29.852588 17663 sgd_solver.cpp:106] Iteration 38600, lr = 1e-06
I0312 04:47:22.252732 17663 solver.cpp:228] Iteration 38700, loss = 0.484289
I0312 04:47:22.252753 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 04:47:22.252760 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634078 (* 1 = 0.0634078 loss)
I0312 04:47:22.252779 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156832 (* 1 = 0.156832 loss)
I0312 04:47:22.252784 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00864485 (* 1 = 0.00864485 loss)
I0312 04:47:22.252789 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0738412 (* 1 = 0.0738412 loss)
I0312 04:47:22.252792 17663 sgd_solver.cpp:106] Iteration 38700, lr = 1e-06
I0312 04:48:14.915935 17663 solver.cpp:228] Iteration 38800, loss = 0.198852
I0312 04:48:14.915957 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:48:14.915966 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.034164 (* 1 = 0.034164 loss)
I0312 04:48:14.915984 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116088 (* 1 = 0.116088 loss)
I0312 04:48:14.915988 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561687 (* 1 = 0.00561687 loss)
I0312 04:48:14.915992 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0511313 (* 1 = 0.0511313 loss)
I0312 04:48:14.915997 17663 sgd_solver.cpp:106] Iteration 38800, lr = 1e-06
I0312 04:49:07.634492 17663 solver.cpp:228] Iteration 38900, loss = 0.322812
I0312 04:49:07.634541 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 04:49:07.634549 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463697 (* 1 = 0.0463697 loss)
I0312 04:49:07.634568 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121143 (* 1 = 0.121143 loss)
I0312 04:49:07.634573 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106819 (* 1 = 0.0106819 loss)
I0312 04:49:07.634577 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215299 (* 1 = 0.0215299 loss)
I0312 04:49:07.634594 17663 sgd_solver.cpp:106] Iteration 38900, lr = 1e-06
speed: 0.525s / iter
I0312 04:49:59.128356 17663 solver.cpp:228] Iteration 39000, loss = 0.16166
I0312 04:49:59.128378 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:49:59.128386 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299258 (* 1 = 0.0299258 loss)
I0312 04:49:59.128404 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133134 (* 1 = 0.133134 loss)
I0312 04:49:59.128408 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000789874 (* 1 = 0.000789874 loss)
I0312 04:49:59.128413 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00283862 (* 1 = 0.00283862 loss)
I0312 04:49:59.128417 17663 sgd_solver.cpp:106] Iteration 39000, lr = 1e-06
I0312 04:50:51.480213 17663 solver.cpp:228] Iteration 39100, loss = 0.251243
I0312 04:50:51.480237 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 04:50:51.480245 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.100365 (* 1 = 0.100365 loss)
I0312 04:50:51.480264 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111988 (* 1 = 0.111988 loss)
I0312 04:50:51.480268 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00731853 (* 1 = 0.00731853 loss)
I0312 04:50:51.480273 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183038 (* 1 = 0.0183038 loss)
I0312 04:50:51.480290 17663 sgd_solver.cpp:106] Iteration 39100, lr = 1e-06
I0312 04:51:44.308173 17663 solver.cpp:228] Iteration 39200, loss = 0.618394
I0312 04:51:44.308195 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:51:44.308202 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0746878 (* 1 = 0.0746878 loss)
I0312 04:51:44.308221 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12802 (* 1 = 0.12802 loss)
I0312 04:51:44.308226 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171938 (* 1 = 0.0171938 loss)
I0312 04:51:44.308230 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.18735 (* 1 = 0.18735 loss)
I0312 04:51:44.308234 17663 sgd_solver.cpp:106] Iteration 39200, lr = 1e-06
I0312 04:52:37.054940 17663 solver.cpp:228] Iteration 39300, loss = 0.500309
I0312 04:52:37.054963 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 04:52:37.054970 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0752335 (* 1 = 0.0752335 loss)
I0312 04:52:37.054989 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0524479 (* 1 = 0.0524479 loss)
I0312 04:52:37.054994 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0302183 (* 1 = 0.0302183 loss)
I0312 04:52:37.054998 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.379997 (* 1 = 0.379997 loss)
I0312 04:52:37.055003 17663 sgd_solver.cpp:106] Iteration 39300, lr = 1e-06
I0312 04:53:29.989183 17663 solver.cpp:228] Iteration 39400, loss = 0.137549
I0312 04:53:29.989204 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 04:53:29.989212 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163295 (* 1 = 0.0163295 loss)
I0312 04:53:29.989230 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0660288 (* 1 = 0.0660288 loss)
I0312 04:53:29.989235 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368022 (* 1 = 0.00368022 loss)
I0312 04:53:29.989239 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00234676 (* 1 = 0.00234676 loss)
I0312 04:53:29.989244 17663 sgd_solver.cpp:106] Iteration 39400, lr = 1e-06
I0312 04:54:22.278955 17663 solver.cpp:228] Iteration 39500, loss = 0.504321
I0312 04:54:22.278976 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 04:54:22.278985 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.027588 (* 1 = 0.027588 loss)
I0312 04:54:22.279003 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0928556 (* 1 = 0.0928556 loss)
I0312 04:54:22.279007 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0041708 (* 1 = 0.0041708 loss)
I0312 04:54:22.279012 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278767 (* 1 = 0.0278767 loss)
I0312 04:54:22.279017 17663 sgd_solver.cpp:106] Iteration 39500, lr = 1e-06
I0312 04:55:15.062881 17663 solver.cpp:228] Iteration 39600, loss = 0.435328
I0312 04:55:15.062902 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 04:55:15.062911 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.071375 (* 1 = 0.071375 loss)
I0312 04:55:15.062914 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.210675 (* 1 = 0.210675 loss)
I0312 04:55:15.062918 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00435945 (* 1 = 0.00435945 loss)
I0312 04:55:15.062922 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117083 (* 1 = 0.0117083 loss)
I0312 04:55:15.062927 17663 sgd_solver.cpp:106] Iteration 39600, lr = 1e-06
I0312 04:56:07.417780 17663 solver.cpp:228] Iteration 39700, loss = 0.247861
I0312 04:56:07.417804 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 04:56:07.417810 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0249851 (* 1 = 0.0249851 loss)
I0312 04:56:07.417829 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0995965 (* 1 = 0.0995965 loss)
I0312 04:56:07.417832 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00743485 (* 1 = 0.00743485 loss)
I0312 04:56:07.417837 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01812 (* 1 = 0.01812 loss)
I0312 04:56:07.417841 17663 sgd_solver.cpp:106] Iteration 39700, lr = 1e-06
I0312 04:57:00.237556 17663 solver.cpp:228] Iteration 39800, loss = 0.615432
I0312 04:57:00.237581 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 04:57:00.237588 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.123275 (* 1 = 0.123275 loss)
I0312 04:57:00.237607 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.267507 (* 1 = 0.267507 loss)
I0312 04:57:00.237612 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.11735 (* 1 = 0.11735 loss)
I0312 04:57:00.237628 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.130189 (* 1 = 0.130189 loss)
I0312 04:57:00.237633 17663 sgd_solver.cpp:106] Iteration 39800, lr = 1e-06
I0312 04:57:52.599591 17663 solver.cpp:228] Iteration 39900, loss = 0.262642
I0312 04:57:52.599612 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 04:57:52.599620 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107169 (* 1 = 0.0107169 loss)
I0312 04:57:52.599625 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11033 (* 1 = 0.11033 loss)
I0312 04:57:52.599629 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0647864 (* 1 = 0.0647864 loss)
I0312 04:57:52.599633 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0598649 (* 1 = 0.0598649 loss)
I0312 04:57:52.599653 17663 sgd_solver.cpp:106] Iteration 39900, lr = 1e-06
I0312 04:58:44.735848 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_40000.caffemodel
I0312 04:58:45.115773 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_40000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_40000.caffemodel
I0312 04:58:46.297950 17663 solver.cpp:228] Iteration 40000, loss = 0.221301
I0312 04:58:46.297996 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 04:58:46.298004 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347232 (* 1 = 0.0347232 loss)
I0312 04:58:46.298008 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.166021 (* 1 = 0.166021 loss)
I0312 04:58:46.298027 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0286153 (* 1 = 0.0286153 loss)
I0312 04:58:46.298032 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118854 (* 1 = 0.118854 loss)
I0312 04:58:46.298038 17663 sgd_solver.cpp:106] Iteration 40000, lr = 1e-07
I0312 04:59:39.226478 17663 solver.cpp:228] Iteration 40100, loss = 0.297585
I0312 04:59:39.226501 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 04:59:39.226510 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499755 (* 1 = 0.0499755 loss)
I0312 04:59:39.226528 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120598 (* 1 = 0.120598 loss)
I0312 04:59:39.226532 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391738 (* 1 = 0.00391738 loss)
I0312 04:59:39.226537 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566568 (* 1 = 0.0566568 loss)
I0312 04:59:39.226541 17663 sgd_solver.cpp:106] Iteration 40100, lr = 1e-07
I0312 05:00:31.282711 17663 solver.cpp:228] Iteration 40200, loss = 0.62468
I0312 05:00:31.282734 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 05:00:31.282742 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608776 (* 1 = 0.0608776 loss)
I0312 05:00:31.282761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.134648 (* 1 = 0.134648 loss)
I0312 05:00:31.282765 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119298 (* 1 = 0.0119298 loss)
I0312 05:00:31.282769 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275064 (* 1 = 0.0275064 loss)
I0312 05:00:31.282774 17663 sgd_solver.cpp:106] Iteration 40200, lr = 1e-07
I0312 05:01:23.782063 17663 solver.cpp:228] Iteration 40300, loss = 0.283964
I0312 05:01:23.782085 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 05:01:23.782093 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0994067 (* 1 = 0.0994067 loss)
I0312 05:01:23.782097 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.207747 (* 1 = 0.207747 loss)
I0312 05:01:23.782115 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159848 (* 1 = 0.0159848 loss)
I0312 05:01:23.782119 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0442365 (* 1 = 0.0442365 loss)
I0312 05:01:23.782125 17663 sgd_solver.cpp:106] Iteration 40300, lr = 1e-07
I0312 05:02:16.645969 17663 solver.cpp:228] Iteration 40400, loss = 0.271665
I0312 05:02:16.645992 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:02:16.645999 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529317 (* 1 = 0.0529317 loss)
I0312 05:02:16.646004 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0842463 (* 1 = 0.0842463 loss)
I0312 05:02:16.646023 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201323 (* 1 = 0.0201323 loss)
I0312 05:02:16.646026 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185733 (* 1 = 0.185733 loss)
I0312 05:02:16.646033 17663 sgd_solver.cpp:106] Iteration 40400, lr = 1e-07
I0312 05:03:08.690018 17663 solver.cpp:228] Iteration 40500, loss = 0.376314
I0312 05:03:08.690040 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 05:03:08.690047 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.162605 (* 1 = 0.162605 loss)
I0312 05:03:08.690066 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.259208 (* 1 = 0.259208 loss)
I0312 05:03:08.690070 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0345031 (* 1 = 0.0345031 loss)
I0312 05:03:08.690074 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0966713 (* 1 = 0.0966713 loss)
I0312 05:03:08.690093 17663 sgd_solver.cpp:106] Iteration 40500, lr = 1e-07
I0312 05:04:00.449053 17663 solver.cpp:228] Iteration 40600, loss = 0.375359
I0312 05:04:00.449075 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:04:00.449082 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334293 (* 1 = 0.0334293 loss)
I0312 05:04:00.449101 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125077 (* 1 = 0.125077 loss)
I0312 05:04:00.449106 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0360167 (* 1 = 0.0360167 loss)
I0312 05:04:00.449110 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345701 (* 1 = 0.0345701 loss)
I0312 05:04:00.449115 17663 sgd_solver.cpp:106] Iteration 40600, lr = 1e-07
I0312 05:04:53.116122 17663 solver.cpp:228] Iteration 40700, loss = 0.310934
I0312 05:04:53.116147 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:04:53.116154 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0715912 (* 1 = 0.0715912 loss)
I0312 05:04:53.116159 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105044 (* 1 = 0.105044 loss)
I0312 05:04:53.116163 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00430435 (* 1 = 0.00430435 loss)
I0312 05:04:53.116168 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186997 (* 1 = 0.0186997 loss)
I0312 05:04:53.116188 17663 sgd_solver.cpp:106] Iteration 40700, lr = 1e-07
I0312 05:05:45.655097 17663 solver.cpp:228] Iteration 40800, loss = 0.264192
I0312 05:05:45.655119 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 05:05:45.655128 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172883 (* 1 = 0.0172883 loss)
I0312 05:05:45.655145 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0403812 (* 1 = 0.0403812 loss)
I0312 05:05:45.655150 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0047931 (* 1 = 0.0047931 loss)
I0312 05:05:45.655153 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031191 (* 1 = 0.031191 loss)
I0312 05:05:45.655159 17663 sgd_solver.cpp:106] Iteration 40800, lr = 1e-07
I0312 05:06:38.179636 17663 solver.cpp:228] Iteration 40900, loss = 0.702296
I0312 05:06:38.179658 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 05:06:38.179666 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.136311 (* 1 = 0.136311 loss)
I0312 05:06:38.179669 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.275473 (* 1 = 0.275473 loss)
I0312 05:06:38.179687 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0587992 (* 1 = 0.0587992 loss)
I0312 05:06:38.179692 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.163515 (* 1 = 0.163515 loss)
I0312 05:06:38.179697 17663 sgd_solver.cpp:106] Iteration 40900, lr = 1e-07
speed: 0.525s / iter
I0312 05:07:30.527185 17663 solver.cpp:228] Iteration 41000, loss = 0.373321
I0312 05:07:30.527209 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 05:07:30.527216 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365836 (* 1 = 0.0365836 loss)
I0312 05:07:30.527235 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0873638 (* 1 = 0.0873638 loss)
I0312 05:07:30.527240 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.114778 (* 1 = 0.114778 loss)
I0312 05:07:30.527245 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.094788 (* 1 = 0.094788 loss)
I0312 05:07:30.527249 17663 sgd_solver.cpp:106] Iteration 41000, lr = 1e-07
I0312 05:08:23.103438 17663 solver.cpp:228] Iteration 41100, loss = 0.303908
I0312 05:08:23.103461 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 05:08:23.103469 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.160516 (* 1 = 0.160516 loss)
I0312 05:08:23.103473 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.249588 (* 1 = 0.249588 loss)
I0312 05:08:23.103477 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134859 (* 1 = 0.0134859 loss)
I0312 05:08:23.103482 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0398928 (* 1 = 0.0398928 loss)
I0312 05:08:23.103487 17663 sgd_solver.cpp:106] Iteration 41100, lr = 1e-07
I0312 05:09:15.843225 17663 solver.cpp:228] Iteration 41200, loss = 0.364966
I0312 05:09:15.843247 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 05:09:15.843255 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971968 (* 1 = 0.0971968 loss)
I0312 05:09:15.843260 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215089 (* 1 = 0.215089 loss)
I0312 05:09:15.843278 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0375405 (* 1 = 0.0375405 loss)
I0312 05:09:15.843283 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.207479 (* 1 = 0.207479 loss)
I0312 05:09:15.843302 17663 sgd_solver.cpp:106] Iteration 41200, lr = 1e-07
I0312 05:10:08.086222 17663 solver.cpp:228] Iteration 41300, loss = 0.707641
I0312 05:10:08.086243 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 05:10:08.086251 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.205637 (* 1 = 0.205637 loss)
I0312 05:10:08.086256 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.371823 (* 1 = 0.371823 loss)
I0312 05:10:08.086273 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0449554 (* 1 = 0.0449554 loss)
I0312 05:10:08.086277 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.430727 (* 1 = 0.430727 loss)
I0312 05:10:08.086282 17663 sgd_solver.cpp:106] Iteration 41300, lr = 1e-07
I0312 05:11:01.183177 17663 solver.cpp:228] Iteration 41400, loss = 0.176856
I0312 05:11:01.183199 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 05:11:01.183207 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.061293 (* 1 = 0.061293 loss)
I0312 05:11:01.183212 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11299 (* 1 = 0.11299 loss)
I0312 05:11:01.183215 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00704849 (* 1 = 0.00704849 loss)
I0312 05:11:01.183236 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318481 (* 1 = 0.0318481 loss)
I0312 05:11:01.183243 17663 sgd_solver.cpp:106] Iteration 41400, lr = 1e-07
I0312 05:11:53.494961 17663 solver.cpp:228] Iteration 41500, loss = 0.408142
I0312 05:11:53.494984 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 05:11:53.494992 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0796947 (* 1 = 0.0796947 loss)
I0312 05:11:53.495010 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.207683 (* 1 = 0.207683 loss)
I0312 05:11:53.495014 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0918423 (* 1 = 0.0918423 loss)
I0312 05:11:53.495018 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.174719 (* 1 = 0.174719 loss)
I0312 05:11:53.495023 17663 sgd_solver.cpp:106] Iteration 41500, lr = 1e-07
I0312 05:12:45.946152 17663 solver.cpp:228] Iteration 41600, loss = 0.390149
I0312 05:12:45.946174 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:12:45.946182 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544303 (* 1 = 0.0544303 loss)
I0312 05:12:45.946200 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.333265 (* 1 = 0.333265 loss)
I0312 05:12:45.946204 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.194082 (* 1 = 0.194082 loss)
I0312 05:12:45.946208 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125823 (* 1 = 0.125823 loss)
I0312 05:12:45.946213 17663 sgd_solver.cpp:106] Iteration 41600, lr = 1e-07
I0312 05:13:38.505499 17663 solver.cpp:228] Iteration 41700, loss = 0.448164
I0312 05:13:38.505553 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 05:13:38.505561 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.196411 (* 1 = 0.196411 loss)
I0312 05:13:38.505566 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.329826 (* 1 = 0.329826 loss)
I0312 05:13:38.505571 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00352748 (* 1 = 0.00352748 loss)
I0312 05:13:38.505575 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106057 (* 1 = 0.106057 loss)
I0312 05:13:38.505581 17663 sgd_solver.cpp:106] Iteration 41700, lr = 1e-07
I0312 05:14:31.217195 17663 solver.cpp:228] Iteration 41800, loss = 0.545091
I0312 05:14:31.217222 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 05:14:31.217231 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0510492 (* 1 = 0.0510492 loss)
I0312 05:14:31.217249 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0774675 (* 1 = 0.0774675 loss)
I0312 05:14:31.217254 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00837504 (* 1 = 0.00837504 loss)
I0312 05:14:31.217259 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03054 (* 1 = 0.03054 loss)
I0312 05:14:31.217264 17663 sgd_solver.cpp:106] Iteration 41800, lr = 1e-07
I0312 05:15:23.662133 17663 solver.cpp:228] Iteration 41900, loss = 0.236028
I0312 05:15:23.662155 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 05:15:23.662163 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.025103 (* 1 = 0.025103 loss)
I0312 05:15:23.662181 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.068205 (* 1 = 0.068205 loss)
I0312 05:15:23.662185 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00928201 (* 1 = 0.00928201 loss)
I0312 05:15:23.662189 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415552 (* 1 = 0.0415552 loss)
I0312 05:15:23.662207 17663 sgd_solver.cpp:106] Iteration 41900, lr = 1e-07
speed: 0.525s / iter
I0312 05:16:15.786633 17663 solver.cpp:228] Iteration 42000, loss = 0.377511
I0312 05:16:15.786655 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:16:15.786662 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316077 (* 1 = 0.0316077 loss)
I0312 05:16:15.786682 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102275 (* 1 = 0.102275 loss)
I0312 05:16:15.786686 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0797627 (* 1 = 0.0797627 loss)
I0312 05:16:15.786690 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0328191 (* 1 = 0.0328191 loss)
I0312 05:16:15.786695 17663 sgd_solver.cpp:106] Iteration 42000, lr = 1e-07
I0312 05:17:08.335705 17663 solver.cpp:228] Iteration 42100, loss = 0.77372
I0312 05:17:08.335726 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 05:17:08.335733 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.132111 (* 1 = 0.132111 loss)
I0312 05:17:08.335737 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.213871 (* 1 = 0.213871 loss)
I0312 05:17:08.335757 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.486707 (* 1 = 0.486707 loss)
I0312 05:17:08.335760 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.596506 (* 1 = 0.596506 loss)
I0312 05:17:08.335765 17663 sgd_solver.cpp:106] Iteration 42100, lr = 1e-07
I0312 05:18:01.295167 17663 solver.cpp:228] Iteration 42200, loss = 0.20693
I0312 05:18:01.295189 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 05:18:01.295197 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.058442 (* 1 = 0.058442 loss)
I0312 05:18:01.295217 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137148 (* 1 = 0.137148 loss)
I0312 05:18:01.295219 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039308 (* 1 = 0.039308 loss)
I0312 05:18:01.295223 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0848371 (* 1 = 0.0848371 loss)
I0312 05:18:01.295228 17663 sgd_solver.cpp:106] Iteration 42200, lr = 1e-07
I0312 05:18:54.225657 17663 solver.cpp:228] Iteration 42300, loss = 0.65994
I0312 05:18:54.225682 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 05:18:54.225688 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.129647 (* 1 = 0.129647 loss)
I0312 05:18:54.225693 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.308571 (* 1 = 0.308571 loss)
I0312 05:18:54.225713 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0825885 (* 1 = 0.0825885 loss)
I0312 05:18:54.225716 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157414 (* 1 = 0.157414 loss)
I0312 05:18:54.225721 17663 sgd_solver.cpp:106] Iteration 42300, lr = 1e-07
I0312 05:19:47.021632 17663 solver.cpp:228] Iteration 42400, loss = 0.308495
I0312 05:19:47.021653 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 05:19:47.021661 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331838 (* 1 = 0.0331838 loss)
I0312 05:19:47.021666 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.122296 (* 1 = 0.122296 loss)
I0312 05:19:47.021684 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100719 (* 1 = 0.0100719 loss)
I0312 05:19:47.021687 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0672863 (* 1 = 0.0672863 loss)
I0312 05:19:47.021692 17663 sgd_solver.cpp:106] Iteration 42400, lr = 1e-07
I0312 05:20:39.959048 17663 solver.cpp:228] Iteration 42500, loss = 0.250383
I0312 05:20:39.959070 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 05:20:39.959079 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270016 (* 1 = 0.0270016 loss)
I0312 05:20:39.959097 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133559 (* 1 = 0.133559 loss)
I0312 05:20:39.959101 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00489869 (* 1 = 0.00489869 loss)
I0312 05:20:39.959106 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325828 (* 1 = 0.0325828 loss)
I0312 05:20:39.959111 17663 sgd_solver.cpp:106] Iteration 42500, lr = 1e-07
I0312 05:21:32.366449 17663 solver.cpp:228] Iteration 42600, loss = 0.644964
I0312 05:21:32.366470 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 05:21:32.366477 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0878306 (* 1 = 0.0878306 loss)
I0312 05:21:32.366497 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186651 (* 1 = 0.186651 loss)
I0312 05:21:32.366502 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00547383 (* 1 = 0.00547383 loss)
I0312 05:21:32.366505 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0801507 (* 1 = 0.0801507 loss)
I0312 05:21:32.366509 17663 sgd_solver.cpp:106] Iteration 42600, lr = 1e-07
I0312 05:22:25.487807 17663 solver.cpp:228] Iteration 42700, loss = 0.720793
I0312 05:22:25.487828 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 05:22:25.487834 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.196349 (* 1 = 0.196349 loss)
I0312 05:22:25.487854 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.254251 (* 1 = 0.254251 loss)
I0312 05:22:25.487857 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0539995 (* 1 = 0.0539995 loss)
I0312 05:22:25.487861 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.196736 (* 1 = 0.196736 loss)
I0312 05:22:25.487879 17663 sgd_solver.cpp:106] Iteration 42700, lr = 1e-07
I0312 05:23:17.700007 17663 solver.cpp:228] Iteration 42800, loss = 0.762715
I0312 05:23:17.700031 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 05:23:17.700039 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.106018 (* 1 = 0.106018 loss)
I0312 05:23:17.700044 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.286071 (* 1 = 0.286071 loss)
I0312 05:23:17.700048 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759674 (* 1 = 0.00759674 loss)
I0312 05:23:17.700052 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.249553 (* 1 = 0.249553 loss)
I0312 05:23:17.700072 17663 sgd_solver.cpp:106] Iteration 42800, lr = 1e-07
I0312 05:24:10.639711 17663 solver.cpp:228] Iteration 42900, loss = 0.274617
I0312 05:24:10.639734 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:24:10.639740 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440445 (* 1 = 0.0440445 loss)
I0312 05:24:10.639760 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102921 (* 1 = 0.102921 loss)
I0312 05:24:10.639765 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00763813 (* 1 = 0.00763813 loss)
I0312 05:24:10.639780 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0576111 (* 1 = 0.0576111 loss)
I0312 05:24:10.639786 17663 sgd_solver.cpp:106] Iteration 42900, lr = 1e-07
speed: 0.525s / iter
I0312 05:25:03.018307 17663 solver.cpp:228] Iteration 43000, loss = 0.206692
I0312 05:25:03.018452 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 05:25:03.018508 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.109493 (* 1 = 0.109493 loss)
I0312 05:25:03.018556 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165185 (* 1 = 0.165185 loss)
I0312 05:25:03.018604 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00370057 (* 1 = 0.00370057 loss)
I0312 05:25:03.018651 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01295 (* 1 = 0.01295 loss)
I0312 05:25:03.018698 17663 sgd_solver.cpp:106] Iteration 43000, lr = 1e-07
I0312 05:25:55.073529 17663 solver.cpp:228] Iteration 43100, loss = 0.230174
I0312 05:25:55.073552 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:25:55.073560 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0898793 (* 1 = 0.0898793 loss)
I0312 05:25:55.073580 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.119309 (* 1 = 0.119309 loss)
I0312 05:25:55.073583 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157741 (* 1 = 0.00157741 loss)
I0312 05:25:55.073588 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188017 (* 1 = 0.0188017 loss)
I0312 05:25:55.073593 17663 sgd_solver.cpp:106] Iteration 43100, lr = 1e-07
I0312 05:26:46.571657 17663 solver.cpp:228] Iteration 43200, loss = 0.360894
I0312 05:26:46.571679 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 05:26:46.571687 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.26279 (* 1 = 0.26279 loss)
I0312 05:26:46.571705 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.237649 (* 1 = 0.237649 loss)
I0312 05:26:46.571710 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159593 (* 1 = 0.0159593 loss)
I0312 05:26:46.571714 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0692627 (* 1 = 0.0692627 loss)
I0312 05:26:46.571719 17663 sgd_solver.cpp:106] Iteration 43200, lr = 1e-07
I0312 05:27:39.461447 17663 solver.cpp:228] Iteration 43300, loss = 0.460414
I0312 05:27:39.461469 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 05:27:39.461477 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.216444 (* 1 = 0.216444 loss)
I0312 05:27:39.461483 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.373043 (* 1 = 0.373043 loss)
I0312 05:27:39.461486 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00904278 (* 1 = 0.00904278 loss)
I0312 05:27:39.461491 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.143925 (* 1 = 0.143925 loss)
I0312 05:27:39.461510 17663 sgd_solver.cpp:106] Iteration 43300, lr = 1e-07
I0312 05:28:31.827603 17663 solver.cpp:228] Iteration 43400, loss = 0.838076
I0312 05:28:31.827626 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 05:28:31.827635 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.22742 (* 1 = 0.22742 loss)
I0312 05:28:31.827653 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.336981 (* 1 = 0.336981 loss)
I0312 05:28:31.827657 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211638 (* 1 = 0.0211638 loss)
I0312 05:28:31.827661 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121147 (* 1 = 0.121147 loss)
I0312 05:28:31.827666 17663 sgd_solver.cpp:106] Iteration 43400, lr = 1e-07
I0312 05:29:24.086702 17663 solver.cpp:228] Iteration 43500, loss = 0.402587
I0312 05:29:24.086724 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 05:29:24.086730 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0664326 (* 1 = 0.0664326 loss)
I0312 05:29:24.086750 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0862608 (* 1 = 0.0862608 loss)
I0312 05:29:24.086755 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00148994 (* 1 = 0.00148994 loss)
I0312 05:29:24.086758 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228387 (* 1 = 0.0228387 loss)
I0312 05:29:24.086763 17663 sgd_solver.cpp:106] Iteration 43500, lr = 1e-07
I0312 05:30:16.013520 17663 solver.cpp:228] Iteration 43600, loss = 0.36599
I0312 05:30:16.013543 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:30:16.013551 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.135466 (* 1 = 0.135466 loss)
I0312 05:30:16.013569 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133925 (* 1 = 0.133925 loss)
I0312 05:30:16.013574 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254214 (* 1 = 0.0254214 loss)
I0312 05:30:16.013592 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119612 (* 1 = 0.119612 loss)
I0312 05:30:16.013597 17663 sgd_solver.cpp:106] Iteration 43600, lr = 1e-07
I0312 05:31:08.361696 17663 solver.cpp:228] Iteration 43700, loss = 0.616459
I0312 05:31:08.361716 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 05:31:08.361723 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329208 (* 1 = 0.0329208 loss)
I0312 05:31:08.361743 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0414471 (* 1 = 0.0414471 loss)
I0312 05:31:08.361747 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00288786 (* 1 = 0.00288786 loss)
I0312 05:31:08.361752 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135895 (* 1 = 0.0135895 loss)
I0312 05:31:08.361755 17663 sgd_solver.cpp:106] Iteration 43700, lr = 1e-07
I0312 05:32:01.569587 17663 solver.cpp:228] Iteration 43800, loss = 0.484233
I0312 05:32:01.569610 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 05:32:01.569617 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.158845 (* 1 = 0.158845 loss)
I0312 05:32:01.569636 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.310869 (* 1 = 0.310869 loss)
I0312 05:32:01.569641 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.150118 (* 1 = 0.150118 loss)
I0312 05:32:01.569645 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.16953 (* 1 = 0.16953 loss)
I0312 05:32:01.569664 17663 sgd_solver.cpp:106] Iteration 43800, lr = 1e-07
I0312 05:32:53.666795 17663 solver.cpp:228] Iteration 43900, loss = 0.318957
I0312 05:32:53.666817 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 05:32:53.666824 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268962 (* 1 = 0.0268962 loss)
I0312 05:32:53.666843 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0841515 (* 1 = 0.0841515 loss)
I0312 05:32:53.666847 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229592 (* 1 = 0.00229592 loss)
I0312 05:32:53.666852 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00586115 (* 1 = 0.00586115 loss)
I0312 05:32:53.666857 17663 sgd_solver.cpp:106] Iteration 43900, lr = 1e-07
speed: 0.525s / iter
I0312 05:33:46.434662 17663 solver.cpp:228] Iteration 44000, loss = 0.339883
I0312 05:33:46.434813 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 05:33:46.434870 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0955598 (* 1 = 0.0955598 loss)
I0312 05:33:46.434919 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120205 (* 1 = 0.120205 loss)
I0312 05:33:46.434976 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366453 (* 1 = 0.0366453 loss)
I0312 05:33:46.435024 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243638 (* 1 = 0.0243638 loss)
I0312 05:33:46.435070 17663 sgd_solver.cpp:106] Iteration 44000, lr = 1e-07
I0312 05:34:38.825599 17663 solver.cpp:228] Iteration 44100, loss = 0.384764
I0312 05:34:38.825623 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 05:34:38.825629 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810387 (* 1 = 0.0810387 loss)
I0312 05:34:38.825634 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.204731 (* 1 = 0.204731 loss)
I0312 05:34:38.825652 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180283 (* 1 = 0.0180283 loss)
I0312 05:34:38.825657 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0887825 (* 1 = 0.0887825 loss)
I0312 05:34:38.825664 17663 sgd_solver.cpp:106] Iteration 44100, lr = 1e-07
I0312 05:35:31.453341 17663 solver.cpp:228] Iteration 44200, loss = 0.188801
I0312 05:35:31.453363 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 05:35:31.453371 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0483421 (* 1 = 0.0483421 loss)
I0312 05:35:31.453389 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180189 (* 1 = 0.180189 loss)
I0312 05:35:31.453393 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276227 (* 1 = 0.00276227 loss)
I0312 05:35:31.453398 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129116 (* 1 = 0.0129116 loss)
I0312 05:35:31.453403 17663 sgd_solver.cpp:106] Iteration 44200, lr = 1e-07
I0312 05:36:23.361359 17663 solver.cpp:228] Iteration 44300, loss = 0.404076
I0312 05:36:23.361382 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 05:36:23.361389 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413286 (* 1 = 0.0413286 loss)
I0312 05:36:23.361407 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.224496 (* 1 = 0.224496 loss)
I0312 05:36:23.361412 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040429 (* 1 = 0.040429 loss)
I0312 05:36:23.361415 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0902282 (* 1 = 0.0902282 loss)
I0312 05:36:23.361420 17663 sgd_solver.cpp:106] Iteration 44300, lr = 1e-07
I0312 05:37:15.854310 17663 solver.cpp:228] Iteration 44400, loss = 0.293369
I0312 05:37:15.854331 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:37:15.854337 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310014 (* 1 = 0.0310014 loss)
I0312 05:37:15.854357 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0878765 (* 1 = 0.0878765 loss)
I0312 05:37:15.854362 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00823959 (* 1 = 0.00823959 loss)
I0312 05:37:15.854365 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246949 (* 1 = 0.0246949 loss)
I0312 05:37:15.854370 17663 sgd_solver.cpp:106] Iteration 44400, lr = 1e-07
I0312 05:38:07.741130 17663 solver.cpp:228] Iteration 44500, loss = 0.384121
I0312 05:38:07.741153 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 05:38:07.741161 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511621 (* 1 = 0.0511621 loss)
I0312 05:38:07.741179 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.185872 (* 1 = 0.185872 loss)
I0312 05:38:07.741184 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630511 (* 1 = 0.00630511 loss)
I0312 05:38:07.741189 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0540464 (* 1 = 0.0540464 loss)
I0312 05:38:07.741194 17663 sgd_solver.cpp:106] Iteration 44500, lr = 1e-07
I0312 05:39:00.029063 17663 solver.cpp:228] Iteration 44600, loss = 0.805918
I0312 05:39:00.029085 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0312 05:39:00.029093 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.289818 (* 1 = 0.289818 loss)
I0312 05:39:00.029096 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.549073 (* 1 = 0.549073 loss)
I0312 05:39:00.029114 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0487133 (* 1 = 0.0487133 loss)
I0312 05:39:00.029119 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037535 (* 1 = 0.037535 loss)
I0312 05:39:00.029124 17663 sgd_solver.cpp:106] Iteration 44600, lr = 1e-07
I0312 05:39:52.289206 17663 solver.cpp:228] Iteration 44700, loss = 0.214522
I0312 05:39:52.289227 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:39:52.289235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274345 (* 1 = 0.0274345 loss)
I0312 05:39:52.289254 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0951433 (* 1 = 0.0951433 loss)
I0312 05:39:52.289258 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00077662 (* 1 = 0.00077662 loss)
I0312 05:39:52.289263 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113057 (* 1 = 0.0113057 loss)
I0312 05:39:52.289268 17663 sgd_solver.cpp:106] Iteration 44700, lr = 1e-07
I0312 05:40:44.915261 17663 solver.cpp:228] Iteration 44800, loss = 0.48638
I0312 05:40:44.915288 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 05:40:44.915295 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386142 (* 1 = 0.0386142 loss)
I0312 05:40:44.915315 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100708 (* 1 = 0.100708 loss)
I0312 05:40:44.915320 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0025672 (* 1 = 0.0025672 loss)
I0312 05:40:44.915324 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149066 (* 1 = 0.0149066 loss)
I0312 05:40:44.915329 17663 sgd_solver.cpp:106] Iteration 44800, lr = 1e-07
I0312 05:41:38.029022 17663 solver.cpp:228] Iteration 44900, loss = 0.182452
I0312 05:41:38.029047 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:41:38.029055 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347305 (* 1 = 0.0347305 loss)
I0312 05:41:38.029074 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0897839 (* 1 = 0.0897839 loss)
I0312 05:41:38.029079 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398441 (* 1 = 0.00398441 loss)
I0312 05:41:38.029083 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030684 (* 1 = 0.030684 loss)
I0312 05:41:38.029088 17663 sgd_solver.cpp:106] Iteration 44900, lr = 1e-07
speed: 0.525s / iter
I0312 05:42:30.913020 17663 solver.cpp:228] Iteration 45000, loss = 0.320588
I0312 05:42:30.913179 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 05:42:30.913235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.079784 (* 1 = 0.079784 loss)
I0312 05:42:30.913283 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183384 (* 1 = 0.183384 loss)
I0312 05:42:30.913331 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0692214 (* 1 = 0.0692214 loss)
I0312 05:42:30.913378 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0636385 (* 1 = 0.0636385 loss)
I0312 05:42:30.913425 17663 sgd_solver.cpp:106] Iteration 45000, lr = 1e-07
I0312 05:43:23.328440 17663 solver.cpp:228] Iteration 45100, loss = 0.363713
I0312 05:43:23.328462 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 05:43:23.328469 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.101954 (* 1 = 0.101954 loss)
I0312 05:43:23.328488 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.2189 (* 1 = 0.2189 loss)
I0312 05:43:23.328492 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0407544 (* 1 = 0.0407544 loss)
I0312 05:43:23.328496 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.223347 (* 1 = 0.223347 loss)
I0312 05:43:23.328501 17663 sgd_solver.cpp:106] Iteration 45100, lr = 1e-07
I0312 05:44:16.350914 17663 solver.cpp:228] Iteration 45200, loss = 0.428743
I0312 05:44:16.350937 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:44:16.350944 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346147 (* 1 = 0.0346147 loss)
I0312 05:44:16.350965 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.092022 (* 1 = 0.092022 loss)
I0312 05:44:16.350968 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858794 (* 1 = 0.00858794 loss)
I0312 05:44:16.350973 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0933861 (* 1 = 0.0933861 loss)
I0312 05:44:16.350977 17663 sgd_solver.cpp:106] Iteration 45200, lr = 1e-07
I0312 05:45:09.032073 17663 solver.cpp:228] Iteration 45300, loss = 0.512001
I0312 05:45:09.032096 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 05:45:09.032104 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.203231 (* 1 = 0.203231 loss)
I0312 05:45:09.032122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.303132 (* 1 = 0.303132 loss)
I0312 05:45:09.032127 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0458581 (* 1 = 0.0458581 loss)
I0312 05:45:09.032131 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0620929 (* 1 = 0.0620929 loss)
I0312 05:45:09.032135 17663 sgd_solver.cpp:106] Iteration 45300, lr = 1e-07
I0312 05:46:01.974495 17663 solver.cpp:228] Iteration 45400, loss = 0.234452
I0312 05:46:01.974522 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 05:46:01.974530 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440169 (* 1 = 0.0440169 loss)
I0312 05:46:01.974550 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0608082 (* 1 = 0.0608082 loss)
I0312 05:46:01.974553 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165039 (* 1 = 0.0165039 loss)
I0312 05:46:01.974557 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0312181 (* 1 = 0.0312181 loss)
I0312 05:46:01.974563 17663 sgd_solver.cpp:106] Iteration 45400, lr = 1e-07
I0312 05:46:55.608160 17663 solver.cpp:228] Iteration 45500, loss = 0.380696
I0312 05:46:55.608183 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 05:46:55.608191 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0825141 (* 1 = 0.0825141 loss)
I0312 05:46:55.608196 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147221 (* 1 = 0.147221 loss)
I0312 05:46:55.608201 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0432532 (* 1 = 0.0432532 loss)
I0312 05:46:55.608204 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0619643 (* 1 = 0.0619643 loss)
I0312 05:46:55.608223 17663 sgd_solver.cpp:106] Iteration 45500, lr = 1e-07
I0312 05:47:47.887766 17663 solver.cpp:228] Iteration 45600, loss = 0.374717
I0312 05:47:47.887789 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:47:47.887795 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159681 (* 1 = 0.0159681 loss)
I0312 05:47:47.887814 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0985519 (* 1 = 0.0985519 loss)
I0312 05:47:47.887818 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0674964 (* 1 = 0.0674964 loss)
I0312 05:47:47.887822 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0500071 (* 1 = 0.0500071 loss)
I0312 05:47:47.887827 17663 sgd_solver.cpp:106] Iteration 45600, lr = 1e-07
I0312 05:48:40.642911 17663 solver.cpp:228] Iteration 45700, loss = 0.426572
I0312 05:48:40.642932 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:48:40.642940 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.031077 (* 1 = 0.031077 loss)
I0312 05:48:40.642944 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0997483 (* 1 = 0.0997483 loss)
I0312 05:48:40.642963 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0699976 (* 1 = 0.0699976 loss)
I0312 05:48:40.642966 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.280427 (* 1 = 0.280427 loss)
I0312 05:48:40.642971 17663 sgd_solver.cpp:106] Iteration 45700, lr = 1e-07
I0312 05:49:33.171402 17663 solver.cpp:228] Iteration 45800, loss = 0.293059
I0312 05:49:33.171424 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 05:49:33.171432 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381631 (* 1 = 0.0381631 loss)
I0312 05:49:33.171437 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.127743 (* 1 = 0.127743 loss)
I0312 05:49:33.171455 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00731014 (* 1 = 0.00731014 loss)
I0312 05:49:33.171459 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00461394 (* 1 = 0.00461394 loss)
I0312 05:49:33.171464 17663 sgd_solver.cpp:106] Iteration 45800, lr = 1e-07
I0312 05:50:26.416503 17663 solver.cpp:228] Iteration 45900, loss = 0.283493
I0312 05:50:26.416544 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 05:50:26.416553 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321913 (* 1 = 0.0321913 loss)
I0312 05:50:26.416558 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0968603 (* 1 = 0.0968603 loss)
I0312 05:50:26.416563 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111001 (* 1 = 0.0111001 loss)
I0312 05:50:26.416568 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353245 (* 1 = 0.0353245 loss)
I0312 05:50:26.416587 17663 sgd_solver.cpp:106] Iteration 45900, lr = 1e-07
speed: 0.525s / iter
I0312 05:51:18.267866 17663 solver.cpp:228] Iteration 46000, loss = 0.79852
I0312 05:51:18.267889 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 05:51:18.267896 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.245346 (* 1 = 0.245346 loss)
I0312 05:51:18.267915 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.337141 (* 1 = 0.337141 loss)
I0312 05:51:18.267920 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226117 (* 1 = 0.0226117 loss)
I0312 05:51:18.267923 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.34051 (* 1 = 0.34051 loss)
I0312 05:51:18.267941 17663 sgd_solver.cpp:106] Iteration 46000, lr = 1e-07
I0312 05:52:10.723286 17663 solver.cpp:228] Iteration 46100, loss = 0.573709
I0312 05:52:10.723309 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 05:52:10.723317 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.300339 (* 1 = 0.300339 loss)
I0312 05:52:10.723335 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.442579 (* 1 = 0.442579 loss)
I0312 05:52:10.723340 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289395 (* 1 = 0.0289395 loss)
I0312 05:52:10.723343 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.23422 (* 1 = 0.23422 loss)
I0312 05:52:10.723350 17663 sgd_solver.cpp:106] Iteration 46100, lr = 1e-07
I0312 05:53:03.360843 17663 solver.cpp:228] Iteration 46200, loss = 0.207152
I0312 05:53:03.360867 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 05:53:03.360873 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0311408 (* 1 = 0.0311408 loss)
I0312 05:53:03.360893 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0667039 (* 1 = 0.0667039 loss)
I0312 05:53:03.360896 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256006 (* 1 = 0.0256006 loss)
I0312 05:53:03.360900 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0642014 (* 1 = 0.0642014 loss)
I0312 05:53:03.360905 17663 sgd_solver.cpp:106] Iteration 46200, lr = 1e-07
I0312 05:53:55.907151 17663 solver.cpp:228] Iteration 46300, loss = 0.249104
I0312 05:53:55.907174 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 05:53:55.907181 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0701658 (* 1 = 0.0701658 loss)
I0312 05:53:55.907200 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121295 (* 1 = 0.121295 loss)
I0312 05:53:55.907204 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0443441 (* 1 = 0.0443441 loss)
I0312 05:53:55.907208 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.114931 (* 1 = 0.114931 loss)
I0312 05:53:55.907227 17663 sgd_solver.cpp:106] Iteration 46300, lr = 1e-07
I0312 05:54:48.901733 17663 solver.cpp:228] Iteration 46400, loss = 0.314869
I0312 05:54:48.901757 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:54:48.901764 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.026738 (* 1 = 0.026738 loss)
I0312 05:54:48.901782 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.068957 (* 1 = 0.068957 loss)
I0312 05:54:48.901787 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327747 (* 1 = 0.0327747 loss)
I0312 05:54:48.901792 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.247658 (* 1 = 0.247658 loss)
I0312 05:54:48.901796 17663 sgd_solver.cpp:106] Iteration 46400, lr = 1e-07
I0312 05:55:41.064225 17663 solver.cpp:228] Iteration 46500, loss = 0.535612
I0312 05:55:41.064249 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 05:55:41.064257 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518049 (* 1 = 0.0518049 loss)
I0312 05:55:41.064276 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0617278 (* 1 = 0.0617278 loss)
I0312 05:55:41.064281 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174139 (* 1 = 0.0174139 loss)
I0312 05:55:41.064285 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221983 (* 1 = 0.0221983 loss)
I0312 05:55:41.064291 17663 sgd_solver.cpp:106] Iteration 46500, lr = 1e-07
I0312 05:56:33.696364 17663 solver.cpp:228] Iteration 46600, loss = 0.213841
I0312 05:56:33.696388 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 05:56:33.696395 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499501 (* 1 = 0.0499501 loss)
I0312 05:56:33.696414 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.167205 (* 1 = 0.167205 loss)
I0312 05:56:33.696419 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198052 (* 1 = 0.0198052 loss)
I0312 05:56:33.696424 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00504354 (* 1 = 0.00504354 loss)
I0312 05:56:33.696429 17663 sgd_solver.cpp:106] Iteration 46600, lr = 1e-07
I0312 05:57:26.466620 17663 solver.cpp:228] Iteration 46700, loss = 0.161594
I0312 05:57:26.466640 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:57:26.466647 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.020214 (* 1 = 0.020214 loss)
I0312 05:57:26.466666 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0866207 (* 1 = 0.0866207 loss)
I0312 05:57:26.466671 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00971606 (* 1 = 0.00971606 loss)
I0312 05:57:26.466675 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239479 (* 1 = 0.0239479 loss)
I0312 05:57:26.466681 17663 sgd_solver.cpp:106] Iteration 46700, lr = 1e-07
I0312 05:58:19.008484 17663 solver.cpp:228] Iteration 46800, loss = 0.268116
I0312 05:58:19.008519 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 05:58:19.008527 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116865 (* 1 = 0.116865 loss)
I0312 05:58:19.008548 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.234525 (* 1 = 0.234525 loss)
I0312 05:58:19.008551 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625339 (* 1 = 0.00625339 loss)
I0312 05:58:19.008556 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141523 (* 1 = 0.0141523 loss)
I0312 05:58:19.008574 17663 sgd_solver.cpp:106] Iteration 46800, lr = 1e-07
I0312 05:59:11.544998 17663 solver.cpp:228] Iteration 46900, loss = 0.6441
I0312 05:59:11.545022 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 05:59:11.545028 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257995 (* 1 = 0.0257995 loss)
I0312 05:59:11.545048 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.07248 (* 1 = 0.07248 loss)
I0312 05:59:11.545053 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162708 (* 1 = 0.00162708 loss)
I0312 05:59:11.545058 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378463 (* 1 = 0.0378463 loss)
I0312 05:59:11.545061 17663 sgd_solver.cpp:106] Iteration 46900, lr = 1e-07
speed: 0.525s / iter
I0312 06:00:03.850206 17663 solver.cpp:228] Iteration 47000, loss = 0.316086
I0312 06:00:03.850227 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:00:03.850234 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486471 (* 1 = 0.0486471 loss)
I0312 06:00:03.850253 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.128812 (* 1 = 0.128812 loss)
I0312 06:00:03.850258 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00499961 (* 1 = 0.00499961 loss)
I0312 06:00:03.850262 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290099 (* 1 = 0.0290099 loss)
I0312 06:00:03.850267 17663 sgd_solver.cpp:106] Iteration 47000, lr = 1e-07
I0312 06:00:56.672590 17663 solver.cpp:228] Iteration 47100, loss = 0.335779
I0312 06:00:56.672613 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:00:56.672621 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.134581 (* 1 = 0.134581 loss)
I0312 06:00:56.672638 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.217972 (* 1 = 0.217972 loss)
I0312 06:00:56.672642 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149987 (* 1 = 0.0149987 loss)
I0312 06:00:56.672647 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751116 (* 1 = 0.0751116 loss)
I0312 06:00:56.672665 17663 sgd_solver.cpp:106] Iteration 47100, lr = 1e-07
I0312 06:01:49.316325 17663 solver.cpp:228] Iteration 47200, loss = 0.278035
I0312 06:01:49.316347 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 06:01:49.316355 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0450478 (* 1 = 0.0450478 loss)
I0312 06:01:49.316375 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0957084 (* 1 = 0.0957084 loss)
I0312 06:01:49.316378 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0549815 (* 1 = 0.0549815 loss)
I0312 06:01:49.316382 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111606 (* 1 = 0.111606 loss)
I0312 06:01:49.316388 17663 sgd_solver.cpp:106] Iteration 47200, lr = 1e-07
I0312 06:02:41.603029 17663 solver.cpp:228] Iteration 47300, loss = 0.261409
I0312 06:02:41.603050 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:02:41.603057 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0249161 (* 1 = 0.0249161 loss)
I0312 06:02:41.603076 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0499808 (* 1 = 0.0499808 loss)
I0312 06:02:41.603081 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00419633 (* 1 = 0.00419633 loss)
I0312 06:02:41.603085 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257532 (* 1 = 0.0257532 loss)
I0312 06:02:41.603090 17663 sgd_solver.cpp:106] Iteration 47300, lr = 1e-07
I0312 06:03:34.156375 17663 solver.cpp:228] Iteration 47400, loss = 0.246664
I0312 06:03:34.156397 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 06:03:34.156405 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.036524 (* 1 = 0.036524 loss)
I0312 06:03:34.156424 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107602 (* 1 = 0.107602 loss)
I0312 06:03:34.156428 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0893207 (* 1 = 0.0893207 loss)
I0312 06:03:34.156432 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118366 (* 1 = 0.118366 loss)
I0312 06:03:34.156436 17663 sgd_solver.cpp:106] Iteration 47400, lr = 1e-07
I0312 06:04:27.260753 17663 solver.cpp:228] Iteration 47500, loss = 0.715756
I0312 06:04:27.260776 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:04:27.260783 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355519 (* 1 = 0.0355519 loss)
I0312 06:04:27.260802 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188765 (* 1 = 0.188765 loss)
I0312 06:04:27.260807 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0621449 (* 1 = 0.0621449 loss)
I0312 06:04:27.260810 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110634 (* 1 = 0.110634 loss)
I0312 06:04:27.260828 17663 sgd_solver.cpp:106] Iteration 47500, lr = 1e-07
I0312 06:05:19.657707 17663 solver.cpp:228] Iteration 47600, loss = 0.334041
I0312 06:05:19.657732 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:05:19.657739 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0647887 (* 1 = 0.0647887 loss)
I0312 06:05:19.657758 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.190549 (* 1 = 0.190549 loss)
I0312 06:05:19.657763 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139212 (* 1 = 0.0139212 loss)
I0312 06:05:19.657779 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0601519 (* 1 = 0.0601519 loss)
I0312 06:05:19.657785 17663 sgd_solver.cpp:106] Iteration 47600, lr = 1e-07
I0312 06:06:12.248601 17663 solver.cpp:228] Iteration 47700, loss = 0.307032
I0312 06:06:12.248623 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:06:12.248631 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0987699 (* 1 = 0.0987699 loss)
I0312 06:06:12.248648 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.182943 (* 1 = 0.182943 loss)
I0312 06:06:12.248652 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212599 (* 1 = 0.0212599 loss)
I0312 06:06:12.248670 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168171 (* 1 = 0.168171 loss)
I0312 06:06:12.248677 17663 sgd_solver.cpp:106] Iteration 47700, lr = 1e-07
I0312 06:07:04.400293 17663 solver.cpp:228] Iteration 47800, loss = 0.359331
I0312 06:07:04.400315 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:07:04.400322 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0602454 (* 1 = 0.0602454 loss)
I0312 06:07:04.400341 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168736 (* 1 = 0.168736 loss)
I0312 06:07:04.400346 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162005 (* 1 = 0.0162005 loss)
I0312 06:07:04.400349 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0682906 (* 1 = 0.0682906 loss)
I0312 06:07:04.400367 17663 sgd_solver.cpp:106] Iteration 47800, lr = 1e-07
I0312 06:07:56.308691 17663 solver.cpp:228] Iteration 47900, loss = 0.322035
I0312 06:07:56.308714 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 06:07:56.308722 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.147912 (* 1 = 0.147912 loss)
I0312 06:07:56.308740 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.221811 (* 1 = 0.221811 loss)
I0312 06:07:56.308745 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00639105 (* 1 = 0.00639105 loss)
I0312 06:07:56.308750 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0551887 (* 1 = 0.0551887 loss)
I0312 06:07:56.308754 17663 sgd_solver.cpp:106] Iteration 47900, lr = 1e-07
speed: 0.525s / iter
I0312 06:08:48.886978 17663 solver.cpp:228] Iteration 48000, loss = 0.353752
I0312 06:08:48.887131 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 06:08:48.887188 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.148261 (* 1 = 0.148261 loss)
I0312 06:08:48.887236 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.241299 (* 1 = 0.241299 loss)
I0312 06:08:48.887284 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286756 (* 1 = 0.00286756 loss)
I0312 06:08:48.887331 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323402 (* 1 = 0.0323402 loss)
I0312 06:08:48.887377 17663 sgd_solver.cpp:106] Iteration 48000, lr = 1e-07
I0312 06:09:41.532752 17663 solver.cpp:228] Iteration 48100, loss = 0.412041
I0312 06:09:41.532775 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:09:41.532783 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0847838 (* 1 = 0.0847838 loss)
I0312 06:09:41.532802 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.141282 (* 1 = 0.141282 loss)
I0312 06:09:41.532806 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0253039 (* 1 = 0.0253039 loss)
I0312 06:09:41.532810 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0797266 (* 1 = 0.0797266 loss)
I0312 06:09:41.532815 17663 sgd_solver.cpp:106] Iteration 48100, lr = 1e-07
I0312 06:10:33.801355 17663 solver.cpp:228] Iteration 48200, loss = 0.27401
I0312 06:10:33.801378 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 06:10:33.801384 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.050144 (* 1 = 0.050144 loss)
I0312 06:10:33.801403 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0939048 (* 1 = 0.0939048 loss)
I0312 06:10:33.801407 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0312803 (* 1 = 0.0312803 loss)
I0312 06:10:33.801411 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.226723 (* 1 = 0.226723 loss)
I0312 06:10:33.801416 17663 sgd_solver.cpp:106] Iteration 48200, lr = 1e-07
I0312 06:11:26.263474 17663 solver.cpp:228] Iteration 48300, loss = 0.341377
I0312 06:11:26.263499 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:11:26.263505 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.000416548 (* 1 = 0.000416548 loss)
I0312 06:11:26.263525 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.00957812 (* 1 = 0.00957812 loss)
I0312 06:11:26.263530 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200149 (* 1 = 0.0200149 loss)
I0312 06:11:26.263535 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.343405 (* 1 = 0.343405 loss)
I0312 06:11:26.263540 17663 sgd_solver.cpp:106] Iteration 48300, lr = 1e-07
I0312 06:12:18.506340 17663 solver.cpp:228] Iteration 48400, loss = 0.330411
I0312 06:12:18.506376 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 06:12:18.506397 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0893526 (* 1 = 0.0893526 loss)
I0312 06:12:18.506402 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.33535 (* 1 = 0.33535 loss)
I0312 06:12:18.506405 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141246 (* 1 = 0.0141246 loss)
I0312 06:12:18.506409 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0722956 (* 1 = 0.0722956 loss)
I0312 06:12:18.506414 17663 sgd_solver.cpp:106] Iteration 48400, lr = 1e-07
I0312 06:13:11.468991 17663 solver.cpp:228] Iteration 48500, loss = 0.286804
I0312 06:13:11.469014 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:13:11.469022 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142983 (* 1 = 0.142983 loss)
I0312 06:13:11.469041 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215956 (* 1 = 0.215956 loss)
I0312 06:13:11.469045 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107777 (* 1 = 0.0107777 loss)
I0312 06:13:11.469049 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487665 (* 1 = 0.0487665 loss)
I0312 06:13:11.469054 17663 sgd_solver.cpp:106] Iteration 48500, lr = 1e-07
I0312 06:14:04.446998 17663 solver.cpp:228] Iteration 48600, loss = 0.290787
I0312 06:14:04.447021 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 06:14:04.447029 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455657 (* 1 = 0.0455657 loss)
I0312 06:14:04.447033 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0890524 (* 1 = 0.0890524 loss)
I0312 06:14:04.447052 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117625 (* 1 = 0.0117625 loss)
I0312 06:14:04.447057 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150836 (* 1 = 0.150836 loss)
I0312 06:14:04.447062 17663 sgd_solver.cpp:106] Iteration 48600, lr = 1e-07
I0312 06:14:57.291369 17663 solver.cpp:228] Iteration 48700, loss = 0.173874
I0312 06:14:57.291390 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:14:57.291398 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266125 (* 1 = 0.0266125 loss)
I0312 06:14:57.291402 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0498469 (* 1 = 0.0498469 loss)
I0312 06:14:57.291420 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997107 (* 1 = 0.00997107 loss)
I0312 06:14:57.291424 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250013 (* 1 = 0.0250013 loss)
I0312 06:14:57.291429 17663 sgd_solver.cpp:106] Iteration 48700, lr = 1e-07
I0312 06:15:49.893793 17663 solver.cpp:228] Iteration 48800, loss = 0.347075
I0312 06:15:49.893813 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:15:49.893821 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.134483 (* 1 = 0.134483 loss)
I0312 06:15:49.893839 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.174665 (* 1 = 0.174665 loss)
I0312 06:15:49.893843 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205436 (* 1 = 0.0205436 loss)
I0312 06:15:49.893847 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230032 (* 1 = 0.0230032 loss)
I0312 06:15:49.893851 17663 sgd_solver.cpp:106] Iteration 48800, lr = 1e-07
I0312 06:16:42.731773 17663 solver.cpp:228] Iteration 48900, loss = 0.225016
I0312 06:16:42.731796 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:16:42.731802 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455629 (* 1 = 0.0455629 loss)
I0312 06:16:42.731806 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0490174 (* 1 = 0.0490174 loss)
I0312 06:16:42.731811 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208327 (* 1 = 0.0208327 loss)
I0312 06:16:42.731814 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.186348 (* 1 = 0.186348 loss)
I0312 06:16:42.731819 17663 sgd_solver.cpp:106] Iteration 48900, lr = 1e-07
speed: 0.525s / iter
I0312 06:17:37.038240 17663 solver.cpp:228] Iteration 49000, loss = 0.183248
I0312 06:17:37.038383 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:17:37.038439 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00773674 (* 1 = 0.00773674 loss)
I0312 06:17:37.038486 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0779193 (* 1 = 0.0779193 loss)
I0312 06:17:37.038533 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0359655 (* 1 = 0.0359655 loss)
I0312 06:17:37.038579 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.042018 (* 1 = 0.042018 loss)
I0312 06:17:37.038614 17663 sgd_solver.cpp:106] Iteration 49000, lr = 1e-07
I0312 06:18:29.660419 17663 solver.cpp:228] Iteration 49100, loss = 0.232778
I0312 06:18:29.660441 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 06:18:29.660449 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0416901 (* 1 = 0.0416901 loss)
I0312 06:18:29.660454 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0563495 (* 1 = 0.0563495 loss)
I0312 06:18:29.660471 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120338 (* 1 = 0.0120338 loss)
I0312 06:18:29.660476 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600747 (* 1 = 0.0600747 loss)
I0312 06:18:29.660481 17663 sgd_solver.cpp:106] Iteration 49100, lr = 1e-07
I0312 06:19:22.440385 17663 solver.cpp:228] Iteration 49200, loss = 0.412317
I0312 06:19:22.440412 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 06:19:22.440433 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.162086 (* 1 = 0.162086 loss)
I0312 06:19:22.440438 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.247202 (* 1 = 0.247202 loss)
I0312 06:19:22.440443 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150065 (* 1 = 0.0150065 loss)
I0312 06:19:22.440446 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0659315 (* 1 = 0.0659315 loss)
I0312 06:19:22.440467 17663 sgd_solver.cpp:106] Iteration 49200, lr = 1e-07
I0312 06:20:14.634730 17663 solver.cpp:228] Iteration 49300, loss = 0.343332
I0312 06:20:14.634754 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 06:20:14.634762 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400125 (* 1 = 0.0400125 loss)
I0312 06:20:14.634780 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151284 (* 1 = 0.151284 loss)
I0312 06:20:14.634784 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351836 (* 1 = 0.00351836 loss)
I0312 06:20:14.634789 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0807547 (* 1 = 0.0807547 loss)
I0312 06:20:14.634794 17663 sgd_solver.cpp:106] Iteration 49300, lr = 1e-07
I0312 06:21:07.374191 17663 solver.cpp:228] Iteration 49400, loss = 0.321883
I0312 06:21:07.374212 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:21:07.374219 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0617852 (* 1 = 0.0617852 loss)
I0312 06:21:07.374224 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12708 (* 1 = 0.12708 loss)
I0312 06:21:07.374228 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315712 (* 1 = 0.00315712 loss)
I0312 06:21:07.374233 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00962887 (* 1 = 0.00962887 loss)
I0312 06:21:07.374238 17663 sgd_solver.cpp:106] Iteration 49400, lr = 1e-07
I0312 06:21:59.600276 17663 solver.cpp:228] Iteration 49500, loss = 0.592223
I0312 06:21:59.600299 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 06:21:59.600306 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258681 (* 1 = 0.0258681 loss)
I0312 06:21:59.600327 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0877419 (* 1 = 0.0877419 loss)
I0312 06:21:59.600330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125007 (* 1 = 0.0125007 loss)
I0312 06:21:59.600335 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939229 (* 1 = 0.00939229 loss)
I0312 06:21:59.600340 17663 sgd_solver.cpp:106] Iteration 49500, lr = 1e-07
I0312 06:22:51.935596 17663 solver.cpp:228] Iteration 49600, loss = 0.576058
I0312 06:22:51.935619 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:22:51.935626 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.096267 (* 1 = 0.096267 loss)
I0312 06:22:51.935631 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.169827 (* 1 = 0.169827 loss)
I0312 06:22:51.935649 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.09359 (* 1 = 0.09359 loss)
I0312 06:22:51.935653 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.234518 (* 1 = 0.234518 loss)
I0312 06:22:51.935658 17663 sgd_solver.cpp:106] Iteration 49600, lr = 1e-07
I0312 06:23:45.346657 17663 solver.cpp:228] Iteration 49700, loss = 0.274464
I0312 06:23:45.346678 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 06:23:45.346685 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493893 (* 1 = 0.0493893 loss)
I0312 06:23:45.346690 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0748151 (* 1 = 0.0748151 loss)
I0312 06:23:45.346709 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140191 (* 1 = 0.0140191 loss)
I0312 06:23:45.346712 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148722 (* 1 = 0.148722 loss)
I0312 06:23:45.346730 17663 sgd_solver.cpp:106] Iteration 49700, lr = 1e-07
I0312 06:24:38.235569 17663 solver.cpp:228] Iteration 49800, loss = 0.271913
I0312 06:24:38.235590 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:24:38.235597 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0969905 (* 1 = 0.0969905 loss)
I0312 06:24:38.235601 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.187397 (* 1 = 0.187397 loss)
I0312 06:24:38.235606 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00990282 (* 1 = 0.00990282 loss)
I0312 06:24:38.235625 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109161 (* 1 = 0.109161 loss)
I0312 06:24:38.235630 17663 sgd_solver.cpp:106] Iteration 49800, lr = 1e-07
I0312 06:25:30.625630 17663 solver.cpp:228] Iteration 49900, loss = 0.816849
I0312 06:25:30.625653 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:25:30.625660 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105135 (* 1 = 0.105135 loss)
I0312 06:25:30.625679 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.129753 (* 1 = 0.129753 loss)
I0312 06:25:30.625684 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0437991 (* 1 = 0.0437991 loss)
I0312 06:25:30.625689 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.47992 (* 1 = 0.47992 loss)
I0312 06:25:30.625694 17663 sgd_solver.cpp:106] Iteration 49900, lr = 1e-07
I0312 06:26:22.660832 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_50000.caffemodel
I0312 06:26:23.045869 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_50000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_50000.caffemodel
I0312 06:26:24.340582 17663 solver.cpp:228] Iteration 50000, loss = 0.497103
I0312 06:26:24.340605 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 06:26:24.340612 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341379 (* 1 = 0.0341379 loss)
I0312 06:26:24.340617 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135062 (* 1 = 0.135062 loss)
I0312 06:26:24.340636 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.299219 (* 1 = 0.299219 loss)
I0312 06:26:24.340639 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0792078 (* 1 = 0.0792078 loss)
I0312 06:26:24.340658 17663 sgd_solver.cpp:106] Iteration 50000, lr = 1e-08
I0312 06:27:16.448444 17663 solver.cpp:228] Iteration 50100, loss = 0.561592
I0312 06:27:16.448467 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 06:27:16.448474 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.27272 (* 1 = 0.27272 loss)
I0312 06:27:16.448493 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.369672 (* 1 = 0.369672 loss)
I0312 06:27:16.448498 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0612901 (* 1 = 0.0612901 loss)
I0312 06:27:16.448501 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0561121 (* 1 = 0.0561121 loss)
I0312 06:27:16.448518 17663 sgd_solver.cpp:106] Iteration 50100, lr = 1e-08
I0312 06:28:08.997722 17663 solver.cpp:228] Iteration 50200, loss = 0.171793
I0312 06:28:08.997745 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 06:28:08.997752 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320066 (* 1 = 0.0320066 loss)
I0312 06:28:08.997757 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.067398 (* 1 = 0.067398 loss)
I0312 06:28:08.997761 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00934238 (* 1 = 0.00934238 loss)
I0312 06:28:08.997766 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351146 (* 1 = 0.0351146 loss)
I0312 06:28:08.997771 17663 sgd_solver.cpp:106] Iteration 50200, lr = 1e-08
I0312 06:29:01.199242 17663 solver.cpp:228] Iteration 50300, loss = 0.647003
I0312 06:29:01.199265 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 06:29:01.199271 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00212822 (* 1 = 0.00212822 loss)
I0312 06:29:01.199290 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.00732713 (* 1 = 0.00732713 loss)
I0312 06:29:01.199295 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256423 (* 1 = 0.0256423 loss)
I0312 06:29:01.199298 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.73315 (* 1 = 0.73315 loss)
I0312 06:29:01.199303 17663 sgd_solver.cpp:106] Iteration 50300, lr = 1e-08
I0312 06:29:54.338800 17663 solver.cpp:228] Iteration 50400, loss = 0.172885
I0312 06:29:54.338820 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 06:29:54.338829 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0221849 (* 1 = 0.0221849 loss)
I0312 06:29:54.338847 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0741474 (* 1 = 0.0741474 loss)
I0312 06:29:54.338851 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00401283 (* 1 = 0.00401283 loss)
I0312 06:29:54.338855 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00531913 (* 1 = 0.00531913 loss)
I0312 06:29:54.338860 17663 sgd_solver.cpp:106] Iteration 50400, lr = 1e-08
I0312 06:30:46.703255 17663 solver.cpp:228] Iteration 50500, loss = 0.447918
I0312 06:30:46.703279 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:30:46.703287 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.062027 (* 1 = 0.062027 loss)
I0312 06:30:46.703306 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.127291 (* 1 = 0.127291 loss)
I0312 06:30:46.703311 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.1445 (* 1 = 0.1445 loss)
I0312 06:30:46.703327 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.456321 (* 1 = 0.456321 loss)
I0312 06:30:46.703332 17663 sgd_solver.cpp:106] Iteration 50500, lr = 1e-08
I0312 06:31:39.493185 17663 solver.cpp:228] Iteration 50600, loss = 0.275876
I0312 06:31:39.493207 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 06:31:39.493214 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.117287 (* 1 = 0.117287 loss)
I0312 06:31:39.493232 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215596 (* 1 = 0.215596 loss)
I0312 06:31:39.493237 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00548895 (* 1 = 0.00548895 loss)
I0312 06:31:39.493242 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039566 (* 1 = 0.039566 loss)
I0312 06:31:39.493247 17663 sgd_solver.cpp:106] Iteration 50600, lr = 1e-08
I0312 06:32:32.292027 17663 solver.cpp:228] Iteration 50700, loss = 0.337406
I0312 06:32:32.292052 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 06:32:32.292058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.163041 (* 1 = 0.163041 loss)
I0312 06:32:32.292063 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.246071 (* 1 = 0.246071 loss)
I0312 06:32:32.292081 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204389 (* 1 = 0.0204389 loss)
I0312 06:32:32.292086 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103419 (* 1 = 0.103419 loss)
I0312 06:32:32.292091 17663 sgd_solver.cpp:106] Iteration 50700, lr = 1e-08
I0312 06:33:25.202548 17663 solver.cpp:228] Iteration 50800, loss = 0.597752
I0312 06:33:25.202569 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:33:25.202576 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.14352 (* 1 = 0.14352 loss)
I0312 06:33:25.202580 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.154767 (* 1 = 0.154767 loss)
I0312 06:33:25.202600 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0424744 (* 1 = 0.0424744 loss)
I0312 06:33:25.202603 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.236567 (* 1 = 0.236567 loss)
I0312 06:33:25.202608 17663 sgd_solver.cpp:106] Iteration 50800, lr = 1e-08
I0312 06:34:18.140502 17663 solver.cpp:228] Iteration 50900, loss = 0.808987
I0312 06:34:18.140524 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:34:18.140532 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0516707 (* 1 = 0.0516707 loss)
I0312 06:34:18.140552 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1146 (* 1 = 0.1146 loss)
I0312 06:34:18.140555 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00790022 (* 1 = 0.00790022 loss)
I0312 06:34:18.140560 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256274 (* 1 = 0.0256274 loss)
I0312 06:34:18.140564 17663 sgd_solver.cpp:106] Iteration 50900, lr = 1e-08
speed: 0.525s / iter
I0312 06:35:11.541851 17663 solver.cpp:228] Iteration 51000, loss = 0.28798
I0312 06:35:11.541888 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:35:11.541901 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445235 (* 1 = 0.0445235 loss)
I0312 06:35:11.541918 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107466 (* 1 = 0.107466 loss)
I0312 06:35:11.541923 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273479 (* 1 = 0.00273479 loss)
I0312 06:35:11.541941 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0500176 (* 1 = 0.0500176 loss)
I0312 06:35:11.541946 17663 sgd_solver.cpp:106] Iteration 51000, lr = 1e-08
I0312 06:36:03.524524 17663 solver.cpp:228] Iteration 51100, loss = 0.239659
I0312 06:36:03.524545 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:36:03.524554 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365663 (* 1 = 0.0365663 loss)
I0312 06:36:03.524571 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.145805 (* 1 = 0.145805 loss)
I0312 06:36:03.524575 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0411891 (* 1 = 0.0411891 loss)
I0312 06:36:03.524580 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383591 (* 1 = 0.0383591 loss)
I0312 06:36:03.524585 17663 sgd_solver.cpp:106] Iteration 51100, lr = 1e-08
I0312 06:36:55.583202 17663 solver.cpp:228] Iteration 51200, loss = 0.46577
I0312 06:36:55.583223 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 06:36:55.583231 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0757079 (* 1 = 0.0757079 loss)
I0312 06:36:55.583250 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.148693 (* 1 = 0.148693 loss)
I0312 06:36:55.583254 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0316096 (* 1 = 0.0316096 loss)
I0312 06:36:55.583258 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0618395 (* 1 = 0.0618395 loss)
I0312 06:36:55.583263 17663 sgd_solver.cpp:106] Iteration 51200, lr = 1e-08
I0312 06:37:48.324213 17663 solver.cpp:228] Iteration 51300, loss = 0.452425
I0312 06:37:48.324235 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 06:37:48.324242 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.128938 (* 1 = 0.128938 loss)
I0312 06:37:48.324247 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.268027 (* 1 = 0.268027 loss)
I0312 06:37:48.324266 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0778796 (* 1 = 0.0778796 loss)
I0312 06:37:48.324270 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.350427 (* 1 = 0.350427 loss)
I0312 06:37:48.324276 17663 sgd_solver.cpp:106] Iteration 51300, lr = 1e-08
I0312 06:38:41.335687 17663 solver.cpp:228] Iteration 51400, loss = 0.294885
I0312 06:38:41.335710 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 06:38:41.335716 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186046 (* 1 = 0.0186046 loss)
I0312 06:38:41.335721 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0795359 (* 1 = 0.0795359 loss)
I0312 06:38:41.335739 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140524 (* 1 = 0.00140524 loss)
I0312 06:38:41.335744 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210324 (* 1 = 0.0210324 loss)
I0312 06:38:41.335749 17663 sgd_solver.cpp:106] Iteration 51400, lr = 1e-08
I0312 06:39:33.746275 17663 solver.cpp:228] Iteration 51500, loss = 0.31963
I0312 06:39:33.746299 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:39:33.746305 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0622971 (* 1 = 0.0622971 loss)
I0312 06:39:33.746325 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116782 (* 1 = 0.116782 loss)
I0312 06:39:33.746328 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245226 (* 1 = 0.0245226 loss)
I0312 06:39:33.746332 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167335 (* 1 = 0.0167335 loss)
I0312 06:39:33.746337 17663 sgd_solver.cpp:106] Iteration 51500, lr = 1e-08
I0312 06:40:25.906023 17663 solver.cpp:228] Iteration 51600, loss = 0.480605
I0312 06:40:25.906045 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:40:25.906052 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.11003 (* 1 = 0.11003 loss)
I0312 06:40:25.906071 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170562 (* 1 = 0.170562 loss)
I0312 06:40:25.906075 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00174739 (* 1 = 0.00174739 loss)
I0312 06:40:25.906080 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272547 (* 1 = 0.0272547 loss)
I0312 06:40:25.906085 17663 sgd_solver.cpp:106] Iteration 51600, lr = 1e-08
I0312 06:41:18.713968 17663 solver.cpp:228] Iteration 51700, loss = 0.313154
I0312 06:41:18.713991 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:41:18.713999 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0976488 (* 1 = 0.0976488 loss)
I0312 06:41:18.714004 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.174135 (* 1 = 0.174135 loss)
I0312 06:41:18.714021 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00739709 (* 1 = 0.00739709 loss)
I0312 06:41:18.714026 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137669 (* 1 = 0.0137669 loss)
I0312 06:41:18.714031 17663 sgd_solver.cpp:106] Iteration 51700, lr = 1e-08
I0312 06:42:10.849131 17663 solver.cpp:228] Iteration 51800, loss = 0.606529
I0312 06:42:10.849154 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 06:42:10.849162 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.102006 (* 1 = 0.102006 loss)
I0312 06:42:10.849181 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.207083 (* 1 = 0.207083 loss)
I0312 06:42:10.849185 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232362 (* 1 = 0.0232362 loss)
I0312 06:42:10.849189 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.20726 (* 1 = 0.20726 loss)
I0312 06:42:10.849195 17663 sgd_solver.cpp:106] Iteration 51800, lr = 1e-08
I0312 06:43:03.587270 17663 solver.cpp:228] Iteration 51900, loss = 0.426655
I0312 06:43:03.587292 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 06:43:03.587299 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141565 (* 1 = 0.141565 loss)
I0312 06:43:03.587304 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.249535 (* 1 = 0.249535 loss)
I0312 06:43:03.587308 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0394228 (* 1 = 0.0394228 loss)
I0312 06:43:03.587312 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.16646 (* 1 = 0.16646 loss)
I0312 06:43:03.587317 17663 sgd_solver.cpp:106] Iteration 51900, lr = 1e-08
speed: 0.525s / iter
I0312 06:43:55.470465 17663 solver.cpp:228] Iteration 52000, loss = 0.836886
I0312 06:43:55.470607 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 06:43:55.470662 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.151064 (* 1 = 0.151064 loss)
I0312 06:43:55.470710 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.218908 (* 1 = 0.218908 loss)
I0312 06:43:55.470757 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182432 (* 1 = 0.0182432 loss)
I0312 06:43:55.470804 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681421 (* 1 = 0.0681421 loss)
I0312 06:43:55.470851 17663 sgd_solver.cpp:106] Iteration 52000, lr = 1e-08
I0312 06:44:47.858067 17663 solver.cpp:228] Iteration 52100, loss = nan
I0312 06:44:47.858088 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:44:47.858096 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360315 (* 1 = 0.0360315 loss)
I0312 06:44:47.858115 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0277306 (* 1 = 0.0277306 loss)
I0312 06:44:47.858119 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0338704 (* 1 = 0.0338704 loss)
I0312 06:44:47.858136 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525431 (* 1 = 0.0525431 loss)
I0312 06:44:47.858141 17663 sgd_solver.cpp:106] Iteration 52100, lr = 1e-08
I0312 06:45:40.211004 17663 solver.cpp:228] Iteration 52200, loss = 0.40884
I0312 06:45:40.211030 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:45:40.211036 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882168 (* 1 = 0.0882168 loss)
I0312 06:45:40.211055 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.228332 (* 1 = 0.228332 loss)
I0312 06:45:40.211061 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274673 (* 1 = 0.0274673 loss)
I0312 06:45:40.211064 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10622 (* 1 = 0.10622 loss)
I0312 06:45:40.211069 17663 sgd_solver.cpp:106] Iteration 52200, lr = 1e-08
I0312 06:46:31.936301 17663 solver.cpp:228] Iteration 52300, loss = 0.563827
I0312 06:46:31.936326 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:46:31.936332 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.103673 (* 1 = 0.103673 loss)
I0312 06:46:31.936352 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.139917 (* 1 = 0.139917 loss)
I0312 06:46:31.936357 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807491 (* 1 = 0.00807491 loss)
I0312 06:46:31.936360 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.228251 (* 1 = 0.228251 loss)
I0312 06:46:31.936378 17663 sgd_solver.cpp:106] Iteration 52300, lr = 1e-08
I0312 06:47:23.632205 17663 solver.cpp:228] Iteration 52400, loss = 0.288
I0312 06:47:23.632227 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:47:23.632235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496524 (* 1 = 0.0496524 loss)
I0312 06:47:23.632254 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146629 (* 1 = 0.146629 loss)
I0312 06:47:23.632258 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467693 (* 1 = 0.00467693 loss)
I0312 06:47:23.632262 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107321 (* 1 = 0.107321 loss)
I0312 06:47:23.632267 17663 sgd_solver.cpp:106] Iteration 52400, lr = 1e-08
I0312 06:48:15.448002 17663 solver.cpp:228] Iteration 52500, loss = 0.269322
I0312 06:48:15.448026 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 06:48:15.448034 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0989753 (* 1 = 0.0989753 loss)
I0312 06:48:15.448052 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107584 (* 1 = 0.107584 loss)
I0312 06:48:15.448056 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018754 (* 1 = 0.018754 loss)
I0312 06:48:15.448060 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129995 (* 1 = 0.129995 loss)
I0312 06:48:15.448065 17663 sgd_solver.cpp:106] Iteration 52500, lr = 1e-08
I0312 06:49:07.987417 17663 solver.cpp:228] Iteration 52600, loss = 0.346959
I0312 06:49:07.987542 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 06:49:07.987586 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0823068 (* 1 = 0.0823068 loss)
I0312 06:49:07.987599 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100357 (* 1 = 0.100357 loss)
I0312 06:49:07.987610 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0339949 (* 1 = 0.0339949 loss)
I0312 06:49:07.987635 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0707132 (* 1 = 0.0707132 loss)
I0312 06:49:07.987648 17663 sgd_solver.cpp:106] Iteration 52600, lr = 1e-08
I0312 06:50:01.297379 17663 solver.cpp:228] Iteration 52700, loss = 0.60368
I0312 06:50:01.297400 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 06:50:01.297407 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956194 (* 1 = 0.0956194 loss)
I0312 06:50:01.297412 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.247943 (* 1 = 0.247943 loss)
I0312 06:50:01.297431 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107735 (* 1 = 0.0107735 loss)
I0312 06:50:01.297435 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0887474 (* 1 = 0.0887474 loss)
I0312 06:50:01.297441 17663 sgd_solver.cpp:106] Iteration 52700, lr = 1e-08
I0312 06:50:53.900423 17663 solver.cpp:228] Iteration 52800, loss = 0.444812
I0312 06:50:53.900460 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 06:50:53.900468 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.162455 (* 1 = 0.162455 loss)
I0312 06:50:53.900486 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.225629 (* 1 = 0.225629 loss)
I0312 06:50:53.900491 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163199 (* 1 = 0.0163199 loss)
I0312 06:50:53.900496 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0713496 (* 1 = 0.0713496 loss)
I0312 06:50:53.900501 17663 sgd_solver.cpp:106] Iteration 52800, lr = 1e-08
I0312 06:51:46.064415 17663 solver.cpp:228] Iteration 52900, loss = 0.453542
I0312 06:51:46.064436 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 06:51:46.064443 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708828 (* 1 = 0.0708828 loss)
I0312 06:51:46.064462 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.148886 (* 1 = 0.148886 loss)
I0312 06:51:46.064466 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111561 (* 1 = 0.0111561 loss)
I0312 06:51:46.064471 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102929 (* 1 = 0.102929 loss)
I0312 06:51:46.064488 17663 sgd_solver.cpp:106] Iteration 52900, lr = 1e-08
speed: 0.525s / iter
I0312 06:52:38.442826 17663 solver.cpp:228] Iteration 53000, loss = 0.205899
I0312 06:52:38.442966 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 06:52:38.443022 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274811 (* 1 = 0.0274811 loss)
I0312 06:52:38.443070 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137933 (* 1 = 0.137933 loss)
I0312 06:52:38.443117 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231185 (* 1 = 0.0231185 loss)
I0312 06:52:38.443164 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0952407 (* 1 = 0.0952407 loss)
I0312 06:52:38.443212 17663 sgd_solver.cpp:106] Iteration 53000, lr = 1e-08
I0312 06:53:31.413426 17663 solver.cpp:228] Iteration 53100, loss = 0.678457
I0312 06:53:31.413450 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 06:53:31.413456 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.259559 (* 1 = 0.259559 loss)
I0312 06:53:31.413475 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.424026 (* 1 = 0.424026 loss)
I0312 06:53:31.413480 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.084918 (* 1 = 0.084918 loss)
I0312 06:53:31.413483 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.251702 (* 1 = 0.251702 loss)
I0312 06:53:31.413489 17663 sgd_solver.cpp:106] Iteration 53100, lr = 1e-08
I0312 06:54:24.422227 17663 solver.cpp:228] Iteration 53200, loss = 0.23422
I0312 06:54:24.422250 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 06:54:24.422256 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270648 (* 1 = 0.0270648 loss)
I0312 06:54:24.422276 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.115718 (* 1 = 0.115718 loss)
I0312 06:54:24.422279 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00446215 (* 1 = 0.00446215 loss)
I0312 06:54:24.422298 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148898 (* 1 = 0.0148898 loss)
I0312 06:54:24.422303 17663 sgd_solver.cpp:106] Iteration 53200, lr = 1e-08
I0312 06:55:17.104624 17663 solver.cpp:228] Iteration 53300, loss = 0.563349
I0312 06:55:17.104660 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 06:55:17.104667 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.117157 (* 1 = 0.117157 loss)
I0312 06:55:17.104686 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.252905 (* 1 = 0.252905 loss)
I0312 06:55:17.104689 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0403021 (* 1 = 0.0403021 loss)
I0312 06:55:17.104693 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0822024 (* 1 = 0.0822024 loss)
I0312 06:55:17.104698 17663 sgd_solver.cpp:106] Iteration 53300, lr = 1e-08
I0312 06:56:09.584764 17663 solver.cpp:228] Iteration 53400, loss = 0.947194
I0312 06:56:09.584785 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0312 06:56:09.584792 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.437132 (* 1 = 0.437132 loss)
I0312 06:56:09.584811 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.670878 (* 1 = 0.670878 loss)
I0312 06:56:09.584815 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.226066 (* 1 = 0.226066 loss)
I0312 06:56:09.584820 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.444815 (* 1 = 0.444815 loss)
I0312 06:56:09.584823 17663 sgd_solver.cpp:106] Iteration 53400, lr = 1e-08
I0312 06:57:01.813616 17663 solver.cpp:228] Iteration 53500, loss = 0.583357
I0312 06:57:01.813827 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 06:57:01.813886 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0769575 (* 1 = 0.0769575 loss)
I0312 06:57:01.813947 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0793056 (* 1 = 0.0793056 loss)
I0312 06:57:01.813997 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271813 (* 1 = 0.0271813 loss)
I0312 06:57:01.814043 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.256449 (* 1 = 0.256449 loss)
I0312 06:57:01.814090 17663 sgd_solver.cpp:106] Iteration 53500, lr = 1e-08
I0312 06:57:54.695329 17663 solver.cpp:228] Iteration 53600, loss = 0.208183
I0312 06:57:54.695351 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 06:57:54.695358 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.019293 (* 1 = 0.019293 loss)
I0312 06:57:54.695377 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0601137 (* 1 = 0.0601137 loss)
I0312 06:57:54.695381 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106241 (* 1 = 0.0106241 loss)
I0312 06:57:54.695385 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00442282 (* 1 = 0.00442282 loss)
I0312 06:57:54.695390 17663 sgd_solver.cpp:106] Iteration 53600, lr = 1e-08
I0312 06:58:47.367429 17663 solver.cpp:228] Iteration 53700, loss = 0.335995
I0312 06:58:47.367451 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 06:58:47.367458 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0516772 (* 1 = 0.0516772 loss)
I0312 06:58:47.367462 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.158474 (* 1 = 0.158474 loss)
I0312 06:58:47.367481 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00928208 (* 1 = 0.00928208 loss)
I0312 06:58:47.367486 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0544475 (* 1 = 0.0544475 loss)
I0312 06:58:47.367491 17663 sgd_solver.cpp:106] Iteration 53700, lr = 1e-08
I0312 06:59:40.214246 17663 solver.cpp:228] Iteration 53800, loss = 0.141825
I0312 06:59:40.214268 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 06:59:40.214277 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142447 (* 1 = 0.0142447 loss)
I0312 06:59:40.214295 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0988345 (* 1 = 0.0988345 loss)
I0312 06:59:40.214299 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120449 (* 1 = 0.0120449 loss)
I0312 06:59:40.214304 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0734667 (* 1 = 0.0734667 loss)
I0312 06:59:40.214323 17663 sgd_solver.cpp:106] Iteration 53800, lr = 1e-08
I0312 07:00:31.867725 17663 solver.cpp:228] Iteration 53900, loss = 0.842528
I0312 07:00:31.867748 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 07:00:31.867755 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.113776 (* 1 = 0.113776 loss)
I0312 07:00:31.867774 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.226992 (* 1 = 0.226992 loss)
I0312 07:00:31.867779 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0850449 (* 1 = 0.0850449 loss)
I0312 07:00:31.867784 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0707995 (* 1 = 0.0707995 loss)
I0312 07:00:31.867789 17663 sgd_solver.cpp:106] Iteration 53900, lr = 1e-08
speed: 0.525s / iter
I0312 07:01:24.542024 17663 solver.cpp:228] Iteration 54000, loss = 0.431466
I0312 07:01:24.542225 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 07:01:24.542284 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.110357 (* 1 = 0.110357 loss)
I0312 07:01:24.542331 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.205532 (* 1 = 0.205532 loss)
I0312 07:01:24.542378 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0559989 (* 1 = 0.0559989 loss)
I0312 07:01:24.542425 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.217878 (* 1 = 0.217878 loss)
I0312 07:01:24.542472 17663 sgd_solver.cpp:106] Iteration 54000, lr = 1e-08
I0312 07:02:17.086236 17663 solver.cpp:228] Iteration 54100, loss = 0.466361
I0312 07:02:17.086258 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 07:02:17.086266 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.362014 (* 1 = 0.362014 loss)
I0312 07:02:17.086285 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.412272 (* 1 = 0.412272 loss)
I0312 07:02:17.086290 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165184 (* 1 = 0.0165184 loss)
I0312 07:02:17.086295 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219206 (* 1 = 0.0219206 loss)
I0312 07:02:17.086300 17663 sgd_solver.cpp:106] Iteration 54100, lr = 1e-08
I0312 07:03:09.246443 17663 solver.cpp:228] Iteration 54200, loss = 0.178465
I0312 07:03:09.246464 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:03:09.246471 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0534188 (* 1 = 0.0534188 loss)
I0312 07:03:09.246490 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0874364 (* 1 = 0.0874364 loss)
I0312 07:03:09.246495 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245638 (* 1 = 0.00245638 loss)
I0312 07:03:09.246500 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101752 (* 1 = 0.0101752 loss)
I0312 07:03:09.246505 17663 sgd_solver.cpp:106] Iteration 54200, lr = 1e-08
I0312 07:04:01.836042 17663 solver.cpp:228] Iteration 54300, loss = 0.885935
I0312 07:04:01.836064 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 07:04:01.836071 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.171283 (* 1 = 0.171283 loss)
I0312 07:04:01.836076 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.30757 (* 1 = 0.30757 loss)
I0312 07:04:01.836093 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00980825 (* 1 = 0.00980825 loss)
I0312 07:04:01.836098 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495106 (* 1 = 0.0495106 loss)
I0312 07:04:01.836103 17663 sgd_solver.cpp:106] Iteration 54300, lr = 1e-08
I0312 07:04:54.338316 17663 solver.cpp:228] Iteration 54400, loss = 0.326608
I0312 07:04:54.338340 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 07:04:54.338347 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0733041 (* 1 = 0.0733041 loss)
I0312 07:04:54.338366 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0864942 (* 1 = 0.0864942 loss)
I0312 07:04:54.338371 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109487 (* 1 = 0.00109487 loss)
I0312 07:04:54.338376 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018497 (* 1 = 0.018497 loss)
I0312 07:04:54.338380 17663 sgd_solver.cpp:106] Iteration 54400, lr = 1e-08
I0312 07:05:46.353153 17663 solver.cpp:228] Iteration 54500, loss = 0.448729
I0312 07:05:46.353176 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 07:05:46.353184 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.182996 (* 1 = 0.182996 loss)
I0312 07:05:46.353188 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.323329 (* 1 = 0.323329 loss)
I0312 07:05:46.353207 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00254969 (* 1 = 0.00254969 loss)
I0312 07:05:46.353212 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352586 (* 1 = 0.0352586 loss)
I0312 07:05:46.353217 17663 sgd_solver.cpp:106] Iteration 54500, lr = 1e-08
I0312 07:06:38.774783 17663 solver.cpp:228] Iteration 54600, loss = 0.173379
I0312 07:06:38.774806 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 07:06:38.774812 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235592 (* 1 = 0.0235592 loss)
I0312 07:06:38.774817 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.119475 (* 1 = 0.119475 loss)
I0312 07:06:38.774835 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276579 (* 1 = 0.0276579 loss)
I0312 07:06:38.774840 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0524381 (* 1 = 0.0524381 loss)
I0312 07:06:38.774845 17663 sgd_solver.cpp:106] Iteration 54600, lr = 1e-08
I0312 07:07:31.513326 17663 solver.cpp:228] Iteration 54700, loss = 0.313762
I0312 07:07:31.513350 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:07:31.513357 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.106652 (* 1 = 0.106652 loss)
I0312 07:07:31.513362 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.18277 (* 1 = 0.18277 loss)
I0312 07:07:31.513366 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034689 (* 1 = 0.0034689 loss)
I0312 07:07:31.513370 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343296 (* 1 = 0.0343296 loss)
I0312 07:07:31.513391 17663 sgd_solver.cpp:106] Iteration 54700, lr = 1e-08
I0312 07:08:23.645956 17663 solver.cpp:228] Iteration 54800, loss = 1.02785
I0312 07:08:23.645983 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:08:23.645990 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0227857 (* 1 = 0.0227857 loss)
I0312 07:08:23.646010 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0838358 (* 1 = 0.0838358 loss)
I0312 07:08:23.646015 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00952102 (* 1 = 0.00952102 loss)
I0312 07:08:23.646019 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00744143 (* 1 = 0.00744143 loss)
I0312 07:08:23.646024 17663 sgd_solver.cpp:106] Iteration 54800, lr = 1e-08
I0312 07:09:15.907829 17663 solver.cpp:228] Iteration 54900, loss = 0.459225
I0312 07:09:15.907850 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:09:15.907856 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0876034 (* 1 = 0.0876034 loss)
I0312 07:09:15.907876 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.153259 (* 1 = 0.153259 loss)
I0312 07:09:15.907881 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011475 (* 1 = 0.011475 loss)
I0312 07:09:15.907884 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335397 (* 1 = 0.0335397 loss)
I0312 07:09:15.907888 17663 sgd_solver.cpp:106] Iteration 54900, lr = 1e-08
speed: 0.525s / iter
I0312 07:10:08.869941 17663 solver.cpp:228] Iteration 55000, loss = 1.16339
I0312 07:10:08.870144 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 07:10:08.870205 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937873 (* 1 = 0.0937873 loss)
I0312 07:10:08.870254 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.128433 (* 1 = 0.128433 loss)
I0312 07:10:08.870301 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.065874 (* 1 = 0.065874 loss)
I0312 07:10:08.870362 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.503844 (* 1 = 0.503844 loss)
I0312 07:10:08.870411 17663 sgd_solver.cpp:106] Iteration 55000, lr = 1e-08
I0312 07:11:01.429256 17663 solver.cpp:228] Iteration 55100, loss = 0.489529
I0312 07:11:01.429280 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 07:11:01.429287 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0915877 (* 1 = 0.0915877 loss)
I0312 07:11:01.429306 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219076 (* 1 = 0.219076 loss)
I0312 07:11:01.429311 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00940615 (* 1 = 0.00940615 loss)
I0312 07:11:01.429314 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176344 (* 1 = 0.0176344 loss)
I0312 07:11:01.429319 17663 sgd_solver.cpp:106] Iteration 55100, lr = 1e-08
I0312 07:11:53.412072 17663 solver.cpp:228] Iteration 55200, loss = 0.286159
I0312 07:11:53.412094 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 07:11:53.412102 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.029335 (* 1 = 0.029335 loss)
I0312 07:11:53.412107 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103593 (* 1 = 0.103593 loss)
I0312 07:11:53.412125 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112445 (* 1 = 0.0112445 loss)
I0312 07:11:53.412129 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473017 (* 1 = 0.0473017 loss)
I0312 07:11:53.412134 17663 sgd_solver.cpp:106] Iteration 55200, lr = 1e-08
I0312 07:12:45.959892 17663 solver.cpp:228] Iteration 55300, loss = 0.139627
I0312 07:12:45.959916 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 07:12:45.959923 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475802 (* 1 = 0.0475802 loss)
I0312 07:12:45.959944 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.08996 (* 1 = 0.08996 loss)
I0312 07:12:45.959947 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00387954 (* 1 = 0.00387954 loss)
I0312 07:12:45.959951 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00394795 (* 1 = 0.00394795 loss)
I0312 07:12:45.959969 17663 sgd_solver.cpp:106] Iteration 55300, lr = 1e-08
I0312 07:13:37.954879 17663 solver.cpp:228] Iteration 55400, loss = 0.190932
I0312 07:13:37.954900 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:13:37.954907 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360575 (* 1 = 0.0360575 loss)
I0312 07:13:37.954912 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0277957 (* 1 = 0.0277957 loss)
I0312 07:13:37.954931 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00722156 (* 1 = 0.00722156 loss)
I0312 07:13:37.954934 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216404 (* 1 = 0.0216404 loss)
I0312 07:13:37.954941 17663 sgd_solver.cpp:106] Iteration 55400, lr = 1e-08
I0312 07:14:30.179867 17663 solver.cpp:228] Iteration 55500, loss = 0.214547
I0312 07:14:30.179891 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:14:30.179898 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0404044 (* 1 = 0.0404044 loss)
I0312 07:14:30.179917 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.214272 (* 1 = 0.214272 loss)
I0312 07:14:30.179922 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00460538 (* 1 = 0.00460538 loss)
I0312 07:14:30.179926 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111907 (* 1 = 0.0111907 loss)
I0312 07:14:30.179931 17663 sgd_solver.cpp:106] Iteration 55500, lr = 1e-08
I0312 07:15:22.294616 17663 solver.cpp:228] Iteration 55600, loss = 0.164259
I0312 07:15:22.294641 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:15:22.294647 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239798 (* 1 = 0.0239798 loss)
I0312 07:15:22.294667 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.115686 (* 1 = 0.115686 loss)
I0312 07:15:22.294672 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427515 (* 1 = 0.00427515 loss)
I0312 07:15:22.294688 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103289 (* 1 = 0.103289 loss)
I0312 07:15:22.294693 17663 sgd_solver.cpp:106] Iteration 55600, lr = 1e-08
I0312 07:16:14.456285 17663 solver.cpp:228] Iteration 55700, loss = 0.695517
I0312 07:16:14.456307 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0312 07:16:14.456315 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.391771 (* 1 = 0.391771 loss)
I0312 07:16:14.456320 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.552653 (* 1 = 0.552653 loss)
I0312 07:16:14.456337 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.036637 (* 1 = 0.036637 loss)
I0312 07:16:14.456341 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.182205 (* 1 = 0.182205 loss)
I0312 07:16:14.456347 17663 sgd_solver.cpp:106] Iteration 55700, lr = 1e-08
I0312 07:17:06.913027 17663 solver.cpp:228] Iteration 55800, loss = 0.211361
I0312 07:17:06.913049 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 07:17:06.913058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0948833 (* 1 = 0.0948833 loss)
I0312 07:17:06.913077 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.132111 (* 1 = 0.132111 loss)
I0312 07:17:06.913081 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100037 (* 1 = 0.0100037 loss)
I0312 07:17:06.913085 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472004 (* 1 = 0.0472004 loss)
I0312 07:17:06.913090 17663 sgd_solver.cpp:106] Iteration 55800, lr = 1e-08
I0312 07:17:58.815937 17663 solver.cpp:228] Iteration 55900, loss = 0.547377
I0312 07:17:58.815958 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:17:58.815965 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142819 (* 1 = 0.142819 loss)
I0312 07:17:58.815984 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.256153 (* 1 = 0.256153 loss)
I0312 07:17:58.815989 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187006 (* 1 = 0.0187006 loss)
I0312 07:17:58.815992 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438885 (* 1 = 0.0438885 loss)
I0312 07:17:58.815999 17663 sgd_solver.cpp:106] Iteration 55900, lr = 1e-08
speed: 0.525s / iter
I0312 07:18:51.238323 17663 solver.cpp:228] Iteration 56000, loss = 0.175836
I0312 07:18:51.238473 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:18:51.238533 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107895 (* 1 = 0.0107895 loss)
I0312 07:18:51.238579 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0297816 (* 1 = 0.0297816 loss)
I0312 07:18:51.238626 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00509087 (* 1 = 0.00509087 loss)
I0312 07:18:51.238673 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302433 (* 1 = 0.0302433 loss)
I0312 07:18:51.238719 17663 sgd_solver.cpp:106] Iteration 56000, lr = 1e-08
I0312 07:19:44.275229 17663 solver.cpp:228] Iteration 56100, loss = 0.280632
I0312 07:19:44.275252 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:19:44.275259 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462699 (* 1 = 0.0462699 loss)
I0312 07:19:44.275279 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0855971 (* 1 = 0.0855971 loss)
I0312 07:19:44.275282 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245446 (* 1 = 0.0245446 loss)
I0312 07:19:44.275286 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0905365 (* 1 = 0.0905365 loss)
I0312 07:19:44.275291 17663 sgd_solver.cpp:106] Iteration 56100, lr = 1e-08
I0312 07:20:37.239481 17663 solver.cpp:228] Iteration 56200, loss = 0.408852
I0312 07:20:37.239502 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 07:20:37.239511 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442082 (* 1 = 0.0442082 loss)
I0312 07:20:37.239529 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.162661 (* 1 = 0.162661 loss)
I0312 07:20:37.239533 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210239 (* 1 = 0.0210239 loss)
I0312 07:20:37.239550 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0614407 (* 1 = 0.0614407 loss)
I0312 07:20:37.239555 17663 sgd_solver.cpp:106] Iteration 56200, lr = 1e-08
I0312 07:21:29.496498 17663 solver.cpp:228] Iteration 56300, loss = 0.356556
I0312 07:21:29.496521 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 07:21:29.496528 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13472 (* 1 = 0.13472 loss)
I0312 07:21:29.496548 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.223834 (* 1 = 0.223834 loss)
I0312 07:21:29.496552 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112639 (* 1 = 0.0112639 loss)
I0312 07:21:29.496556 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129468 (* 1 = 0.129468 loss)
I0312 07:21:29.496562 17663 sgd_solver.cpp:106] Iteration 56300, lr = 1e-08
I0312 07:22:21.523149 17663 solver.cpp:228] Iteration 56400, loss = 0.137102
I0312 07:22:21.523171 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 07:22:21.523178 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384011 (* 1 = 0.0384011 loss)
I0312 07:22:21.523198 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0688559 (* 1 = 0.0688559 loss)
I0312 07:22:21.523202 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00849137 (* 1 = 0.00849137 loss)
I0312 07:22:21.523207 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683844 (* 1 = 0.0683844 loss)
I0312 07:22:21.523212 17663 sgd_solver.cpp:106] Iteration 56400, lr = 1e-08
I0312 07:23:13.631902 17663 solver.cpp:228] Iteration 56500, loss = 0.583679
I0312 07:23:13.631927 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 07:23:13.631934 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.170596 (* 1 = 0.170596 loss)
I0312 07:23:13.631953 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.59379 (* 1 = 0.59379 loss)
I0312 07:23:13.631958 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.139661 (* 1 = 0.139661 loss)
I0312 07:23:13.631961 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.147613 (* 1 = 0.147613 loss)
I0312 07:23:13.631979 17663 sgd_solver.cpp:106] Iteration 56500, lr = 1e-08
I0312 07:24:06.055217 17663 solver.cpp:228] Iteration 56600, loss = 0.442725
I0312 07:24:06.055239 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 07:24:06.055246 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229995 (* 1 = 0.0229995 loss)
I0312 07:24:06.055251 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161531 (* 1 = 0.161531 loss)
I0312 07:24:06.055269 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.081838 (* 1 = 0.081838 loss)
I0312 07:24:06.055274 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121112 (* 1 = 0.121112 loss)
I0312 07:24:06.055291 17663 sgd_solver.cpp:106] Iteration 56600, lr = 1e-08
I0312 07:24:58.586370 17663 solver.cpp:228] Iteration 56700, loss = 0.487079
I0312 07:24:58.586392 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 07:24:58.586400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.304146 (* 1 = 0.304146 loss)
I0312 07:24:58.586403 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.397305 (* 1 = 0.397305 loss)
I0312 07:24:58.586422 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155549 (* 1 = 0.0155549 loss)
I0312 07:24:58.586426 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134395 (* 1 = 0.134395 loss)
I0312 07:24:58.586431 17663 sgd_solver.cpp:106] Iteration 56700, lr = 1e-08
I0312 07:25:51.636083 17663 solver.cpp:228] Iteration 56800, loss = 0.287424
I0312 07:25:51.636106 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 07:25:51.636114 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0813635 (* 1 = 0.0813635 loss)
I0312 07:25:51.636133 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.164277 (* 1 = 0.164277 loss)
I0312 07:25:51.636137 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00572509 (* 1 = 0.00572509 loss)
I0312 07:25:51.636142 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270601 (* 1 = 0.0270601 loss)
I0312 07:25:51.636147 17663 sgd_solver.cpp:106] Iteration 56800, lr = 1e-08
I0312 07:26:44.207550 17663 solver.cpp:228] Iteration 56900, loss = 0.432559
I0312 07:26:44.207571 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 07:26:44.207577 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357919 (* 1 = 0.0357919 loss)
I0312 07:26:44.207597 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0336797 (* 1 = 0.0336797 loss)
I0312 07:26:44.207600 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218006 (* 1 = 0.0218006 loss)
I0312 07:26:44.207605 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866219 (* 1 = 0.00866219 loss)
I0312 07:26:44.207609 17663 sgd_solver.cpp:106] Iteration 56900, lr = 1e-08
speed: 0.525s / iter
I0312 07:27:36.706835 17663 solver.cpp:228] Iteration 57000, loss = 0.444275
I0312 07:27:36.707022 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:27:36.707082 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274346 (* 1 = 0.0274346 loss)
I0312 07:27:36.707130 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0830022 (* 1 = 0.0830022 loss)
I0312 07:27:36.707168 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213188 (* 1 = 0.0213188 loss)
I0312 07:27:36.707176 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.163165 (* 1 = 0.163165 loss)
I0312 07:27:36.707182 17663 sgd_solver.cpp:106] Iteration 57000, lr = 1e-08
I0312 07:28:29.425366 17663 solver.cpp:228] Iteration 57100, loss = 0.389435
I0312 07:28:29.425388 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 07:28:29.425395 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527959 (* 1 = 0.0527959 loss)
I0312 07:28:29.425400 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0998932 (* 1 = 0.0998932 loss)
I0312 07:28:29.425418 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202703 (* 1 = 0.0202703 loss)
I0312 07:28:29.425422 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.142471 (* 1 = 0.142471 loss)
I0312 07:28:29.425427 17663 sgd_solver.cpp:106] Iteration 57100, lr = 1e-08
I0312 07:29:22.473459 17663 solver.cpp:228] Iteration 57200, loss = 0.304914
I0312 07:29:22.473480 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:29:22.473489 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.000533967 (* 1 = 0.000533967 loss)
I0312 07:29:22.473492 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.00699888 (* 1 = 0.00699888 loss)
I0312 07:29:22.473511 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189156 (* 1 = 0.0189156 loss)
I0312 07:29:22.473515 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.342586 (* 1 = 0.342586 loss)
I0312 07:29:22.473520 17663 sgd_solver.cpp:106] Iteration 57200, lr = 1e-08
I0312 07:30:14.231921 17663 solver.cpp:228] Iteration 57300, loss = 0.852938
I0312 07:30:14.231942 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 07:30:14.231950 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.19935 (* 1 = 0.19935 loss)
I0312 07:30:14.231968 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.338314 (* 1 = 0.338314 loss)
I0312 07:30:14.231972 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0532385 (* 1 = 0.0532385 loss)
I0312 07:30:14.231976 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.203813 (* 1 = 0.203813 loss)
I0312 07:30:14.231982 17663 sgd_solver.cpp:106] Iteration 57300, lr = 1e-08
I0312 07:31:07.200945 17663 solver.cpp:228] Iteration 57400, loss = 0.879957
I0312 07:31:07.200966 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 07:31:07.200973 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.167985 (* 1 = 0.167985 loss)
I0312 07:31:07.200978 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.171785 (* 1 = 0.171785 loss)
I0312 07:31:07.200997 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0947636 (* 1 = 0.0947636 loss)
I0312 07:31:07.201001 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.380401 (* 1 = 0.380401 loss)
I0312 07:31:07.201006 17663 sgd_solver.cpp:106] Iteration 57400, lr = 1e-08
I0312 07:31:59.128962 17663 solver.cpp:228] Iteration 57500, loss = 0.269442
I0312 07:31:59.128985 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 07:31:59.128993 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.109155 (* 1 = 0.109155 loss)
I0312 07:31:59.128998 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.250851 (* 1 = 0.250851 loss)
I0312 07:31:59.129001 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073178 (* 1 = 0.0073178 loss)
I0312 07:31:59.129006 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300155 (* 1 = 0.0300155 loss)
I0312 07:31:59.129025 17663 sgd_solver.cpp:106] Iteration 57500, lr = 1e-08
I0312 07:32:51.227669 17663 solver.cpp:228] Iteration 57600, loss = 0.224171
I0312 07:32:51.227692 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:32:51.227700 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268341 (* 1 = 0.0268341 loss)
I0312 07:32:51.227720 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102139 (* 1 = 0.102139 loss)
I0312 07:32:51.227723 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00464419 (* 1 = 0.00464419 loss)
I0312 07:32:51.227727 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272879 (* 1 = 0.0272879 loss)
I0312 07:32:51.227733 17663 sgd_solver.cpp:106] Iteration 57600, lr = 1e-08
I0312 07:33:43.454231 17663 solver.cpp:228] Iteration 57700, loss = 0.161165
I0312 07:33:43.454252 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 07:33:43.454258 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0208901 (* 1 = 0.0208901 loss)
I0312 07:33:43.454277 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0910086 (* 1 = 0.0910086 loss)
I0312 07:33:43.454282 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00979356 (* 1 = 0.00979356 loss)
I0312 07:33:43.454285 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179665 (* 1 = 0.0179665 loss)
I0312 07:33:43.454303 17663 sgd_solver.cpp:106] Iteration 57700, lr = 1e-08
I0312 07:34:36.303443 17663 solver.cpp:228] Iteration 57800, loss = 0.536618
I0312 07:34:36.303467 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:34:36.303473 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.149473 (* 1 = 0.149473 loss)
I0312 07:34:36.303493 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.31893 (* 1 = 0.31893 loss)
I0312 07:34:36.303498 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0520006 (* 1 = 0.0520006 loss)
I0312 07:34:36.303503 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115088 (* 1 = 0.115088 loss)
I0312 07:34:36.303508 17663 sgd_solver.cpp:106] Iteration 57800, lr = 1e-08
I0312 07:35:28.662371 17663 solver.cpp:228] Iteration 57900, loss = 0.492381
I0312 07:35:28.662392 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 07:35:28.662400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.014726 (* 1 = 0.014726 loss)
I0312 07:35:28.662418 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0928689 (* 1 = 0.0928689 loss)
I0312 07:35:28.662422 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152871 (* 1 = 0.0152871 loss)
I0312 07:35:28.662439 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0656537 (* 1 = 0.0656537 loss)
I0312 07:35:28.662444 17663 sgd_solver.cpp:106] Iteration 57900, lr = 1e-08
speed: 0.525s / iter
I0312 07:36:21.139358 17663 solver.cpp:228] Iteration 58000, loss = 0.360715
I0312 07:36:21.139484 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:36:21.139539 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119374 (* 1 = 0.119374 loss)
I0312 07:36:21.139588 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.209884 (* 1 = 0.209884 loss)
I0312 07:36:21.139636 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0486142 (* 1 = 0.0486142 loss)
I0312 07:36:21.139683 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.174737 (* 1 = 0.174737 loss)
I0312 07:36:21.139729 17663 sgd_solver.cpp:106] Iteration 58000, lr = 1e-08
I0312 07:37:13.667330 17663 solver.cpp:228] Iteration 58100, loss = 0.410885
I0312 07:37:13.667354 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:37:13.667362 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.168433 (* 1 = 0.168433 loss)
I0312 07:37:13.667381 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.239268 (* 1 = 0.239268 loss)
I0312 07:37:13.667387 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150751 (* 1 = 0.0150751 loss)
I0312 07:37:13.667402 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0389839 (* 1 = 0.0389839 loss)
I0312 07:37:13.667407 17663 sgd_solver.cpp:106] Iteration 58100, lr = 1e-08
I0312 07:38:05.965492 17663 solver.cpp:228] Iteration 58200, loss = 0.195129
I0312 07:38:05.965514 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 07:38:05.965521 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544719 (* 1 = 0.0544719 loss)
I0312 07:38:05.965526 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.191417 (* 1 = 0.191417 loss)
I0312 07:38:05.965544 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00627285 (* 1 = 0.00627285 loss)
I0312 07:38:05.965549 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229688 (* 1 = 0.0229688 loss)
I0312 07:38:05.965553 17663 sgd_solver.cpp:106] Iteration 58200, lr = 1e-08
I0312 07:38:58.231566 17663 solver.cpp:228] Iteration 58300, loss = 0.504434
I0312 07:38:58.231590 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 07:38:58.231596 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383201 (* 1 = 0.0383201 loss)
I0312 07:38:58.231616 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0319244 (* 1 = 0.0319244 loss)
I0312 07:38:58.231621 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155776 (* 1 = 0.0155776 loss)
I0312 07:38:58.231624 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.057337 (* 1 = 0.057337 loss)
I0312 07:38:58.231642 17663 sgd_solver.cpp:106] Iteration 58300, lr = 1e-08
I0312 07:39:50.625950 17663 solver.cpp:228] Iteration 58400, loss = 0.652144
I0312 07:39:50.625972 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:39:50.625979 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.151641 (* 1 = 0.151641 loss)
I0312 07:39:50.625998 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.254806 (* 1 = 0.254806 loss)
I0312 07:39:50.626003 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0864617 (* 1 = 0.0864617 loss)
I0312 07:39:50.626006 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.252687 (* 1 = 0.252687 loss)
I0312 07:39:50.626011 17663 sgd_solver.cpp:106] Iteration 58400, lr = 1e-08
I0312 07:40:43.037922 17663 solver.cpp:228] Iteration 58500, loss = 0.617734
I0312 07:40:43.037958 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0312 07:40:43.037978 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.240589 (* 1 = 0.240589 loss)
I0312 07:40:43.037983 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.426555 (* 1 = 0.426555 loss)
I0312 07:40:43.038002 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.224258 (* 1 = 0.224258 loss)
I0312 07:40:43.038004 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.222773 (* 1 = 0.222773 loss)
I0312 07:40:43.038024 17663 sgd_solver.cpp:106] Iteration 58500, lr = 1e-08
I0312 07:41:35.186036 17663 solver.cpp:228] Iteration 58600, loss = 0.468067
I0312 07:41:35.186058 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:41:35.186065 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0615371 (* 1 = 0.0615371 loss)
I0312 07:41:35.186084 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.212334 (* 1 = 0.212334 loss)
I0312 07:41:35.186089 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484591 (* 1 = 0.00484591 loss)
I0312 07:41:35.186092 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0736648 (* 1 = 0.0736648 loss)
I0312 07:41:35.186110 17663 sgd_solver.cpp:106] Iteration 58600, lr = 1e-08
I0312 07:42:28.321241 17663 solver.cpp:228] Iteration 58700, loss = 0.374315
I0312 07:42:28.321262 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 07:42:28.321269 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729772 (* 1 = 0.0729772 loss)
I0312 07:42:28.321288 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13183 (* 1 = 0.13183 loss)
I0312 07:42:28.321292 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205304 (* 1 = 0.0205304 loss)
I0312 07:42:28.321296 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.20464 (* 1 = 0.20464 loss)
I0312 07:42:28.321300 17663 sgd_solver.cpp:106] Iteration 58700, lr = 1e-08
I0312 07:43:20.597837 17663 solver.cpp:228] Iteration 58800, loss = 0.294057
I0312 07:43:20.597976 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 07:43:20.598031 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.114486 (* 1 = 0.114486 loss)
I0312 07:43:20.598078 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106721 (* 1 = 0.106721 loss)
I0312 07:43:20.598124 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188429 (* 1 = 0.0188429 loss)
I0312 07:43:20.598170 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108825 (* 1 = 0.108825 loss)
I0312 07:43:20.598215 17663 sgd_solver.cpp:106] Iteration 58800, lr = 1e-08
I0312 07:44:12.997154 17663 solver.cpp:228] Iteration 58900, loss = 0.308793
I0312 07:44:12.997177 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 07:44:12.997184 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.127754 (* 1 = 0.127754 loss)
I0312 07:44:12.997203 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.298012 (* 1 = 0.298012 loss)
I0312 07:44:12.997207 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00962983 (* 1 = 0.00962983 loss)
I0312 07:44:12.997211 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00828917 (* 1 = 0.00828917 loss)
I0312 07:44:12.997216 17663 sgd_solver.cpp:106] Iteration 58900, lr = 1e-08
speed: 0.525s / iter
I0312 07:45:05.471380 17663 solver.cpp:228] Iteration 59000, loss = 0.187899
I0312 07:45:05.471405 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 07:45:05.471412 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509498 (* 1 = 0.0509498 loss)
I0312 07:45:05.471431 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105125 (* 1 = 0.105125 loss)
I0312 07:45:05.471436 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00812421 (* 1 = 0.00812421 loss)
I0312 07:45:05.471441 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.004331 (* 1 = 0.004331 loss)
I0312 07:45:05.471446 17663 sgd_solver.cpp:106] Iteration 59000, lr = 1e-08
I0312 07:45:57.820065 17663 solver.cpp:228] Iteration 59100, loss = 0.472206
I0312 07:45:57.820087 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 07:45:57.820094 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0577913 (* 1 = 0.0577913 loss)
I0312 07:45:57.820099 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0860799 (* 1 = 0.0860799 loss)
I0312 07:45:57.820103 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0461644 (* 1 = 0.0461644 loss)
I0312 07:45:57.820107 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040287 (* 1 = 0.040287 loss)
I0312 07:45:57.820112 17663 sgd_solver.cpp:106] Iteration 59100, lr = 1e-08
I0312 07:46:49.738838 17663 solver.cpp:228] Iteration 59200, loss = 0.225933
I0312 07:46:49.738859 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:46:49.738867 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203136 (* 1 = 0.0203136 loss)
I0312 07:46:49.738885 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0324493 (* 1 = 0.0324493 loss)
I0312 07:46:49.738889 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129658 (* 1 = 0.0129658 loss)
I0312 07:46:49.738893 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131994 (* 1 = 0.0131994 loss)
I0312 07:46:49.738898 17663 sgd_solver.cpp:106] Iteration 59200, lr = 1e-08
I0312 07:47:42.520112 17663 solver.cpp:228] Iteration 59300, loss = 0.292758
I0312 07:47:42.520133 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 07:47:42.520140 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0495613 (* 1 = 0.0495613 loss)
I0312 07:47:42.520144 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.255416 (* 1 = 0.255416 loss)
I0312 07:47:42.520164 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02556 (* 1 = 0.02556 loss)
I0312 07:47:42.520169 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.092043 (* 1 = 0.092043 loss)
I0312 07:47:42.520174 17663 sgd_solver.cpp:106] Iteration 59300, lr = 1e-08
I0312 07:48:34.951261 17663 solver.cpp:228] Iteration 59400, loss = 0.672813
I0312 07:48:34.951283 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:48:34.951290 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0603835 (* 1 = 0.0603835 loss)
I0312 07:48:34.951309 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0325165 (* 1 = 0.0325165 loss)
I0312 07:48:34.951313 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00536213 (* 1 = 0.00536213 loss)
I0312 07:48:34.951318 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.242274 (* 1 = 0.242274 loss)
I0312 07:48:34.951323 17663 sgd_solver.cpp:106] Iteration 59400, lr = 1e-08
I0312 07:49:26.977589 17663 solver.cpp:228] Iteration 59500, loss = 0.268349
I0312 07:49:26.977612 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 07:49:26.977618 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219141 (* 1 = 0.0219141 loss)
I0312 07:49:26.977638 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135224 (* 1 = 0.135224 loss)
I0312 07:49:26.977643 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132893 (* 1 = 0.0132893 loss)
I0312 07:49:26.977646 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532174 (* 1 = 0.0532174 loss)
I0312 07:49:26.977664 17663 sgd_solver.cpp:106] Iteration 59500, lr = 1e-08
I0312 07:50:19.793361 17663 solver.cpp:228] Iteration 59600, loss = 0.497702
I0312 07:50:19.793383 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 07:50:19.793390 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0801154 (* 1 = 0.0801154 loss)
I0312 07:50:19.793409 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.164984 (* 1 = 0.164984 loss)
I0312 07:50:19.793413 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0607629 (* 1 = 0.0607629 loss)
I0312 07:50:19.793431 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.512819 (* 1 = 0.512819 loss)
I0312 07:50:19.793435 17663 sgd_solver.cpp:106] Iteration 59600, lr = 1e-08
I0312 07:51:12.569524 17663 solver.cpp:228] Iteration 59700, loss = 0.129237
I0312 07:51:12.569730 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:51:12.569790 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.04279 (* 1 = 0.04279 loss)
I0312 07:51:12.569856 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0380339 (* 1 = 0.0380339 loss)
I0312 07:51:12.569921 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00324663 (* 1 = 0.00324663 loss)
I0312 07:51:12.569968 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024025 (* 1 = 0.024025 loss)
I0312 07:51:12.570015 17663 sgd_solver.cpp:106] Iteration 59700, lr = 1e-08
I0312 07:52:05.018676 17663 solver.cpp:228] Iteration 59800, loss = 0.242238
I0312 07:52:05.018707 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 07:52:05.018714 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0846488 (* 1 = 0.0846488 loss)
I0312 07:52:05.018719 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.209121 (* 1 = 0.209121 loss)
I0312 07:52:05.018724 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039499 (* 1 = 0.039499 loss)
I0312 07:52:05.018728 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430963 (* 1 = 0.0430963 loss)
I0312 07:52:05.018733 17663 sgd_solver.cpp:106] Iteration 59800, lr = 1e-08
I0312 07:52:57.422111 17663 solver.cpp:228] Iteration 59900, loss = 0.199365
I0312 07:52:57.422132 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 07:52:57.422139 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174921 (* 1 = 0.0174921 loss)
I0312 07:52:57.422158 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0850838 (* 1 = 0.0850838 loss)
I0312 07:52:57.422163 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116898 (* 1 = 0.0116898 loss)
I0312 07:52:57.422166 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308101 (* 1 = 0.0308101 loss)
I0312 07:52:57.422184 17663 sgd_solver.cpp:106] Iteration 59900, lr = 1e-08
I0312 07:53:49.850920 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_60000.caffemodel
I0312 07:53:50.232324 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_60000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_60000.caffemodel
I0312 07:53:51.346369 17663 solver.cpp:228] Iteration 60000, loss = 0.479079
I0312 07:53:51.346393 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 07:53:51.346400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.196422 (* 1 = 0.196422 loss)
I0312 07:53:51.346405 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.367731 (* 1 = 0.367731 loss)
I0312 07:53:51.346424 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119402 (* 1 = 0.0119402 loss)
I0312 07:53:51.346428 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.14739 (* 1 = 0.14739 loss)
I0312 07:53:51.346433 17663 sgd_solver.cpp:106] Iteration 60000, lr = 1e-09
I0312 07:54:43.346854 17663 solver.cpp:228] Iteration 60100, loss = 0.363271
I0312 07:54:43.346877 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:54:43.346885 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599402 (* 1 = 0.0599402 loss)
I0312 07:54:43.346904 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.2028 (* 1 = 0.2028 loss)
I0312 07:54:43.346909 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119096 (* 1 = 0.0119096 loss)
I0312 07:54:43.346926 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334105 (* 1 = 0.0334105 loss)
I0312 07:54:43.346931 17663 sgd_solver.cpp:106] Iteration 60100, lr = 1e-09
I0312 07:55:36.053656 17663 solver.cpp:228] Iteration 60200, loss = 0.372797
I0312 07:55:36.053678 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:55:36.053686 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0917161 (* 1 = 0.0917161 loss)
I0312 07:55:36.053691 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.176368 (* 1 = 0.176368 loss)
I0312 07:55:36.053695 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139596 (* 1 = 0.0139596 loss)
I0312 07:55:36.053699 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105763 (* 1 = 0.105763 loss)
I0312 07:55:36.053719 17663 sgd_solver.cpp:106] Iteration 60200, lr = 1e-09
I0312 07:56:29.156436 17663 solver.cpp:228] Iteration 60300, loss = 0.108751
I0312 07:56:29.156460 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 07:56:29.156466 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264794 (* 1 = 0.0264794 loss)
I0312 07:56:29.156486 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0538767 (* 1 = 0.0538767 loss)
I0312 07:56:29.156491 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117036 (* 1 = 0.0117036 loss)
I0312 07:56:29.156494 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137833 (* 1 = 0.0137833 loss)
I0312 07:56:29.156499 17663 sgd_solver.cpp:106] Iteration 60300, lr = 1e-09
I0312 07:57:22.281603 17663 solver.cpp:228] Iteration 60400, loss = 0.323528
I0312 07:57:22.281625 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 07:57:22.281633 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387402 (* 1 = 0.0387402 loss)
I0312 07:57:22.281652 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.109111 (* 1 = 0.109111 loss)
I0312 07:57:22.281656 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016514 (* 1 = 0.0016514 loss)
I0312 07:57:22.281661 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00604884 (* 1 = 0.00604884 loss)
I0312 07:57:22.281666 17663 sgd_solver.cpp:106] Iteration 60400, lr = 1e-09
I0312 07:58:14.583150 17663 solver.cpp:228] Iteration 60500, loss = 0.434165
I0312 07:58:14.583171 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 07:58:14.583178 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.104927 (* 1 = 0.104927 loss)
I0312 07:58:14.583197 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183391 (* 1 = 0.183391 loss)
I0312 07:58:14.583201 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147945 (* 1 = 0.0147945 loss)
I0312 07:58:14.583205 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0522169 (* 1 = 0.0522169 loss)
I0312 07:58:14.583210 17663 sgd_solver.cpp:106] Iteration 60500, lr = 1e-09
I0312 07:59:06.431818 17663 solver.cpp:228] Iteration 60600, loss = 0.472238
I0312 07:59:06.431841 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0312 07:59:06.431849 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.203164 (* 1 = 0.203164 loss)
I0312 07:59:06.431854 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.499039 (* 1 = 0.499039 loss)
I0312 07:59:06.431859 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989118 (* 1 = 0.00989118 loss)
I0312 07:59:06.431862 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0655195 (* 1 = 0.0655195 loss)
I0312 07:59:06.431881 17663 sgd_solver.cpp:106] Iteration 60600, lr = 1e-09
I0312 07:59:58.565800 17663 solver.cpp:228] Iteration 60700, loss = 0.24089
I0312 07:59:58.565822 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 07:59:58.565829 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696613 (* 1 = 0.0696613 loss)
I0312 07:59:58.565848 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125547 (* 1 = 0.125547 loss)
I0312 07:59:58.565852 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00679703 (* 1 = 0.00679703 loss)
I0312 07:59:58.565857 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169919 (* 1 = 0.0169919 loss)
I0312 07:59:58.565876 17663 sgd_solver.cpp:106] Iteration 60700, lr = 1e-09
I0312 08:00:51.109700 17663 solver.cpp:228] Iteration 60800, loss = 0.419548
I0312 08:00:51.109721 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 08:00:51.109730 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.281428 (* 1 = 0.281428 loss)
I0312 08:00:51.109748 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.318836 (* 1 = 0.318836 loss)
I0312 08:00:51.109752 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0426992 (* 1 = 0.0426992 loss)
I0312 08:00:51.109756 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.070667 (* 1 = 0.070667 loss)
I0312 08:00:51.109761 17663 sgd_solver.cpp:106] Iteration 60800, lr = 1e-09
I0312 08:01:43.857928 17663 solver.cpp:228] Iteration 60900, loss = 0.315807
I0312 08:01:43.857949 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 08:01:43.857956 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0645738 (* 1 = 0.0645738 loss)
I0312 08:01:43.857975 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165351 (* 1 = 0.165351 loss)
I0312 08:01:43.857980 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128036 (* 1 = 0.0128036 loss)
I0312 08:01:43.857983 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11996 (* 1 = 0.11996 loss)
I0312 08:01:43.857990 17663 sgd_solver.cpp:106] Iteration 60900, lr = 1e-09
speed: 0.525s / iter
I0312 08:02:36.969722 17663 solver.cpp:228] Iteration 61000, loss = 0.177202
I0312 08:02:36.969744 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 08:02:36.969751 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.031069 (* 1 = 0.031069 loss)
I0312 08:02:36.969770 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147508 (* 1 = 0.147508 loss)
I0312 08:02:36.969774 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0225692 (* 1 = 0.0225692 loss)
I0312 08:02:36.969779 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0689796 (* 1 = 0.0689796 loss)
I0312 08:02:36.969784 17663 sgd_solver.cpp:106] Iteration 61000, lr = 1e-09
I0312 08:03:28.965651 17663 solver.cpp:228] Iteration 61100, loss = 0.524448
I0312 08:03:28.965672 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:03:28.965679 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.156304 (* 1 = 0.156304 loss)
I0312 08:03:28.965684 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149853 (* 1 = 0.149853 loss)
I0312 08:03:28.965703 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.025243 (* 1 = 0.025243 loss)
I0312 08:03:28.965706 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.227791 (* 1 = 0.227791 loss)
I0312 08:03:28.965723 17663 sgd_solver.cpp:106] Iteration 61100, lr = 1e-09
I0312 08:04:21.991420 17663 solver.cpp:228] Iteration 61200, loss = 0.254447
I0312 08:04:21.991443 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 08:04:21.991451 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.017634 (* 1 = 0.017634 loss)
I0312 08:04:21.991469 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0176304 (* 1 = 0.0176304 loss)
I0312 08:04:21.991474 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324139 (* 1 = 0.0324139 loss)
I0312 08:04:21.991478 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191712 (* 1 = 0.191712 loss)
I0312 08:04:21.991483 17663 sgd_solver.cpp:106] Iteration 61200, lr = 1e-09
I0312 08:05:14.308686 17663 solver.cpp:228] Iteration 61300, loss = 0.326911
I0312 08:05:14.308707 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 08:05:14.308714 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822751 (* 1 = 0.0822751 loss)
I0312 08:05:14.308719 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.127663 (* 1 = 0.127663 loss)
I0312 08:05:14.308737 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00893328 (* 1 = 0.00893328 loss)
I0312 08:05:14.308742 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174486 (* 1 = 0.0174486 loss)
I0312 08:05:14.308759 17663 sgd_solver.cpp:106] Iteration 61300, lr = 1e-09
I0312 08:06:06.782029 17663 solver.cpp:228] Iteration 61400, loss = 0.420205
I0312 08:06:06.782050 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 08:06:06.782058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.176913 (* 1 = 0.176913 loss)
I0312 08:06:06.782076 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.286688 (* 1 = 0.286688 loss)
I0312 08:06:06.782081 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0568437 (* 1 = 0.0568437 loss)
I0312 08:06:06.782085 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452291 (* 1 = 0.0452291 loss)
I0312 08:06:06.782089 17663 sgd_solver.cpp:106] Iteration 61400, lr = 1e-09
I0312 08:06:58.889946 17663 solver.cpp:228] Iteration 61500, loss = 0.377246
I0312 08:06:58.889966 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 08:06:58.889974 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574452 (* 1 = 0.0574452 loss)
I0312 08:06:58.889992 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133588 (* 1 = 0.133588 loss)
I0312 08:06:58.889997 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00365882 (* 1 = 0.00365882 loss)
I0312 08:06:58.890002 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144219 (* 1 = 0.0144219 loss)
I0312 08:06:58.890007 17663 sgd_solver.cpp:106] Iteration 61500, lr = 1e-09
I0312 08:07:51.783445 17663 solver.cpp:228] Iteration 61600, loss = 0.459915
I0312 08:07:51.783468 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 08:07:51.783475 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125775 (* 1 = 0.125775 loss)
I0312 08:07:51.783494 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.277784 (* 1 = 0.277784 loss)
I0312 08:07:51.783499 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.140123 (* 1 = 0.140123 loss)
I0312 08:07:51.783502 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145278 (* 1 = 0.145278 loss)
I0312 08:07:51.783507 17663 sgd_solver.cpp:106] Iteration 61600, lr = 1e-09
I0312 08:08:43.643736 17663 solver.cpp:228] Iteration 61700, loss = 0.375041
I0312 08:08:43.643759 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 08:08:43.643766 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481443 (* 1 = 0.0481443 loss)
I0312 08:08:43.643770 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.109599 (* 1 = 0.109599 loss)
I0312 08:08:43.643790 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0508389 (* 1 = 0.0508389 loss)
I0312 08:08:43.643793 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123379 (* 1 = 0.0123379 loss)
I0312 08:08:43.643800 17663 sgd_solver.cpp:106] Iteration 61700, lr = 1e-09
I0312 08:09:36.112124 17663 solver.cpp:228] Iteration 61800, loss = 0.379612
I0312 08:09:36.112145 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 08:09:36.112152 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0967796 (* 1 = 0.0967796 loss)
I0312 08:09:36.112171 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.304513 (* 1 = 0.304513 loss)
I0312 08:09:36.112175 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158903 (* 1 = 0.0158903 loss)
I0312 08:09:36.112179 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035118 (* 1 = 0.035118 loss)
I0312 08:09:36.112185 17663 sgd_solver.cpp:106] Iteration 61800, lr = 1e-09
I0312 08:10:28.257860 17663 solver.cpp:228] Iteration 61900, loss = 0.143049
I0312 08:10:28.257882 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 08:10:28.257889 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0506911 (* 1 = 0.0506911 loss)
I0312 08:10:28.257913 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135775 (* 1 = 0.135775 loss)
I0312 08:10:28.257917 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010281 (* 1 = 0.010281 loss)
I0312 08:10:28.257922 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01482 (* 1 = 0.01482 loss)
I0312 08:10:28.257927 17663 sgd_solver.cpp:106] Iteration 61900, lr = 1e-09
speed: 0.525s / iter
I0312 08:11:20.221304 17663 solver.cpp:228] Iteration 62000, loss = 0.624344
I0312 08:11:20.221452 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 08:11:20.221519 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.220046 (* 1 = 0.220046 loss)
I0312 08:11:20.221568 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.311987 (* 1 = 0.311987 loss)
I0312 08:11:20.221614 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246905 (* 1 = 0.0246905 loss)
I0312 08:11:20.221660 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0707406 (* 1 = 0.0707406 loss)
I0312 08:11:20.221707 17663 sgd_solver.cpp:106] Iteration 62000, lr = 1e-09
I0312 08:12:12.504287 17663 solver.cpp:228] Iteration 62100, loss = 0.355946
I0312 08:12:12.504310 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 08:12:12.504318 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608779 (* 1 = 0.0608779 loss)
I0312 08:12:12.504338 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106517 (* 1 = 0.106517 loss)
I0312 08:12:12.504341 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162271 (* 1 = 0.0162271 loss)
I0312 08:12:12.504346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117973 (* 1 = 0.117973 loss)
I0312 08:12:12.504351 17663 sgd_solver.cpp:106] Iteration 62100, lr = 1e-09
I0312 08:13:05.115118 17663 solver.cpp:228] Iteration 62200, loss = 0.247613
I0312 08:13:05.115139 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 08:13:05.115145 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793142 (* 1 = 0.0793142 loss)
I0312 08:13:05.115164 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11912 (* 1 = 0.11912 loss)
I0312 08:13:05.115170 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0742257 (* 1 = 0.0742257 loss)
I0312 08:13:05.115172 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.143794 (* 1 = 0.143794 loss)
I0312 08:13:05.115177 17663 sgd_solver.cpp:106] Iteration 62200, lr = 1e-09
I0312 08:13:56.903596 17663 solver.cpp:228] Iteration 62300, loss = 0.147318
I0312 08:13:56.903620 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 08:13:56.903627 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162448 (* 1 = 0.0162448 loss)
I0312 08:13:56.903631 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0308599 (* 1 = 0.0308599 loss)
I0312 08:13:56.903650 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00396462 (* 1 = 0.00396462 loss)
I0312 08:13:56.903654 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154431 (* 1 = 0.0154431 loss)
I0312 08:13:56.903672 17663 sgd_solver.cpp:106] Iteration 62300, lr = 1e-09
I0312 08:14:49.557399 17663 solver.cpp:228] Iteration 62400, loss = 0.58674
I0312 08:14:49.557421 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:14:49.557430 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.179063 (* 1 = 0.179063 loss)
I0312 08:14:49.557448 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.232397 (* 1 = 0.232397 loss)
I0312 08:14:49.557452 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00520031 (* 1 = 0.00520031 loss)
I0312 08:14:49.557469 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326715 (* 1 = 0.0326715 loss)
I0312 08:14:49.557474 17663 sgd_solver.cpp:106] Iteration 62400, lr = 1e-09
I0312 08:15:42.333446 17663 solver.cpp:228] Iteration 62500, loss = 0.348926
I0312 08:15:42.333468 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 08:15:42.333475 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.121008 (* 1 = 0.121008 loss)
I0312 08:15:42.333480 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.313446 (* 1 = 0.313446 loss)
I0312 08:15:42.333498 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0521194 (* 1 = 0.0521194 loss)
I0312 08:15:42.333503 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0983923 (* 1 = 0.0983923 loss)
I0312 08:15:42.333508 17663 sgd_solver.cpp:106] Iteration 62500, lr = 1e-09
I0312 08:16:35.014791 17663 solver.cpp:228] Iteration 62600, loss = 0.345154
I0312 08:16:35.014812 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 08:16:35.014820 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.107201 (* 1 = 0.107201 loss)
I0312 08:16:35.014838 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0576503 (* 1 = 0.0576503 loss)
I0312 08:16:35.014843 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149497 (* 1 = 0.0149497 loss)
I0312 08:16:35.014847 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.216038 (* 1 = 0.216038 loss)
I0312 08:16:35.014852 17663 sgd_solver.cpp:106] Iteration 62600, lr = 1e-09
I0312 08:17:27.903806 17663 solver.cpp:228] Iteration 62700, loss = 0.326993
I0312 08:17:27.903829 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 08:17:27.903836 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372514 (* 1 = 0.0372514 loss)
I0312 08:17:27.903841 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0849669 (* 1 = 0.0849669 loss)
I0312 08:17:27.903859 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184956 (* 1 = 0.0184956 loss)
I0312 08:17:27.903863 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.190724 (* 1 = 0.190724 loss)
I0312 08:17:27.903869 17663 sgd_solver.cpp:106] Iteration 62700, lr = 1e-09
I0312 08:18:20.239099 17663 solver.cpp:228] Iteration 62800, loss = 0.478566
I0312 08:18:20.239128 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 08:18:20.239137 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998182 (* 1 = 0.0998182 loss)
I0312 08:18:20.239156 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.305372 (* 1 = 0.305372 loss)
I0312 08:18:20.239161 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00859836 (* 1 = 0.00859836 loss)
I0312 08:18:20.239164 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104949 (* 1 = 0.104949 loss)
I0312 08:18:20.239171 17663 sgd_solver.cpp:106] Iteration 62800, lr = 1e-09
I0312 08:19:12.364828 17663 solver.cpp:228] Iteration 62900, loss = 0.61249
I0312 08:19:12.364852 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 08:19:12.364872 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.28949 (* 1 = 0.28949 loss)
I0312 08:19:12.364877 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.350457 (* 1 = 0.350457 loss)
I0312 08:19:12.364881 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.123525 (* 1 = 0.123525 loss)
I0312 08:19:12.364886 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.077908 (* 1 = 0.077908 loss)
I0312 08:19:12.364907 17663 sgd_solver.cpp:106] Iteration 62900, lr = 1e-09
speed: 0.525s / iter
I0312 08:20:04.842900 17663 solver.cpp:228] Iteration 63000, loss = 0.271745
I0312 08:20:04.842921 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 08:20:04.842928 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.146775 (* 1 = 0.146775 loss)
I0312 08:20:04.842947 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.232635 (* 1 = 0.232635 loss)
I0312 08:20:04.842952 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0042442 (* 1 = 0.0042442 loss)
I0312 08:20:04.842955 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293081 (* 1 = 0.0293081 loss)
I0312 08:20:04.842960 17663 sgd_solver.cpp:106] Iteration 63000, lr = 1e-09
I0312 08:20:58.015642 17663 solver.cpp:228] Iteration 63100, loss = 0.462145
I0312 08:20:58.015666 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:20:58.015673 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.154043 (* 1 = 0.154043 loss)
I0312 08:20:58.015678 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186629 (* 1 = 0.186629 loss)
I0312 08:20:58.015697 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00515588 (* 1 = 0.00515588 loss)
I0312 08:20:58.015702 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0393407 (* 1 = 0.0393407 loss)
I0312 08:20:58.015707 17663 sgd_solver.cpp:106] Iteration 63100, lr = 1e-09
I0312 08:21:49.812944 17663 solver.cpp:228] Iteration 63200, loss = 0.2545
I0312 08:21:49.812968 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:21:49.812976 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625644 (* 1 = 0.0625644 loss)
I0312 08:21:49.812995 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.14025 (* 1 = 0.14025 loss)
I0312 08:21:49.813000 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00936859 (* 1 = 0.00936859 loss)
I0312 08:21:49.813004 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603374 (* 1 = 0.0603374 loss)
I0312 08:21:49.813009 17663 sgd_solver.cpp:106] Iteration 63200, lr = 1e-09
I0312 08:22:42.428442 17663 solver.cpp:228] Iteration 63300, loss = 0.211143
I0312 08:22:42.428463 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 08:22:42.428470 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0530487 (* 1 = 0.0530487 loss)
I0312 08:22:42.428489 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0597008 (* 1 = 0.0597008 loss)
I0312 08:22:42.428493 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281316 (* 1 = 0.0281316 loss)
I0312 08:22:42.428498 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0730714 (* 1 = 0.0730714 loss)
I0312 08:22:42.428503 17663 sgd_solver.cpp:106] Iteration 63300, lr = 1e-09
I0312 08:23:34.829186 17663 solver.cpp:228] Iteration 63400, loss = 0.45144
I0312 08:23:34.829210 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 08:23:34.829217 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.056511 (* 1 = 0.056511 loss)
I0312 08:23:34.829236 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13243 (* 1 = 0.13243 loss)
I0312 08:23:34.829242 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00342558 (* 1 = 0.00342558 loss)
I0312 08:23:34.829246 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147011 (* 1 = 0.0147011 loss)
I0312 08:23:34.829252 17663 sgd_solver.cpp:106] Iteration 63400, lr = 1e-09
I0312 08:24:26.878528 17663 solver.cpp:228] Iteration 63500, loss = 0.301533
I0312 08:24:26.878557 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 08:24:26.878566 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.135199 (* 1 = 0.135199 loss)
I0312 08:24:26.878584 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.21622 (* 1 = 0.21622 loss)
I0312 08:24:26.878590 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241326 (* 1 = 0.00241326 loss)
I0312 08:24:26.878595 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218347 (* 1 = 0.0218347 loss)
I0312 08:24:26.878600 17663 sgd_solver.cpp:106] Iteration 63500, lr = 1e-09
I0312 08:25:19.313308 17663 solver.cpp:228] Iteration 63600, loss = 0.699607
I0312 08:25:19.313329 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 08:25:19.313336 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.237632 (* 1 = 0.237632 loss)
I0312 08:25:19.313355 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.392006 (* 1 = 0.392006 loss)
I0312 08:25:19.313359 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.338336 (* 1 = 0.338336 loss)
I0312 08:25:19.313362 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.325572 (* 1 = 0.325572 loss)
I0312 08:25:19.313367 17663 sgd_solver.cpp:106] Iteration 63600, lr = 1e-09
I0312 08:26:11.664624 17663 solver.cpp:228] Iteration 63700, loss = 0.422938
I0312 08:26:11.664649 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:26:11.664655 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142317 (* 1 = 0.142317 loss)
I0312 08:26:11.664674 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.16274 (* 1 = 0.16274 loss)
I0312 08:26:11.664680 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218099 (* 1 = 0.0218099 loss)
I0312 08:26:11.664683 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201206 (* 1 = 0.0201206 loss)
I0312 08:26:11.664687 17663 sgd_solver.cpp:106] Iteration 63700, lr = 1e-09
I0312 08:27:04.432729 17663 solver.cpp:228] Iteration 63800, loss = 0.561258
I0312 08:27:04.432750 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 08:27:04.432757 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.203991 (* 1 = 0.203991 loss)
I0312 08:27:04.432775 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.286205 (* 1 = 0.286205 loss)
I0312 08:27:04.432780 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108074 (* 1 = 0.0108074 loss)
I0312 08:27:04.432785 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122712 (* 1 = 0.122712 loss)
I0312 08:27:04.432801 17663 sgd_solver.cpp:106] Iteration 63800, lr = 1e-09
I0312 08:27:56.585041 17663 solver.cpp:228] Iteration 63900, loss = 0.513215
I0312 08:27:56.585062 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:27:56.585069 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.101395 (* 1 = 0.101395 loss)
I0312 08:27:56.585088 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189061 (* 1 = 0.189061 loss)
I0312 08:27:56.585093 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102308 (* 1 = 0.0102308 loss)
I0312 08:27:56.585096 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661695 (* 1 = 0.0661695 loss)
I0312 08:27:56.585114 17663 sgd_solver.cpp:106] Iteration 63900, lr = 1e-09
speed: 0.525s / iter
I0312 08:28:48.480242 17663 solver.cpp:228] Iteration 64000, loss = 0.208561
I0312 08:28:48.480278 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:28:48.480285 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0530823 (* 1 = 0.0530823 loss)
I0312 08:28:48.480305 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11459 (* 1 = 0.11459 loss)
I0312 08:28:48.480310 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161228 (* 1 = 0.0161228 loss)
I0312 08:28:48.480314 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658522 (* 1 = 0.0658522 loss)
I0312 08:28:48.480334 17663 sgd_solver.cpp:106] Iteration 64000, lr = 1e-09
I0312 08:29:41.462793 17663 solver.cpp:228] Iteration 64100, loss = 0.402102
I0312 08:29:41.462819 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 08:29:41.462826 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.222411 (* 1 = 0.222411 loss)
I0312 08:29:41.462846 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.280825 (* 1 = 0.280825 loss)
I0312 08:29:41.462851 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176267 (* 1 = 0.0176267 loss)
I0312 08:29:41.462855 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0850319 (* 1 = 0.0850319 loss)
I0312 08:29:41.462860 17663 sgd_solver.cpp:106] Iteration 64100, lr = 1e-09
I0312 08:30:34.248770 17663 solver.cpp:228] Iteration 64200, loss = 0.319317
I0312 08:30:34.248793 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 08:30:34.248800 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.14541 (* 1 = 0.14541 loss)
I0312 08:30:34.248821 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.247607 (* 1 = 0.247607 loss)
I0312 08:30:34.248826 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00999374 (* 1 = 0.00999374 loss)
I0312 08:30:34.248829 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0724464 (* 1 = 0.0724464 loss)
I0312 08:30:34.248834 17663 sgd_solver.cpp:106] Iteration 64200, lr = 1e-09
I0312 08:31:26.187463 17663 solver.cpp:228] Iteration 64300, loss = 0.427408
I0312 08:31:26.187486 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:31:26.187494 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0720986 (* 1 = 0.0720986 loss)
I0312 08:31:26.187513 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0988514 (* 1 = 0.0988514 loss)
I0312 08:31:26.187520 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772139 (* 1 = 0.00772139 loss)
I0312 08:31:26.187523 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192761 (* 1 = 0.0192761 loss)
I0312 08:31:26.187530 17663 sgd_solver.cpp:106] Iteration 64300, lr = 1e-09
I0312 08:32:18.516095 17663 solver.cpp:228] Iteration 64400, loss = 0.263414
I0312 08:32:18.516116 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:32:18.516124 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0535224 (* 1 = 0.0535224 loss)
I0312 08:32:18.516129 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11667 (* 1 = 0.11667 loss)
I0312 08:32:18.516147 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145588 (* 1 = 0.0145588 loss)
I0312 08:32:18.516151 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126757 (* 1 = 0.126757 loss)
I0312 08:32:18.516157 17663 sgd_solver.cpp:106] Iteration 64400, lr = 1e-09
I0312 08:33:11.063277 17663 solver.cpp:228] Iteration 64500, loss = 0.404525
I0312 08:33:11.063298 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:33:11.063307 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882185 (* 1 = 0.0882185 loss)
I0312 08:33:11.063325 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196583 (* 1 = 0.196583 loss)
I0312 08:33:11.063329 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121873 (* 1 = 0.0121873 loss)
I0312 08:33:11.063333 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127544 (* 1 = 0.127544 loss)
I0312 08:33:11.063350 17663 sgd_solver.cpp:106] Iteration 64500, lr = 1e-09
I0312 08:34:02.884543 17663 solver.cpp:228] Iteration 64600, loss = 0.57951
I0312 08:34:02.884567 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0312 08:34:02.884573 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141239 (* 1 = 0.141239 loss)
I0312 08:34:02.884577 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.381637 (* 1 = 0.381637 loss)
I0312 08:34:02.884596 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.123072 (* 1 = 0.123072 loss)
I0312 08:34:02.884600 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0779768 (* 1 = 0.0779768 loss)
I0312 08:34:02.884626 17663 sgd_solver.cpp:106] Iteration 64600, lr = 1e-09
I0312 08:34:56.094247 17663 solver.cpp:228] Iteration 64700, loss = 0.333957
I0312 08:34:56.094269 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 08:34:56.094276 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386025 (* 1 = 0.0386025 loss)
I0312 08:34:56.094281 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0745681 (* 1 = 0.0745681 loss)
I0312 08:34:56.094300 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134319 (* 1 = 0.0134319 loss)
I0312 08:34:56.094305 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0386234 (* 1 = 0.0386234 loss)
I0312 08:34:56.094310 17663 sgd_solver.cpp:106] Iteration 64700, lr = 1e-09
I0312 08:35:48.278340 17663 solver.cpp:228] Iteration 64800, loss = 0.282069
I0312 08:35:48.278362 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 08:35:48.278370 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201031 (* 1 = 0.0201031 loss)
I0312 08:35:48.278374 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0317321 (* 1 = 0.0317321 loss)
I0312 08:35:48.278378 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234021 (* 1 = 0.0234021 loss)
I0312 08:35:48.278383 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112206 (* 1 = 0.112206 loss)
I0312 08:35:48.278388 17663 sgd_solver.cpp:106] Iteration 64800, lr = 1e-09
I0312 08:36:40.957319 17663 solver.cpp:228] Iteration 64900, loss = 0.34005
I0312 08:36:40.957341 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:36:40.957348 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0914016 (* 1 = 0.0914016 loss)
I0312 08:36:40.957367 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.241592 (* 1 = 0.241592 loss)
I0312 08:36:40.957371 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153128 (* 1 = 0.0153128 loss)
I0312 08:36:40.957376 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182186 (* 1 = 0.0182186 loss)
I0312 08:36:40.957381 17663 sgd_solver.cpp:106] Iteration 64900, lr = 1e-09
speed: 0.525s / iter
I0312 08:37:33.080732 17663 solver.cpp:228] Iteration 65000, loss = 0.428228
I0312 08:37:33.080754 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 08:37:33.080762 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.16108 (* 1 = 0.16108 loss)
I0312 08:37:33.080766 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157459 (* 1 = 0.157459 loss)
I0312 08:37:33.080770 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0438373 (* 1 = 0.0438373 loss)
I0312 08:37:33.080775 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0756954 (* 1 = 0.0756954 loss)
I0312 08:37:33.080793 17663 sgd_solver.cpp:106] Iteration 65000, lr = 1e-09
I0312 08:38:25.296700 17663 solver.cpp:228] Iteration 65100, loss = 0.231154
I0312 08:38:25.296739 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 08:38:25.296761 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0480349 (* 1 = 0.0480349 loss)
I0312 08:38:25.296766 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.162741 (* 1 = 0.162741 loss)
I0312 08:38:25.296771 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00303259 (* 1 = 0.00303259 loss)
I0312 08:38:25.296774 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026166 (* 1 = 0.026166 loss)
I0312 08:38:25.296779 17663 sgd_solver.cpp:106] Iteration 65100, lr = 1e-09
I0312 08:39:17.756516 17663 solver.cpp:228] Iteration 65200, loss = 0.368492
I0312 08:39:17.756538 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:39:17.756561 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.072435 (* 1 = 0.072435 loss)
I0312 08:39:17.756566 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.155062 (* 1 = 0.155062 loss)
I0312 08:39:17.756569 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182197 (* 1 = 0.0182197 loss)
I0312 08:39:17.756573 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.172913 (* 1 = 0.172913 loss)
I0312 08:39:17.756578 17663 sgd_solver.cpp:106] Iteration 65200, lr = 1e-09
I0312 08:40:09.781116 17663 solver.cpp:228] Iteration 65300, loss = 0.648185
I0312 08:40:09.781136 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 08:40:09.781143 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0688089 (* 1 = 0.0688089 loss)
I0312 08:40:09.781162 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.153271 (* 1 = 0.153271 loss)
I0312 08:40:09.781167 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108858 (* 1 = 0.0108858 loss)
I0312 08:40:09.781170 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0642988 (* 1 = 0.0642988 loss)
I0312 08:40:09.781175 17663 sgd_solver.cpp:106] Iteration 65300, lr = 1e-09
I0312 08:41:02.345054 17663 solver.cpp:228] Iteration 65400, loss = 0.229176
I0312 08:41:02.345075 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 08:41:02.345083 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0480704 (* 1 = 0.0480704 loss)
I0312 08:41:02.345088 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.145496 (* 1 = 0.145496 loss)
I0312 08:41:02.345093 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242558 (* 1 = 0.0242558 loss)
I0312 08:41:02.345095 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0593172 (* 1 = 0.0593172 loss)
I0312 08:41:02.345115 17663 sgd_solver.cpp:106] Iteration 65400, lr = 1e-09
I0312 08:41:54.712944 17663 solver.cpp:228] Iteration 65500, loss = 0.723428
I0312 08:41:54.712966 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:41:54.712973 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.109175 (* 1 = 0.109175 loss)
I0312 08:41:54.712977 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.227278 (* 1 = 0.227278 loss)
I0312 08:41:54.712996 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0424027 (* 1 = 0.0424027 loss)
I0312 08:41:54.713001 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.4987 (* 1 = 0.4987 loss)
I0312 08:41:54.713006 17663 sgd_solver.cpp:106] Iteration 65500, lr = 1e-09
I0312 08:42:47.536026 17663 solver.cpp:228] Iteration 65600, loss = 0.303054
I0312 08:42:47.536047 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:42:47.536056 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0452459 (* 1 = 0.0452459 loss)
I0312 08:42:47.536061 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.084144 (* 1 = 0.084144 loss)
I0312 08:42:47.536064 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294942 (* 1 = 0.00294942 loss)
I0312 08:42:47.536068 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00772742 (* 1 = 0.00772742 loss)
I0312 08:42:47.536074 17663 sgd_solver.cpp:106] Iteration 65600, lr = 1e-09
I0312 08:43:39.880628 17663 solver.cpp:228] Iteration 65700, loss = 0.390414
I0312 08:43:39.880652 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 08:43:39.880659 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760203 (* 1 = 0.0760203 loss)
I0312 08:43:39.880679 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117827 (* 1 = 0.117827 loss)
I0312 08:43:39.880683 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0238228 (* 1 = 0.0238228 loss)
I0312 08:43:39.880700 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0526654 (* 1 = 0.0526654 loss)
I0312 08:43:39.880705 17663 sgd_solver.cpp:106] Iteration 65700, lr = 1e-09
I0312 08:44:32.109289 17663 solver.cpp:228] Iteration 65800, loss = 0.381287
I0312 08:44:32.109313 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 08:44:32.109319 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0781542 (* 1 = 0.0781542 loss)
I0312 08:44:32.109324 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.184547 (* 1 = 0.184547 loss)
I0312 08:44:32.109329 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00727697 (* 1 = 0.00727697 loss)
I0312 08:44:32.109333 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150117 (* 1 = 0.0150117 loss)
I0312 08:44:32.109352 17663 sgd_solver.cpp:106] Iteration 65800, lr = 1e-09
I0312 08:45:24.872254 17663 solver.cpp:228] Iteration 65900, loss = 0.51002
I0312 08:45:24.872277 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 08:45:24.872283 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.16152 (* 1 = 0.16152 loss)
I0312 08:45:24.872287 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.332103 (* 1 = 0.332103 loss)
I0312 08:45:24.872306 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.056586 (* 1 = 0.056586 loss)
I0312 08:45:24.872311 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438186 (* 1 = 0.0438186 loss)
I0312 08:45:24.872315 17663 sgd_solver.cpp:106] Iteration 65900, lr = 1e-09
speed: 0.525s / iter
I0312 08:46:16.912792 17663 solver.cpp:228] Iteration 66000, loss = 0.25891
I0312 08:46:16.912947 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 08:46:16.913007 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435748 (* 1 = 0.0435748 loss)
I0312 08:46:16.913054 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170202 (* 1 = 0.170202 loss)
I0312 08:46:16.913102 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00784002 (* 1 = 0.00784002 loss)
I0312 08:46:16.913149 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119662 (* 1 = 0.119662 loss)
I0312 08:46:16.913197 17663 sgd_solver.cpp:106] Iteration 66000, lr = 1e-09
I0312 08:47:09.729979 17663 solver.cpp:228] Iteration 66100, loss = 0.201619
I0312 08:47:09.730002 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:47:09.730010 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422213 (* 1 = 0.0422213 loss)
I0312 08:47:09.730028 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114839 (* 1 = 0.114839 loss)
I0312 08:47:09.730032 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021142 (* 1 = 0.021142 loss)
I0312 08:47:09.730036 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222544 (* 1 = 0.0222544 loss)
I0312 08:47:09.730041 17663 sgd_solver.cpp:106] Iteration 66100, lr = 1e-09
I0312 08:48:02.033314 17663 solver.cpp:228] Iteration 66200, loss = 0.476852
I0312 08:48:02.033336 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 08:48:02.033344 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.103484 (* 1 = 0.103484 loss)
I0312 08:48:02.033362 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11038 (* 1 = 0.11038 loss)
I0312 08:48:02.033367 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187578 (* 1 = 0.0187578 loss)
I0312 08:48:02.033371 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121752 (* 1 = 0.121752 loss)
I0312 08:48:02.033376 17663 sgd_solver.cpp:106] Iteration 66200, lr = 1e-09
I0312 08:48:54.805636 17663 solver.cpp:228] Iteration 66300, loss = 0.326417
I0312 08:48:54.805658 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:48:54.805666 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.016794 (* 1 = 0.016794 loss)
I0312 08:48:54.805685 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0662671 (* 1 = 0.0662671 loss)
I0312 08:48:54.805690 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033021 (* 1 = 0.0033021 loss)
I0312 08:48:54.805693 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121607 (* 1 = 0.0121607 loss)
I0312 08:48:54.805699 17663 sgd_solver.cpp:106] Iteration 66300, lr = 1e-09
I0312 08:49:46.851868 17663 solver.cpp:228] Iteration 66400, loss = 0.605991
I0312 08:49:46.851891 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0312 08:49:46.851897 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.274298 (* 1 = 0.274298 loss)
I0312 08:49:46.851917 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.490449 (* 1 = 0.490449 loss)
I0312 08:49:46.851922 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0494744 (* 1 = 0.0494744 loss)
I0312 08:49:46.851938 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.240868 (* 1 = 0.240868 loss)
I0312 08:49:46.851943 17663 sgd_solver.cpp:106] Iteration 66400, lr = 1e-09
I0312 08:50:39.469131 17663 solver.cpp:228] Iteration 66500, loss = 0.387152
I0312 08:50:39.469153 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 08:50:39.469161 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222461 (* 1 = 0.0222461 loss)
I0312 08:50:39.469179 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0484731 (* 1 = 0.0484731 loss)
I0312 08:50:39.469183 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00340445 (* 1 = 0.00340445 loss)
I0312 08:50:39.469187 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00380016 (* 1 = 0.00380016 loss)
I0312 08:50:39.469192 17663 sgd_solver.cpp:106] Iteration 66500, lr = 1e-09
I0312 08:51:31.434159 17663 solver.cpp:228] Iteration 66600, loss = 0.802303
I0312 08:51:31.434180 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:51:31.434186 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.162196 (* 1 = 0.162196 loss)
I0312 08:51:31.434204 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149641 (* 1 = 0.149641 loss)
I0312 08:51:31.434209 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279659 (* 1 = 0.0279659 loss)
I0312 08:51:31.434213 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0934703 (* 1 = 0.0934703 loss)
I0312 08:51:31.434217 17663 sgd_solver.cpp:106] Iteration 66600, lr = 1e-09
I0312 08:52:24.393240 17663 solver.cpp:228] Iteration 66700, loss = 0.482297
I0312 08:52:24.393263 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 08:52:24.393270 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810941 (* 1 = 0.0810941 loss)
I0312 08:52:24.393290 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.176111 (* 1 = 0.176111 loss)
I0312 08:52:24.393293 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142507 (* 1 = 0.0142507 loss)
I0312 08:52:24.393298 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105426 (* 1 = 0.105426 loss)
I0312 08:52:24.393316 17663 sgd_solver.cpp:106] Iteration 66700, lr = 1e-09
I0312 08:53:16.331334 17663 solver.cpp:228] Iteration 66800, loss = 0.352837
I0312 08:53:16.331357 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 08:53:16.331364 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.053287 (* 1 = 0.053287 loss)
I0312 08:53:16.331383 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.163669 (* 1 = 0.163669 loss)
I0312 08:53:16.331388 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197274 (* 1 = 0.0197274 loss)
I0312 08:53:16.331392 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216567 (* 1 = 0.0216567 loss)
I0312 08:53:16.331396 17663 sgd_solver.cpp:106] Iteration 66800, lr = 1e-09
I0312 08:54:09.139137 17663 solver.cpp:228] Iteration 66900, loss = 0.403457
I0312 08:54:09.139159 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 08:54:09.139166 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501236 (* 1 = 0.0501236 loss)
I0312 08:54:09.139173 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168419 (* 1 = 0.168419 loss)
I0312 08:54:09.139176 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238734 (* 1 = 0.00238734 loss)
I0312 08:54:09.139180 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176198 (* 1 = 0.0176198 loss)
I0312 08:54:09.139184 17663 sgd_solver.cpp:106] Iteration 66900, lr = 1e-09
speed: 0.525s / iter
I0312 08:55:01.646103 17663 solver.cpp:228] Iteration 67000, loss = 0.136574
I0312 08:55:01.646127 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 08:55:01.646134 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325981 (* 1 = 0.0325981 loss)
I0312 08:55:01.646153 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0818014 (* 1 = 0.0818014 loss)
I0312 08:55:01.646157 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183975 (* 1 = 0.0183975 loss)
I0312 08:55:01.646162 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00259844 (* 1 = 0.00259844 loss)
I0312 08:55:01.646167 17663 sgd_solver.cpp:106] Iteration 67000, lr = 1e-09
I0312 08:55:53.534195 17663 solver.cpp:228] Iteration 67100, loss = 0.24898
I0312 08:55:53.534217 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 08:55:53.534225 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.023635 (* 1 = 0.023635 loss)
I0312 08:55:53.534230 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0918052 (* 1 = 0.0918052 loss)
I0312 08:55:53.534248 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00380465 (* 1 = 0.00380465 loss)
I0312 08:55:53.534252 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211847 (* 1 = 0.0211847 loss)
I0312 08:55:53.534258 17663 sgd_solver.cpp:106] Iteration 67100, lr = 1e-09
I0312 08:56:45.940454 17663 solver.cpp:228] Iteration 67200, loss = 0.494745
I0312 08:56:45.940477 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 08:56:45.940485 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.185176 (* 1 = 0.185176 loss)
I0312 08:56:45.940490 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.316134 (* 1 = 0.316134 loss)
I0312 08:56:45.940508 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00598365 (* 1 = 0.00598365 loss)
I0312 08:56:45.940512 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0700789 (* 1 = 0.0700789 loss)
I0312 08:56:45.940517 17663 sgd_solver.cpp:106] Iteration 67200, lr = 1e-09
I0312 08:57:38.687860 17663 solver.cpp:228] Iteration 67300, loss = 0.273727
I0312 08:57:38.687880 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 08:57:38.687887 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0217645 (* 1 = 0.0217645 loss)
I0312 08:57:38.687906 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0791841 (* 1 = 0.0791841 loss)
I0312 08:57:38.687911 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00345455 (* 1 = 0.00345455 loss)
I0312 08:57:38.687914 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00541947 (* 1 = 0.00541947 loss)
I0312 08:57:38.687919 17663 sgd_solver.cpp:106] Iteration 67300, lr = 1e-09
I0312 08:58:30.662448 17663 solver.cpp:228] Iteration 67400, loss = 0.410619
I0312 08:58:30.662469 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 08:58:30.662477 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519307 (* 1 = 0.0519307 loss)
I0312 08:58:30.662495 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.194305 (* 1 = 0.194305 loss)
I0312 08:58:30.662499 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778355 (* 1 = 0.00778355 loss)
I0312 08:58:30.662503 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322632 (* 1 = 0.0322632 loss)
I0312 08:58:30.662521 17663 sgd_solver.cpp:106] Iteration 67400, lr = 1e-09
I0312 08:59:23.393270 17663 solver.cpp:228] Iteration 67500, loss = 0.118331
I0312 08:59:23.393291 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 08:59:23.393299 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00996563 (* 1 = 0.00996563 loss)
I0312 08:59:23.393304 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0404085 (* 1 = 0.0404085 loss)
I0312 08:59:23.393308 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0554567 (* 1 = 0.0554567 loss)
I0312 08:59:23.393312 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0506647 (* 1 = 0.0506647 loss)
I0312 08:59:23.393317 17663 sgd_solver.cpp:106] Iteration 67500, lr = 1e-09
I0312 09:00:15.922076 17663 solver.cpp:228] Iteration 67600, loss = 0.393438
I0312 09:00:15.922097 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 09:00:15.922104 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0834225 (* 1 = 0.0834225 loss)
I0312 09:00:15.922122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.249961 (* 1 = 0.249961 loss)
I0312 09:00:15.922127 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261779 (* 1 = 0.0261779 loss)
I0312 09:00:15.922132 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147502 (* 1 = 0.0147502 loss)
I0312 09:00:15.922137 17663 sgd_solver.cpp:106] Iteration 67600, lr = 1e-09
I0312 09:01:07.342463 17663 solver.cpp:228] Iteration 67700, loss = 0.437475
I0312 09:01:07.342484 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:01:07.342492 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116853 (* 1 = 0.116853 loss)
I0312 09:01:07.342511 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189124 (* 1 = 0.189124 loss)
I0312 09:01:07.342515 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0982349 (* 1 = 0.0982349 loss)
I0312 09:01:07.342519 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149372 (* 1 = 0.149372 loss)
I0312 09:01:07.342525 17663 sgd_solver.cpp:106] Iteration 67700, lr = 1e-09
I0312 09:01:59.502269 17663 solver.cpp:228] Iteration 67800, loss = 0.263197
I0312 09:01:59.502290 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:01:59.502297 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0380704 (* 1 = 0.0380704 loss)
I0312 09:01:59.502302 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.174043 (* 1 = 0.174043 loss)
I0312 09:01:59.502321 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134407 (* 1 = 0.0134407 loss)
I0312 09:01:59.502324 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.06913 (* 1 = 0.06913 loss)
I0312 09:01:59.502329 17663 sgd_solver.cpp:106] Iteration 67800, lr = 1e-09
I0312 09:02:51.995523 17663 solver.cpp:228] Iteration 67900, loss = 0.384417
I0312 09:02:51.995546 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 09:02:51.995554 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.058564 (* 1 = 0.058564 loss)
I0312 09:02:51.995573 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.086345 (* 1 = 0.086345 loss)
I0312 09:02:51.995577 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185158 (* 1 = 0.0185158 loss)
I0312 09:02:51.995581 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.325438 (* 1 = 0.325438 loss)
I0312 09:02:51.995586 17663 sgd_solver.cpp:106] Iteration 67900, lr = 1e-09
speed: 0.525s / iter
I0312 09:03:44.049612 17663 solver.cpp:228] Iteration 68000, loss = 0.456156
I0312 09:03:44.049815 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 09:03:44.049875 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324665 (* 1 = 0.0324665 loss)
I0312 09:03:44.049937 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.208534 (* 1 = 0.208534 loss)
I0312 09:03:44.049985 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.11148 (* 1 = 0.11148 loss)
I0312 09:03:44.050032 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.066598 (* 1 = 0.066598 loss)
I0312 09:03:44.050081 17663 sgd_solver.cpp:106] Iteration 68000, lr = 1e-09
I0312 09:04:37.055840 17663 solver.cpp:228] Iteration 68100, loss = 0.384221
I0312 09:04:37.055861 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 09:04:37.055868 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.173563 (* 1 = 0.173563 loss)
I0312 09:04:37.055886 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.272095 (* 1 = 0.272095 loss)
I0312 09:04:37.055891 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342223 (* 1 = 0.0342223 loss)
I0312 09:04:37.055894 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545854 (* 1 = 0.0545854 loss)
I0312 09:04:37.055899 17663 sgd_solver.cpp:106] Iteration 68100, lr = 1e-09
I0312 09:05:29.364035 17663 solver.cpp:228] Iteration 68200, loss = 0.269083
I0312 09:05:29.364058 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:05:29.364064 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.021119 (* 1 = 0.021119 loss)
I0312 09:05:29.364068 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0715058 (* 1 = 0.0715058 loss)
I0312 09:05:29.364073 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141304 (* 1 = 0.0141304 loss)
I0312 09:05:29.364078 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00558232 (* 1 = 0.00558232 loss)
I0312 09:05:29.364081 17663 sgd_solver.cpp:106] Iteration 68200, lr = 1e-09
I0312 09:06:21.553565 17663 solver.cpp:228] Iteration 68300, loss = 0.519014
I0312 09:06:21.553587 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:06:21.553594 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691893 (* 1 = 0.0691893 loss)
I0312 09:06:21.553598 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.159697 (* 1 = 0.159697 loss)
I0312 09:06:21.553617 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00533929 (* 1 = 0.00533929 loss)
I0312 09:06:21.553622 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.182301 (* 1 = 0.182301 loss)
I0312 09:06:21.553627 17663 sgd_solver.cpp:106] Iteration 68300, lr = 1e-09
I0312 09:07:14.332003 17663 solver.cpp:228] Iteration 68400, loss = 0.154358
I0312 09:07:14.332026 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 09:07:14.332033 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272366 (* 1 = 0.0272366 loss)
I0312 09:07:14.332038 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0634623 (* 1 = 0.0634623 loss)
I0312 09:07:14.332056 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00469891 (* 1 = 0.00469891 loss)
I0312 09:07:14.332060 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00333311 (* 1 = 0.00333311 loss)
I0312 09:07:14.332067 17663 sgd_solver.cpp:106] Iteration 68400, lr = 1e-09
I0312 09:08:07.399001 17663 solver.cpp:228] Iteration 68500, loss = 0.522472
I0312 09:08:07.399029 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:08:07.399037 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.043356 (* 1 = 0.043356 loss)
I0312 09:08:07.399056 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156347 (* 1 = 0.156347 loss)
I0312 09:08:07.399060 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019711 (* 1 = 0.019711 loss)
I0312 09:08:07.399065 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0550655 (* 1 = 0.0550655 loss)
I0312 09:08:07.399071 17663 sgd_solver.cpp:106] Iteration 68500, lr = 1e-09
I0312 09:09:00.076460 17663 solver.cpp:228] Iteration 68600, loss = 0.227319
I0312 09:09:00.076483 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:09:00.076490 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0438607 (* 1 = 0.0438607 loss)
I0312 09:09:00.076509 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.139417 (* 1 = 0.139417 loss)
I0312 09:09:00.076514 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00195035 (* 1 = 0.00195035 loss)
I0312 09:09:00.076519 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178458 (* 1 = 0.0178458 loss)
I0312 09:09:00.076524 17663 sgd_solver.cpp:106] Iteration 68600, lr = 1e-09
I0312 09:09:52.422242 17663 solver.cpp:228] Iteration 68700, loss = 0.480723
I0312 09:09:52.422263 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:09:52.422271 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0844693 (* 1 = 0.0844693 loss)
I0312 09:09:52.422289 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104833 (* 1 = 0.104833 loss)
I0312 09:09:52.422293 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0410459 (* 1 = 0.0410459 loss)
I0312 09:09:52.422297 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.15434 (* 1 = 0.15434 loss)
I0312 09:09:52.422302 17663 sgd_solver.cpp:106] Iteration 68700, lr = 1e-09
I0312 09:10:45.585338 17663 solver.cpp:228] Iteration 68800, loss = 0.463646
I0312 09:10:45.585360 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 09:10:45.585367 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.118978 (* 1 = 0.118978 loss)
I0312 09:10:45.585371 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.209469 (* 1 = 0.209469 loss)
I0312 09:10:45.585389 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00244483 (* 1 = 0.00244483 loss)
I0312 09:10:45.585393 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481422 (* 1 = 0.0481422 loss)
I0312 09:10:45.585398 17663 sgd_solver.cpp:106] Iteration 68800, lr = 1e-09
I0312 09:11:37.543113 17663 solver.cpp:228] Iteration 68900, loss = 0.16246
I0312 09:11:37.543134 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:11:37.543143 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0646399 (* 1 = 0.0646399 loss)
I0312 09:11:37.543161 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0782624 (* 1 = 0.0782624 loss)
I0312 09:11:37.543165 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209251 (* 1 = 0.0209251 loss)
I0312 09:11:37.543169 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00703347 (* 1 = 0.00703347 loss)
I0312 09:11:37.543174 17663 sgd_solver.cpp:106] Iteration 68900, lr = 1e-09
speed: 0.525s / iter
I0312 09:12:30.049144 17663 solver.cpp:228] Iteration 69000, loss = 0.281796
I0312 09:12:30.049314 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 09:12:30.049371 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0588409 (* 1 = 0.0588409 loss)
I0312 09:12:30.049419 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172482 (* 1 = 0.172482 loss)
I0312 09:12:30.049468 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00524191 (* 1 = 0.00524191 loss)
I0312 09:12:30.049513 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0670355 (* 1 = 0.0670355 loss)
I0312 09:12:30.049561 17663 sgd_solver.cpp:106] Iteration 69000, lr = 1e-09
I0312 09:13:22.735927 17663 solver.cpp:228] Iteration 69100, loss = 0.291199
I0312 09:13:22.735949 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:13:22.735956 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169073 (* 1 = 0.0169073 loss)
I0312 09:13:22.735975 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0651883 (* 1 = 0.0651883 loss)
I0312 09:13:22.735980 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319342 (* 1 = 0.00319342 loss)
I0312 09:13:22.735996 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024232 (* 1 = 0.024232 loss)
I0312 09:13:22.736001 17663 sgd_solver.cpp:106] Iteration 69100, lr = 1e-09
I0312 09:14:15.904479 17663 solver.cpp:228] Iteration 69200, loss = 0.340536
I0312 09:14:15.904500 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 09:14:15.904507 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.109777 (* 1 = 0.109777 loss)
I0312 09:14:15.904527 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.222242 (* 1 = 0.222242 loss)
I0312 09:14:15.904531 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040014 (* 1 = 0.040014 loss)
I0312 09:14:15.904536 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624674 (* 1 = 0.0624674 loss)
I0312 09:14:15.904541 17663 sgd_solver.cpp:106] Iteration 69200, lr = 1e-09
I0312 09:15:08.352563 17663 solver.cpp:228] Iteration 69300, loss = 0.314458
I0312 09:15:08.352586 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:15:08.352594 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.086009 (* 1 = 0.086009 loss)
I0312 09:15:08.352612 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.208278 (* 1 = 0.208278 loss)
I0312 09:15:08.352617 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191478 (* 1 = 0.0191478 loss)
I0312 09:15:08.352622 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337087 (* 1 = 0.0337087 loss)
I0312 09:15:08.352627 17663 sgd_solver.cpp:106] Iteration 69300, lr = 1e-09
I0312 09:16:01.267808 17663 solver.cpp:228] Iteration 69400, loss = 0.454767
I0312 09:16:01.267832 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 09:16:01.267839 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.101924 (* 1 = 0.101924 loss)
I0312 09:16:01.267858 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.300096 (* 1 = 0.300096 loss)
I0312 09:16:01.267863 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589854 (* 1 = 0.00589854 loss)
I0312 09:16:01.267868 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031465 (* 1 = 0.031465 loss)
I0312 09:16:01.267873 17663 sgd_solver.cpp:106] Iteration 69400, lr = 1e-09
I0312 09:16:53.843571 17663 solver.cpp:228] Iteration 69500, loss = 0.496259
I0312 09:16:53.843595 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:16:53.843601 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0979609 (* 1 = 0.0979609 loss)
I0312 09:16:53.843621 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189103 (* 1 = 0.189103 loss)
I0312 09:16:53.843624 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154163 (* 1 = 0.0154163 loss)
I0312 09:16:53.843628 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.114781 (* 1 = 0.114781 loss)
I0312 09:16:53.843647 17663 sgd_solver.cpp:106] Iteration 69500, lr = 1e-09
I0312 09:17:45.760648 17663 solver.cpp:228] Iteration 69600, loss = 0.366532
I0312 09:17:45.760668 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:17:45.760675 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.135972 (* 1 = 0.135972 loss)
I0312 09:17:45.760680 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.15125 (* 1 = 0.15125 loss)
I0312 09:17:45.760699 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00804499 (* 1 = 0.00804499 loss)
I0312 09:17:45.760704 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263043 (* 1 = 0.0263043 loss)
I0312 09:17:45.760709 17663 sgd_solver.cpp:106] Iteration 69600, lr = 1e-09
I0312 09:18:38.931183 17663 solver.cpp:228] Iteration 69700, loss = 1.11336
I0312 09:18:38.931205 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:18:38.931212 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.158519 (* 1 = 0.158519 loss)
I0312 09:18:38.931231 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.554524 (* 1 = 0.554524 loss)
I0312 09:18:38.931236 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0907004 (* 1 = 0.0907004 loss)
I0312 09:18:38.931238 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0779119 (* 1 = 0.0779119 loss)
I0312 09:18:38.931243 17663 sgd_solver.cpp:106] Iteration 69700, lr = 1e-09
I0312 09:19:31.602339 17663 solver.cpp:228] Iteration 69800, loss = 0.186094
I0312 09:19:31.602360 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 09:19:31.602368 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0470065 (* 1 = 0.0470065 loss)
I0312 09:19:31.602387 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0909189 (* 1 = 0.0909189 loss)
I0312 09:19:31.602392 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00584812 (* 1 = 0.00584812 loss)
I0312 09:19:31.602396 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100346 (* 1 = 0.100346 loss)
I0312 09:19:31.602414 17663 sgd_solver.cpp:106] Iteration 69800, lr = 1e-09
I0312 09:20:24.756778 17663 solver.cpp:228] Iteration 69900, loss = 0.313409
I0312 09:20:24.756801 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 09:20:24.756809 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0552732 (* 1 = 0.0552732 loss)
I0312 09:20:24.756814 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180526 (* 1 = 0.180526 loss)
I0312 09:20:24.756819 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00500678 (* 1 = 0.00500678 loss)
I0312 09:20:24.756822 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246603 (* 1 = 0.0246603 loss)
I0312 09:20:24.756842 17663 sgd_solver.cpp:106] Iteration 69900, lr = 1e-09
I0312 09:21:17.672773 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_70000.caffemodel
I0312 09:21:18.173732 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_70000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_70000.caffemodel
I0312 09:21:19.294011 17663 solver.cpp:228] Iteration 70000, loss = 0.724034
I0312 09:21:19.294034 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:21:19.294042 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144405 (* 1 = 0.0144405 loss)
I0312 09:21:19.294061 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0829837 (* 1 = 0.0829837 loss)
I0312 09:21:19.294065 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00661575 (* 1 = 0.00661575 loss)
I0312 09:21:19.294082 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00203396 (* 1 = 0.00203396 loss)
I0312 09:21:19.294088 17663 sgd_solver.cpp:106] Iteration 70000, lr = 1e-10
I0312 09:22:11.441617 17663 solver.cpp:228] Iteration 70100, loss = 0.257314
I0312 09:22:11.441639 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:22:11.441648 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.040571 (* 1 = 0.040571 loss)
I0312 09:22:11.441666 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172155 (* 1 = 0.172155 loss)
I0312 09:22:11.441670 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737802 (* 1 = 0.00737802 loss)
I0312 09:22:11.441675 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171387 (* 1 = 0.0171387 loss)
I0312 09:22:11.441679 17663 sgd_solver.cpp:106] Iteration 70100, lr = 1e-10
I0312 09:23:03.903491 17663 solver.cpp:228] Iteration 70200, loss = 0.261107
I0312 09:23:03.903512 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:23:03.903519 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435705 (* 1 = 0.0435705 loss)
I0312 09:23:03.903537 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.131039 (* 1 = 0.131039 loss)
I0312 09:23:03.903542 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0395927 (* 1 = 0.0395927 loss)
I0312 09:23:03.903547 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362657 (* 1 = 0.0362657 loss)
I0312 09:23:03.903551 17663 sgd_solver.cpp:106] Iteration 70200, lr = 1e-10
I0312 09:23:56.875792 17663 solver.cpp:228] Iteration 70300, loss = 0.309736
I0312 09:23:56.875814 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:23:56.875823 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0263831 (* 1 = 0.0263831 loss)
I0312 09:23:56.875841 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.163171 (* 1 = 0.163171 loss)
I0312 09:23:56.875845 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106927 (* 1 = 0.0106927 loss)
I0312 09:23:56.875861 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193049 (* 1 = 0.0193049 loss)
I0312 09:23:56.875866 17663 sgd_solver.cpp:106] Iteration 70300, lr = 1e-10
I0312 09:24:50.466300 17663 solver.cpp:228] Iteration 70400, loss = 0.240749
I0312 09:24:50.466321 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 09:24:50.466329 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0515641 (* 1 = 0.0515641 loss)
I0312 09:24:50.466348 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.16331 (* 1 = 0.16331 loss)
I0312 09:24:50.466352 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146202 (* 1 = 0.0146202 loss)
I0312 09:24:50.466356 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117114 (* 1 = 0.117114 loss)
I0312 09:24:50.466362 17663 sgd_solver.cpp:106] Iteration 70400, lr = 1e-10
I0312 09:25:43.559523 17663 solver.cpp:228] Iteration 70500, loss = 0.380568
I0312 09:25:43.559543 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:25:43.559551 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256502 (* 1 = 0.0256502 loss)
I0312 09:25:43.559571 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.134046 (* 1 = 0.134046 loss)
I0312 09:25:43.559574 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023494 (* 1 = 0.023494 loss)
I0312 09:25:43.559578 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.293184 (* 1 = 0.293184 loss)
I0312 09:25:43.559583 17663 sgd_solver.cpp:106] Iteration 70500, lr = 1e-10
I0312 09:26:36.105304 17663 solver.cpp:228] Iteration 70600, loss = 0.339494
I0312 09:26:36.105329 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 09:26:36.105335 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205623 (* 1 = 0.0205623 loss)
I0312 09:26:36.105353 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0936263 (* 1 = 0.0936263 loss)
I0312 09:26:36.105358 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233545 (* 1 = 0.00233545 loss)
I0312 09:26:36.105376 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267905 (* 1 = 0.0267905 loss)
I0312 09:26:36.105381 17663 sgd_solver.cpp:106] Iteration 70600, lr = 1e-10
I0312 09:27:28.994452 17663 solver.cpp:228] Iteration 70700, loss = 0.275181
I0312 09:27:28.994474 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 09:27:28.994482 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119371 (* 1 = 0.119371 loss)
I0312 09:27:28.994501 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.280738 (* 1 = 0.280738 loss)
I0312 09:27:28.994505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115082 (* 1 = 0.0115082 loss)
I0312 09:27:28.994523 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266569 (* 1 = 0.0266569 loss)
I0312 09:27:28.994529 17663 sgd_solver.cpp:106] Iteration 70700, lr = 1e-10
I0312 09:28:20.974880 17663 solver.cpp:228] Iteration 70800, loss = 0.302681
I0312 09:28:20.974906 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 09:28:20.974913 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0221417 (* 1 = 0.0221417 loss)
I0312 09:28:20.974932 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0705844 (* 1 = 0.0705844 loss)
I0312 09:28:20.974937 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141367 (* 1 = 0.00141367 loss)
I0312 09:28:20.974941 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00828586 (* 1 = 0.00828586 loss)
I0312 09:28:20.974946 17663 sgd_solver.cpp:106] Iteration 70800, lr = 1e-10
I0312 09:29:13.346324 17663 solver.cpp:228] Iteration 70900, loss = 0.382265
I0312 09:29:13.346346 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 09:29:13.346354 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0406133 (* 1 = 0.0406133 loss)
I0312 09:29:13.346372 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196661 (* 1 = 0.196661 loss)
I0312 09:29:13.346377 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163748 (* 1 = 0.0163748 loss)
I0312 09:29:13.346381 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490719 (* 1 = 0.0490719 loss)
I0312 09:29:13.346386 17663 sgd_solver.cpp:106] Iteration 70900, lr = 1e-10
speed: 0.525s / iter
I0312 09:30:06.622910 17663 solver.cpp:228] Iteration 71000, loss = 0.412727
I0312 09:30:06.622931 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 09:30:06.622938 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.232754 (* 1 = 0.232754 loss)
I0312 09:30:06.622957 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.356273 (* 1 = 0.356273 loss)
I0312 09:30:06.622961 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0308442 (* 1 = 0.0308442 loss)
I0312 09:30:06.622965 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0986172 (* 1 = 0.0986172 loss)
I0312 09:30:06.622970 17663 sgd_solver.cpp:106] Iteration 71000, lr = 1e-10
I0312 09:30:58.426156 17663 solver.cpp:228] Iteration 71100, loss = 0.227164
I0312 09:30:58.426178 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:30:58.426185 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0630786 (* 1 = 0.0630786 loss)
I0312 09:30:58.426205 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157636 (* 1 = 0.157636 loss)
I0312 09:30:58.426209 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0550149 (* 1 = 0.0550149 loss)
I0312 09:30:58.426213 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624148 (* 1 = 0.0624148 loss)
I0312 09:30:58.426218 17663 sgd_solver.cpp:106] Iteration 71100, lr = 1e-10
I0312 09:31:50.998984 17663 solver.cpp:228] Iteration 71200, loss = 0.185728
I0312 09:31:50.999007 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 09:31:50.999014 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.112222 (* 1 = 0.112222 loss)
I0312 09:31:50.999033 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123352 (* 1 = 0.123352 loss)
I0312 09:31:50.999037 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010163 (* 1 = 0.010163 loss)
I0312 09:31:50.999042 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303038 (* 1 = 0.0303038 loss)
I0312 09:31:50.999060 17663 sgd_solver.cpp:106] Iteration 71200, lr = 1e-10
I0312 09:32:43.640996 17663 solver.cpp:228] Iteration 71300, loss = 0.479847
I0312 09:32:43.641019 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 09:32:43.641026 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.118589 (* 1 = 0.118589 loss)
I0312 09:32:43.641031 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.257653 (* 1 = 0.257653 loss)
I0312 09:32:43.641034 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176503 (* 1 = 0.0176503 loss)
I0312 09:32:43.641038 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137346 (* 1 = 0.0137346 loss)
I0312 09:32:43.641043 17663 sgd_solver.cpp:106] Iteration 71300, lr = 1e-10
I0312 09:33:36.588193 17663 solver.cpp:228] Iteration 71400, loss = 0.32997
I0312 09:33:36.588217 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 09:33:36.588227 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371473 (* 1 = 0.0371473 loss)
I0312 09:33:36.588245 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107613 (* 1 = 0.107613 loss)
I0312 09:33:36.588249 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0395077 (* 1 = 0.0395077 loss)
I0312 09:33:36.588253 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0287422 (* 1 = 0.0287422 loss)
I0312 09:33:36.588259 17663 sgd_solver.cpp:106] Iteration 71400, lr = 1e-10
I0312 09:34:28.964313 17663 solver.cpp:228] Iteration 71500, loss = 0.336902
I0312 09:34:28.964335 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:34:28.964342 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0733417 (* 1 = 0.0733417 loss)
I0312 09:34:28.964361 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.207967 (* 1 = 0.207967 loss)
I0312 09:34:28.964365 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0379666 (* 1 = 0.0379666 loss)
I0312 09:34:28.964370 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0639587 (* 1 = 0.0639587 loss)
I0312 09:34:28.964375 17663 sgd_solver.cpp:106] Iteration 71500, lr = 1e-10
I0312 09:35:21.183315 17663 solver.cpp:228] Iteration 71600, loss = 0.373667
I0312 09:35:21.183338 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 09:35:21.183346 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.143771 (* 1 = 0.143771 loss)
I0312 09:35:21.183351 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.158411 (* 1 = 0.158411 loss)
I0312 09:35:21.183369 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010054 (* 1 = 0.010054 loss)
I0312 09:35:21.183373 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331052 (* 1 = 0.0331052 loss)
I0312 09:35:21.183392 17663 sgd_solver.cpp:106] Iteration 71600, lr = 1e-10
I0312 09:36:14.068331 17663 solver.cpp:228] Iteration 71700, loss = 0.340034
I0312 09:36:14.068352 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:36:14.068359 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373258 (* 1 = 0.0373258 loss)
I0312 09:36:14.068378 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116711 (* 1 = 0.116711 loss)
I0312 09:36:14.068382 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164183 (* 1 = 0.0164183 loss)
I0312 09:36:14.068399 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.18004 (* 1 = 0.18004 loss)
I0312 09:36:14.068404 17663 sgd_solver.cpp:106] Iteration 71700, lr = 1e-10
I0312 09:37:06.574765 17663 solver.cpp:228] Iteration 71800, loss = 0.778933
I0312 09:37:06.574787 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 09:37:06.574795 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.25434 (* 1 = 0.25434 loss)
I0312 09:37:06.574815 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.479948 (* 1 = 0.479948 loss)
I0312 09:37:06.574818 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211717 (* 1 = 0.0211717 loss)
I0312 09:37:06.574822 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.246862 (* 1 = 0.246862 loss)
I0312 09:37:06.574827 17663 sgd_solver.cpp:106] Iteration 71800, lr = 1e-10
I0312 09:37:59.287241 17663 solver.cpp:228] Iteration 71900, loss = 0.434902
I0312 09:37:59.287262 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 09:37:59.287269 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125883 (* 1 = 0.125883 loss)
I0312 09:37:59.287288 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.27147 (* 1 = 0.27147 loss)
I0312 09:37:59.287292 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192661 (* 1 = 0.0192661 loss)
I0312 09:37:59.287297 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560288 (* 1 = 0.0560288 loss)
I0312 09:37:59.287300 17663 sgd_solver.cpp:106] Iteration 71900, lr = 1e-10
speed: 0.525s / iter
I0312 09:38:51.292237 17663 solver.cpp:228] Iteration 72000, loss = 0.431038
I0312 09:38:51.292397 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 09:38:51.292454 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141375 (* 1 = 0.141375 loss)
I0312 09:38:51.292501 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.249769 (* 1 = 0.249769 loss)
I0312 09:38:51.292549 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0238341 (* 1 = 0.0238341 loss)
I0312 09:38:51.292595 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124389 (* 1 = 0.124389 loss)
I0312 09:38:51.292642 17663 sgd_solver.cpp:106] Iteration 72000, lr = 1e-10
I0312 09:39:44.346685 17663 solver.cpp:228] Iteration 72100, loss = 0.5252
I0312 09:39:44.346709 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 09:39:44.346716 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0424591 (* 1 = 0.0424591 loss)
I0312 09:39:44.346735 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0853094 (* 1 = 0.0853094 loss)
I0312 09:39:44.346738 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0968118 (* 1 = 0.0968118 loss)
I0312 09:39:44.346743 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168282 (* 1 = 0.168282 loss)
I0312 09:39:44.346761 17663 sgd_solver.cpp:106] Iteration 72100, lr = 1e-10
I0312 09:40:36.360256 17663 solver.cpp:228] Iteration 72200, loss = 0.316833
I0312 09:40:36.360280 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:40:36.360287 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.108293 (* 1 = 0.108293 loss)
I0312 09:40:36.360291 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.178243 (* 1 = 0.178243 loss)
I0312 09:40:36.360296 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0067512 (* 1 = 0.0067512 loss)
I0312 09:40:36.360299 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024999 (* 1 = 0.024999 loss)
I0312 09:40:36.360304 17663 sgd_solver.cpp:106] Iteration 72200, lr = 1e-10
I0312 09:41:28.350942 17663 solver.cpp:228] Iteration 72300, loss = 0.452466
I0312 09:41:28.350965 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0312 09:41:28.350972 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.180172 (* 1 = 0.180172 loss)
I0312 09:41:28.350977 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.384167 (* 1 = 0.384167 loss)
I0312 09:41:28.350996 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0507493 (* 1 = 0.0507493 loss)
I0312 09:41:28.351001 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0914698 (* 1 = 0.0914698 loss)
I0312 09:41:28.351006 17663 sgd_solver.cpp:106] Iteration 72300, lr = 1e-10
I0312 09:42:20.638540 17663 solver.cpp:228] Iteration 72400, loss = 0.137034
I0312 09:42:20.638563 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 09:42:20.638571 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.046502 (* 1 = 0.046502 loss)
I0312 09:42:20.638574 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0639758 (* 1 = 0.0639758 loss)
I0312 09:42:20.638594 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0041386 (* 1 = 0.0041386 loss)
I0312 09:42:20.638598 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186436 (* 1 = 0.0186436 loss)
I0312 09:42:20.638603 17663 sgd_solver.cpp:106] Iteration 72400, lr = 1e-10
I0312 09:43:13.140976 17663 solver.cpp:228] Iteration 72500, loss = 0.659493
I0312 09:43:13.140998 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0312 09:43:13.141005 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.400668 (* 1 = 0.400668 loss)
I0312 09:43:13.141024 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.496811 (* 1 = 0.496811 loss)
I0312 09:43:13.141028 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256579 (* 1 = 0.0256579 loss)
I0312 09:43:13.141047 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1092 (* 1 = 0.1092 loss)
I0312 09:43:13.141052 17663 sgd_solver.cpp:106] Iteration 72500, lr = 1e-10
I0312 09:44:05.697862 17663 solver.cpp:228] Iteration 72600, loss = 0.361799
I0312 09:44:05.697885 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 09:44:05.697912 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.132475 (* 1 = 0.132475 loss)
I0312 09:44:05.697917 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.205721 (* 1 = 0.205721 loss)
I0312 09:44:05.697921 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0326377 (* 1 = 0.0326377 loss)
I0312 09:44:05.697926 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11423 (* 1 = 0.11423 loss)
I0312 09:44:05.697932 17663 sgd_solver.cpp:106] Iteration 72600, lr = 1e-10
I0312 09:44:58.225833 17663 solver.cpp:228] Iteration 72700, loss = 0.250567
I0312 09:44:58.225855 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:44:58.225862 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441774 (* 1 = 0.0441774 loss)
I0312 09:44:58.225883 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.158402 (* 1 = 0.158402 loss)
I0312 09:44:58.225886 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0572032 (* 1 = 0.0572032 loss)
I0312 09:44:58.225890 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0772775 (* 1 = 0.0772775 loss)
I0312 09:44:58.225914 17663 sgd_solver.cpp:106] Iteration 72700, lr = 1e-10
I0312 09:45:51.617528 17663 solver.cpp:228] Iteration 72800, loss = 0.26597
I0312 09:45:51.617549 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 09:45:51.617557 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0388172 (* 1 = 0.0388172 loss)
I0312 09:45:51.617561 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.20196 (* 1 = 0.20196 loss)
I0312 09:45:51.617580 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379946 (* 1 = 0.00379946 loss)
I0312 09:45:51.617585 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301919 (* 1 = 0.0301919 loss)
I0312 09:45:51.617602 17663 sgd_solver.cpp:106] Iteration 72800, lr = 1e-10
I0312 09:46:44.267465 17663 solver.cpp:228] Iteration 72900, loss = 0.331447
I0312 09:46:44.267487 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 09:46:44.267494 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336428 (* 1 = 0.0336428 loss)
I0312 09:46:44.267513 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.118799 (* 1 = 0.118799 loss)
I0312 09:46:44.267516 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0977756 (* 1 = 0.0977756 loss)
I0312 09:46:44.267520 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0727112 (* 1 = 0.0727112 loss)
I0312 09:46:44.267539 17663 sgd_solver.cpp:106] Iteration 72900, lr = 1e-10
speed: 0.525s / iter
I0312 09:47:36.459025 17663 solver.cpp:228] Iteration 73000, loss = 0.516482
I0312 09:47:36.459048 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 09:47:36.459055 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0935533 (* 1 = 0.0935533 loss)
I0312 09:47:36.459075 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181683 (* 1 = 0.181683 loss)
I0312 09:47:36.459079 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0914737 (* 1 = 0.0914737 loss)
I0312 09:47:36.459084 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.239565 (* 1 = 0.239565 loss)
I0312 09:47:36.459089 17663 sgd_solver.cpp:106] Iteration 73000, lr = 1e-10
I0312 09:48:29.005177 17663 solver.cpp:228] Iteration 73100, loss = 0.768142
I0312 09:48:29.005213 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 09:48:29.005234 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119501 (* 1 = 0.119501 loss)
I0312 09:48:29.005239 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.406208 (* 1 = 0.406208 loss)
I0312 09:48:29.005255 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248262 (* 1 = 0.0248262 loss)
I0312 09:48:29.005260 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885795 (* 1 = 0.0885795 loss)
I0312 09:48:29.005265 17663 sgd_solver.cpp:106] Iteration 73100, lr = 1e-10
I0312 09:49:21.605578 17663 solver.cpp:228] Iteration 73200, loss = 0.578886
I0312 09:49:21.605604 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 09:49:21.605613 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322069 (* 1 = 0.0322069 loss)
I0312 09:49:21.605619 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0645425 (* 1 = 0.0645425 loss)
I0312 09:49:21.605623 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.033926 (* 1 = 0.033926 loss)
I0312 09:49:21.605628 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0580504 (* 1 = 0.0580504 loss)
I0312 09:49:21.605646 17663 sgd_solver.cpp:106] Iteration 73200, lr = 1e-10
I0312 09:50:13.921352 17663 solver.cpp:228] Iteration 73300, loss = 0.40262
I0312 09:50:13.921375 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 09:50:13.921382 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105286 (* 1 = 0.105286 loss)
I0312 09:50:13.921387 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.235922 (* 1 = 0.235922 loss)
I0312 09:50:13.921391 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293701 (* 1 = 0.0293701 loss)
I0312 09:50:13.921396 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137149 (* 1 = 0.137149 loss)
I0312 09:50:13.921401 17663 sgd_solver.cpp:106] Iteration 73300, lr = 1e-10
I0312 09:51:06.363126 17663 solver.cpp:228] Iteration 73400, loss = 0.310902
I0312 09:51:06.363148 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 09:51:06.363155 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.141349 (* 1 = 0.141349 loss)
I0312 09:51:06.363174 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.229099 (* 1 = 0.229099 loss)
I0312 09:51:06.363179 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100753 (* 1 = 0.0100753 loss)
I0312 09:51:06.363183 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0504672 (* 1 = 0.0504672 loss)
I0312 09:51:06.363201 17663 sgd_solver.cpp:106] Iteration 73400, lr = 1e-10
I0312 09:51:58.734124 17663 solver.cpp:228] Iteration 73500, loss = 0.623225
I0312 09:51:58.734145 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:51:58.734153 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0621838 (* 1 = 0.0621838 loss)
I0312 09:51:58.734171 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172078 (* 1 = 0.172078 loss)
I0312 09:51:58.734175 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121492 (* 1 = 0.0121492 loss)
I0312 09:51:58.734179 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.285164 (* 1 = 0.285164 loss)
I0312 09:51:58.734184 17663 sgd_solver.cpp:106] Iteration 73500, lr = 1e-10
I0312 09:52:52.025001 17663 solver.cpp:228] Iteration 73600, loss = 0.648864
I0312 09:52:52.025023 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 09:52:52.025030 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.205748 (* 1 = 0.205748 loss)
I0312 09:52:52.025050 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.291527 (* 1 = 0.291527 loss)
I0312 09:52:52.025054 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0513543 (* 1 = 0.0513543 loss)
I0312 09:52:52.025058 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.323611 (* 1 = 0.323611 loss)
I0312 09:52:52.025063 17663 sgd_solver.cpp:106] Iteration 73600, lr = 1e-10
I0312 09:53:43.992029 17663 solver.cpp:228] Iteration 73700, loss = 0.267255
I0312 09:53:43.992050 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 09:53:43.992058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318778 (* 1 = 0.0318778 loss)
I0312 09:53:43.992076 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0932431 (* 1 = 0.0932431 loss)
I0312 09:53:43.992080 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208535 (* 1 = 0.0208535 loss)
I0312 09:53:43.992084 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0589212 (* 1 = 0.0589212 loss)
I0312 09:53:43.992089 17663 sgd_solver.cpp:106] Iteration 73700, lr = 1e-10
I0312 09:54:36.124306 17663 solver.cpp:228] Iteration 73800, loss = 0.259926
I0312 09:54:36.124328 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 09:54:36.124336 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442904 (* 1 = 0.0442904 loss)
I0312 09:54:36.124354 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120307 (* 1 = 0.120307 loss)
I0312 09:54:36.124358 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029467 (* 1 = 0.029467 loss)
I0312 09:54:36.124362 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.167423 (* 1 = 0.167423 loss)
I0312 09:54:36.124367 17663 sgd_solver.cpp:106] Iteration 73800, lr = 1e-10
I0312 09:55:28.740619 17663 solver.cpp:228] Iteration 73900, loss = 0.469671
I0312 09:55:28.740645 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 09:55:28.740654 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.17799 (* 1 = 0.17799 loss)
I0312 09:55:28.740658 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.384877 (* 1 = 0.384877 loss)
I0312 09:55:28.740677 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0539042 (* 1 = 0.0539042 loss)
I0312 09:55:28.740681 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.216292 (* 1 = 0.216292 loss)
I0312 09:55:28.740700 17663 sgd_solver.cpp:106] Iteration 73900, lr = 1e-10
speed: 0.525s / iter
I0312 09:56:22.212869 17663 solver.cpp:228] Iteration 74000, loss = 0.775389
I0312 09:56:22.212891 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0312 09:56:22.212898 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.367915 (* 1 = 0.367915 loss)
I0312 09:56:22.212916 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.527819 (* 1 = 0.527819 loss)
I0312 09:56:22.212921 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0562952 (* 1 = 0.0562952 loss)
I0312 09:56:22.212937 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.295076 (* 1 = 0.295076 loss)
I0312 09:56:22.212942 17663 sgd_solver.cpp:106] Iteration 74000, lr = 1e-10
I0312 09:57:13.784554 17663 solver.cpp:228] Iteration 74100, loss = 0.522304
I0312 09:57:13.784574 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 09:57:13.784581 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373723 (* 1 = 0.0373723 loss)
I0312 09:57:13.784600 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165107 (* 1 = 0.165107 loss)
I0312 09:57:13.784605 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011112 (* 1 = 0.011112 loss)
I0312 09:57:13.784608 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.261774 (* 1 = 0.261774 loss)
I0312 09:57:13.784626 17663 sgd_solver.cpp:106] Iteration 74100, lr = 1e-10
I0312 09:58:05.724293 17663 solver.cpp:228] Iteration 74200, loss = 0.399192
I0312 09:58:05.724315 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 09:58:05.724323 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124229 (* 1 = 0.124229 loss)
I0312 09:58:05.724341 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.09537 (* 1 = 0.09537 loss)
I0312 09:58:05.724345 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120301 (* 1 = 0.0120301 loss)
I0312 09:58:05.724362 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276835 (* 1 = 0.0276835 loss)
I0312 09:58:05.724367 17663 sgd_solver.cpp:106] Iteration 74200, lr = 1e-10
I0312 09:58:57.534701 17663 solver.cpp:228] Iteration 74300, loss = 0.805048
I0312 09:58:57.534723 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0312 09:58:57.534729 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.395802 (* 1 = 0.395802 loss)
I0312 09:58:57.534749 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.676876 (* 1 = 0.676876 loss)
I0312 09:58:57.534752 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.113991 (* 1 = 0.113991 loss)
I0312 09:58:57.534756 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.256024 (* 1 = 0.256024 loss)
I0312 09:58:57.534775 17663 sgd_solver.cpp:106] Iteration 74300, lr = 1e-10
I0312 09:59:49.864488 17663 solver.cpp:228] Iteration 74400, loss = 0.196168
I0312 09:59:49.864511 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 09:59:49.864517 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312075 (* 1 = 0.0312075 loss)
I0312 09:59:49.864522 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0706662 (* 1 = 0.0706662 loss)
I0312 09:59:49.864527 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00331091 (* 1 = 0.00331091 loss)
I0312 09:59:49.864531 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421561 (* 1 = 0.0421561 loss)
I0312 09:59:49.864536 17663 sgd_solver.cpp:106] Iteration 74400, lr = 1e-10
I0312 10:00:42.092818 17663 solver.cpp:228] Iteration 74500, loss = 0.25421
I0312 10:00:42.092839 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 10:00:42.092846 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115222 (* 1 = 0.0115222 loss)
I0312 10:00:42.092850 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.075079 (* 1 = 0.075079 loss)
I0312 10:00:42.092854 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00885161 (* 1 = 0.00885161 loss)
I0312 10:00:42.092874 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0287855 (* 1 = 0.0287855 loss)
I0312 10:00:42.092877 17663 sgd_solver.cpp:106] Iteration 74500, lr = 1e-10
I0312 10:01:34.854176 17663 solver.cpp:228] Iteration 74600, loss = 0.259539
I0312 10:01:34.854199 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:01:34.854207 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290524 (* 1 = 0.0290524 loss)
I0312 10:01:34.854225 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.075898 (* 1 = 0.075898 loss)
I0312 10:01:34.854230 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521936 (* 1 = 0.00521936 loss)
I0312 10:01:34.854248 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00747446 (* 1 = 0.00747446 loss)
I0312 10:01:34.854252 17663 sgd_solver.cpp:106] Iteration 74600, lr = 1e-10
I0312 10:02:27.989384 17663 solver.cpp:228] Iteration 74700, loss = 0.303468
I0312 10:02:27.989408 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 10:02:27.989416 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.138281 (* 1 = 0.138281 loss)
I0312 10:02:27.989435 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.262319 (* 1 = 0.262319 loss)
I0312 10:02:27.989439 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115121 (* 1 = 0.0115121 loss)
I0312 10:02:27.989444 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195311 (* 1 = 0.0195311 loss)
I0312 10:02:27.989449 17663 sgd_solver.cpp:106] Iteration 74700, lr = 1e-10
I0312 10:03:20.413511 17663 solver.cpp:228] Iteration 74800, loss = 0.416929
I0312 10:03:20.413533 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 10:03:20.413540 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18178 (* 1 = 0.18178 loss)
I0312 10:03:20.413558 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.299814 (* 1 = 0.299814 loss)
I0312 10:03:20.413563 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185531 (* 1 = 0.0185531 loss)
I0312 10:03:20.413568 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0972538 (* 1 = 0.0972538 loss)
I0312 10:03:20.413573 17663 sgd_solver.cpp:106] Iteration 74800, lr = 1e-10
I0312 10:04:12.810757 17663 solver.cpp:228] Iteration 74900, loss = 0.546592
I0312 10:04:12.810780 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 10:04:12.810786 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.100445 (* 1 = 0.100445 loss)
I0312 10:04:12.810791 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0841113 (* 1 = 0.0841113 loss)
I0312 10:04:12.810796 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181234 (* 1 = 0.0181234 loss)
I0312 10:04:12.810799 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190422 (* 1 = 0.0190422 loss)
I0312 10:04:12.810803 17663 sgd_solver.cpp:106] Iteration 74900, lr = 1e-10
speed: 0.525s / iter
I0312 10:05:05.603924 17663 solver.cpp:228] Iteration 75000, loss = 0.507301
I0312 10:05:05.604100 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 10:05:05.604141 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0660037 (* 1 = 0.0660037 loss)
I0312 10:05:05.604147 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104009 (* 1 = 0.104009 loss)
I0312 10:05:05.604164 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0067899 (* 1 = 0.0067899 loss)
I0312 10:05:05.604169 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0849365 (* 1 = 0.0849365 loss)
I0312 10:05:05.604188 17663 sgd_solver.cpp:106] Iteration 75000, lr = 1e-10
I0312 10:05:58.207043 17663 solver.cpp:228] Iteration 75100, loss = 0.232464
I0312 10:05:58.207063 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:05:58.207070 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0660875 (* 1 = 0.0660875 loss)
I0312 10:05:58.207075 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0629908 (* 1 = 0.0629908 loss)
I0312 10:05:58.207094 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00797261 (* 1 = 0.00797261 loss)
I0312 10:05:58.207098 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187761 (* 1 = 0.0187761 loss)
I0312 10:05:58.207103 17663 sgd_solver.cpp:106] Iteration 75100, lr = 1e-10
I0312 10:06:50.551218 17663 solver.cpp:228] Iteration 75200, loss = 0.227126
I0312 10:06:50.551240 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 10:06:50.551247 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0728985 (* 1 = 0.0728985 loss)
I0312 10:06:50.551266 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.160344 (* 1 = 0.160344 loss)
I0312 10:06:50.551270 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00457412 (* 1 = 0.00457412 loss)
I0312 10:06:50.551275 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187578 (* 1 = 0.0187578 loss)
I0312 10:06:50.551280 17663 sgd_solver.cpp:106] Iteration 75200, lr = 1e-10
I0312 10:07:42.790540 17663 solver.cpp:228] Iteration 75300, loss = 0.214797
I0312 10:07:42.790562 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 10:07:42.790570 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0800481 (* 1 = 0.0800481 loss)
I0312 10:07:42.790573 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170417 (* 1 = 0.170417 loss)
I0312 10:07:42.790592 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117712 (* 1 = 0.0117712 loss)
I0312 10:07:42.790596 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0422895 (* 1 = 0.0422895 loss)
I0312 10:07:42.790601 17663 sgd_solver.cpp:106] Iteration 75300, lr = 1e-10
I0312 10:08:35.659451 17663 solver.cpp:228] Iteration 75400, loss = 0.376528
I0312 10:08:35.659474 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 10:08:35.659482 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.118859 (* 1 = 0.118859 loss)
I0312 10:08:35.659502 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.166945 (* 1 = 0.166945 loss)
I0312 10:08:35.659505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02129 (* 1 = 0.02129 loss)
I0312 10:08:35.659509 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.247613 (* 1 = 0.247613 loss)
I0312 10:08:35.659514 17663 sgd_solver.cpp:106] Iteration 75400, lr = 1e-10
I0312 10:09:28.647821 17663 solver.cpp:228] Iteration 75500, loss = 0.393473
I0312 10:09:28.647842 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 10:09:28.647850 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244928 (* 1 = 0.0244928 loss)
I0312 10:09:28.647868 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0639598 (* 1 = 0.0639598 loss)
I0312 10:09:28.647872 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185316 (* 1 = 0.0185316 loss)
I0312 10:09:28.647876 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263896 (* 1 = 0.0263896 loss)
I0312 10:09:28.647881 17663 sgd_solver.cpp:106] Iteration 75500, lr = 1e-10
I0312 10:10:20.255574 17663 solver.cpp:228] Iteration 75600, loss = 0.313733
I0312 10:10:20.255595 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 10:10:20.255614 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00205392 (* 1 = 0.00205392 loss)
I0312 10:10:20.255633 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0479068 (* 1 = 0.0479068 loss)
I0312 10:10:20.255637 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.197793 (* 1 = 0.197793 loss)
I0312 10:10:20.255641 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.28227 (* 1 = 0.28227 loss)
I0312 10:10:20.255659 17663 sgd_solver.cpp:106] Iteration 75600, lr = 1e-10
I0312 10:11:13.402803 17663 solver.cpp:228] Iteration 75700, loss = 0.230041
I0312 10:11:13.402825 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:11:13.402833 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542838 (* 1 = 0.0542838 loss)
I0312 10:11:13.402837 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117762 (* 1 = 0.117762 loss)
I0312 10:11:13.402842 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0301816 (* 1 = 0.0301816 loss)
I0312 10:11:13.402845 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0411325 (* 1 = 0.0411325 loss)
I0312 10:11:13.402865 17663 sgd_solver.cpp:106] Iteration 75700, lr = 1e-10
I0312 10:12:05.324650 17663 solver.cpp:228] Iteration 75800, loss = 0.14805
I0312 10:12:05.324671 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:12:05.324678 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.115015 (* 1 = 0.115015 loss)
I0312 10:12:05.324697 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0926675 (* 1 = 0.0926675 loss)
I0312 10:12:05.324702 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00688287 (* 1 = 0.00688287 loss)
I0312 10:12:05.324705 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124386 (* 1 = 0.0124386 loss)
I0312 10:12:05.324723 17663 sgd_solver.cpp:106] Iteration 75800, lr = 1e-10
I0312 10:12:57.798102 17663 solver.cpp:228] Iteration 75900, loss = 0.141614
I0312 10:12:57.798125 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:12:57.798132 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0367685 (* 1 = 0.0367685 loss)
I0312 10:12:57.798151 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0871494 (* 1 = 0.0871494 loss)
I0312 10:12:57.798156 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858828 (* 1 = 0.00858828 loss)
I0312 10:12:57.798173 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183578 (* 1 = 0.0183578 loss)
I0312 10:12:57.798178 17663 sgd_solver.cpp:106] Iteration 75900, lr = 1e-10
speed: 0.525s / iter
I0312 10:13:49.857623 17663 solver.cpp:228] Iteration 76000, loss = 0.523156
I0312 10:13:49.857780 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 10:13:49.857836 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0862616 (* 1 = 0.0862616 loss)
I0312 10:13:49.857884 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.171446 (* 1 = 0.171446 loss)
I0312 10:13:49.857942 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.069596 (* 1 = 0.069596 loss)
I0312 10:13:49.857990 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0519989 (* 1 = 0.0519989 loss)
I0312 10:13:49.858038 17663 sgd_solver.cpp:106] Iteration 76000, lr = 1e-10
I0312 10:14:42.273433 17663 solver.cpp:228] Iteration 76100, loss = 0.688415
I0312 10:14:42.273455 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 10:14:42.273463 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220793 (* 1 = 0.0220793 loss)
I0312 10:14:42.273483 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.282617 (* 1 = 0.282617 loss)
I0312 10:14:42.273486 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.15328 (* 1 = 0.15328 loss)
I0312 10:14:42.273504 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.166743 (* 1 = 0.166743 loss)
I0312 10:14:42.273509 17663 sgd_solver.cpp:106] Iteration 76100, lr = 1e-10
I0312 10:15:34.362462 17663 solver.cpp:228] Iteration 76200, loss = 0.248874
I0312 10:15:34.362485 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:15:34.362493 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156562 (* 1 = 0.0156562 loss)
I0312 10:15:34.362511 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0985918 (* 1 = 0.0985918 loss)
I0312 10:15:34.362515 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0078724 (* 1 = 0.0078724 loss)
I0312 10:15:34.362520 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134856 (* 1 = 0.134856 loss)
I0312 10:15:34.362525 17663 sgd_solver.cpp:106] Iteration 76200, lr = 1e-10
I0312 10:16:26.760313 17663 solver.cpp:228] Iteration 76300, loss = 0.219212
I0312 10:16:26.760336 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 10:16:26.760344 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816793 (* 1 = 0.0816793 loss)
I0312 10:16:26.760362 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.203271 (* 1 = 0.203271 loss)
I0312 10:16:26.760366 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338157 (* 1 = 0.00338157 loss)
I0312 10:16:26.760370 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0349156 (* 1 = 0.0349156 loss)
I0312 10:16:26.760375 17663 sgd_solver.cpp:106] Iteration 76300, lr = 1e-10
I0312 10:17:18.630993 17663 solver.cpp:228] Iteration 76400, loss = 0.431947
I0312 10:17:18.631016 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 10:17:18.631024 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.220098 (* 1 = 0.220098 loss)
I0312 10:17:18.631029 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.345646 (* 1 = 0.345646 loss)
I0312 10:17:18.631033 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124572 (* 1 = 0.0124572 loss)
I0312 10:17:18.631036 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267223 (* 1 = 0.0267223 loss)
I0312 10:17:18.631057 17663 sgd_solver.cpp:106] Iteration 76400, lr = 1e-10
I0312 10:18:11.652775 17663 solver.cpp:228] Iteration 76500, loss = 0.376473
I0312 10:18:11.652797 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 10:18:11.652806 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0864707 (* 1 = 0.0864707 loss)
I0312 10:18:11.652824 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17949 (* 1 = 0.17949 loss)
I0312 10:18:11.652829 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200142 (* 1 = 0.00200142 loss)
I0312 10:18:11.652833 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121174 (* 1 = 0.0121174 loss)
I0312 10:18:11.652838 17663 sgd_solver.cpp:106] Iteration 76500, lr = 1e-10
I0312 10:19:04.201586 17663 solver.cpp:228] Iteration 76600, loss = 0.292694
I0312 10:19:04.201613 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 10:19:04.201622 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0847353 (* 1 = 0.0847353 loss)
I0312 10:19:04.201640 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.203337 (* 1 = 0.203337 loss)
I0312 10:19:04.201645 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137424 (* 1 = 0.0137424 loss)
I0312 10:19:04.201649 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127145 (* 1 = 0.127145 loss)
I0312 10:19:04.201654 17663 sgd_solver.cpp:106] Iteration 76600, lr = 1e-10
I0312 10:19:56.740602 17663 solver.cpp:228] Iteration 76700, loss = 0.742115
I0312 10:19:56.740624 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 10:19:56.740631 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.208097 (* 1 = 0.208097 loss)
I0312 10:19:56.740636 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.436673 (* 1 = 0.436673 loss)
I0312 10:19:56.740655 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0564356 (* 1 = 0.0564356 loss)
I0312 10:19:56.740659 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339974 (* 1 = 0.0339974 loss)
I0312 10:19:56.740664 17663 sgd_solver.cpp:106] Iteration 76700, lr = 1e-10
I0312 10:20:48.658339 17663 solver.cpp:228] Iteration 76800, loss = 0.203821
I0312 10:20:48.658360 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 10:20:48.658366 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0647719 (* 1 = 0.0647719 loss)
I0312 10:20:48.658370 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100918 (* 1 = 0.100918 loss)
I0312 10:20:48.658388 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157967 (* 1 = 0.0157967 loss)
I0312 10:20:48.658392 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322821 (* 1 = 0.0322821 loss)
I0312 10:20:48.658411 17663 sgd_solver.cpp:106] Iteration 76800, lr = 1e-10
I0312 10:21:41.176072 17663 solver.cpp:228] Iteration 76900, loss = 0.283154
I0312 10:21:41.176096 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 10:21:41.176103 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0618603 (* 1 = 0.0618603 loss)
I0312 10:21:41.176122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188057 (* 1 = 0.188057 loss)
I0312 10:21:41.176127 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0547858 (* 1 = 0.0547858 loss)
I0312 10:21:41.176131 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0709929 (* 1 = 0.0709929 loss)
I0312 10:21:41.176136 17663 sgd_solver.cpp:106] Iteration 76900, lr = 1e-10
speed: 0.525s / iter
I0312 10:22:34.155848 17663 solver.cpp:228] Iteration 77000, loss = 0.381816
I0312 10:22:34.156002 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 10:22:34.156060 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.2536 (* 1 = 0.2536 loss)
I0312 10:22:34.156108 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.310021 (* 1 = 0.310021 loss)
I0312 10:22:34.156155 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136474 (* 1 = 0.0136474 loss)
I0312 10:22:34.156203 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100569 (* 1 = 0.100569 loss)
I0312 10:22:34.156250 17663 sgd_solver.cpp:106] Iteration 77000, lr = 1e-10
I0312 10:23:26.555903 17663 solver.cpp:228] Iteration 77100, loss = 0.275673
I0312 10:23:26.555924 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 10:23:26.555932 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0913329 (* 1 = 0.0913329 loss)
I0312 10:23:26.555951 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186555 (* 1 = 0.186555 loss)
I0312 10:23:26.555955 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0257163 (* 1 = 0.0257163 loss)
I0312 10:23:26.555959 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282052 (* 1 = 0.0282052 loss)
I0312 10:23:26.555964 17663 sgd_solver.cpp:106] Iteration 77100, lr = 1e-10
I0312 10:24:18.900377 17663 solver.cpp:228] Iteration 77200, loss = 0.266269
I0312 10:24:18.900399 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:24:18.900408 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.105258 (* 1 = 0.105258 loss)
I0312 10:24:18.900427 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.153611 (* 1 = 0.153611 loss)
I0312 10:24:18.900431 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00814426 (* 1 = 0.00814426 loss)
I0312 10:24:18.900436 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229671 (* 1 = 0.0229671 loss)
I0312 10:24:18.900441 17663 sgd_solver.cpp:106] Iteration 77200, lr = 1e-10
I0312 10:25:10.915098 17663 solver.cpp:228] Iteration 77300, loss = 0.653909
I0312 10:25:10.915122 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 10:25:10.915128 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815717 (* 1 = 0.0815717 loss)
I0312 10:25:10.915148 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.237417 (* 1 = 0.237417 loss)
I0312 10:25:10.915151 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0525308 (* 1 = 0.0525308 loss)
I0312 10:25:10.915155 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.210335 (* 1 = 0.210335 loss)
I0312 10:25:10.915160 17663 sgd_solver.cpp:106] Iteration 77300, lr = 1e-10
I0312 10:26:03.433060 17663 solver.cpp:228] Iteration 77400, loss = 1.02344
I0312 10:26:03.433084 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:26:03.433091 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0389881 (* 1 = 0.0389881 loss)
I0312 10:26:03.433110 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.060849 (* 1 = 0.060849 loss)
I0312 10:26:03.433115 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169272 (* 1 = 0.00169272 loss)
I0312 10:26:03.433120 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015223 (* 1 = 0.015223 loss)
I0312 10:26:03.433125 17663 sgd_solver.cpp:106] Iteration 77400, lr = 1e-10
I0312 10:26:55.782254 17663 solver.cpp:228] Iteration 77500, loss = 0.292382
I0312 10:26:55.782275 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 10:26:55.782282 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195832 (* 1 = 0.0195832 loss)
I0312 10:26:55.782301 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121487 (* 1 = 0.121487 loss)
I0312 10:26:55.782305 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0560343 (* 1 = 0.0560343 loss)
I0312 10:26:55.782310 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181465 (* 1 = 0.0181465 loss)
I0312 10:26:55.782326 17663 sgd_solver.cpp:106] Iteration 77500, lr = 1e-10
I0312 10:27:48.633288 17663 solver.cpp:228] Iteration 77600, loss = 0.680941
I0312 10:27:48.633311 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0312 10:27:48.633318 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.282116 (* 1 = 0.282116 loss)
I0312 10:27:48.633337 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.545717 (* 1 = 0.545717 loss)
I0312 10:27:48.633342 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0486132 (* 1 = 0.0486132 loss)
I0312 10:27:48.633347 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0863072 (* 1 = 0.0863072 loss)
I0312 10:27:48.633352 17663 sgd_solver.cpp:106] Iteration 77600, lr = 1e-10
I0312 10:28:40.884763 17663 solver.cpp:228] Iteration 77700, loss = 0.199248
I0312 10:28:40.884786 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 10:28:40.884793 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243646 (* 1 = 0.0243646 loss)
I0312 10:28:40.884814 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0355287 (* 1 = 0.0355287 loss)
I0312 10:28:40.884817 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148897 (* 1 = 0.0148897 loss)
I0312 10:28:40.884821 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.114005 (* 1 = 0.114005 loss)
I0312 10:28:40.884838 17663 sgd_solver.cpp:106] Iteration 77700, lr = 1e-10
I0312 10:29:33.711913 17663 solver.cpp:228] Iteration 77800, loss = 0.422804
I0312 10:29:33.711935 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 10:29:33.711941 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.128414 (* 1 = 0.128414 loss)
I0312 10:29:33.711946 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.193587 (* 1 = 0.193587 loss)
I0312 10:29:33.711964 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170638 (* 1 = 0.0170638 loss)
I0312 10:29:33.711968 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0900675 (* 1 = 0.0900675 loss)
I0312 10:29:33.711973 17663 sgd_solver.cpp:106] Iteration 77800, lr = 1e-10
I0312 10:30:25.749867 17663 solver.cpp:228] Iteration 77900, loss = 0.113295
I0312 10:30:25.749889 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:30:25.749900 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339625 (* 1 = 0.0339625 loss)
I0312 10:30:25.749905 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0745693 (* 1 = 0.0745693 loss)
I0312 10:30:25.749924 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00547933 (* 1 = 0.00547933 loss)
I0312 10:30:25.749928 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197577 (* 1 = 0.0197577 loss)
I0312 10:30:25.749945 17663 sgd_solver.cpp:106] Iteration 77900, lr = 1e-10
speed: 0.525s / iter
I0312 10:31:18.028451 17663 solver.cpp:228] Iteration 78000, loss = 0.237447
I0312 10:31:18.028612 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:31:18.028669 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447315 (* 1 = 0.0447315 loss)
I0312 10:31:18.028718 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0851995 (* 1 = 0.0851995 loss)
I0312 10:31:18.028765 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156726 (* 1 = 0.0156726 loss)
I0312 10:31:18.028813 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00231922 (* 1 = 0.00231922 loss)
I0312 10:31:18.028859 17663 sgd_solver.cpp:106] Iteration 78000, lr = 1e-10
I0312 10:32:10.692181 17663 solver.cpp:228] Iteration 78100, loss = 0.29748
I0312 10:32:10.692205 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:32:10.692212 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.05978 (* 1 = 0.05978 loss)
I0312 10:32:10.692231 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123155 (* 1 = 0.123155 loss)
I0312 10:32:10.692235 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027193 (* 1 = 0.027193 loss)
I0312 10:32:10.692239 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0441763 (* 1 = 0.0441763 loss)
I0312 10:32:10.692245 17663 sgd_solver.cpp:106] Iteration 78100, lr = 1e-10
I0312 10:33:03.263679 17663 solver.cpp:228] Iteration 78200, loss = 0.389182
I0312 10:33:03.263702 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 10:33:03.263710 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.166209 (* 1 = 0.166209 loss)
I0312 10:33:03.263730 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219018 (* 1 = 0.219018 loss)
I0312 10:33:03.263733 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0433585 (* 1 = 0.0433585 loss)
I0312 10:33:03.263737 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.141285 (* 1 = 0.141285 loss)
I0312 10:33:03.263742 17663 sgd_solver.cpp:106] Iteration 78200, lr = 1e-10
I0312 10:33:55.945451 17663 solver.cpp:228] Iteration 78300, loss = 0.193245
I0312 10:33:55.945474 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 10:33:55.945482 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666249 (* 1 = 0.0666249 loss)
I0312 10:33:55.945487 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172341 (* 1 = 0.172341 loss)
I0312 10:33:55.945505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561795 (* 1 = 0.00561795 loss)
I0312 10:33:55.945510 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019634 (* 1 = 0.019634 loss)
I0312 10:33:55.945515 17663 sgd_solver.cpp:106] Iteration 78300, lr = 1e-10
I0312 10:34:48.818017 17663 solver.cpp:228] Iteration 78400, loss = 0.162918
I0312 10:34:48.818212 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 10:34:48.818269 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326904 (* 1 = 0.0326904 loss)
I0312 10:34:48.818316 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0840633 (* 1 = 0.0840633 loss)
I0312 10:34:48.818352 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00819657 (* 1 = 0.00819657 loss)
I0312 10:34:48.818367 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172443 (* 1 = 0.0172443 loss)
I0312 10:34:48.818374 17663 sgd_solver.cpp:106] Iteration 78400, lr = 1e-10
I0312 10:35:41.507274 17663 solver.cpp:228] Iteration 78500, loss = 0.274868
I0312 10:35:41.507299 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 10:35:41.507308 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719449 (* 1 = 0.0719449 loss)
I0312 10:35:41.507326 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188584 (* 1 = 0.188584 loss)
I0312 10:35:41.507330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0527618 (* 1 = 0.0527618 loss)
I0312 10:35:41.507334 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358135 (* 1 = 0.0358135 loss)
I0312 10:35:41.507340 17663 sgd_solver.cpp:106] Iteration 78500, lr = 1e-10
I0312 10:36:33.514467 17663 solver.cpp:228] Iteration 78600, loss = 0.166791
I0312 10:36:33.514494 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:36:33.514503 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295209 (* 1 = 0.0295209 loss)
I0312 10:36:33.514523 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0986553 (* 1 = 0.0986553 loss)
I0312 10:36:33.514528 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100535 (* 1 = 0.0100535 loss)
I0312 10:36:33.514531 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117459 (* 1 = 0.0117459 loss)
I0312 10:36:33.514536 17663 sgd_solver.cpp:106] Iteration 78600, lr = 1e-10
I0312 10:37:25.865355 17663 solver.cpp:228] Iteration 78700, loss = 0.234117
I0312 10:37:25.865375 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 10:37:25.865382 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236922 (* 1 = 0.0236922 loss)
I0312 10:37:25.865401 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.259918 (* 1 = 0.259918 loss)
I0312 10:37:25.865406 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00367466 (* 1 = 0.00367466 loss)
I0312 10:37:25.865409 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00265053 (* 1 = 0.00265053 loss)
I0312 10:37:25.865414 17663 sgd_solver.cpp:106] Iteration 78700, lr = 1e-10
I0312 10:38:17.886809 17663 solver.cpp:228] Iteration 78800, loss = 0.215133
I0312 10:38:17.886832 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 10:38:17.886840 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0875905 (* 1 = 0.0875905 loss)
I0312 10:38:17.886844 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172049 (* 1 = 0.172049 loss)
I0312 10:38:17.886863 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145346 (* 1 = 0.0145346 loss)
I0312 10:38:17.886868 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352707 (* 1 = 0.0352707 loss)
I0312 10:38:17.886873 17663 sgd_solver.cpp:106] Iteration 78800, lr = 1e-10
I0312 10:39:10.468622 17663 solver.cpp:228] Iteration 78900, loss = 0.489361
I0312 10:39:10.468646 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 10:39:10.468652 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.145304 (* 1 = 0.145304 loss)
I0312 10:39:10.468657 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.278805 (* 1 = 0.278805 loss)
I0312 10:39:10.468677 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226521 (* 1 = 0.0226521 loss)
I0312 10:39:10.468680 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0467667 (* 1 = 0.0467667 loss)
I0312 10:39:10.468685 17663 sgd_solver.cpp:106] Iteration 78900, lr = 1e-10
speed: 0.525s / iter
I0312 10:40:02.716495 17663 solver.cpp:228] Iteration 79000, loss = 0.110617
I0312 10:40:02.716655 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 10:40:02.716712 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00970686 (* 1 = 0.00970686 loss)
I0312 10:40:02.716761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0303184 (* 1 = 0.0303184 loss)
I0312 10:40:02.716809 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247173 (* 1 = 0.00247173 loss)
I0312 10:40:02.716856 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274178 (* 1 = 0.0274178 loss)
I0312 10:40:02.716902 17663 sgd_solver.cpp:106] Iteration 79000, lr = 1e-10
I0312 10:40:54.938843 17663 solver.cpp:228] Iteration 79100, loss = 0.655568
I0312 10:40:54.938864 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 10:40:54.938871 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.167189 (* 1 = 0.167189 loss)
I0312 10:40:54.938890 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.271076 (* 1 = 0.271076 loss)
I0312 10:40:54.938894 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.15319 (* 1 = 0.15319 loss)
I0312 10:40:54.938899 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185889 (* 1 = 0.185889 loss)
I0312 10:40:54.938916 17663 sgd_solver.cpp:106] Iteration 79100, lr = 1e-10
I0312 10:41:47.472247 17663 solver.cpp:228] Iteration 79200, loss = 0.421652
I0312 10:41:47.472280 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 10:41:47.472287 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0673193 (* 1 = 0.0673193 loss)
I0312 10:41:47.472306 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.177673 (* 1 = 0.177673 loss)
I0312 10:41:47.472311 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737715 (* 1 = 0.00737715 loss)
I0312 10:41:47.472326 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050171 (* 1 = 0.050171 loss)
I0312 10:41:47.472332 17663 sgd_solver.cpp:106] Iteration 79200, lr = 1e-10
I0312 10:42:39.991305 17663 solver.cpp:228] Iteration 79300, loss = 0.409174
I0312 10:42:39.991327 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 10:42:39.991333 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0260754 (* 1 = 0.0260754 loss)
I0312 10:42:39.991338 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104032 (* 1 = 0.104032 loss)
I0312 10:42:39.991343 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00426877 (* 1 = 0.00426877 loss)
I0312 10:42:39.991346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.184098 (* 1 = 0.184098 loss)
I0312 10:42:39.991351 17663 sgd_solver.cpp:106] Iteration 79300, lr = 1e-10
I0312 10:43:32.232764 17663 solver.cpp:228] Iteration 79400, loss = 0.430445
I0312 10:43:32.232794 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 10:43:32.232815 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124605 (* 1 = 0.124605 loss)
I0312 10:43:32.232820 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180992 (* 1 = 0.180992 loss)
I0312 10:43:32.232825 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0994792 (* 1 = 0.0994792 loss)
I0312 10:43:32.232828 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164937 (* 1 = 0.164937 loss)
I0312 10:43:32.232836 17663 sgd_solver.cpp:106] Iteration 79400, lr = 1e-10
I0312 10:44:24.773705 17663 solver.cpp:228] Iteration 79500, loss = 0.1989
I0312 10:44:24.773726 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:44:24.773733 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244173 (* 1 = 0.0244173 loss)
I0312 10:44:24.773752 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0975494 (* 1 = 0.0975494 loss)
I0312 10:44:24.773756 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00447747 (* 1 = 0.00447747 loss)
I0312 10:44:24.773761 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00207282 (* 1 = 0.00207282 loss)
I0312 10:44:24.773766 17663 sgd_solver.cpp:106] Iteration 79500, lr = 1e-10
I0312 10:45:17.230726 17663 solver.cpp:228] Iteration 79600, loss = 0.425024
I0312 10:45:17.230747 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 10:45:17.230754 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.114427 (* 1 = 0.114427 loss)
I0312 10:45:17.230773 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.184259 (* 1 = 0.184259 loss)
I0312 10:45:17.230778 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00910315 (* 1 = 0.00910315 loss)
I0312 10:45:17.230782 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0475568 (* 1 = 0.0475568 loss)
I0312 10:45:17.230800 17663 sgd_solver.cpp:106] Iteration 79600, lr = 1e-10
I0312 10:46:09.592141 17663 solver.cpp:228] Iteration 79700, loss = 0.429414
I0312 10:46:09.592165 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 10:46:09.592172 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374832 (* 1 = 0.0374832 loss)
I0312 10:46:09.592192 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198501 (* 1 = 0.198501 loss)
I0312 10:46:09.592196 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189972 (* 1 = 0.00189972 loss)
I0312 10:46:09.592200 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0915251 (* 1 = 0.0915251 loss)
I0312 10:46:09.592206 17663 sgd_solver.cpp:106] Iteration 79700, lr = 1e-10
I0312 10:47:02.326733 17663 solver.cpp:228] Iteration 79800, loss = 0.292673
I0312 10:47:02.326756 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:47:02.326763 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566061 (* 1 = 0.0566061 loss)
I0312 10:47:02.326783 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0889312 (* 1 = 0.0889312 loss)
I0312 10:47:02.326787 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202463 (* 1 = 0.0202463 loss)
I0312 10:47:02.326792 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265439 (* 1 = 0.0265439 loss)
I0312 10:47:02.326797 17663 sgd_solver.cpp:106] Iteration 79800, lr = 1e-10
I0312 10:47:54.319594 17663 solver.cpp:228] Iteration 79900, loss = 0.41075
I0312 10:47:54.319617 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:47:54.319625 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653434 (* 1 = 0.0653434 loss)
I0312 10:47:54.319644 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123321 (* 1 = 0.123321 loss)
I0312 10:47:54.319648 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201319 (* 1 = 0.0201319 loss)
I0312 10:47:54.319653 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0840386 (* 1 = 0.0840386 loss)
I0312 10:47:54.319658 17663 sgd_solver.cpp:106] Iteration 79900, lr = 1e-10
I0312 10:48:46.057224 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_80000.caffemodel
I0312 10:48:46.584448 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_80000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_80000.caffemodel
I0312 10:48:47.668923 17663 solver.cpp:228] Iteration 80000, loss = 0.222295
I0312 10:48:47.668947 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 10:48:47.668954 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0639254 (* 1 = 0.0639254 loss)
I0312 10:48:47.668974 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.076983 (* 1 = 0.076983 loss)
I0312 10:48:47.668978 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00156481 (* 1 = 0.00156481 loss)
I0312 10:48:47.668982 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238038 (* 1 = 0.0238038 loss)
I0312 10:48:47.668987 17663 sgd_solver.cpp:106] Iteration 80000, lr = 1e-11
I0312 10:49:40.202267 17663 solver.cpp:228] Iteration 80100, loss = 1.19817
I0312 10:49:40.202289 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:49:40.202297 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278037 (* 1 = 0.0278037 loss)
I0312 10:49:40.202316 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146265 (* 1 = 0.146265 loss)
I0312 10:49:40.202319 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279332 (* 1 = 0.0279332 loss)
I0312 10:49:40.202337 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448747 (* 1 = 0.0448747 loss)
I0312 10:49:40.202342 17663 sgd_solver.cpp:106] Iteration 80100, lr = 1e-11
I0312 10:50:33.224603 17663 solver.cpp:228] Iteration 80200, loss = 0.287552
I0312 10:50:33.224624 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 10:50:33.224632 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447195 (* 1 = 0.0447195 loss)
I0312 10:50:33.224651 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198867 (* 1 = 0.198867 loss)
I0312 10:50:33.224655 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364508 (* 1 = 0.0364508 loss)
I0312 10:50:33.224659 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.179507 (* 1 = 0.179507 loss)
I0312 10:50:33.224664 17663 sgd_solver.cpp:106] Iteration 80200, lr = 1e-11
I0312 10:51:25.566268 17663 solver.cpp:228] Iteration 80300, loss = 0.439991
I0312 10:51:25.566295 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 10:51:25.566304 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.216031 (* 1 = 0.216031 loss)
I0312 10:51:25.566309 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.328483 (* 1 = 0.328483 loss)
I0312 10:51:25.566313 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040697 (* 1 = 0.040697 loss)
I0312 10:51:25.566318 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0964772 (* 1 = 0.0964772 loss)
I0312 10:51:25.566337 17663 sgd_solver.cpp:106] Iteration 80300, lr = 1e-11
I0312 10:52:18.380517 17663 solver.cpp:228] Iteration 80400, loss = 0.419264
I0312 10:52:18.380539 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:52:18.380547 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613287 (* 1 = 0.0613287 loss)
I0312 10:52:18.380551 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0946214 (* 1 = 0.0946214 loss)
I0312 10:52:18.380555 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150343 (* 1 = 0.00150343 loss)
I0312 10:52:18.380559 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104694 (* 1 = 0.0104694 loss)
I0312 10:52:18.380564 17663 sgd_solver.cpp:106] Iteration 80400, lr = 1e-11
I0312 10:53:11.031021 17663 solver.cpp:228] Iteration 80500, loss = 0.723766
I0312 10:53:11.031044 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 10:53:11.031051 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186247 (* 1 = 0.0186247 loss)
I0312 10:53:11.031056 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0555509 (* 1 = 0.0555509 loss)
I0312 10:53:11.031075 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00795059 (* 1 = 0.00795059 loss)
I0312 10:53:11.031080 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139097 (* 1 = 0.0139097 loss)
I0312 10:53:11.031098 17663 sgd_solver.cpp:106] Iteration 80500, lr = 1e-11
I0312 10:54:03.777079 17663 solver.cpp:228] Iteration 80600, loss = 0.291362
I0312 10:54:03.777101 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:54:03.777108 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.028132 (* 1 = 0.028132 loss)
I0312 10:54:03.777113 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0887908 (* 1 = 0.0887908 loss)
I0312 10:54:03.777132 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0036506 (* 1 = 0.0036506 loss)
I0312 10:54:03.777137 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317799 (* 1 = 0.0317799 loss)
I0312 10:54:03.777142 17663 sgd_solver.cpp:106] Iteration 80600, lr = 1e-11
I0312 10:54:56.134582 17663 solver.cpp:228] Iteration 80700, loss = 0.269024
I0312 10:54:56.134603 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 10:54:56.134610 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.103571 (* 1 = 0.103571 loss)
I0312 10:54:56.134615 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.125349 (* 1 = 0.125349 loss)
I0312 10:54:56.134634 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314826 (* 1 = 0.0314826 loss)
I0312 10:54:56.134639 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323013 (* 1 = 0.0323013 loss)
I0312 10:54:56.134644 17663 sgd_solver.cpp:106] Iteration 80700, lr = 1e-11
I0312 10:55:48.309139 17663 solver.cpp:228] Iteration 80800, loss = 0.337937
I0312 10:55:48.309161 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 10:55:48.309168 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0926466 (* 1 = 0.0926466 loss)
I0312 10:55:48.309172 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.187165 (* 1 = 0.187165 loss)
I0312 10:55:48.309190 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198133 (* 1 = 0.00198133 loss)
I0312 10:55:48.309195 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011295 (* 1 = 0.011295 loss)
I0312 10:55:48.309201 17663 sgd_solver.cpp:106] Iteration 80800, lr = 1e-11
I0312 10:56:40.524189 17663 solver.cpp:228] Iteration 80900, loss = 0.420034
I0312 10:56:40.524211 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 10:56:40.524219 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890721 (* 1 = 0.0890721 loss)
I0312 10:56:40.524237 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.132908 (* 1 = 0.132908 loss)
I0312 10:56:40.524241 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026322 (* 1 = 0.0026322 loss)
I0312 10:56:40.524245 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346563 (* 1 = 0.0346563 loss)
I0312 10:56:40.524263 17663 sgd_solver.cpp:106] Iteration 80900, lr = 1e-11
speed: 0.525s / iter
I0312 10:57:32.696279 17663 solver.cpp:228] Iteration 81000, loss = 0.343984
I0312 10:57:32.696410 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 10:57:32.696466 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0118184 (* 1 = 0.0118184 loss)
I0312 10:57:32.696516 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0687743 (* 1 = 0.0687743 loss)
I0312 10:57:32.696534 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00543291 (* 1 = 0.00543291 loss)
I0312 10:57:32.696540 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319002 (* 1 = 0.0319002 loss)
I0312 10:57:32.696547 17663 sgd_solver.cpp:106] Iteration 81000, lr = 1e-11
I0312 10:58:25.096371 17663 solver.cpp:228] Iteration 81100, loss = 0.186727
I0312 10:58:25.096392 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 10:58:25.096400 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368146 (* 1 = 0.0368146 loss)
I0312 10:58:25.096418 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0834279 (* 1 = 0.0834279 loss)
I0312 10:58:25.096422 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109404 (* 1 = 0.0109404 loss)
I0312 10:58:25.096426 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0497462 (* 1 = 0.0497462 loss)
I0312 10:58:25.096431 17663 sgd_solver.cpp:106] Iteration 81100, lr = 1e-11
I0312 10:59:17.965363 17663 solver.cpp:228] Iteration 81200, loss = 0.618107
I0312 10:59:17.965385 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 10:59:17.965407 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273717 (* 1 = 0.0273717 loss)
I0312 10:59:17.965425 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.120021 (* 1 = 0.120021 loss)
I0312 10:59:17.965430 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0333619 (* 1 = 0.0333619 loss)
I0312 10:59:17.965448 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0957233 (* 1 = 0.0957233 loss)
I0312 10:59:17.965454 17663 sgd_solver.cpp:106] Iteration 81200, lr = 1e-11
I0312 11:00:10.557813 17663 solver.cpp:228] Iteration 81300, loss = 0.243488
I0312 11:00:10.557838 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 11:00:10.557845 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312588 (* 1 = 0.0312588 loss)
I0312 11:00:10.557850 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13668 (* 1 = 0.13668 loss)
I0312 11:00:10.557855 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144369 (* 1 = 0.0144369 loss)
I0312 11:00:10.557873 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00890704 (* 1 = 0.00890704 loss)
I0312 11:00:10.557878 17663 sgd_solver.cpp:106] Iteration 81300, lr = 1e-11
I0312 11:01:03.129902 17663 solver.cpp:228] Iteration 81400, loss = 0.436545
I0312 11:01:03.129952 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:01:03.129974 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593635 (* 1 = 0.0593635 loss)
I0312 11:01:03.129979 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183845 (* 1 = 0.183845 loss)
I0312 11:01:03.129984 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00812041 (* 1 = 0.00812041 loss)
I0312 11:01:03.129988 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194594 (* 1 = 0.0194594 loss)
I0312 11:01:03.129993 17663 sgd_solver.cpp:106] Iteration 81400, lr = 1e-11
I0312 11:01:55.916733 17663 solver.cpp:228] Iteration 81500, loss = 0.456306
I0312 11:01:55.916755 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 11:01:55.916762 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.259305 (* 1 = 0.259305 loss)
I0312 11:01:55.916781 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.365008 (* 1 = 0.365008 loss)
I0312 11:01:55.916785 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00667594 (* 1 = 0.00667594 loss)
I0312 11:01:55.916790 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451255 (* 1 = 0.0451255 loss)
I0312 11:01:55.916807 17663 sgd_solver.cpp:106] Iteration 81500, lr = 1e-11
I0312 11:02:48.573096 17663 solver.cpp:228] Iteration 81600, loss = 0.259618
I0312 11:02:48.573117 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 11:02:48.573125 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0114489 (* 1 = 0.0114489 loss)
I0312 11:02:48.573144 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0292691 (* 1 = 0.0292691 loss)
I0312 11:02:48.573148 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00219408 (* 1 = 0.00219408 loss)
I0312 11:02:48.573153 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021816 (* 1 = 0.021816 loss)
I0312 11:02:48.573158 17663 sgd_solver.cpp:106] Iteration 81600, lr = 1e-11
I0312 11:03:41.005897 17663 solver.cpp:228] Iteration 81700, loss = 0.718274
I0312 11:03:41.005939 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 11:03:41.005945 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.319422 (* 1 = 0.319422 loss)
I0312 11:03:41.005964 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.491528 (* 1 = 0.491528 loss)
I0312 11:03:41.005967 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.113164 (* 1 = 0.113164 loss)
I0312 11:03:41.005986 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.25188 (* 1 = 0.25188 loss)
I0312 11:03:41.005991 17663 sgd_solver.cpp:106] Iteration 81700, lr = 1e-11
I0312 11:04:32.932420 17663 solver.cpp:228] Iteration 81800, loss = 0.447266
I0312 11:04:32.932443 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 11:04:32.932451 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827176 (* 1 = 0.0827176 loss)
I0312 11:04:32.932456 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102177 (* 1 = 0.102177 loss)
I0312 11:04:32.932474 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0224141 (* 1 = 0.0224141 loss)
I0312 11:04:32.932478 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.182375 (* 1 = 0.182375 loss)
I0312 11:04:32.932483 17663 sgd_solver.cpp:106] Iteration 81800, lr = 1e-11
I0312 11:05:24.882943 17663 solver.cpp:228] Iteration 81900, loss = 0.309591
I0312 11:05:24.882966 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 11:05:24.882972 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357419 (* 1 = 0.0357419 loss)
I0312 11:05:24.882977 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0637977 (* 1 = 0.0637977 loss)
I0312 11:05:24.882995 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00908693 (* 1 = 0.00908693 loss)
I0312 11:05:24.882999 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190747 (* 1 = 0.0190747 loss)
I0312 11:05:24.883004 17663 sgd_solver.cpp:106] Iteration 81900, lr = 1e-11
speed: 0.525s / iter
I0312 11:06:17.357226 17663 solver.cpp:228] Iteration 82000, loss = 0.336457
I0312 11:06:17.357358 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 11:06:17.357415 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.122708 (* 1 = 0.122708 loss)
I0312 11:06:17.357463 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.214485 (* 1 = 0.214485 loss)
I0312 11:06:17.357509 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.129628 (* 1 = 0.129628 loss)
I0312 11:06:17.357556 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.078561 (* 1 = 0.078561 loss)
I0312 11:06:17.357604 17663 sgd_solver.cpp:106] Iteration 82000, lr = 1e-11
I0312 11:07:09.924288 17663 solver.cpp:228] Iteration 82100, loss = 0.857375
I0312 11:07:09.924311 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:07:09.924319 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.181698 (* 1 = 0.181698 loss)
I0312 11:07:09.924324 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.208202 (* 1 = 0.208202 loss)
I0312 11:07:09.924342 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0352765 (* 1 = 0.0352765 loss)
I0312 11:07:09.924346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.212061 (* 1 = 0.212061 loss)
I0312 11:07:09.924351 17663 sgd_solver.cpp:106] Iteration 82100, lr = 1e-11
I0312 11:08:02.124388 17663 solver.cpp:228] Iteration 82200, loss = 0.227847
I0312 11:08:02.124409 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:08:02.124416 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608621 (* 1 = 0.0608621 loss)
I0312 11:08:02.124421 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.177324 (* 1 = 0.177324 loss)
I0312 11:08:02.124439 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137524 (* 1 = 0.0137524 loss)
I0312 11:08:02.124444 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01744 (* 1 = 0.01744 loss)
I0312 11:08:02.124449 17663 sgd_solver.cpp:106] Iteration 82200, lr = 1e-11
I0312 11:08:55.419752 17663 solver.cpp:228] Iteration 82300, loss = 0.324679
I0312 11:08:55.419776 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 11:08:55.419783 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544675 (* 1 = 0.0544675 loss)
I0312 11:08:55.419788 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.118947 (* 1 = 0.118947 loss)
I0312 11:08:55.419807 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00096393 (* 1 = 0.00096393 loss)
I0312 11:08:55.419811 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221359 (* 1 = 0.0221359 loss)
I0312 11:08:55.419817 17663 sgd_solver.cpp:106] Iteration 82300, lr = 1e-11
I0312 11:09:47.275136 17663 solver.cpp:228] Iteration 82400, loss = 0.224607
I0312 11:09:47.275158 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:09:47.275166 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532149 (* 1 = 0.0532149 loss)
I0312 11:09:47.275184 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0970836 (* 1 = 0.0970836 loss)
I0312 11:09:47.275188 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111631 (* 1 = 0.0111631 loss)
I0312 11:09:47.275192 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0551941 (* 1 = 0.0551941 loss)
I0312 11:09:47.275197 17663 sgd_solver.cpp:106] Iteration 82400, lr = 1e-11
I0312 11:10:40.407212 17663 solver.cpp:228] Iteration 82500, loss = 0.146392
I0312 11:10:40.407232 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 11:10:40.407239 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0787983 (* 1 = 0.0787983 loss)
I0312 11:10:40.407243 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12646 (* 1 = 0.12646 loss)
I0312 11:10:40.407263 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801478 (* 1 = 0.00801478 loss)
I0312 11:10:40.407266 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155313 (* 1 = 0.0155313 loss)
I0312 11:10:40.407271 17663 sgd_solver.cpp:106] Iteration 82500, lr = 1e-11
I0312 11:11:33.341707 17663 solver.cpp:228] Iteration 82600, loss = 0.228455
I0312 11:11:33.341730 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 11:11:33.341738 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379919 (* 1 = 0.0379919 loss)
I0312 11:11:33.341758 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.149257 (* 1 = 0.149257 loss)
I0312 11:11:33.341763 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539286 (* 1 = 0.00539286 loss)
I0312 11:11:33.341766 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131639 (* 1 = 0.0131639 loss)
I0312 11:11:33.341771 17663 sgd_solver.cpp:106] Iteration 82600, lr = 1e-11
I0312 11:12:26.121088 17663 solver.cpp:228] Iteration 82700, loss = 0.372593
I0312 11:12:26.121109 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:12:26.121117 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.155073 (* 1 = 0.155073 loss)
I0312 11:12:26.121121 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.241423 (* 1 = 0.241423 loss)
I0312 11:12:26.121140 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131756 (* 1 = 0.0131756 loss)
I0312 11:12:26.121145 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0910186 (* 1 = 0.0910186 loss)
I0312 11:12:26.121150 17663 sgd_solver.cpp:106] Iteration 82700, lr = 1e-11
I0312 11:13:19.060839 17663 solver.cpp:228] Iteration 82800, loss = 0.35656
I0312 11:13:19.060863 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:13:19.060869 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0922901 (* 1 = 0.0922901 loss)
I0312 11:13:19.060889 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0957026 (* 1 = 0.0957026 loss)
I0312 11:13:19.060892 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0287935 (* 1 = 0.0287935 loss)
I0312 11:13:19.060896 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.327006 (* 1 = 0.327006 loss)
I0312 11:13:19.060901 17663 sgd_solver.cpp:106] Iteration 82800, lr = 1e-11
I0312 11:14:11.281033 17663 solver.cpp:228] Iteration 82900, loss = 0.281475
I0312 11:14:11.281054 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:14:11.281061 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169774 (* 1 = 0.0169774 loss)
I0312 11:14:11.281080 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0930113 (* 1 = 0.0930113 loss)
I0312 11:14:11.281085 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.075042 (* 1 = 0.075042 loss)
I0312 11:14:11.281088 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.249505 (* 1 = 0.249505 loss)
I0312 11:14:11.281093 17663 sgd_solver.cpp:106] Iteration 82900, lr = 1e-11
speed: 0.525s / iter
I0312 11:15:04.305821 17663 solver.cpp:228] Iteration 83000, loss = 0.203754
I0312 11:15:04.306006 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:15:04.306066 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335486 (* 1 = 0.0335486 loss)
I0312 11:15:04.306115 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0733505 (* 1 = 0.0733505 loss)
I0312 11:15:04.306164 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157408 (* 1 = 0.0157408 loss)
I0312 11:15:04.306210 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0867276 (* 1 = 0.0867276 loss)
I0312 11:15:04.306258 17663 sgd_solver.cpp:106] Iteration 83000, lr = 1e-11
I0312 11:15:57.151206 17663 solver.cpp:228] Iteration 83100, loss = 0.94098
I0312 11:15:57.151228 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 11:15:57.151235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.12545 (* 1 = 0.12545 loss)
I0312 11:15:57.151239 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.37295 (* 1 = 0.37295 loss)
I0312 11:15:57.151258 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.304405 (* 1 = 0.304405 loss)
I0312 11:15:57.151263 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.225761 (* 1 = 0.225761 loss)
I0312 11:15:57.151280 17663 sgd_solver.cpp:106] Iteration 83100, lr = 1e-11
I0312 11:16:49.614889 17663 solver.cpp:228] Iteration 83200, loss = 0.247326
I0312 11:16:49.614910 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:16:49.614917 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116457 (* 1 = 0.116457 loss)
I0312 11:16:49.614936 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.21385 (* 1 = 0.21385 loss)
I0312 11:16:49.614940 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00746921 (* 1 = 0.00746921 loss)
I0312 11:16:49.614959 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488372 (* 1 = 0.0488372 loss)
I0312 11:16:49.614964 17663 sgd_solver.cpp:106] Iteration 83200, lr = 1e-11
I0312 11:17:42.156667 17663 solver.cpp:228] Iteration 83300, loss = 0.59194
I0312 11:17:42.156690 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0312 11:17:42.156697 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0768773 (* 1 = 0.0768773 loss)
I0312 11:17:42.156718 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.436553 (* 1 = 0.436553 loss)
I0312 11:17:42.156720 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.163954 (* 1 = 0.163954 loss)
I0312 11:17:42.156725 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.098366 (* 1 = 0.098366 loss)
I0312 11:17:42.156729 17663 sgd_solver.cpp:106] Iteration 83300, lr = 1e-11
I0312 11:18:34.520944 17663 solver.cpp:228] Iteration 83400, loss = 0.32291
I0312 11:18:34.520968 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:18:34.520975 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224266 (* 1 = 0.0224266 loss)
I0312 11:18:34.520980 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0517102 (* 1 = 0.0517102 loss)
I0312 11:18:34.520999 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00397644 (* 1 = 0.00397644 loss)
I0312 11:18:34.521003 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123786 (* 1 = 0.0123786 loss)
I0312 11:18:34.521008 17663 sgd_solver.cpp:106] Iteration 83400, lr = 1e-11
I0312 11:19:27.380178 17663 solver.cpp:228] Iteration 83500, loss = 0.324338
I0312 11:19:27.380201 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:19:27.380208 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.150592 (* 1 = 0.150592 loss)
I0312 11:19:27.380228 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.218247 (* 1 = 0.218247 loss)
I0312 11:19:27.380231 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145092 (* 1 = 0.0145092 loss)
I0312 11:19:27.380235 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165358 (* 1 = 0.0165358 loss)
I0312 11:19:27.380240 17663 sgd_solver.cpp:106] Iteration 83500, lr = 1e-11
I0312 11:20:19.079788 17663 solver.cpp:228] Iteration 83600, loss = 0.488968
I0312 11:20:19.079816 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 11:20:19.079824 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.184941 (* 1 = 0.184941 loss)
I0312 11:20:19.079829 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.423573 (* 1 = 0.423573 loss)
I0312 11:20:19.079834 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0575888 (* 1 = 0.0575888 loss)
I0312 11:20:19.079838 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0416565 (* 1 = 0.0416565 loss)
I0312 11:20:19.079843 17663 sgd_solver.cpp:106] Iteration 83600, lr = 1e-11
I0312 11:21:11.634945 17663 solver.cpp:228] Iteration 83700, loss = 0.305036
I0312 11:21:11.634965 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:21:11.634974 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0375478 (* 1 = 0.0375478 loss)
I0312 11:21:11.634991 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.110732 (* 1 = 0.110732 loss)
I0312 11:21:11.634996 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248858 (* 1 = 0.0248858 loss)
I0312 11:21:11.635000 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0719038 (* 1 = 0.0719038 loss)
I0312 11:21:11.635004 17663 sgd_solver.cpp:106] Iteration 83700, lr = 1e-11
I0312 11:22:04.687731 17663 solver.cpp:228] Iteration 83800, loss = 0.166879
I0312 11:22:04.687753 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 11:22:04.687760 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685261 (* 1 = 0.0685261 loss)
I0312 11:22:04.687764 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112853 (* 1 = 0.112853 loss)
I0312 11:22:04.687783 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082583 (* 1 = 0.0082583 loss)
I0312 11:22:04.687788 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301314 (* 1 = 0.0301314 loss)
I0312 11:22:04.687793 17663 sgd_solver.cpp:106] Iteration 83800, lr = 1e-11
I0312 11:22:57.134295 17663 solver.cpp:228] Iteration 83900, loss = 0.768565
I0312 11:22:57.134317 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0312 11:22:57.134325 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.346509 (* 1 = 0.346509 loss)
I0312 11:22:57.134330 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.649202 (* 1 = 0.649202 loss)
I0312 11:22:57.134347 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0846524 (* 1 = 0.0846524 loss)
I0312 11:22:57.134351 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.255374 (* 1 = 0.255374 loss)
I0312 11:22:57.134369 17663 sgd_solver.cpp:106] Iteration 83900, lr = 1e-11
speed: 0.525s / iter
I0312 11:23:49.779192 17663 solver.cpp:228] Iteration 84000, loss = 0.52608
I0312 11:23:49.779345 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:23:49.779402 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511266 (* 1 = 0.0511266 loss)
I0312 11:23:49.779451 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.127235 (* 1 = 0.127235 loss)
I0312 11:23:49.779498 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00509752 (* 1 = 0.00509752 loss)
I0312 11:23:49.779557 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701657 (* 1 = 0.0701657 loss)
I0312 11:23:49.779604 17663 sgd_solver.cpp:106] Iteration 84000, lr = 1e-11
I0312 11:24:41.997025 17663 solver.cpp:228] Iteration 84100, loss = 0.297812
I0312 11:24:41.997047 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 11:24:41.997056 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334722 (* 1 = 0.0334722 loss)
I0312 11:24:41.997074 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.109998 (* 1 = 0.109998 loss)
I0312 11:24:41.997078 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0064865 (* 1 = 0.0064865 loss)
I0312 11:24:41.997082 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245634 (* 1 = 0.0245634 loss)
I0312 11:24:41.997100 17663 sgd_solver.cpp:106] Iteration 84100, lr = 1e-11
I0312 11:25:34.540549 17663 solver.cpp:228] Iteration 84200, loss = 0.343106
I0312 11:25:34.540570 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 11:25:34.540578 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0580804 (* 1 = 0.0580804 loss)
I0312 11:25:34.540582 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.18075 (* 1 = 0.18075 loss)
I0312 11:25:34.540601 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00526506 (* 1 = 0.00526506 loss)
I0312 11:25:34.540606 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0996402 (* 1 = 0.0996402 loss)
I0312 11:25:34.540623 17663 sgd_solver.cpp:106] Iteration 84200, lr = 1e-11
I0312 11:26:27.235280 17663 solver.cpp:228] Iteration 84300, loss = 0.231396
I0312 11:26:27.235307 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:26:27.235316 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0656689 (* 1 = 0.0656689 loss)
I0312 11:26:27.235334 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106984 (* 1 = 0.106984 loss)
I0312 11:26:27.235339 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00506579 (* 1 = 0.00506579 loss)
I0312 11:26:27.235343 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350525 (* 1 = 0.0350525 loss)
I0312 11:26:27.235349 17663 sgd_solver.cpp:106] Iteration 84300, lr = 1e-11
I0312 11:27:19.668459 17663 solver.cpp:228] Iteration 84400, loss = 0.299252
I0312 11:27:19.668481 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:27:19.668489 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295205 (* 1 = 0.0295205 loss)
I0312 11:27:19.668493 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116154 (* 1 = 0.116154 loss)
I0312 11:27:19.668512 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00749305 (* 1 = 0.00749305 loss)
I0312 11:27:19.668516 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0513724 (* 1 = 0.0513724 loss)
I0312 11:27:19.668521 17663 sgd_solver.cpp:106] Iteration 84400, lr = 1e-11
I0312 11:28:12.197165 17663 solver.cpp:228] Iteration 84500, loss = 0.638065
I0312 11:28:12.197186 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 11:28:12.197193 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.212363 (* 1 = 0.212363 loss)
I0312 11:28:12.197198 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.251999 (* 1 = 0.251999 loss)
I0312 11:28:12.197217 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0409528 (* 1 = 0.0409528 loss)
I0312 11:28:12.197221 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.197996 (* 1 = 0.197996 loss)
I0312 11:28:12.197238 17663 sgd_solver.cpp:106] Iteration 84500, lr = 1e-11
I0312 11:29:04.717007 17663 solver.cpp:228] Iteration 84600, loss = 0.354139
I0312 11:29:04.717031 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:29:04.717038 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.086369 (* 1 = 0.086369 loss)
I0312 11:29:04.717043 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0816434 (* 1 = 0.0816434 loss)
I0312 11:29:04.717062 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174605 (* 1 = 0.0174605 loss)
I0312 11:29:04.717067 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101442 (* 1 = 0.101442 loss)
I0312 11:29:04.717072 17663 sgd_solver.cpp:106] Iteration 84600, lr = 1e-11
I0312 11:29:57.330380 17663 solver.cpp:228] Iteration 84700, loss = 0.320969
I0312 11:29:57.330402 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:29:57.330410 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447728 (* 1 = 0.0447728 loss)
I0312 11:29:57.330415 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0679594 (* 1 = 0.0679594 loss)
I0312 11:29:57.330420 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00744279 (* 1 = 0.00744279 loss)
I0312 11:29:57.330423 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0050386 (* 1 = 0.0050386 loss)
I0312 11:29:57.330428 17663 sgd_solver.cpp:106] Iteration 84700, lr = 1e-11
I0312 11:30:50.233860 17663 solver.cpp:228] Iteration 84800, loss = 0.475354
I0312 11:30:50.233882 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:30:50.233889 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116058 (* 1 = 0.116058 loss)
I0312 11:30:50.233911 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196968 (* 1 = 0.196968 loss)
I0312 11:30:50.233916 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0039413 (* 1 = 0.0039413 loss)
I0312 11:30:50.233934 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207967 (* 1 = 0.0207967 loss)
I0312 11:30:50.233939 17663 sgd_solver.cpp:106] Iteration 84800, lr = 1e-11
I0312 11:31:43.142891 17663 solver.cpp:228] Iteration 84900, loss = 0.321094
I0312 11:31:43.142913 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 11:31:43.142920 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347109 (* 1 = 0.0347109 loss)
I0312 11:31:43.142925 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.158749 (* 1 = 0.158749 loss)
I0312 11:31:43.142943 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167479 (* 1 = 0.0167479 loss)
I0312 11:31:43.142946 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451438 (* 1 = 0.0451438 loss)
I0312 11:31:43.142964 17663 sgd_solver.cpp:106] Iteration 84900, lr = 1e-11
speed: 0.525s / iter
I0312 11:32:35.509336 17663 solver.cpp:228] Iteration 85000, loss = 0.222908
I0312 11:32:35.509359 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:32:35.509367 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0861711 (* 1 = 0.0861711 loss)
I0312 11:32:35.509387 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.227085 (* 1 = 0.227085 loss)
I0312 11:32:35.509390 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035588 (* 1 = 0.0035588 loss)
I0312 11:32:35.509394 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0406522 (* 1 = 0.0406522 loss)
I0312 11:32:35.509399 17663 sgd_solver.cpp:106] Iteration 85000, lr = 1e-11
I0312 11:33:27.721155 17663 solver.cpp:228] Iteration 85100, loss = 0.197816
I0312 11:33:27.721176 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:33:27.721184 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279312 (* 1 = 0.0279312 loss)
I0312 11:33:27.721202 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0845749 (* 1 = 0.0845749 loss)
I0312 11:33:27.721206 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228244 (* 1 = 0.0228244 loss)
I0312 11:33:27.721210 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235683 (* 1 = 0.0235683 loss)
I0312 11:33:27.721215 17663 sgd_solver.cpp:106] Iteration 85100, lr = 1e-11
I0312 11:34:20.298728 17663 solver.cpp:228] Iteration 85200, loss = 0.333884
I0312 11:34:20.298749 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 11:34:20.298758 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.107043 (* 1 = 0.107043 loss)
I0312 11:34:20.298761 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172256 (* 1 = 0.172256 loss)
I0312 11:34:20.298779 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00770533 (* 1 = 0.00770533 loss)
I0312 11:34:20.298784 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421043 (* 1 = 0.0421043 loss)
I0312 11:34:20.298790 17663 sgd_solver.cpp:106] Iteration 85200, lr = 1e-11
I0312 11:35:13.064399 17663 solver.cpp:228] Iteration 85300, loss = 1.74434
I0312 11:35:13.064419 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 11:35:13.064426 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691654 (* 1 = 0.0691654 loss)
I0312 11:35:13.064445 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1614 (* 1 = 0.1614 loss)
I0312 11:35:13.064450 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00638111 (* 1 = 0.00638111 loss)
I0312 11:35:13.064455 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0807358 (* 1 = 0.0807358 loss)
I0312 11:35:13.064471 17663 sgd_solver.cpp:106] Iteration 85300, lr = 1e-11
I0312 11:36:05.242463 17663 solver.cpp:228] Iteration 85400, loss = 0.750335
I0312 11:36:05.242489 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 11:36:05.242496 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.208288 (* 1 = 0.208288 loss)
I0312 11:36:05.242516 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.331718 (* 1 = 0.331718 loss)
I0312 11:36:05.242522 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00830059 (* 1 = 0.00830059 loss)
I0312 11:36:05.242525 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.389503 (* 1 = 0.389503 loss)
I0312 11:36:05.242530 17663 sgd_solver.cpp:106] Iteration 85400, lr = 1e-11
I0312 11:36:57.918963 17663 solver.cpp:228] Iteration 85500, loss = 0.301194
I0312 11:36:57.918987 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 11:36:57.918995 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0490915 (* 1 = 0.0490915 loss)
I0312 11:36:57.919014 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.134428 (* 1 = 0.134428 loss)
I0312 11:36:57.919018 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218208 (* 1 = 0.00218208 loss)
I0312 11:36:57.919035 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00954039 (* 1 = 0.00954039 loss)
I0312 11:36:57.919040 17663 sgd_solver.cpp:106] Iteration 85500, lr = 1e-11
I0312 11:37:50.316056 17663 solver.cpp:228] Iteration 85600, loss = 0.46758
I0312 11:37:50.316078 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 11:37:50.316085 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571356 (* 1 = 0.0571356 loss)
I0312 11:37:50.316104 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.199063 (* 1 = 0.199063 loss)
I0312 11:37:50.316109 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490459 (* 1 = 0.00490459 loss)
I0312 11:37:50.316113 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00659627 (* 1 = 0.00659627 loss)
I0312 11:37:50.316118 17663 sgd_solver.cpp:106] Iteration 85600, lr = 1e-11
I0312 11:38:43.136845 17663 solver.cpp:228] Iteration 85700, loss = 0.439812
I0312 11:38:43.136868 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 11:38:43.136875 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0960924 (* 1 = 0.0960924 loss)
I0312 11:38:43.136894 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.132791 (* 1 = 0.132791 loss)
I0312 11:38:43.136898 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0853865 (* 1 = 0.0853865 loss)
I0312 11:38:43.136915 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.424672 (* 1 = 0.424672 loss)
I0312 11:38:43.136921 17663 sgd_solver.cpp:106] Iteration 85700, lr = 1e-11
I0312 11:39:34.770884 17663 solver.cpp:228] Iteration 85800, loss = 0.125583
I0312 11:39:34.770907 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:39:34.770915 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0072553 (* 1 = 0.0072553 loss)
I0312 11:39:34.770933 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0544803 (* 1 = 0.0544803 loss)
I0312 11:39:34.770937 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692311 (* 1 = 0.00692311 loss)
I0312 11:39:34.770942 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00327108 (* 1 = 0.00327108 loss)
I0312 11:39:34.770947 17663 sgd_solver.cpp:106] Iteration 85800, lr = 1e-11
I0312 11:40:26.999223 17663 solver.cpp:228] Iteration 85900, loss = 0.296534
I0312 11:40:26.999245 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 11:40:26.999253 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334874 (* 1 = 0.0334874 loss)
I0312 11:40:26.999271 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.129843 (* 1 = 0.129843 loss)
I0312 11:40:26.999275 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00582989 (* 1 = 0.00582989 loss)
I0312 11:40:26.999280 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861718 (* 1 = 0.00861718 loss)
I0312 11:40:26.999284 17663 sgd_solver.cpp:106] Iteration 85900, lr = 1e-11
speed: 0.525s / iter
I0312 11:41:18.887485 17663 solver.cpp:228] Iteration 86000, loss = 0.456934
I0312 11:41:18.887506 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:41:18.887514 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0977282 (* 1 = 0.0977282 loss)
I0312 11:41:18.887533 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.199913 (* 1 = 0.199913 loss)
I0312 11:41:18.887537 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0420631 (* 1 = 0.0420631 loss)
I0312 11:41:18.887554 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.251411 (* 1 = 0.251411 loss)
I0312 11:41:18.887560 17663 sgd_solver.cpp:106] Iteration 86000, lr = 1e-11
I0312 11:42:11.212944 17663 solver.cpp:228] Iteration 86100, loss = 0.372271
I0312 11:42:11.212965 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 11:42:11.212971 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374765 (* 1 = 0.0374765 loss)
I0312 11:42:11.212990 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117241 (* 1 = 0.117241 loss)
I0312 11:42:11.212996 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00331421 (* 1 = 0.00331421 loss)
I0312 11:42:11.212999 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0783035 (* 1 = 0.0783035 loss)
I0312 11:42:11.213004 17663 sgd_solver.cpp:106] Iteration 86100, lr = 1e-11
I0312 11:43:03.862730 17663 solver.cpp:228] Iteration 86200, loss = 0.5571
I0312 11:43:03.862751 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 11:43:03.862757 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.193348 (* 1 = 0.193348 loss)
I0312 11:43:03.862776 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.251007 (* 1 = 0.251007 loss)
I0312 11:43:03.862781 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0412185 (* 1 = 0.0412185 loss)
I0312 11:43:03.862784 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.257631 (* 1 = 0.257631 loss)
I0312 11:43:03.862802 17663 sgd_solver.cpp:106] Iteration 86200, lr = 1e-11
I0312 11:43:56.686367 17663 solver.cpp:228] Iteration 86300, loss = 0.844492
I0312 11:43:56.686388 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0312 11:43:56.686395 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.403745 (* 1 = 0.403745 loss)
I0312 11:43:56.686400 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.536039 (* 1 = 0.536039 loss)
I0312 11:43:56.686419 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324649 (* 1 = 0.0324649 loss)
I0312 11:43:56.686424 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.243693 (* 1 = 0.243693 loss)
I0312 11:43:56.686429 17663 sgd_solver.cpp:106] Iteration 86300, lr = 1e-11
I0312 11:44:49.589726 17663 solver.cpp:228] Iteration 86400, loss = 0.295085
I0312 11:44:49.589748 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 11:44:49.589756 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.139706 (* 1 = 0.139706 loss)
I0312 11:44:49.589773 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.181865 (* 1 = 0.181865 loss)
I0312 11:44:49.589777 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0312401 (* 1 = 0.0312401 loss)
I0312 11:44:49.589781 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.052909 (* 1 = 0.052909 loss)
I0312 11:44:49.589787 17663 sgd_solver.cpp:106] Iteration 86400, lr = 1e-11
I0312 11:45:42.035364 17663 solver.cpp:228] Iteration 86500, loss = 0.275214
I0312 11:45:42.035385 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:45:42.035392 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.114477 (* 1 = 0.114477 loss)
I0312 11:45:42.035411 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198179 (* 1 = 0.198179 loss)
I0312 11:45:42.035415 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0361767 (* 1 = 0.0361767 loss)
I0312 11:45:42.035419 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0643141 (* 1 = 0.0643141 loss)
I0312 11:45:42.035436 17663 sgd_solver.cpp:106] Iteration 86500, lr = 1e-11
I0312 11:46:34.447489 17663 solver.cpp:228] Iteration 86600, loss = 0.516047
I0312 11:46:34.447511 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 11:46:34.447520 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.23404 (* 1 = 0.23404 loss)
I0312 11:46:34.447538 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.357514 (* 1 = 0.357514 loss)
I0312 11:46:34.447542 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228706 (* 1 = 0.0228706 loss)
I0312 11:46:34.447559 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.19573 (* 1 = 0.19573 loss)
I0312 11:46:34.447564 17663 sgd_solver.cpp:106] Iteration 86600, lr = 1e-11
I0312 11:47:26.751721 17663 solver.cpp:228] Iteration 86700, loss = 0.380859
I0312 11:47:26.751742 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:47:26.751750 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0659077 (* 1 = 0.0659077 loss)
I0312 11:47:26.751754 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.197915 (* 1 = 0.197915 loss)
I0312 11:47:26.751773 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100419 (* 1 = 0.0100419 loss)
I0312 11:47:26.751777 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.241962 (* 1 = 0.241962 loss)
I0312 11:47:26.751782 17663 sgd_solver.cpp:106] Iteration 86700, lr = 1e-11
I0312 11:48:19.367015 17663 solver.cpp:228] Iteration 86800, loss = 0.669983
I0312 11:48:19.367036 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 11:48:19.367043 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.190091 (* 1 = 0.190091 loss)
I0312 11:48:19.367048 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.320895 (* 1 = 0.320895 loss)
I0312 11:48:19.367066 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0657471 (* 1 = 0.0657471 loss)
I0312 11:48:19.367070 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.304626 (* 1 = 0.304626 loss)
I0312 11:48:19.367089 17663 sgd_solver.cpp:106] Iteration 86800, lr = 1e-11
I0312 11:49:12.244257 17663 solver.cpp:228] Iteration 86900, loss = 0.612548
I0312 11:49:12.244279 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:49:12.244287 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175566 (* 1 = 0.0175566 loss)
I0312 11:49:12.244292 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0937531 (* 1 = 0.0937531 loss)
I0312 11:49:12.244295 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484374 (* 1 = 0.00484374 loss)
I0312 11:49:12.244300 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121784 (* 1 = 0.121784 loss)
I0312 11:49:12.244305 17663 sgd_solver.cpp:106] Iteration 86900, lr = 1e-11
speed: 0.525s / iter
I0312 11:50:04.537571 17663 solver.cpp:228] Iteration 87000, loss = 0.247577
I0312 11:50:04.537592 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 11:50:04.537600 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171701 (* 1 = 0.0171701 loss)
I0312 11:50:04.537618 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.11108 (* 1 = 0.11108 loss)
I0312 11:50:04.537623 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338849 (* 1 = 0.00338849 loss)
I0312 11:50:04.537627 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359551 (* 1 = 0.0359551 loss)
I0312 11:50:04.537632 17663 sgd_solver.cpp:106] Iteration 87000, lr = 1e-11
I0312 11:50:56.704130 17663 solver.cpp:228] Iteration 87100, loss = 0.658179
I0312 11:50:56.704151 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 11:50:56.704159 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0848097 (* 1 = 0.0848097 loss)
I0312 11:50:56.704177 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.139225 (* 1 = 0.139225 loss)
I0312 11:50:56.704181 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0584485 (* 1 = 0.0584485 loss)
I0312 11:50:56.704185 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111956 (* 1 = 0.111956 loss)
I0312 11:50:56.704203 17663 sgd_solver.cpp:106] Iteration 87100, lr = 1e-11
I0312 11:51:49.068569 17663 solver.cpp:228] Iteration 87200, loss = 0.320288
I0312 11:51:49.068593 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 11:51:49.068599 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702579 (* 1 = 0.0702579 loss)
I0312 11:51:49.068604 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.204996 (* 1 = 0.204996 loss)
I0312 11:51:49.068622 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376265 (* 1 = 0.00376265 loss)
I0312 11:51:49.068626 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.082874 (* 1 = 0.082874 loss)
I0312 11:51:49.068632 17663 sgd_solver.cpp:106] Iteration 87200, lr = 1e-11
I0312 11:52:41.802292 17663 solver.cpp:228] Iteration 87300, loss = 0.210545
I0312 11:52:41.802314 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 11:52:41.802322 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685101 (* 1 = 0.0685101 loss)
I0312 11:52:41.802326 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.126631 (* 1 = 0.126631 loss)
I0312 11:52:41.802345 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00631257 (* 1 = 0.00631257 loss)
I0312 11:52:41.802350 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247593 (* 1 = 0.0247593 loss)
I0312 11:52:41.802356 17663 sgd_solver.cpp:106] Iteration 87300, lr = 1e-11
I0312 11:53:34.552636 17663 solver.cpp:228] Iteration 87400, loss = 0.219515
I0312 11:53:34.552661 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:53:34.552670 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0470496 (* 1 = 0.0470496 loss)
I0312 11:53:34.552688 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.176275 (* 1 = 0.176275 loss)
I0312 11:53:34.552692 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204643 (* 1 = 0.0204643 loss)
I0312 11:53:34.552709 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0893286 (* 1 = 0.0893286 loss)
I0312 11:53:34.552714 17663 sgd_solver.cpp:106] Iteration 87400, lr = 1e-11
I0312 11:54:27.369421 17663 solver.cpp:228] Iteration 87500, loss = 0.144621
I0312 11:54:27.369442 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 11:54:27.369451 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346096 (* 1 = 0.0346096 loss)
I0312 11:54:27.369454 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112704 (* 1 = 0.112704 loss)
I0312 11:54:27.369458 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00274963 (* 1 = 0.00274963 loss)
I0312 11:54:27.369462 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00735181 (* 1 = 0.00735181 loss)
I0312 11:54:27.369467 17663 sgd_solver.cpp:106] Iteration 87500, lr = 1e-11
I0312 11:55:20.074306 17663 solver.cpp:228] Iteration 87600, loss = 0.130383
I0312 11:55:20.074327 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 11:55:20.074334 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203348 (* 1 = 0.0203348 loss)
I0312 11:55:20.074353 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0710277 (* 1 = 0.0710277 loss)
I0312 11:55:20.074358 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00395709 (* 1 = 0.00395709 loss)
I0312 11:55:20.074362 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0025756 (* 1 = 0.0025756 loss)
I0312 11:55:20.074368 17663 sgd_solver.cpp:106] Iteration 87600, lr = 1e-11
I0312 11:56:12.399966 17663 solver.cpp:228] Iteration 87700, loss = 0.749691
I0312 11:56:12.399989 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 11:56:12.399996 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.140135 (* 1 = 0.140135 loss)
I0312 11:56:12.400014 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.229728 (* 1 = 0.229728 loss)
I0312 11:56:12.400019 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251067 (* 1 = 0.0251067 loss)
I0312 11:56:12.400023 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.535661 (* 1 = 0.535661 loss)
I0312 11:56:12.400028 17663 sgd_solver.cpp:106] Iteration 87700, lr = 1e-11
I0312 11:57:05.172895 17663 solver.cpp:228] Iteration 87800, loss = 0.396407
I0312 11:57:05.172917 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 11:57:05.172924 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0345679 (* 1 = 0.0345679 loss)
I0312 11:57:05.172930 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0726141 (* 1 = 0.0726141 loss)
I0312 11:57:05.172933 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00384998 (* 1 = 0.00384998 loss)
I0312 11:57:05.172937 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169184 (* 1 = 0.0169184 loss)
I0312 11:57:05.172942 17663 sgd_solver.cpp:106] Iteration 87800, lr = 1e-11
I0312 11:57:57.764997 17663 solver.cpp:228] Iteration 87900, loss = 0.429207
I0312 11:57:57.765018 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:57:57.765025 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18923 (* 1 = 0.18923 loss)
I0312 11:57:57.765044 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.177848 (* 1 = 0.177848 loss)
I0312 11:57:57.765048 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0494764 (* 1 = 0.0494764 loss)
I0312 11:57:57.765053 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495719 (* 1 = 0.0495719 loss)
I0312 11:57:57.765058 17663 sgd_solver.cpp:106] Iteration 87900, lr = 1e-11
speed: 0.525s / iter
I0312 11:58:50.766378 17663 solver.cpp:228] Iteration 88000, loss = 0.348548
I0312 11:58:50.766408 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 11:58:50.766417 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142318 (* 1 = 0.142318 loss)
I0312 11:58:50.766423 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.226821 (* 1 = 0.226821 loss)
I0312 11:58:50.766427 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261601 (* 1 = 0.0261601 loss)
I0312 11:58:50.766433 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0904927 (* 1 = 0.0904927 loss)
I0312 11:58:50.766451 17663 sgd_solver.cpp:106] Iteration 88000, lr = 1e-11
I0312 11:59:43.315152 17663 solver.cpp:228] Iteration 88100, loss = 0.288127
I0312 11:59:43.315176 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 11:59:43.315183 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0011011 (* 1 = 0.0011011 loss)
I0312 11:59:43.315202 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0580175 (* 1 = 0.0580175 loss)
I0312 11:59:43.315207 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.228928 (* 1 = 0.228928 loss)
I0312 11:59:43.315223 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0787733 (* 1 = 0.0787733 loss)
I0312 11:59:43.315228 17663 sgd_solver.cpp:106] Iteration 88100, lr = 1e-11
I0312 12:00:35.466645 17663 solver.cpp:228] Iteration 88200, loss = 0.697204
I0312 12:00:35.466670 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 12:00:35.466689 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.263829 (* 1 = 0.263829 loss)
I0312 12:00:35.466693 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.301023 (* 1 = 0.301023 loss)
I0312 12:00:35.466697 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0175592 (* 1 = 0.0175592 loss)
I0312 12:00:35.466702 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.381299 (* 1 = 0.381299 loss)
I0312 12:00:35.466722 17663 sgd_solver.cpp:106] Iteration 88200, lr = 1e-11
I0312 12:01:28.086829 17663 solver.cpp:228] Iteration 88300, loss = 0.226868
I0312 12:01:28.086851 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 12:01:28.086858 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0662375 (* 1 = 0.0662375 loss)
I0312 12:01:28.086877 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151059 (* 1 = 0.151059 loss)
I0312 12:01:28.086881 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221504 (* 1 = 0.00221504 loss)
I0312 12:01:28.086885 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00900775 (* 1 = 0.00900775 loss)
I0312 12:01:28.086890 17663 sgd_solver.cpp:106] Iteration 88300, lr = 1e-11
I0312 12:02:20.517428 17663 solver.cpp:228] Iteration 88400, loss = 0.744725
I0312 12:02:20.517452 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 12:02:20.517458 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107263 (* 1 = 0.0107263 loss)
I0312 12:02:20.517478 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0216628 (* 1 = 0.0216628 loss)
I0312 12:02:20.517482 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082388 (* 1 = 0.0082388 loss)
I0312 12:02:20.517487 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039522 (* 1 = 0.039522 loss)
I0312 12:02:20.517491 17663 sgd_solver.cpp:106] Iteration 88400, lr = 1e-11
I0312 12:03:12.472239 17663 solver.cpp:228] Iteration 88500, loss = 0.167194
I0312 12:03:12.472260 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:03:12.472268 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383132 (* 1 = 0.0383132 loss)
I0312 12:03:12.472286 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0930112 (* 1 = 0.0930112 loss)
I0312 12:03:12.472291 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00573272 (* 1 = 0.00573272 loss)
I0312 12:03:12.472295 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0719147 (* 1 = 0.0719147 loss)
I0312 12:03:12.472313 17663 sgd_solver.cpp:106] Iteration 88500, lr = 1e-11
I0312 12:04:04.924568 17663 solver.cpp:228] Iteration 88600, loss = 0.520938
I0312 12:04:04.924589 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 12:04:04.924597 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.150703 (* 1 = 0.150703 loss)
I0312 12:04:04.924615 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.255775 (* 1 = 0.255775 loss)
I0312 12:04:04.924619 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170326 (* 1 = 0.0170326 loss)
I0312 12:04:04.924623 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448036 (* 1 = 0.0448036 loss)
I0312 12:04:04.924641 17663 sgd_solver.cpp:106] Iteration 88600, lr = 1e-11
I0312 12:04:57.223625 17663 solver.cpp:228] Iteration 88700, loss = 0.163541
I0312 12:04:57.223650 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 12:04:57.223657 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0456936 (* 1 = 0.0456936 loss)
I0312 12:04:57.223677 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0592182 (* 1 = 0.0592182 loss)
I0312 12:04:57.223681 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231176 (* 1 = 0.00231176 loss)
I0312 12:04:57.223686 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134462 (* 1 = 0.0134462 loss)
I0312 12:04:57.223691 17663 sgd_solver.cpp:106] Iteration 88700, lr = 1e-11
I0312 12:05:50.602293 17663 solver.cpp:228] Iteration 88800, loss = 0.442882
I0312 12:05:50.602314 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 12:05:50.602321 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0667034 (* 1 = 0.0667034 loss)
I0312 12:05:50.602340 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.235157 (* 1 = 0.235157 loss)
I0312 12:05:50.602344 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00764674 (* 1 = 0.00764674 loss)
I0312 12:05:50.602349 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0882485 (* 1 = 0.0882485 loss)
I0312 12:05:50.602354 17663 sgd_solver.cpp:106] Iteration 88800, lr = 1e-11
I0312 12:06:42.712971 17663 solver.cpp:228] Iteration 88900, loss = 0.413419
I0312 12:06:42.712992 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 12:06:42.712999 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119633 (* 1 = 0.119633 loss)
I0312 12:06:42.713018 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.227381 (* 1 = 0.227381 loss)
I0312 12:06:42.713022 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0622234 (* 1 = 0.0622234 loss)
I0312 12:06:42.713027 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120932 (* 1 = 0.120932 loss)
I0312 12:06:42.713032 17663 sgd_solver.cpp:106] Iteration 88900, lr = 1e-11
speed: 0.525s / iter
I0312 12:07:35.132069 17663 solver.cpp:228] Iteration 89000, loss = 0.359809
I0312 12:07:35.132092 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 12:07:35.132100 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0130248 (* 1 = 0.0130248 loss)
I0312 12:07:35.132119 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0904596 (* 1 = 0.0904596 loss)
I0312 12:07:35.132124 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00405313 (* 1 = 0.00405313 loss)
I0312 12:07:35.132128 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112419 (* 1 = 0.0112419 loss)
I0312 12:07:35.132133 17663 sgd_solver.cpp:106] Iteration 89000, lr = 1e-11
I0312 12:08:28.513633 17663 solver.cpp:228] Iteration 89100, loss = 0.209772
I0312 12:08:28.513655 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 12:08:28.513662 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0480074 (* 1 = 0.0480074 loss)
I0312 12:08:28.513681 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168941 (* 1 = 0.168941 loss)
I0312 12:08:28.513685 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491397 (* 1 = 0.00491397 loss)
I0312 12:08:28.513689 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200903 (* 1 = 0.0200903 loss)
I0312 12:08:28.513695 17663 sgd_solver.cpp:106] Iteration 89100, lr = 1e-11
I0312 12:09:20.898011 17663 solver.cpp:228] Iteration 89200, loss = 0.365309
I0312 12:09:20.898032 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:09:20.898041 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0943469 (* 1 = 0.0943469 loss)
I0312 12:09:20.898058 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.180888 (* 1 = 0.180888 loss)
I0312 12:09:20.898063 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378964 (* 1 = 0.0378964 loss)
I0312 12:09:20.898066 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615164 (* 1 = 0.0615164 loss)
I0312 12:09:20.898072 17663 sgd_solver.cpp:106] Iteration 89200, lr = 1e-11
I0312 12:10:13.241956 17663 solver.cpp:228] Iteration 89300, loss = 0.33624
I0312 12:10:13.241984 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 12:10:13.241992 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10308 (* 1 = 0.10308 loss)
I0312 12:10:13.241997 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.26402 (* 1 = 0.26402 loss)
I0312 12:10:13.242002 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109737 (* 1 = 0.0109737 loss)
I0312 12:10:13.242019 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0673499 (* 1 = 0.0673499 loss)
I0312 12:10:13.242027 17663 sgd_solver.cpp:106] Iteration 89300, lr = 1e-11
I0312 12:11:05.813086 17663 solver.cpp:228] Iteration 89400, loss = 0.199816
I0312 12:11:05.813107 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:11:05.813114 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240283 (* 1 = 0.0240283 loss)
I0312 12:11:05.813118 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0959805 (* 1 = 0.0959805 loss)
I0312 12:11:05.813138 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00712403 (* 1 = 0.00712403 loss)
I0312 12:11:05.813141 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242314 (* 1 = 0.0242314 loss)
I0312 12:11:05.813146 17663 sgd_solver.cpp:106] Iteration 89400, lr = 1e-11
I0312 12:11:58.673120 17663 solver.cpp:228] Iteration 89500, loss = 0.15538
I0312 12:11:58.673141 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:11:58.673148 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731148 (* 1 = 0.0731148 loss)
I0312 12:11:58.673153 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.110817 (* 1 = 0.110817 loss)
I0312 12:11:58.673172 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577431 (* 1 = 0.00577431 loss)
I0312 12:11:58.673177 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194103 (* 1 = 0.0194103 loss)
I0312 12:11:58.673193 17663 sgd_solver.cpp:106] Iteration 89500, lr = 1e-11
I0312 12:12:51.131534 17663 solver.cpp:228] Iteration 89600, loss = 0.210293
I0312 12:12:51.131557 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 12:12:51.131564 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0139179 (* 1 = 0.0139179 loss)
I0312 12:12:51.131583 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0699805 (* 1 = 0.0699805 loss)
I0312 12:12:51.131588 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205248 (* 1 = 0.00205248 loss)
I0312 12:12:51.131592 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00800401 (* 1 = 0.00800401 loss)
I0312 12:12:51.131597 17663 sgd_solver.cpp:106] Iteration 89600, lr = 1e-11
I0312 12:13:43.391834 17663 solver.cpp:228] Iteration 89700, loss = 0.324414
I0312 12:13:43.391855 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 12:13:43.391863 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562073 (* 1 = 0.0562073 loss)
I0312 12:13:43.391867 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13747 (* 1 = 0.13747 loss)
I0312 12:13:43.391886 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164814 (* 1 = 0.0164814 loss)
I0312 12:13:43.391891 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121499 (* 1 = 0.121499 loss)
I0312 12:13:43.391896 17663 sgd_solver.cpp:106] Iteration 89700, lr = 1e-11
I0312 12:14:35.694496 17663 solver.cpp:228] Iteration 89800, loss = 0.119871
I0312 12:14:35.694522 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 12:14:35.694530 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00956309 (* 1 = 0.00956309 loss)
I0312 12:14:35.694550 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0553044 (* 1 = 0.0553044 loss)
I0312 12:14:35.694555 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0078458 (* 1 = 0.0078458 loss)
I0312 12:14:35.694558 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270707 (* 1 = 0.0270707 loss)
I0312 12:14:35.694563 17663 sgd_solver.cpp:106] Iteration 89800, lr = 1e-11
I0312 12:15:28.795648 17663 solver.cpp:228] Iteration 89900, loss = 0.524742
I0312 12:15:28.795677 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 12:15:28.795686 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.034064 (* 1 = 0.034064 loss)
I0312 12:15:28.795706 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0753207 (* 1 = 0.0753207 loss)
I0312 12:15:28.795709 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00277497 (* 1 = 0.00277497 loss)
I0312 12:15:28.795714 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023623 (* 1 = 0.023623 loss)
I0312 12:15:28.795722 17663 sgd_solver.cpp:106] Iteration 89900, lr = 1e-11
I0312 12:16:20.754034 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_90000.caffemodel
I0312 12:16:21.349548 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_90000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_90000.caffemodel
I0312 12:16:22.493857 17663 solver.cpp:228] Iteration 90000, loss = 0.198476
I0312 12:16:22.493881 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 12:16:22.493888 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368615 (* 1 = 0.0368615 loss)
I0312 12:16:22.493913 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.134218 (* 1 = 0.134218 loss)
I0312 12:16:22.493917 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111864 (* 1 = 0.0111864 loss)
I0312 12:16:22.493934 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10279 (* 1 = 0.10279 loss)
I0312 12:16:22.493939 17663 sgd_solver.cpp:106] Iteration 90000, lr = 1e-12
I0312 12:17:14.918601 17663 solver.cpp:228] Iteration 90100, loss = 1.17511
I0312 12:17:14.918623 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0312 12:17:14.918630 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.299316 (* 1 = 0.299316 loss)
I0312 12:17:14.918649 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.423859 (* 1 = 0.423859 loss)
I0312 12:17:14.918653 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.138241 (* 1 = 0.138241 loss)
I0312 12:17:14.918658 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.298023 (* 1 = 0.298023 loss)
I0312 12:17:14.918674 17663 sgd_solver.cpp:106] Iteration 90100, lr = 1e-12
I0312 12:18:08.497505 17663 solver.cpp:228] Iteration 90200, loss = 0.847638
I0312 12:18:08.497525 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0312 12:18:08.497532 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.428907 (* 1 = 0.428907 loss)
I0312 12:18:08.497551 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.502211 (* 1 = 0.502211 loss)
I0312 12:18:08.497555 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0723205 (* 1 = 0.0723205 loss)
I0312 12:18:08.497560 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.138717 (* 1 = 0.138717 loss)
I0312 12:18:08.497565 17663 sgd_solver.cpp:106] Iteration 90200, lr = 1e-12
I0312 12:19:00.519794 17663 solver.cpp:228] Iteration 90300, loss = 0.323667
I0312 12:19:00.519816 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 12:19:00.519824 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519278 (* 1 = 0.0519278 loss)
I0312 12:19:00.519829 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215492 (* 1 = 0.215492 loss)
I0312 12:19:00.519846 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102393 (* 1 = 0.0102393 loss)
I0312 12:19:00.519850 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635367 (* 1 = 0.0635367 loss)
I0312 12:19:00.519855 17663 sgd_solver.cpp:106] Iteration 90300, lr = 1e-12
I0312 12:19:52.174516 17663 solver.cpp:228] Iteration 90400, loss = 0.410548
I0312 12:19:52.174537 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:19:52.174545 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0749053 (* 1 = 0.0749053 loss)
I0312 12:19:52.174563 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103248 (* 1 = 0.103248 loss)
I0312 12:19:52.174567 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126776 (* 1 = 0.0126776 loss)
I0312 12:19:52.174571 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.091631 (* 1 = 0.091631 loss)
I0312 12:19:52.174589 17663 sgd_solver.cpp:106] Iteration 90400, lr = 1e-12
I0312 12:20:44.562688 17663 solver.cpp:228] Iteration 90500, loss = 0.315794
I0312 12:20:44.562708 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 12:20:44.562716 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.135392 (* 1 = 0.135392 loss)
I0312 12:20:44.562721 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186992 (* 1 = 0.186992 loss)
I0312 12:20:44.562738 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0518885 (* 1 = 0.0518885 loss)
I0312 12:20:44.562742 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144102 (* 1 = 0.144102 loss)
I0312 12:20:44.562759 17663 sgd_solver.cpp:106] Iteration 90500, lr = 1e-12
I0312 12:21:36.881101 17663 solver.cpp:228] Iteration 90600, loss = 0.335773
I0312 12:21:36.881122 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 12:21:36.881129 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990797 (* 1 = 0.0990797 loss)
I0312 12:21:36.881134 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.264961 (* 1 = 0.264961 loss)
I0312 12:21:36.881152 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157632 (* 1 = 0.0157632 loss)
I0312 12:21:36.881156 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363276 (* 1 = 0.0363276 loss)
I0312 12:21:36.881161 17663 sgd_solver.cpp:106] Iteration 90600, lr = 1e-12
I0312 12:22:29.488256 17663 solver.cpp:228] Iteration 90700, loss = 0.243162
I0312 12:22:29.488286 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 12:22:29.488294 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413135 (* 1 = 0.0413135 loss)
I0312 12:22:29.488299 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.177257 (* 1 = 0.177257 loss)
I0312 12:22:29.488306 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00374859 (* 1 = 0.00374859 loss)
I0312 12:22:29.488309 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318936 (* 1 = 0.0318936 loss)
I0312 12:22:29.488328 17663 sgd_solver.cpp:106] Iteration 90700, lr = 1e-12
I0312 12:23:21.750242 17663 solver.cpp:228] Iteration 90800, loss = 0.932424
I0312 12:23:21.750264 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 12:23:21.750272 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.228114 (* 1 = 0.228114 loss)
I0312 12:23:21.750291 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.290669 (* 1 = 0.290669 loss)
I0312 12:23:21.750295 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.169384 (* 1 = 0.169384 loss)
I0312 12:23:21.750313 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110318 (* 1 = 0.110318 loss)
I0312 12:23:21.750318 17663 sgd_solver.cpp:106] Iteration 90800, lr = 1e-12
I0312 12:24:14.158535 17663 solver.cpp:228] Iteration 90900, loss = 0.277153
I0312 12:24:14.158560 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 12:24:14.158567 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.110696 (* 1 = 0.110696 loss)
I0312 12:24:14.158572 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170241 (* 1 = 0.170241 loss)
I0312 12:24:14.158576 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154689 (* 1 = 0.0154689 loss)
I0312 12:24:14.158581 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.138869 (* 1 = 0.138869 loss)
I0312 12:24:14.158586 17663 sgd_solver.cpp:106] Iteration 90900, lr = 1e-12
speed: 0.525s / iter
I0312 12:25:06.296833 17663 solver.cpp:228] Iteration 91000, loss = 0.275706
I0312 12:25:06.296861 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 12:25:06.296869 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0547175 (* 1 = 0.0547175 loss)
I0312 12:25:06.296875 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.12762 (* 1 = 0.12762 loss)
I0312 12:25:06.296893 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138022 (* 1 = 0.0138022 loss)
I0312 12:25:06.296897 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0543334 (* 1 = 0.0543334 loss)
I0312 12:25:06.296903 17663 sgd_solver.cpp:106] Iteration 91000, lr = 1e-12
I0312 12:25:58.021503 17663 solver.cpp:228] Iteration 91100, loss = 0.442557
I0312 12:25:58.021541 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 12:25:58.021549 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124057 (* 1 = 0.124057 loss)
I0312 12:25:58.021554 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144884 (* 1 = 0.144884 loss)
I0312 12:25:58.021559 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00819214 (* 1 = 0.00819214 loss)
I0312 12:25:58.021564 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0407791 (* 1 = 0.0407791 loss)
I0312 12:25:58.021569 17663 sgd_solver.cpp:106] Iteration 91100, lr = 1e-12
I0312 12:26:50.244691 17663 solver.cpp:228] Iteration 91200, loss = 0.408267
I0312 12:26:50.244712 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 12:26:50.244720 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18009 (* 1 = 0.18009 loss)
I0312 12:26:50.244738 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.278521 (* 1 = 0.278521 loss)
I0312 12:26:50.244742 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.03824 (* 1 = 0.03824 loss)
I0312 12:26:50.244746 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566186 (* 1 = 0.0566186 loss)
I0312 12:26:50.244751 17663 sgd_solver.cpp:106] Iteration 91200, lr = 1e-12
I0312 12:27:42.895419 17663 solver.cpp:228] Iteration 91300, loss = 0.423404
I0312 12:27:42.895439 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 12:27:42.895447 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.214992 (* 1 = 0.214992 loss)
I0312 12:27:42.895450 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.304312 (* 1 = 0.304312 loss)
I0312 12:27:42.895469 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0336472 (* 1 = 0.0336472 loss)
I0312 12:27:42.895473 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0942499 (* 1 = 0.0942499 loss)
I0312 12:27:42.895478 17663 sgd_solver.cpp:106] Iteration 91300, lr = 1e-12
I0312 12:28:35.380417 17663 solver.cpp:228] Iteration 91400, loss = 0.250291
I0312 12:28:35.380452 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 12:28:35.380460 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0505289 (* 1 = 0.0505289 loss)
I0312 12:28:35.380465 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146276 (* 1 = 0.146276 loss)
I0312 12:28:35.380470 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00142954 (* 1 = 0.00142954 loss)
I0312 12:28:35.380473 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00992135 (* 1 = 0.00992135 loss)
I0312 12:28:35.380478 17663 sgd_solver.cpp:106] Iteration 91400, lr = 1e-12
I0312 12:29:27.900266 17663 solver.cpp:228] Iteration 91500, loss = 0.471334
I0312 12:29:27.900288 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 12:29:27.900296 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.176569 (* 1 = 0.176569 loss)
I0312 12:29:27.900300 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186308 (* 1 = 0.186308 loss)
I0312 12:29:27.900305 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0654134 (* 1 = 0.0654134 loss)
I0312 12:29:27.900307 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.386173 (* 1 = 0.386173 loss)
I0312 12:29:27.900312 17663 sgd_solver.cpp:106] Iteration 91500, lr = 1e-12
I0312 12:30:20.419827 17663 solver.cpp:228] Iteration 91600, loss = 0.580096
I0312 12:30:20.419850 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 12:30:20.419857 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.194355 (* 1 = 0.194355 loss)
I0312 12:30:20.419876 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.490023 (* 1 = 0.490023 loss)
I0312 12:30:20.419880 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0438781 (* 1 = 0.0438781 loss)
I0312 12:30:20.419884 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0970874 (* 1 = 0.0970874 loss)
I0312 12:30:20.419889 17663 sgd_solver.cpp:106] Iteration 91600, lr = 1e-12
I0312 12:31:13.310608 17663 solver.cpp:228] Iteration 91700, loss = 0.146035
I0312 12:31:13.310629 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:31:13.310636 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390446 (* 1 = 0.0390446 loss)
I0312 12:31:13.310655 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0730941 (* 1 = 0.0730941 loss)
I0312 12:31:13.310659 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0492356 (* 1 = 0.0492356 loss)
I0312 12:31:13.310663 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351383 (* 1 = 0.0351383 loss)
I0312 12:31:13.310668 17663 sgd_solver.cpp:106] Iteration 91700, lr = 1e-12
I0312 12:32:05.989405 17663 solver.cpp:228] Iteration 91800, loss = 0.360481
I0312 12:32:05.989429 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 12:32:05.989436 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466153 (* 1 = 0.0466153 loss)
I0312 12:32:05.989455 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.183783 (* 1 = 0.183783 loss)
I0312 12:32:05.989459 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.055586 (* 1 = 0.055586 loss)
I0312 12:32:05.989464 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033585 (* 1 = 0.033585 loss)
I0312 12:32:05.989470 17663 sgd_solver.cpp:106] Iteration 91800, lr = 1e-12
I0312 12:32:57.856534 17663 solver.cpp:228] Iteration 91900, loss = 0.160772
I0312 12:32:57.856554 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 12:32:57.856561 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229028 (* 1 = 0.0229028 loss)
I0312 12:32:57.856580 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0376998 (* 1 = 0.0376998 loss)
I0312 12:32:57.856585 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122661 (* 1 = 0.0122661 loss)
I0312 12:32:57.856588 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00514558 (* 1 = 0.00514558 loss)
I0312 12:32:57.856593 17663 sgd_solver.cpp:106] Iteration 91900, lr = 1e-12
speed: 0.525s / iter
I0312 12:33:50.883872 17663 solver.cpp:228] Iteration 92000, loss = 0.0863042
I0312 12:33:50.884109 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 12:33:50.884169 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175291 (* 1 = 0.0175291 loss)
I0312 12:33:50.884218 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0708847 (* 1 = 0.0708847 loss)
I0312 12:33:50.884266 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133382 (* 1 = 0.00133382 loss)
I0312 12:33:50.884313 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00833648 (* 1 = 0.00833648 loss)
I0312 12:33:50.884361 17663 sgd_solver.cpp:106] Iteration 92000, lr = 1e-12
I0312 12:34:43.665871 17663 solver.cpp:228] Iteration 92100, loss = 0.281144
I0312 12:34:43.665899 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 12:34:43.665921 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.089039 (* 1 = 0.089039 loss)
I0312 12:34:43.665926 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.293916 (* 1 = 0.293916 loss)
I0312 12:34:43.665946 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695489 (* 1 = 0.00695489 loss)
I0312 12:34:43.665949 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141309 (* 1 = 0.0141309 loss)
I0312 12:34:43.665968 17663 sgd_solver.cpp:106] Iteration 92100, lr = 1e-12
I0312 12:35:36.733093 17663 solver.cpp:228] Iteration 92200, loss = 0.35677
I0312 12:35:36.733114 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 12:35:36.733122 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415503 (* 1 = 0.0415503 loss)
I0312 12:35:36.733141 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0670962 (* 1 = 0.0670962 loss)
I0312 12:35:36.733145 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233266 (* 1 = 0.00233266 loss)
I0312 12:35:36.733162 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182796 (* 1 = 0.0182796 loss)
I0312 12:35:36.733167 17663 sgd_solver.cpp:106] Iteration 92200, lr = 1e-12
I0312 12:36:29.927425 17663 solver.cpp:228] Iteration 92300, loss = 0.36482
I0312 12:36:29.927446 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 12:36:29.927454 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0857084 (* 1 = 0.0857084 loss)
I0312 12:36:29.927459 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.292201 (* 1 = 0.292201 loss)
I0312 12:36:29.927477 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111567 (* 1 = 0.0111567 loss)
I0312 12:36:29.927481 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0702627 (* 1 = 0.0702627 loss)
I0312 12:36:29.927487 17663 sgd_solver.cpp:106] Iteration 92300, lr = 1e-12
I0312 12:37:22.332504 17663 solver.cpp:228] Iteration 92400, loss = 0.184322
I0312 12:37:22.332525 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 12:37:22.332532 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387883 (* 1 = 0.0387883 loss)
I0312 12:37:22.332551 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0487586 (* 1 = 0.0487586 loss)
I0312 12:37:22.332556 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203748 (* 1 = 0.0203748 loss)
I0312 12:37:22.332559 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0812644 (* 1 = 0.0812644 loss)
I0312 12:37:22.332564 17663 sgd_solver.cpp:106] Iteration 92400, lr = 1e-12
I0312 12:38:15.302747 17663 solver.cpp:228] Iteration 92500, loss = 0.135748
I0312 12:38:15.302772 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 12:38:15.302779 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190655 (* 1 = 0.0190655 loss)
I0312 12:38:15.302798 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0778246 (* 1 = 0.0778246 loss)
I0312 12:38:15.302803 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285845 (* 1 = 0.00285845 loss)
I0312 12:38:15.302806 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0749829 (* 1 = 0.0749829 loss)
I0312 12:38:15.302811 17663 sgd_solver.cpp:106] Iteration 92500, lr = 1e-12
I0312 12:39:07.296777 17663 solver.cpp:228] Iteration 92600, loss = 0.466388
I0312 12:39:07.296799 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 12:39:07.296808 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0469785 (* 1 = 0.0469785 loss)
I0312 12:39:07.296811 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.142997 (* 1 = 0.142997 loss)
I0312 12:39:07.296815 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.155911 (* 1 = 0.155911 loss)
I0312 12:39:07.296819 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.38241 (* 1 = 0.38241 loss)
I0312 12:39:07.296838 17663 sgd_solver.cpp:106] Iteration 92600, lr = 1e-12
I0312 12:39:59.317011 17663 solver.cpp:228] Iteration 92700, loss = 0.91855
I0312 12:39:59.317034 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0312 12:39:59.317041 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.527775 (* 1 = 0.527775 loss)
I0312 12:39:59.317045 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.522426 (* 1 = 0.522426 loss)
I0312 12:39:59.317065 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274173 (* 1 = 0.0274173 loss)
I0312 12:39:59.317068 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.245551 (* 1 = 0.245551 loss)
I0312 12:39:59.317073 17663 sgd_solver.cpp:106] Iteration 92700, lr = 1e-12
I0312 12:40:51.569489 17663 solver.cpp:228] Iteration 92800, loss = 0.26684
I0312 12:40:51.569512 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 12:40:51.569519 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10246 (* 1 = 0.10246 loss)
I0312 12:40:51.569538 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.141287 (* 1 = 0.141287 loss)
I0312 12:40:51.569543 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0440203 (* 1 = 0.0440203 loss)
I0312 12:40:51.569547 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0729604 (* 1 = 0.0729604 loss)
I0312 12:40:51.569552 17663 sgd_solver.cpp:106] Iteration 92800, lr = 1e-12
I0312 12:41:44.786942 17663 solver.cpp:228] Iteration 92900, loss = 0.241828
I0312 12:41:44.786964 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 12:41:44.786972 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237837 (* 1 = 0.0237837 loss)
I0312 12:41:44.786976 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0712023 (* 1 = 0.0712023 loss)
I0312 12:41:44.786994 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125689 (* 1 = 0.0125689 loss)
I0312 12:41:44.786999 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00467679 (* 1 = 0.00467679 loss)
I0312 12:41:44.787004 17663 sgd_solver.cpp:106] Iteration 92900, lr = 1e-12
speed: 0.525s / iter
I0312 12:42:37.732756 17663 solver.cpp:228] Iteration 93000, loss = 0.30928
I0312 12:42:37.732964 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 12:42:37.733021 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795058 (* 1 = 0.0795058 loss)
I0312 12:42:37.733069 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.252205 (* 1 = 0.252205 loss)
I0312 12:42:37.733117 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0600001 (* 1 = 0.0600001 loss)
I0312 12:42:37.733163 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144181 (* 1 = 0.0144181 loss)
I0312 12:42:37.733211 17663 sgd_solver.cpp:106] Iteration 93000, lr = 1e-12
I0312 12:43:30.348392 17663 solver.cpp:228] Iteration 93100, loss = 0.552272
I0312 12:43:30.348414 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 12:43:30.348421 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.170615 (* 1 = 0.170615 loss)
I0312 12:43:30.348440 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.19356 (* 1 = 0.19356 loss)
I0312 12:43:30.348445 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0344399 (* 1 = 0.0344399 loss)
I0312 12:43:30.348461 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.198997 (* 1 = 0.198997 loss)
I0312 12:43:30.348466 17663 sgd_solver.cpp:106] Iteration 93100, lr = 1e-12
I0312 12:44:22.670140 17663 solver.cpp:228] Iteration 93200, loss = 0.432521
I0312 12:44:22.670161 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 12:44:22.670168 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.04786 (* 1 = 0.04786 loss)
I0312 12:44:22.670186 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156578 (* 1 = 0.156578 loss)
I0312 12:44:22.670191 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0048831 (* 1 = 0.0048831 loss)
I0312 12:44:22.670194 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439533 (* 1 = 0.0439533 loss)
I0312 12:44:22.670199 17663 sgd_solver.cpp:106] Iteration 93200, lr = 1e-12
I0312 12:45:15.924931 17663 solver.cpp:228] Iteration 93300, loss = 0.531025
I0312 12:45:15.924953 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 12:45:15.924960 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.151379 (* 1 = 0.151379 loss)
I0312 12:45:15.924978 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.269486 (* 1 = 0.269486 loss)
I0312 12:45:15.924983 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0089237 (* 1 = 0.0089237 loss)
I0312 12:45:15.924988 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0783534 (* 1 = 0.0783534 loss)
I0312 12:45:15.925005 17663 sgd_solver.cpp:106] Iteration 93300, lr = 1e-12
I0312 12:46:08.428510 17663 solver.cpp:228] Iteration 93400, loss = 0.65369
I0312 12:46:08.428722 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 12:46:08.428781 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.331977 (* 1 = 0.331977 loss)
I0312 12:46:08.428829 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.515571 (* 1 = 0.515571 loss)
I0312 12:46:08.428876 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0552269 (* 1 = 0.0552269 loss)
I0312 12:46:08.428923 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.211721 (* 1 = 0.211721 loss)
I0312 12:46:08.428970 17663 sgd_solver.cpp:106] Iteration 93400, lr = 1e-12
I0312 12:47:01.039572 17663 solver.cpp:228] Iteration 93500, loss = 0.369641
I0312 12:47:01.039594 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 12:47:01.039602 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.157835 (* 1 = 0.157835 loss)
I0312 12:47:01.039620 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.267754 (* 1 = 0.267754 loss)
I0312 12:47:01.039624 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0305365 (* 1 = 0.0305365 loss)
I0312 12:47:01.039629 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0699344 (* 1 = 0.0699344 loss)
I0312 12:47:01.039633 17663 sgd_solver.cpp:106] Iteration 93500, lr = 1e-12
I0312 12:47:53.028133 17663 solver.cpp:228] Iteration 93600, loss = 0.195995
I0312 12:47:53.028168 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 12:47:53.028177 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0694113 (* 1 = 0.0694113 loss)
I0312 12:47:53.028195 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116053 (* 1 = 0.116053 loss)
I0312 12:47:53.028199 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00563214 (* 1 = 0.00563214 loss)
I0312 12:47:53.028204 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324912 (* 1 = 0.0324912 loss)
I0312 12:47:53.028208 17663 sgd_solver.cpp:106] Iteration 93600, lr = 1e-12
I0312 12:48:45.130532 17663 solver.cpp:228] Iteration 93700, loss = 0.505101
I0312 12:48:45.130551 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 12:48:45.130559 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.126581 (* 1 = 0.126581 loss)
I0312 12:48:45.130578 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.178058 (* 1 = 0.178058 loss)
I0312 12:48:45.130583 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0335797 (* 1 = 0.0335797 loss)
I0312 12:48:45.130585 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487417 (* 1 = 0.0487417 loss)
I0312 12:48:45.130604 17663 sgd_solver.cpp:106] Iteration 93700, lr = 1e-12
I0312 12:49:37.505372 17663 solver.cpp:228] Iteration 93800, loss = 0.418365
I0312 12:49:37.505393 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 12:49:37.505399 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.153093 (* 1 = 0.153093 loss)
I0312 12:49:37.505404 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.218432 (* 1 = 0.218432 loss)
I0312 12:49:37.505409 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0330804 (* 1 = 0.0330804 loss)
I0312 12:49:37.505412 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190236 (* 1 = 0.0190236 loss)
I0312 12:49:37.505417 17663 sgd_solver.cpp:106] Iteration 93800, lr = 1e-12
I0312 12:50:30.024087 17663 solver.cpp:228] Iteration 93900, loss = 0.744156
I0312 12:50:30.024111 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:50:30.024118 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485489 (* 1 = 0.0485489 loss)
I0312 12:50:30.024137 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0618649 (* 1 = 0.0618649 loss)
I0312 12:50:30.024142 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0063394 (* 1 = 0.0063394 loss)
I0312 12:50:30.024145 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.167265 (* 1 = 0.167265 loss)
I0312 12:50:30.024150 17663 sgd_solver.cpp:106] Iteration 93900, lr = 1e-12
speed: 0.525s / iter
I0312 12:51:21.824100 17663 solver.cpp:228] Iteration 94000, loss = 0.772806
I0312 12:51:21.824234 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 12:51:21.824291 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.209778 (* 1 = 0.209778 loss)
I0312 12:51:21.824338 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.321538 (* 1 = 0.321538 loss)
I0312 12:51:21.824385 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0488436 (* 1 = 0.0488436 loss)
I0312 12:51:21.824432 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0426017 (* 1 = 0.0426017 loss)
I0312 12:51:21.824478 17663 sgd_solver.cpp:106] Iteration 94000, lr = 1e-12
I0312 12:52:14.231981 17663 solver.cpp:228] Iteration 94100, loss = 0.314384
I0312 12:52:14.232005 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 12:52:14.232012 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.168814 (* 1 = 0.168814 loss)
I0312 12:52:14.232031 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.185925 (* 1 = 0.185925 loss)
I0312 12:52:14.232035 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172677 (* 1 = 0.0172677 loss)
I0312 12:52:14.232040 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0749108 (* 1 = 0.0749108 loss)
I0312 12:52:14.232045 17663 sgd_solver.cpp:106] Iteration 94100, lr = 1e-12
I0312 12:53:07.705551 17663 solver.cpp:228] Iteration 94200, loss = 0.378069
I0312 12:53:07.705575 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 12:53:07.705582 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.157357 (* 1 = 0.157357 loss)
I0312 12:53:07.705601 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.190011 (* 1 = 0.190011 loss)
I0312 12:53:07.705605 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020981 (* 1 = 0.020981 loss)
I0312 12:53:07.705610 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107269 (* 1 = 0.107269 loss)
I0312 12:53:07.705615 17663 sgd_solver.cpp:106] Iteration 94200, lr = 1e-12
I0312 12:53:59.530478 17663 solver.cpp:228] Iteration 94300, loss = 0.44001
I0312 12:53:59.530500 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 12:53:59.530508 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0927214 (* 1 = 0.0927214 loss)
I0312 12:53:59.530513 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.201769 (* 1 = 0.201769 loss)
I0312 12:53:59.530516 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00413967 (* 1 = 0.00413967 loss)
I0312 12:53:59.530520 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0617995 (* 1 = 0.0617995 loss)
I0312 12:53:59.530525 17663 sgd_solver.cpp:106] Iteration 94300, lr = 1e-12
I0312 12:54:51.908310 17663 solver.cpp:228] Iteration 94400, loss = 0.255415
I0312 12:54:51.908332 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 12:54:51.908340 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0648628 (* 1 = 0.0648628 loss)
I0312 12:54:51.908360 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0874521 (* 1 = 0.0874521 loss)
I0312 12:54:51.908363 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241479 (* 1 = 0.0241479 loss)
I0312 12:54:51.908367 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128584 (* 1 = 0.128584 loss)
I0312 12:54:51.908372 17663 sgd_solver.cpp:106] Iteration 94400, lr = 1e-12
I0312 12:55:44.934633 17663 solver.cpp:228] Iteration 94500, loss = 0.732785
I0312 12:55:44.934659 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 12:55:44.934666 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10236 (* 1 = 0.10236 loss)
I0312 12:55:44.934685 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.255115 (* 1 = 0.255115 loss)
I0312 12:55:44.934690 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136903 (* 1 = 0.0136903 loss)
I0312 12:55:44.934695 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027312 (* 1 = 0.027312 loss)
I0312 12:55:44.934700 17663 sgd_solver.cpp:106] Iteration 94500, lr = 1e-12
I0312 12:56:37.371908 17663 solver.cpp:228] Iteration 94600, loss = 0.293142
I0312 12:56:37.371930 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 12:56:37.371937 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732976 (* 1 = 0.0732976 loss)
I0312 12:56:37.371956 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.188299 (* 1 = 0.188299 loss)
I0312 12:56:37.371960 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0495774 (* 1 = 0.0495774 loss)
I0312 12:56:37.371964 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0810756 (* 1 = 0.0810756 loss)
I0312 12:56:37.371969 17663 sgd_solver.cpp:106] Iteration 94600, lr = 1e-12
I0312 12:57:29.725813 17663 solver.cpp:228] Iteration 94700, loss = 0.229326
I0312 12:57:29.725836 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 12:57:29.725844 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353605 (* 1 = 0.0353605 loss)
I0312 12:57:29.725863 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170822 (* 1 = 0.170822 loss)
I0312 12:57:29.725867 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171225 (* 1 = 0.0171225 loss)
I0312 12:57:29.725872 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701559 (* 1 = 0.0701559 loss)
I0312 12:57:29.725877 17663 sgd_solver.cpp:106] Iteration 94700, lr = 1e-12
I0312 12:58:22.231062 17663 solver.cpp:228] Iteration 94800, loss = 0.502021
I0312 12:58:22.231086 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 12:58:22.231093 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0996962 (* 1 = 0.0996962 loss)
I0312 12:58:22.231112 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0931391 (* 1 = 0.0931391 loss)
I0312 12:58:22.231117 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159201 (* 1 = 0.0159201 loss)
I0312 12:58:22.231133 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.301888 (* 1 = 0.301888 loss)
I0312 12:58:22.231138 17663 sgd_solver.cpp:106] Iteration 94800, lr = 1e-12
I0312 12:59:15.099891 17663 solver.cpp:228] Iteration 94900, loss = 0.714476
I0312 12:59:15.099913 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 12:59:15.099920 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322255 (* 1 = 0.0322255 loss)
I0312 12:59:15.099939 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121601 (* 1 = 0.121601 loss)
I0312 12:59:15.099943 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00488876 (* 1 = 0.00488876 loss)
I0312 12:59:15.099948 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.231779 (* 1 = 0.231779 loss)
I0312 12:59:15.099966 17663 sgd_solver.cpp:106] Iteration 94900, lr = 1e-12
speed: 0.525s / iter
I0312 13:00:07.393678 17663 solver.cpp:228] Iteration 95000, loss = 0.326281
I0312 13:00:07.393702 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 13:00:07.393709 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.186891 (* 1 = 0.186891 loss)
I0312 13:00:07.393728 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.265255 (* 1 = 0.265255 loss)
I0312 13:00:07.393733 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241962 (* 1 = 0.0241962 loss)
I0312 13:00:07.393736 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0556146 (* 1 = 0.0556146 loss)
I0312 13:00:07.393754 17663 sgd_solver.cpp:106] Iteration 95000, lr = 1e-12
I0312 13:01:00.546792 17663 solver.cpp:228] Iteration 95100, loss = 0.199228
I0312 13:01:00.546986 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 13:01:00.547045 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00719871 (* 1 = 0.00719871 loss)
I0312 13:01:00.547094 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.064686 (* 1 = 0.064686 loss)
I0312 13:01:00.547140 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0823625 (* 1 = 0.0823625 loss)
I0312 13:01:00.547186 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207435 (* 1 = 0.0207435 loss)
I0312 13:01:00.547235 17663 sgd_solver.cpp:106] Iteration 95100, lr = 1e-12
I0312 13:01:52.995985 17663 solver.cpp:228] Iteration 95200, loss = 0.829583
I0312 13:01:52.996006 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 13:01:52.996014 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0818442 (* 1 = 0.0818442 loss)
I0312 13:01:52.996033 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215759 (* 1 = 0.215759 loss)
I0312 13:01:52.996037 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0748187 (* 1 = 0.0748187 loss)
I0312 13:01:52.996054 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.285769 (* 1 = 0.285769 loss)
I0312 13:01:52.996059 17663 sgd_solver.cpp:106] Iteration 95200, lr = 1e-12
I0312 13:02:45.369302 17663 solver.cpp:228] Iteration 95300, loss = 0.350616
I0312 13:02:45.369326 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 13:02:45.369333 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319615 (* 1 = 0.0319615 loss)
I0312 13:02:45.369338 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0716552 (* 1 = 0.0716552 loss)
I0312 13:02:45.369343 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360377 (* 1 = 0.00360377 loss)
I0312 13:02:45.369346 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00479562 (* 1 = 0.00479562 loss)
I0312 13:02:45.369350 17663 sgd_solver.cpp:106] Iteration 95300, lr = 1e-12
I0312 13:03:38.177103 17663 solver.cpp:228] Iteration 95400, loss = 0.424367
I0312 13:03:38.177124 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 13:03:38.177130 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18876 (* 1 = 0.18876 loss)
I0312 13:03:38.177150 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189681 (* 1 = 0.189681 loss)
I0312 13:03:38.177155 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00930404 (* 1 = 0.00930404 loss)
I0312 13:03:38.177158 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0703874 (* 1 = 0.0703874 loss)
I0312 13:03:38.177162 17663 sgd_solver.cpp:106] Iteration 95400, lr = 1e-12
I0312 13:04:31.135265 17663 solver.cpp:228] Iteration 95500, loss = 0.721416
I0312 13:04:31.135288 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 13:04:31.135294 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.113833 (* 1 = 0.113833 loss)
I0312 13:04:31.135313 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.196641 (* 1 = 0.196641 loss)
I0312 13:04:31.135318 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275776 (* 1 = 0.0275776 loss)
I0312 13:04:31.135321 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134652 (* 1 = 0.134652 loss)
I0312 13:04:31.135326 17663 sgd_solver.cpp:106] Iteration 95500, lr = 1e-12
I0312 13:05:23.514302 17663 solver.cpp:228] Iteration 95600, loss = 0.624853
I0312 13:05:23.514324 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.92233
I0312 13:05:23.514333 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13377 (* 1 = 0.13377 loss)
I0312 13:05:23.514350 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.294123 (* 1 = 0.294123 loss)
I0312 13:05:23.514355 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0697802 (* 1 = 0.0697802 loss)
I0312 13:05:23.514359 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.268843 (* 1 = 0.268843 loss)
I0312 13:05:23.514364 17663 sgd_solver.cpp:106] Iteration 95600, lr = 1e-12
I0312 13:06:16.043941 17663 solver.cpp:228] Iteration 95700, loss = 0.840975
I0312 13:06:16.043969 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 13:06:16.043977 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.129843 (* 1 = 0.129843 loss)
I0312 13:06:16.043997 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.256189 (* 1 = 0.256189 loss)
I0312 13:06:16.044000 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0063784 (* 1 = 0.0063784 loss)
I0312 13:06:16.044004 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495411 (* 1 = 0.0495411 loss)
I0312 13:06:16.044010 17663 sgd_solver.cpp:106] Iteration 95700, lr = 1e-12
I0312 13:07:09.032791 17663 solver.cpp:228] Iteration 95800, loss = 0.42911
I0312 13:07:09.032814 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 13:07:09.032820 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.175077 (* 1 = 0.175077 loss)
I0312 13:07:09.032840 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.296951 (* 1 = 0.296951 loss)
I0312 13:07:09.032845 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00614416 (* 1 = 0.00614416 loss)
I0312 13:07:09.032861 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0573427 (* 1 = 0.0573427 loss)
I0312 13:07:09.032866 17663 sgd_solver.cpp:106] Iteration 95800, lr = 1e-12
I0312 13:08:00.943420 17663 solver.cpp:228] Iteration 95900, loss = 0.656997
I0312 13:08:00.943450 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 13:08:00.943457 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125931 (* 1 = 0.125931 loss)
I0312 13:08:00.943477 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.222533 (* 1 = 0.222533 loss)
I0312 13:08:00.943482 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172157 (* 1 = 0.0172157 loss)
I0312 13:08:00.943486 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.308565 (* 1 = 0.308565 loss)
I0312 13:08:00.943492 17663 sgd_solver.cpp:106] Iteration 95900, lr = 1e-12
speed: 0.525s / iter
I0312 13:08:52.760958 17663 solver.cpp:228] Iteration 96000, loss = 0.183179
I0312 13:08:52.760988 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:08:52.760998 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323786 (* 1 = 0.0323786 loss)
I0312 13:08:52.761003 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0647644 (* 1 = 0.0647644 loss)
I0312 13:08:52.761008 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00847918 (* 1 = 0.00847918 loss)
I0312 13:08:52.761013 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013065 (* 1 = 0.013065 loss)
I0312 13:08:52.761018 17663 sgd_solver.cpp:106] Iteration 96000, lr = 1e-12
I0312 13:09:45.760349 17663 solver.cpp:228] Iteration 96100, loss = 0.995457
I0312 13:09:45.760370 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 13:09:45.760377 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.21734 (* 1 = 0.21734 loss)
I0312 13:09:45.760396 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.258458 (* 1 = 0.258458 loss)
I0312 13:09:45.760401 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0336846 (* 1 = 0.0336846 loss)
I0312 13:09:45.760404 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.158576 (* 1 = 0.158576 loss)
I0312 13:09:45.760409 17663 sgd_solver.cpp:106] Iteration 96100, lr = 1e-12
I0312 13:10:39.071955 17663 solver.cpp:228] Iteration 96200, loss = 0.281497
I0312 13:10:39.071979 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 13:10:39.071986 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.119193 (* 1 = 0.119193 loss)
I0312 13:10:39.072005 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.122968 (* 1 = 0.122968 loss)
I0312 13:10:39.072008 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420095 (* 1 = 0.00420095 loss)
I0312 13:10:39.072028 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0790485 (* 1 = 0.0790485 loss)
I0312 13:10:39.072033 17663 sgd_solver.cpp:106] Iteration 96200, lr = 1e-12
I0312 13:11:32.046406 17663 solver.cpp:228] Iteration 96300, loss = 0.300863
I0312 13:11:32.046427 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 13:11:32.046434 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0202742 (* 1 = 0.0202742 loss)
I0312 13:11:32.046452 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0943235 (* 1 = 0.0943235 loss)
I0312 13:11:32.046458 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245774 (* 1 = 0.0245774 loss)
I0312 13:11:32.046461 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0077464 (* 1 = 0.0077464 loss)
I0312 13:11:32.046466 17663 sgd_solver.cpp:106] Iteration 96300, lr = 1e-12
I0312 13:12:23.889986 17663 solver.cpp:228] Iteration 96400, loss = 1.25822
I0312 13:12:23.890007 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 13:12:23.890014 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.207663 (* 1 = 0.207663 loss)
I0312 13:12:23.890034 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.189108 (* 1 = 0.189108 loss)
I0312 13:12:23.890038 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0287894 (* 1 = 0.0287894 loss)
I0312 13:12:23.890043 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.283892 (* 1 = 0.283892 loss)
I0312 13:12:23.890048 17663 sgd_solver.cpp:106] Iteration 96400, lr = 1e-12
I0312 13:13:16.480056 17663 solver.cpp:228] Iteration 96500, loss = 0.478291
I0312 13:13:16.480079 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 13:13:16.480087 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576276 (* 1 = 0.0576276 loss)
I0312 13:13:16.480105 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.249486 (* 1 = 0.249486 loss)
I0312 13:13:16.480109 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124488 (* 1 = 0.0124488 loss)
I0312 13:13:16.480126 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0984147 (* 1 = 0.0984147 loss)
I0312 13:13:16.480132 17663 sgd_solver.cpp:106] Iteration 96500, lr = 1e-12
I0312 13:14:09.549986 17663 solver.cpp:228] Iteration 96600, loss = 0.292836
I0312 13:14:09.550009 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 13:14:09.550016 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234714 (* 1 = 0.0234714 loss)
I0312 13:14:09.550035 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0551513 (* 1 = 0.0551513 loss)
I0312 13:14:09.550040 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00326358 (* 1 = 0.00326358 loss)
I0312 13:14:09.550045 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0901398 (* 1 = 0.0901398 loss)
I0312 13:14:09.550050 17663 sgd_solver.cpp:106] Iteration 96600, lr = 1e-12
I0312 13:15:01.519793 17663 solver.cpp:228] Iteration 96700, loss = 0.535767
I0312 13:15:01.519822 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 13:15:01.519830 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.120651 (* 1 = 0.120651 loss)
I0312 13:15:01.519835 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.179564 (* 1 = 0.179564 loss)
I0312 13:15:01.519840 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470586 (* 1 = 0.00470586 loss)
I0312 13:15:01.519845 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532229 (* 1 = 0.0532229 loss)
I0312 13:15:01.519852 17663 sgd_solver.cpp:106] Iteration 96700, lr = 1e-12
I0312 13:15:54.330137 17663 solver.cpp:228] Iteration 96800, loss = 0.590888
I0312 13:15:54.330157 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:15:54.330164 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230346 (* 1 = 0.0230346 loss)
I0312 13:15:54.330183 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0924995 (* 1 = 0.0924995 loss)
I0312 13:15:54.330188 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379 (* 1 = 0.00379 loss)
I0312 13:15:54.330191 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0854545 (* 1 = 0.0854545 loss)
I0312 13:15:54.330196 17663 sgd_solver.cpp:106] Iteration 96800, lr = 1e-12
I0312 13:16:46.473031 17663 solver.cpp:228] Iteration 96900, loss = 0.559194
I0312 13:16:46.473053 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 13:16:46.473060 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.237736 (* 1 = 0.237736 loss)
I0312 13:16:46.473080 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.333043 (* 1 = 0.333043 loss)
I0312 13:16:46.473084 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242225 (* 1 = 0.0242225 loss)
I0312 13:16:46.473088 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.230559 (* 1 = 0.230559 loss)
I0312 13:16:46.473093 17663 sgd_solver.cpp:106] Iteration 96900, lr = 1e-12
speed: 0.525s / iter
I0312 13:17:38.588277 17663 solver.cpp:228] Iteration 97000, loss = 0.897169
I0312 13:17:38.588297 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 13:17:38.588304 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.301223 (* 1 = 0.301223 loss)
I0312 13:17:38.588310 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.4447 (* 1 = 0.4447 loss)
I0312 13:17:38.588327 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0493753 (* 1 = 0.0493753 loss)
I0312 13:17:38.588332 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.261221 (* 1 = 0.261221 loss)
I0312 13:17:38.588337 17663 sgd_solver.cpp:106] Iteration 97000, lr = 1e-12
I0312 13:18:31.582486 17663 solver.cpp:228] Iteration 97100, loss = 0.46556
I0312 13:18:31.582509 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 13:18:31.582516 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142534 (* 1 = 0.142534 loss)
I0312 13:18:31.582521 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.283927 (* 1 = 0.283927 loss)
I0312 13:18:31.582525 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0532393 (* 1 = 0.0532393 loss)
I0312 13:18:31.582530 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.297916 (* 1 = 0.297916 loss)
I0312 13:18:31.582535 17663 sgd_solver.cpp:106] Iteration 97100, lr = 1e-12
I0312 13:19:24.138145 17663 solver.cpp:228] Iteration 97200, loss = 0.441263
I0312 13:19:24.138167 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 13:19:24.138175 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0705608 (* 1 = 0.0705608 loss)
I0312 13:19:24.138180 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.224273 (* 1 = 0.224273 loss)
I0312 13:19:24.138185 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00771079 (* 1 = 0.00771079 loss)
I0312 13:19:24.138188 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270047 (* 1 = 0.0270047 loss)
I0312 13:19:24.138208 17663 sgd_solver.cpp:106] Iteration 97200, lr = 1e-12
I0312 13:20:16.797307 17663 solver.cpp:228] Iteration 97300, loss = 0.619501
I0312 13:20:16.797327 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 13:20:16.797334 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486025 (* 1 = 0.0486025 loss)
I0312 13:20:16.797353 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112099 (* 1 = 0.112099 loss)
I0312 13:20:16.797358 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0699251 (* 1 = 0.0699251 loss)
I0312 13:20:16.797361 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.254324 (* 1 = 0.254324 loss)
I0312 13:20:16.797379 17663 sgd_solver.cpp:106] Iteration 97300, lr = 1e-12
I0312 13:21:08.611968 17663 solver.cpp:228] Iteration 97400, loss = 0.5727
I0312 13:21:08.611990 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:21:08.611997 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0296339 (* 1 = 0.0296339 loss)
I0312 13:21:08.612002 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117331 (* 1 = 0.117331 loss)
I0312 13:21:08.612020 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119084 (* 1 = 0.0119084 loss)
I0312 13:21:08.612025 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179079 (* 1 = 0.0179079 loss)
I0312 13:21:08.612030 17663 sgd_solver.cpp:106] Iteration 97400, lr = 1e-12
I0312 13:22:00.469028 17663 solver.cpp:228] Iteration 97500, loss = 0.621159
I0312 13:22:00.469050 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 13:22:00.469058 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.23094 (* 1 = 0.23094 loss)
I0312 13:22:00.469063 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.391578 (* 1 = 0.391578 loss)
I0312 13:22:00.469068 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174738 (* 1 = 0.0174738 loss)
I0312 13:22:00.469071 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.214243 (* 1 = 0.214243 loss)
I0312 13:22:00.469090 17663 sgd_solver.cpp:106] Iteration 97500, lr = 1e-12
I0312 13:22:52.705286 17663 solver.cpp:228] Iteration 97600, loss = 0.183836
I0312 13:22:52.705308 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:22:52.705315 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.027272 (* 1 = 0.027272 loss)
I0312 13:22:52.705334 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0787882 (* 1 = 0.0787882 loss)
I0312 13:22:52.705339 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173736 (* 1 = 0.00173736 loss)
I0312 13:22:52.705356 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188399 (* 1 = 0.0188399 loss)
I0312 13:22:52.705361 17663 sgd_solver.cpp:106] Iteration 97600, lr = 1e-12
I0312 13:23:46.065037 17663 solver.cpp:228] Iteration 97700, loss = 0.277033
I0312 13:23:46.065060 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 13:23:46.065068 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337554 (* 1 = 0.0337554 loss)
I0312 13:23:46.065073 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.103129 (* 1 = 0.103129 loss)
I0312 13:23:46.065076 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000798741 (* 1 = 0.000798741 loss)
I0312 13:23:46.065080 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306191 (* 1 = 0.0306191 loss)
I0312 13:23:46.065085 17663 sgd_solver.cpp:106] Iteration 97700, lr = 1e-12
I0312 13:24:38.902534 17663 solver.cpp:228] Iteration 97800, loss = 0.368952
I0312 13:24:38.902554 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 13:24:38.902562 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.18421 (* 1 = 0.18421 loss)
I0312 13:24:38.902581 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.382862 (* 1 = 0.382862 loss)
I0312 13:24:38.902585 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382291 (* 1 = 0.00382291 loss)
I0312 13:24:38.902590 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0789697 (* 1 = 0.0789697 loss)
I0312 13:24:38.902607 17663 sgd_solver.cpp:106] Iteration 97800, lr = 1e-12
I0312 13:25:31.454804 17663 solver.cpp:228] Iteration 97900, loss = 0.381409
I0312 13:25:31.454825 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 13:25:31.454833 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729011 (* 1 = 0.0729011 loss)
I0312 13:25:31.454851 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.16292 (* 1 = 0.16292 loss)
I0312 13:25:31.454855 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00199854 (* 1 = 0.00199854 loss)
I0312 13:25:31.454859 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261516 (* 1 = 0.0261516 loss)
I0312 13:25:31.454864 17663 sgd_solver.cpp:106] Iteration 97900, lr = 1e-12
speed: 0.525s / iter
I0312 13:26:23.109690 17663 solver.cpp:228] Iteration 98000, loss = 0.508525
I0312 13:26:23.109714 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 13:26:23.109721 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0976358 (* 1 = 0.0976358 loss)
I0312 13:26:23.109725 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.248272 (* 1 = 0.248272 loss)
I0312 13:26:23.109745 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.107897 (* 1 = 0.107897 loss)
I0312 13:26:23.109748 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0456691 (* 1 = 0.0456691 loss)
I0312 13:26:23.109753 17663 sgd_solver.cpp:106] Iteration 98000, lr = 1e-12
I0312 13:27:15.589582 17663 solver.cpp:228] Iteration 98100, loss = 0.758847
I0312 13:27:15.589604 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 13:27:15.589612 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.358903 (* 1 = 0.358903 loss)
I0312 13:27:15.589630 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.431758 (* 1 = 0.431758 loss)
I0312 13:27:15.589634 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.245812 (* 1 = 0.245812 loss)
I0312 13:27:15.589651 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13514 (* 1 = 0.13514 loss)
I0312 13:27:15.589656 17663 sgd_solver.cpp:106] Iteration 98100, lr = 1e-12
I0312 13:28:08.225122 17663 solver.cpp:228] Iteration 98200, loss = 0.419306
I0312 13:28:08.225143 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 13:28:08.225152 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459735 (* 1 = 0.0459735 loss)
I0312 13:28:08.225157 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104403 (* 1 = 0.104403 loss)
I0312 13:28:08.225174 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104295 (* 1 = 0.0104295 loss)
I0312 13:28:08.225179 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051896 (* 1 = 0.051896 loss)
I0312 13:28:08.225184 17663 sgd_solver.cpp:106] Iteration 98200, lr = 1e-12
I0312 13:29:00.634099 17663 solver.cpp:228] Iteration 98300, loss = 0.460805
I0312 13:29:00.634126 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 13:29:00.634133 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0573906 (* 1 = 0.0573906 loss)
I0312 13:29:00.634137 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0982442 (* 1 = 0.0982442 loss)
I0312 13:29:00.634142 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00466176 (* 1 = 0.00466176 loss)
I0312 13:29:00.634146 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245839 (* 1 = 0.0245839 loss)
I0312 13:29:00.634151 17663 sgd_solver.cpp:106] Iteration 98300, lr = 1e-12
I0312 13:29:53.121520 17663 solver.cpp:228] Iteration 98400, loss = 0.204224
I0312 13:29:53.121544 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 13:29:53.121552 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.031004 (* 1 = 0.031004 loss)
I0312 13:29:53.121572 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117684 (* 1 = 0.117684 loss)
I0312 13:29:53.121577 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133354 (* 1 = 0.0133354 loss)
I0312 13:29:53.121580 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10927 (* 1 = 0.10927 loss)
I0312 13:29:53.121587 17663 sgd_solver.cpp:106] Iteration 98400, lr = 1e-12
I0312 13:30:46.078445 17663 solver.cpp:228] Iteration 98500, loss = 0.201939
I0312 13:30:46.078470 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 13:30:46.078478 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0545064 (* 1 = 0.0545064 loss)
I0312 13:30:46.078497 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112093 (* 1 = 0.112093 loss)
I0312 13:30:46.078503 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518206 (* 1 = 0.00518206 loss)
I0312 13:30:46.078521 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388729 (* 1 = 0.0388729 loss)
I0312 13:30:46.078526 17663 sgd_solver.cpp:106] Iteration 98500, lr = 1e-12
I0312 13:31:38.331760 17663 solver.cpp:228] Iteration 98600, loss = 0.248503
I0312 13:31:38.331782 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 13:31:38.331789 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13141 (* 1 = 0.13141 loss)
I0312 13:31:38.331794 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.151365 (* 1 = 0.151365 loss)
I0312 13:31:38.331799 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485914 (* 1 = 0.00485914 loss)
I0312 13:31:38.331802 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244201 (* 1 = 0.0244201 loss)
I0312 13:31:38.331807 17663 sgd_solver.cpp:106] Iteration 98600, lr = 1e-12
I0312 13:32:30.562340 17663 solver.cpp:228] Iteration 98700, loss = 0.43542
I0312 13:32:30.562361 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 13:32:30.562367 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116733 (* 1 = 0.116733 loss)
I0312 13:32:30.562372 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.203041 (* 1 = 0.203041 loss)
I0312 13:32:30.562391 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0292157 (* 1 = 0.0292157 loss)
I0312 13:32:30.562394 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.211762 (* 1 = 0.211762 loss)
I0312 13:32:30.562399 17663 sgd_solver.cpp:106] Iteration 98700, lr = 1e-12
I0312 13:33:22.711396 17663 solver.cpp:228] Iteration 98800, loss = 0.224085
I0312 13:33:22.711418 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:33:22.711426 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453905 (* 1 = 0.0453905 loss)
I0312 13:33:22.711444 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114079 (* 1 = 0.114079 loss)
I0312 13:33:22.711448 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160737 (* 1 = 0.0160737 loss)
I0312 13:33:22.711452 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234251 (* 1 = 0.0234251 loss)
I0312 13:33:22.711457 17663 sgd_solver.cpp:106] Iteration 98800, lr = 1e-12
I0312 13:34:15.153056 17663 solver.cpp:228] Iteration 98900, loss = 0.394326
I0312 13:34:15.153095 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 13:34:15.153101 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.12813 (* 1 = 0.12813 loss)
I0312 13:34:15.153120 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.387053 (* 1 = 0.387053 loss)
I0312 13:34:15.153125 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0674195 (* 1 = 0.0674195 loss)
I0312 13:34:15.153128 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00821273 (* 1 = 0.00821273 loss)
I0312 13:34:15.153133 17663 sgd_solver.cpp:106] Iteration 98900, lr = 1e-12
speed: 0.525s / iter
I0312 13:35:07.392473 17663 solver.cpp:228] Iteration 99000, loss = 0.231582
I0312 13:35:07.392513 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 13:35:07.392521 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0210603 (* 1 = 0.0210603 loss)
I0312 13:35:07.392526 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.042753 (* 1 = 0.042753 loss)
I0312 13:35:07.392530 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0070809 (* 1 = 0.0070809 loss)
I0312 13:35:07.392535 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0754653 (* 1 = 0.0754653 loss)
I0312 13:35:07.392540 17663 sgd_solver.cpp:106] Iteration 99000, lr = 1e-12
I0312 13:35:59.527281 17663 solver.cpp:228] Iteration 99100, loss = 0.181476
I0312 13:35:59.527315 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:35:59.527323 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402868 (* 1 = 0.0402868 loss)
I0312 13:35:59.527328 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105422 (* 1 = 0.105422 loss)
I0312 13:35:59.527333 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114065 (* 1 = 0.0114065 loss)
I0312 13:35:59.527336 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216686 (* 1 = 0.0216686 loss)
I0312 13:35:59.527341 17663 sgd_solver.cpp:106] Iteration 99100, lr = 1e-12
I0312 13:36:52.704823 17663 solver.cpp:228] Iteration 99200, loss = 0.305988
I0312 13:36:52.704996 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 13:36:52.705055 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0306349 (* 1 = 0.0306349 loss)
I0312 13:36:52.705104 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.124048 (* 1 = 0.124048 loss)
I0312 13:36:52.705152 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618345 (* 1 = 0.00618345 loss)
I0312 13:36:52.705199 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624833 (* 1 = 0.0624833 loss)
I0312 13:36:52.705246 17663 sgd_solver.cpp:106] Iteration 99200, lr = 1e-12
I0312 13:37:45.175256 17663 solver.cpp:228] Iteration 99300, loss = 0.497445
I0312 13:37:45.175277 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 13:37:45.175285 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.108224 (* 1 = 0.108224 loss)
I0312 13:37:45.175304 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.18713 (* 1 = 0.18713 loss)
I0312 13:37:45.175308 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0448016 (* 1 = 0.0448016 loss)
I0312 13:37:45.175312 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100202 (* 1 = 0.100202 loss)
I0312 13:37:45.175318 17663 sgd_solver.cpp:106] Iteration 99300, lr = 1e-12
I0312 13:38:37.715204 17663 solver.cpp:228] Iteration 99400, loss = 0.273149
I0312 13:38:37.715225 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:38:37.715232 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.038937 (* 1 = 0.038937 loss)
I0312 13:38:37.715250 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0697117 (* 1 = 0.0697117 loss)
I0312 13:38:37.715255 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015697 (* 1 = 0.015697 loss)
I0312 13:38:37.715260 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168471 (* 1 = 0.168471 loss)
I0312 13:38:37.715263 17663 sgd_solver.cpp:106] Iteration 99400, lr = 1e-12
I0312 13:39:30.502892 17663 solver.cpp:228] Iteration 99500, loss = 0.415522
I0312 13:39:30.502913 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 13:39:30.502921 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.204669 (* 1 = 0.204669 loss)
I0312 13:39:30.502940 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.237989 (* 1 = 0.237989 loss)
I0312 13:39:30.502944 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128161 (* 1 = 0.0128161 loss)
I0312 13:39:30.502948 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183019 (* 1 = 0.0183019 loss)
I0312 13:39:30.502966 17663 sgd_solver.cpp:106] Iteration 99500, lr = 1e-12
I0312 13:40:23.405102 17663 solver.cpp:228] Iteration 99600, loss = 0.362032
I0312 13:40:23.405123 17663 solver.cpp:244]     Train net output #0: accuarcy = 1
I0312 13:40:23.405130 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308728 (* 1 = 0.0308728 loss)
I0312 13:40:23.405150 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0404863 (* 1 = 0.0404863 loss)
I0312 13:40:23.405154 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135893 (* 1 = 0.00135893 loss)
I0312 13:40:23.405158 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00259602 (* 1 = 0.00259602 loss)
I0312 13:40:23.405164 17663 sgd_solver.cpp:106] Iteration 99600, lr = 1e-12
I0312 13:41:15.765368 17663 solver.cpp:228] Iteration 99700, loss = 0.646279
I0312 13:41:15.765393 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 13:41:15.765399 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.190763 (* 1 = 0.190763 loss)
I0312 13:41:15.765419 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.34376 (* 1 = 0.34376 loss)
I0312 13:41:15.765424 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0565784 (* 1 = 0.0565784 loss)
I0312 13:41:15.765427 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395342 (* 1 = 0.0395342 loss)
I0312 13:41:15.765432 17663 sgd_solver.cpp:106] Iteration 99700, lr = 1e-12
I0312 13:42:08.213160 17663 solver.cpp:228] Iteration 99800, loss = 0.408176
I0312 13:42:08.213181 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:42:08.213189 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00833125 (* 1 = 0.00833125 loss)
I0312 13:42:08.213208 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0679864 (* 1 = 0.0679864 loss)
I0312 13:42:08.213212 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315452 (* 1 = 0.00315452 loss)
I0312 13:42:08.213217 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111732 (* 1 = 0.0111732 loss)
I0312 13:42:08.213222 17663 sgd_solver.cpp:106] Iteration 99800, lr = 1e-12
I0312 13:43:01.317096 17663 solver.cpp:228] Iteration 99900, loss = 0.259166
I0312 13:43:01.317117 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:43:01.317124 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215018 (* 1 = 0.0215018 loss)
I0312 13:43:01.317143 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0508111 (* 1 = 0.0508111 loss)
I0312 13:43:01.317147 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012773 (* 1 = 0.012773 loss)
I0312 13:43:01.317152 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0889945 (* 1 = 0.0889945 loss)
I0312 13:43:01.317157 17663 sgd_solver.cpp:106] Iteration 99900, lr = 1e-12
I0312 13:43:53.377465 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_100000.caffemodel
I0312 13:43:53.878415 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_100000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_100000.caffemodel
I0312 13:43:55.027127 17663 solver.cpp:228] Iteration 100000, loss = 0.494026
I0312 13:43:55.027148 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:43:55.027156 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135575 (* 1 = 0.0135575 loss)
I0312 13:43:55.027175 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0495269 (* 1 = 0.0495269 loss)
I0312 13:43:55.027180 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538721 (* 1 = 0.00538721 loss)
I0312 13:43:55.027184 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186078 (* 1 = 0.0186078 loss)
I0312 13:43:55.027189 17663 sgd_solver.cpp:106] Iteration 100000, lr = 1e-13
I0312 13:44:47.363384 17663 solver.cpp:228] Iteration 100100, loss = 0.767795
I0312 13:44:47.363405 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 13:44:47.363414 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.137164 (* 1 = 0.137164 loss)
I0312 13:44:47.363432 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.159417 (* 1 = 0.159417 loss)
I0312 13:44:47.363436 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212656 (* 1 = 0.0212656 loss)
I0312 13:44:47.363440 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0515427 (* 1 = 0.0515427 loss)
I0312 13:44:47.363445 17663 sgd_solver.cpp:106] Iteration 100100, lr = 1e-13
I0312 13:45:39.932823 17663 solver.cpp:228] Iteration 100200, loss = 0.292208
I0312 13:45:39.932844 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 13:45:39.932852 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434008 (* 1 = 0.0434008 loss)
I0312 13:45:39.932870 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.108277 (* 1 = 0.108277 loss)
I0312 13:45:39.932875 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114466 (* 1 = 0.0114466 loss)
I0312 13:45:39.932879 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.180762 (* 1 = 0.180762 loss)
I0312 13:45:39.932884 17663 sgd_solver.cpp:106] Iteration 100200, lr = 1e-13
I0312 13:46:32.135100 17663 solver.cpp:228] Iteration 100300, loss = 0.517186
I0312 13:46:32.135123 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 13:46:32.135129 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0985212 (* 1 = 0.0985212 loss)
I0312 13:46:32.135149 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.240678 (* 1 = 0.240678 loss)
I0312 13:46:32.135152 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0791195 (* 1 = 0.0791195 loss)
I0312 13:46:32.135156 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.392708 (* 1 = 0.392708 loss)
I0312 13:46:32.135162 17663 sgd_solver.cpp:106] Iteration 100300, lr = 1e-13
I0312 13:47:24.455492 17663 solver.cpp:228] Iteration 100400, loss = 0.306144
I0312 13:47:24.455515 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 13:47:24.455523 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.128738 (* 1 = 0.128738 loss)
I0312 13:47:24.455528 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172321 (* 1 = 0.172321 loss)
I0312 13:47:24.455545 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155133 (* 1 = 0.0155133 loss)
I0312 13:47:24.455550 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367151 (* 1 = 0.0367151 loss)
I0312 13:47:24.455555 17663 sgd_solver.cpp:106] Iteration 100400, lr = 1e-13
I0312 13:48:16.867662 17663 solver.cpp:228] Iteration 100500, loss = 0.231722
I0312 13:48:16.867683 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 13:48:16.867691 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0880757 (* 1 = 0.0880757 loss)
I0312 13:48:16.867709 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.14929 (* 1 = 0.14929 loss)
I0312 13:48:16.867714 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00763664 (* 1 = 0.00763664 loss)
I0312 13:48:16.867718 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281835 (* 1 = 0.0281835 loss)
I0312 13:48:16.867723 17663 sgd_solver.cpp:106] Iteration 100500, lr = 1e-13
I0312 13:49:09.550635 17663 solver.cpp:228] Iteration 100600, loss = 0.514837
I0312 13:49:09.550657 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:49:09.550665 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.080856 (* 1 = 0.080856 loss)
I0312 13:49:09.550670 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17107 (* 1 = 0.17107 loss)
I0312 13:49:09.550689 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511799 (* 1 = 0.00511799 loss)
I0312 13:49:09.550693 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282727 (* 1 = 0.0282727 loss)
I0312 13:49:09.550698 17663 sgd_solver.cpp:106] Iteration 100600, lr = 1e-13
I0312 13:50:02.131289 17663 solver.cpp:228] Iteration 100700, loss = 0.085858
I0312 13:50:02.131310 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 13:50:02.131319 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190677 (* 1 = 0.0190677 loss)
I0312 13:50:02.131322 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0297915 (* 1 = 0.0297915 loss)
I0312 13:50:02.131327 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173331 (* 1 = 0.00173331 loss)
I0312 13:50:02.131330 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149934 (* 1 = 0.0149934 loss)
I0312 13:50:02.131336 17663 sgd_solver.cpp:106] Iteration 100700, lr = 1e-13
I0312 13:50:53.646543 17663 solver.cpp:228] Iteration 100800, loss = 0.450293
I0312 13:50:53.646610 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 13:50:53.646617 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.196986 (* 1 = 0.196986 loss)
I0312 13:50:53.646622 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.38867 (* 1 = 0.38867 loss)
I0312 13:50:53.646641 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00798471 (* 1 = 0.00798471 loss)
I0312 13:50:53.646646 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108671 (* 1 = 0.108671 loss)
I0312 13:50:53.646651 17663 sgd_solver.cpp:106] Iteration 100800, lr = 1e-13
I0312 13:51:45.575914 17663 solver.cpp:228] Iteration 100900, loss = 0.304412
I0312 13:51:45.575935 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 13:51:45.575942 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204031 (* 1 = 0.0204031 loss)
I0312 13:51:45.575961 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0415929 (* 1 = 0.0415929 loss)
I0312 13:51:45.575965 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0285421 (* 1 = 0.0285421 loss)
I0312 13:51:45.575969 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.188279 (* 1 = 0.188279 loss)
I0312 13:51:45.575975 17663 sgd_solver.cpp:106] Iteration 100900, lr = 1e-13
speed: 0.525s / iter
I0312 13:52:37.461432 17663 solver.cpp:228] Iteration 101000, loss = 0.123598
I0312 13:52:37.461580 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 13:52:37.461642 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0409582 (* 1 = 0.0409582 loss)
I0312 13:52:37.461690 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0368073 (* 1 = 0.0368073 loss)
I0312 13:52:37.461737 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205659 (* 1 = 0.00205659 loss)
I0312 13:52:37.461786 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0535528 (* 1 = 0.0535528 loss)
I0312 13:52:37.461834 17663 sgd_solver.cpp:106] Iteration 101000, lr = 1e-13
I0312 13:53:29.123358 17663 solver.cpp:228] Iteration 101100, loss = 0.335172
I0312 13:53:29.123379 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 13:53:29.123387 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0734309 (* 1 = 0.0734309 loss)
I0312 13:53:29.123406 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.118578 (* 1 = 0.118578 loss)
I0312 13:53:29.123410 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207898 (* 1 = 0.0207898 loss)
I0312 13:53:29.123414 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.258541 (* 1 = 0.258541 loss)
I0312 13:53:29.123420 17663 sgd_solver.cpp:106] Iteration 101100, lr = 1e-13
I0312 13:54:21.576283 17663 solver.cpp:228] Iteration 101200, loss = 0.335343
I0312 13:54:21.576306 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 13:54:21.576313 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284697 (* 1 = 0.0284697 loss)
I0312 13:54:21.576333 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.115553 (* 1 = 0.115553 loss)
I0312 13:54:21.576337 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633469 (* 1 = 0.00633469 loss)
I0312 13:54:21.576355 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0482583 (* 1 = 0.0482583 loss)
I0312 13:54:21.576360 17663 sgd_solver.cpp:106] Iteration 101200, lr = 1e-13
I0312 13:55:14.549074 17663 solver.cpp:228] Iteration 101300, loss = 0.170984
I0312 13:55:14.549095 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:55:14.549103 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0699108 (* 1 = 0.0699108 loss)
I0312 13:55:14.549121 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.114493 (* 1 = 0.114493 loss)
I0312 13:55:14.549125 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154023 (* 1 = 0.0154023 loss)
I0312 13:55:14.549129 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283519 (* 1 = 0.0283519 loss)
I0312 13:55:14.549134 17663 sgd_solver.cpp:106] Iteration 101300, lr = 1e-13
I0312 13:56:07.685045 17663 solver.cpp:228] Iteration 101400, loss = 0.231043
I0312 13:56:07.685235 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:56:07.685294 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.075932 (* 1 = 0.075932 loss)
I0312 13:56:07.685356 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.109582 (* 1 = 0.109582 loss)
I0312 13:56:07.685403 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211356 (* 1 = 0.0211356 loss)
I0312 13:56:07.685451 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170147 (* 1 = 0.0170147 loss)
I0312 13:56:07.685498 17663 sgd_solver.cpp:106] Iteration 101400, lr = 1e-13
I0312 13:56:59.609647 17663 solver.cpp:228] Iteration 101500, loss = 0.29872
I0312 13:56:59.609668 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 13:56:59.609674 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124867 (* 1 = 0.124867 loss)
I0312 13:56:59.609694 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.201234 (* 1 = 0.201234 loss)
I0312 13:56:59.609699 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00805318 (* 1 = 0.00805318 loss)
I0312 13:56:59.609702 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045436 (* 1 = 0.045436 loss)
I0312 13:56:59.609707 17663 sgd_solver.cpp:106] Iteration 101500, lr = 1e-13
I0312 13:57:51.751675 17663 solver.cpp:228] Iteration 101600, loss = 0.212021
I0312 13:57:51.751698 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 13:57:51.751705 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447181 (* 1 = 0.0447181 loss)
I0312 13:57:51.751709 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0625031 (* 1 = 0.0625031 loss)
I0312 13:57:51.751727 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011392 (* 1 = 0.011392 loss)
I0312 13:57:51.751732 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0690306 (* 1 = 0.0690306 loss)
I0312 13:57:51.751737 17663 sgd_solver.cpp:106] Iteration 101600, lr = 1e-13
I0312 13:58:44.609244 17663 solver.cpp:228] Iteration 101700, loss = 0.129657
I0312 13:58:44.609266 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 13:58:44.609274 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0114062 (* 1 = 0.0114062 loss)
I0312 13:58:44.609293 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0500152 (* 1 = 0.0500152 loss)
I0312 13:58:44.609298 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191009 (* 1 = 0.00191009 loss)
I0312 13:58:44.609302 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340696 (* 1 = 0.0340696 loss)
I0312 13:58:44.609308 17663 sgd_solver.cpp:106] Iteration 101700, lr = 1e-13
I0312 13:59:37.239886 17663 solver.cpp:228] Iteration 101800, loss = 0.180805
I0312 13:59:37.239907 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 13:59:37.239914 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279968 (* 1 = 0.0279968 loss)
I0312 13:59:37.239934 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0688288 (* 1 = 0.0688288 loss)
I0312 13:59:37.239938 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00594107 (* 1 = 0.00594107 loss)
I0312 13:59:37.239943 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219173 (* 1 = 0.0219173 loss)
I0312 13:59:37.239960 17663 sgd_solver.cpp:106] Iteration 101800, lr = 1e-13
I0312 14:00:30.233430 17663 solver.cpp:228] Iteration 101900, loss = 0.700078
I0312 14:00:30.233453 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 14:00:30.233460 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.206332 (* 1 = 0.206332 loss)
I0312 14:00:30.233465 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.39936 (* 1 = 0.39936 loss)
I0312 14:00:30.233469 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0374434 (* 1 = 0.0374434 loss)
I0312 14:00:30.233474 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.167655 (* 1 = 0.167655 loss)
I0312 14:00:30.233492 17663 sgd_solver.cpp:106] Iteration 101900, lr = 1e-13
speed: 0.525s / iter
I0312 14:01:22.613502 17663 solver.cpp:228] Iteration 102000, loss = 0.28554
I0312 14:01:22.613710 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 14:01:22.613786 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347987 (* 1 = 0.0347987 loss)
I0312 14:01:22.613837 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.110601 (* 1 = 0.110601 loss)
I0312 14:01:22.613883 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011195 (* 1 = 0.011195 loss)
I0312 14:01:22.613945 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0534177 (* 1 = 0.0534177 loss)
I0312 14:01:22.613994 17663 sgd_solver.cpp:106] Iteration 102000, lr = 1e-13
I0312 14:02:14.687664 17663 solver.cpp:228] Iteration 102100, loss = 0.207926
I0312 14:02:14.687685 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 14:02:14.687692 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258588 (* 1 = 0.0258588 loss)
I0312 14:02:14.687711 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0727417 (* 1 = 0.0727417 loss)
I0312 14:02:14.687716 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143772 (* 1 = 0.0143772 loss)
I0312 14:02:14.687719 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0636412 (* 1 = 0.0636412 loss)
I0312 14:02:14.687724 17663 sgd_solver.cpp:106] Iteration 102100, lr = 1e-13
I0312 14:03:06.868894 17663 solver.cpp:228] Iteration 102200, loss = 0.320739
I0312 14:03:06.868930 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 14:03:06.868950 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.123753 (* 1 = 0.123753 loss)
I0312 14:03:06.868954 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.263367 (* 1 = 0.263367 loss)
I0312 14:03:06.868975 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214958 (* 1 = 0.0214958 loss)
I0312 14:03:06.868980 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0608321 (* 1 = 0.0608321 loss)
I0312 14:03:06.868985 17663 sgd_solver.cpp:106] Iteration 102200, lr = 1e-13
I0312 14:03:59.489794 17663 solver.cpp:228] Iteration 102300, loss = 0.433288
I0312 14:03:59.489815 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:03:59.489823 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486567 (* 1 = 0.0486567 loss)
I0312 14:03:59.489842 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0761263 (* 1 = 0.0761263 loss)
I0312 14:03:59.489846 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00478018 (* 1 = 0.00478018 loss)
I0312 14:03:59.489850 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034921 (* 1 = 0.034921 loss)
I0312 14:03:59.489856 17663 sgd_solver.cpp:106] Iteration 102300, lr = 1e-13
I0312 14:04:52.235360 17663 solver.cpp:228] Iteration 102400, loss = 0.345157
I0312 14:04:52.235383 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:04:52.235390 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0105464 (* 1 = 0.0105464 loss)
I0312 14:04:52.235410 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0321858 (* 1 = 0.0321858 loss)
I0312 14:04:52.235414 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188068 (* 1 = 0.0188068 loss)
I0312 14:04:52.235419 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566907 (* 1 = 0.0566907 loss)
I0312 14:04:52.235424 17663 sgd_solver.cpp:106] Iteration 102400, lr = 1e-13
I0312 14:05:44.970893 17663 solver.cpp:228] Iteration 102500, loss = 0.35628
I0312 14:05:44.970916 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 14:05:44.970924 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341856 (* 1 = 0.0341856 loss)
I0312 14:05:44.970928 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161709 (* 1 = 0.161709 loss)
I0312 14:05:44.970932 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0447051 (* 1 = 0.0447051 loss)
I0312 14:05:44.970937 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0814031 (* 1 = 0.0814031 loss)
I0312 14:05:44.970955 17663 sgd_solver.cpp:106] Iteration 102500, lr = 1e-13
I0312 14:06:36.729145 17663 solver.cpp:228] Iteration 102600, loss = 0.467131
I0312 14:06:36.729166 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 14:06:36.729173 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0746671 (* 1 = 0.0746671 loss)
I0312 14:06:36.729192 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.200471 (* 1 = 0.200471 loss)
I0312 14:06:36.729197 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00752707 (* 1 = 0.00752707 loss)
I0312 14:06:36.729213 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0605937 (* 1 = 0.0605937 loss)
I0312 14:06:36.729218 17663 sgd_solver.cpp:106] Iteration 102600, lr = 1e-13
I0312 14:07:29.602892 17663 solver.cpp:228] Iteration 102700, loss = 0.253834
I0312 14:07:29.602915 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:07:29.602922 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264766 (* 1 = 0.0264766 loss)
I0312 14:07:29.602926 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.106958 (* 1 = 0.106958 loss)
I0312 14:07:29.602931 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00697634 (* 1 = 0.00697634 loss)
I0312 14:07:29.602936 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.183399 (* 1 = 0.183399 loss)
I0312 14:07:29.602954 17663 sgd_solver.cpp:106] Iteration 102700, lr = 1e-13
I0312 14:08:22.000564 17663 solver.cpp:228] Iteration 102800, loss = 0.150094
I0312 14:08:22.000586 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 14:08:22.000592 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161993 (* 1 = 0.0161993 loss)
I0312 14:08:22.000612 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0212122 (* 1 = 0.0212122 loss)
I0312 14:08:22.000617 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468779 (* 1 = 0.00468779 loss)
I0312 14:08:22.000620 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0876867 (* 1 = 0.0876867 loss)
I0312 14:08:22.000625 17663 sgd_solver.cpp:106] Iteration 102800, lr = 1e-13
I0312 14:09:15.209100 17663 solver.cpp:228] Iteration 102900, loss = 0.507619
I0312 14:09:15.209123 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 14:09:15.209131 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.112945 (* 1 = 0.112945 loss)
I0312 14:09:15.209149 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.223412 (* 1 = 0.223412 loss)
I0312 14:09:15.209153 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.087038 (* 1 = 0.087038 loss)
I0312 14:09:15.209157 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.271151 (* 1 = 0.271151 loss)
I0312 14:09:15.209162 17663 sgd_solver.cpp:106] Iteration 102900, lr = 1e-13
speed: 0.525s / iter
I0312 14:10:07.711040 17663 solver.cpp:228] Iteration 103000, loss = 0.27335
I0312 14:10:07.711194 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:10:07.711252 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10135 (* 1 = 0.10135 loss)
I0312 14:10:07.711300 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0711996 (* 1 = 0.0711996 loss)
I0312 14:10:07.711347 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192841 (* 1 = 0.0192841 loss)
I0312 14:10:07.711395 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.275626 (* 1 = 0.275626 loss)
I0312 14:10:07.711441 17663 sgd_solver.cpp:106] Iteration 103000, lr = 1e-13
I0312 14:11:00.005733 17663 solver.cpp:228] Iteration 103100, loss = 0.326061
I0312 14:11:00.005756 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:11:00.005764 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340834 (* 1 = 0.0340834 loss)
I0312 14:11:00.005784 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0787134 (* 1 = 0.0787134 loss)
I0312 14:11:00.005787 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00884423 (* 1 = 0.00884423 loss)
I0312 14:11:00.005792 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0941589 (* 1 = 0.0941589 loss)
I0312 14:11:00.005797 17663 sgd_solver.cpp:106] Iteration 103100, lr = 1e-13
I0312 14:11:52.330806 17663 solver.cpp:228] Iteration 103200, loss = 0.48699
I0312 14:11:52.330834 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 14:11:52.330842 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142953 (* 1 = 0.142953 loss)
I0312 14:11:52.330862 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.344052 (* 1 = 0.344052 loss)
I0312 14:11:52.330866 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255675 (* 1 = 0.0255675 loss)
I0312 14:11:52.330871 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.14214 (* 1 = 0.14214 loss)
I0312 14:11:52.330876 17663 sgd_solver.cpp:106] Iteration 103200, lr = 1e-13
I0312 14:12:45.192384 17663 solver.cpp:228] Iteration 103300, loss = 0.367329
I0312 14:12:45.192406 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 14:12:45.192414 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.177275 (* 1 = 0.177275 loss)
I0312 14:12:45.192432 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.306899 (* 1 = 0.306899 loss)
I0312 14:12:45.192436 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633441 (* 1 = 0.00633441 loss)
I0312 14:12:45.192440 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00364631 (* 1 = 0.00364631 loss)
I0312 14:12:45.192445 17663 sgd_solver.cpp:106] Iteration 103300, lr = 1e-13
I0312 14:13:37.135709 17663 solver.cpp:228] Iteration 103400, loss = 0.211203
I0312 14:13:37.135730 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:13:37.135751 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.064733 (* 1 = 0.064733 loss)
I0312 14:13:37.135756 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.115139 (* 1 = 0.115139 loss)
I0312 14:13:37.135761 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00531046 (* 1 = 0.00531046 loss)
I0312 14:13:37.135764 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0320457 (* 1 = 0.0320457 loss)
I0312 14:13:37.135784 17663 sgd_solver.cpp:106] Iteration 103400, lr = 1e-13
I0312 14:14:29.485941 17663 solver.cpp:228] Iteration 103500, loss = 0.230992
I0312 14:14:29.485961 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:14:29.485968 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.044917 (* 1 = 0.044917 loss)
I0312 14:14:29.485987 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0893263 (* 1 = 0.0893263 loss)
I0312 14:14:29.485991 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122467 (* 1 = 0.00122467 loss)
I0312 14:14:29.485996 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104067 (* 1 = 0.0104067 loss)
I0312 14:14:29.486001 17663 sgd_solver.cpp:106] Iteration 103500, lr = 1e-13
I0312 14:15:21.624784 17663 solver.cpp:228] Iteration 103600, loss = 0.386251
I0312 14:15:21.624805 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 14:15:21.624812 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374203 (* 1 = 0.0374203 loss)
I0312 14:15:21.624817 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.155303 (* 1 = 0.155303 loss)
I0312 14:15:21.624835 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040193 (* 1 = 0.040193 loss)
I0312 14:15:21.624840 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0649896 (* 1 = 0.0649896 loss)
I0312 14:15:21.624845 17663 sgd_solver.cpp:106] Iteration 103600, lr = 1e-13
I0312 14:16:14.158547 17663 solver.cpp:228] Iteration 103700, loss = 0.199125
I0312 14:16:14.158569 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:16:14.158576 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362049 (* 1 = 0.0362049 loss)
I0312 14:16:14.158594 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0625815 (* 1 = 0.0625815 loss)
I0312 14:16:14.158598 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116939 (* 1 = 0.0116939 loss)
I0312 14:16:14.158603 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334958 (* 1 = 0.0334958 loss)
I0312 14:16:14.158620 17663 sgd_solver.cpp:106] Iteration 103700, lr = 1e-13
I0312 14:17:06.329584 17663 solver.cpp:228] Iteration 103800, loss = 0.266858
I0312 14:17:06.329605 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:17:06.329613 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.077182 (* 1 = 0.077182 loss)
I0312 14:17:06.329632 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.148043 (* 1 = 0.148043 loss)
I0312 14:17:06.329636 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807606 (* 1 = 0.00807606 loss)
I0312 14:17:06.329653 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0581118 (* 1 = 0.0581118 loss)
I0312 14:17:06.329658 17663 sgd_solver.cpp:106] Iteration 103800, lr = 1e-13
I0312 14:17:58.633999 17663 solver.cpp:228] Iteration 103900, loss = 0.333152
I0312 14:17:58.634021 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 14:17:58.634029 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0928477 (* 1 = 0.0928477 loss)
I0312 14:17:58.634033 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144126 (* 1 = 0.144126 loss)
I0312 14:17:58.634052 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0632514 (* 1 = 0.0632514 loss)
I0312 14:17:58.634057 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.264937 (* 1 = 0.264937 loss)
I0312 14:17:58.634063 17663 sgd_solver.cpp:106] Iteration 103900, lr = 1e-13
speed: 0.525s / iter
I0312 14:18:51.449614 17663 solver.cpp:228] Iteration 104000, loss = 0.352119
I0312 14:18:51.449636 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 14:18:51.449645 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0782869 (* 1 = 0.0782869 loss)
I0312 14:18:51.449651 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.242418 (* 1 = 0.242418 loss)
I0312 14:18:51.449654 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124017 (* 1 = 0.0124017 loss)
I0312 14:18:51.449658 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480132 (* 1 = 0.0480132 loss)
I0312 14:18:51.449664 17663 sgd_solver.cpp:106] Iteration 104000, lr = 1e-13
I0312 14:19:43.880909 17663 solver.cpp:228] Iteration 104100, loss = 0.238224
I0312 14:19:43.880930 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 14:19:43.880939 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817896 (* 1 = 0.0817896 loss)
I0312 14:19:43.880957 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.177679 (* 1 = 0.177679 loss)
I0312 14:19:43.880961 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111782 (* 1 = 0.0111782 loss)
I0312 14:19:43.880965 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00676317 (* 1 = 0.00676317 loss)
I0312 14:19:43.880970 17663 sgd_solver.cpp:106] Iteration 104100, lr = 1e-13
I0312 14:20:36.781224 17663 solver.cpp:228] Iteration 104200, loss = 0.613162
I0312 14:20:36.781247 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 14:20:36.781255 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.125655 (* 1 = 0.125655 loss)
I0312 14:20:36.781273 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.138439 (* 1 = 0.138439 loss)
I0312 14:20:36.781277 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128065 (* 1 = 0.0128065 loss)
I0312 14:20:36.781281 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246082 (* 1 = 0.0246082 loss)
I0312 14:20:36.781286 17663 sgd_solver.cpp:106] Iteration 104200, lr = 1e-13
I0312 14:21:29.637275 17663 solver.cpp:228] Iteration 104300, loss = 0.229598
I0312 14:21:29.637295 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:21:29.637302 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0584698 (* 1 = 0.0584698 loss)
I0312 14:21:29.637321 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.123057 (* 1 = 0.123057 loss)
I0312 14:21:29.637326 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186654 (* 1 = 0.0186654 loss)
I0312 14:21:29.637329 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00930241 (* 1 = 0.00930241 loss)
I0312 14:21:29.637334 17663 sgd_solver.cpp:106] Iteration 104300, lr = 1e-13
I0312 14:22:22.487206 17663 solver.cpp:228] Iteration 104400, loss = 0.507054
I0312 14:22:22.487229 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 14:22:22.487237 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.248456 (* 1 = 0.248456 loss)
I0312 14:22:22.487257 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.285152 (* 1 = 0.285152 loss)
I0312 14:22:22.487260 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247445 (* 1 = 0.0247445 loss)
I0312 14:22:22.487264 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109081 (* 1 = 0.109081 loss)
I0312 14:22:22.487269 17663 sgd_solver.cpp:106] Iteration 104400, lr = 1e-13
I0312 14:23:15.318573 17663 solver.cpp:228] Iteration 104500, loss = 0.32533
I0312 14:23:15.318595 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 14:23:15.318603 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0980278 (* 1 = 0.0980278 loss)
I0312 14:23:15.318622 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172232 (* 1 = 0.172232 loss)
I0312 14:23:15.318626 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00308859 (* 1 = 0.00308859 loss)
I0312 14:23:15.318642 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252303 (* 1 = 0.0252303 loss)
I0312 14:23:15.318647 17663 sgd_solver.cpp:106] Iteration 104500, lr = 1e-13
I0312 14:24:07.325536 17663 solver.cpp:228] Iteration 104600, loss = 0.446014
I0312 14:24:07.325557 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 14:24:07.325578 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0425629 (* 1 = 0.0425629 loss)
I0312 14:24:07.325582 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.134263 (* 1 = 0.134263 loss)
I0312 14:24:07.325587 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0036044 (* 1 = 0.0036044 loss)
I0312 14:24:07.325592 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109441 (* 1 = 0.0109441 loss)
I0312 14:24:07.325597 17663 sgd_solver.cpp:106] Iteration 104600, lr = 1e-13
I0312 14:25:00.016840 17663 solver.cpp:228] Iteration 104700, loss = 0.321121
I0312 14:25:00.016862 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 14:25:00.016870 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707785 (* 1 = 0.0707785 loss)
I0312 14:25:00.016890 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.10926 (* 1 = 0.10926 loss)
I0312 14:25:00.016893 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00439231 (* 1 = 0.00439231 loss)
I0312 14:25:00.016897 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321057 (* 1 = 0.0321057 loss)
I0312 14:25:00.016902 17663 sgd_solver.cpp:106] Iteration 104700, lr = 1e-13
I0312 14:25:52.588644 17663 solver.cpp:228] Iteration 104800, loss = 0.563176
I0312 14:25:52.588665 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0312 14:25:52.588671 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.252865 (* 1 = 0.252865 loss)
I0312 14:25:52.588690 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.428799 (* 1 = 0.428799 loss)
I0312 14:25:52.588695 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0799886 (* 1 = 0.0799886 loss)
I0312 14:25:52.588698 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164924 (* 1 = 0.164924 loss)
I0312 14:25:52.588716 17663 sgd_solver.cpp:106] Iteration 104800, lr = 1e-13
I0312 14:26:44.985666 17663 solver.cpp:228] Iteration 104900, loss = 0.168349
I0312 14:26:44.985689 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 14:26:44.985697 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441714 (* 1 = 0.0441714 loss)
I0312 14:26:44.985715 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.141766 (* 1 = 0.141766 loss)
I0312 14:26:44.985720 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00752233 (* 1 = 0.00752233 loss)
I0312 14:26:44.985724 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156702 (* 1 = 0.0156702 loss)
I0312 14:26:44.985729 17663 sgd_solver.cpp:106] Iteration 104900, lr = 1e-13
speed: 0.525s / iter
I0312 14:27:36.893764 17663 solver.cpp:228] Iteration 105000, loss = 0.315905
I0312 14:27:36.893934 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 14:27:36.893991 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0949639 (* 1 = 0.0949639 loss)
I0312 14:27:36.894039 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.176212 (* 1 = 0.176212 loss)
I0312 14:27:36.894085 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030025 (* 1 = 0.030025 loss)
I0312 14:27:36.894134 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134578 (* 1 = 0.134578 loss)
I0312 14:27:36.894179 17663 sgd_solver.cpp:106] Iteration 105000, lr = 1e-13
I0312 14:28:28.837688 17663 solver.cpp:228] Iteration 105100, loss = 0.291644
I0312 14:28:28.837709 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 14:28:28.837718 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0863813 (* 1 = 0.0863813 loss)
I0312 14:28:28.837735 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.227015 (* 1 = 0.227015 loss)
I0312 14:28:28.837740 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00442619 (* 1 = 0.00442619 loss)
I0312 14:28:28.837744 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267934 (* 1 = 0.0267934 loss)
I0312 14:28:28.837749 17663 sgd_solver.cpp:106] Iteration 105100, lr = 1e-13
I0312 14:29:21.638041 17663 solver.cpp:228] Iteration 105200, loss = 0.339057
I0312 14:29:21.638064 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 14:29:21.638072 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.037376 (* 1 = 0.037376 loss)
I0312 14:29:21.638092 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.155319 (* 1 = 0.155319 loss)
I0312 14:29:21.638095 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00946967 (* 1 = 0.00946967 loss)
I0312 14:29:21.638100 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.177398 (* 1 = 0.177398 loss)
I0312 14:29:21.638105 17663 sgd_solver.cpp:106] Iteration 105200, lr = 1e-13
I0312 14:30:15.025218 17663 solver.cpp:228] Iteration 105300, loss = 0.17167
I0312 14:30:15.025239 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:30:15.025246 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251009 (* 1 = 0.0251009 loss)
I0312 14:30:15.025264 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0955732 (* 1 = 0.0955732 loss)
I0312 14:30:15.025269 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141067 (* 1 = 0.0141067 loss)
I0312 14:30:15.025274 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00701317 (* 1 = 0.00701317 loss)
I0312 14:30:15.025279 17663 sgd_solver.cpp:106] Iteration 105300, lr = 1e-13
I0312 14:31:07.672349 17663 solver.cpp:228] Iteration 105400, loss = 0.278412
I0312 14:31:07.672371 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 14:31:07.672379 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257061 (* 1 = 0.0257061 loss)
I0312 14:31:07.672397 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.029616 (* 1 = 0.029616 loss)
I0312 14:31:07.672401 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604998 (* 1 = 0.00604998 loss)
I0312 14:31:07.672406 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0868589 (* 1 = 0.0868589 loss)
I0312 14:31:07.672410 17663 sgd_solver.cpp:106] Iteration 105400, lr = 1e-13
I0312 14:32:00.731823 17663 solver.cpp:228] Iteration 105500, loss = 0.367156
I0312 14:32:00.731844 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 14:32:00.731853 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.183244 (* 1 = 0.183244 loss)
I0312 14:32:00.731871 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.347311 (* 1 = 0.347311 loss)
I0312 14:32:00.731875 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00463413 (* 1 = 0.00463413 loss)
I0312 14:32:00.731879 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387818 (* 1 = 0.0387818 loss)
I0312 14:32:00.731884 17663 sgd_solver.cpp:106] Iteration 105500, lr = 1e-13
I0312 14:32:53.804342 17663 solver.cpp:228] Iteration 105600, loss = 0.637719
I0312 14:32:53.804363 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 14:32:53.804370 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.149308 (* 1 = 0.149308 loss)
I0312 14:32:53.804389 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.264141 (* 1 = 0.264141 loss)
I0312 14:32:53.804394 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.183245 (* 1 = 0.183245 loss)
I0312 14:32:53.804397 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.553113 (* 1 = 0.553113 loss)
I0312 14:32:53.804401 17663 sgd_solver.cpp:106] Iteration 105600, lr = 1e-13
I0312 14:33:45.381916 17663 solver.cpp:228] Iteration 105700, loss = 0.338899
I0312 14:33:45.381937 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 14:33:45.381943 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415509 (* 1 = 0.0415509 loss)
I0312 14:33:45.381963 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0877022 (* 1 = 0.0877022 loss)
I0312 14:33:45.381968 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00293166 (* 1 = 0.00293166 loss)
I0312 14:33:45.381971 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051429 (* 1 = 0.051429 loss)
I0312 14:33:45.381975 17663 sgd_solver.cpp:106] Iteration 105700, lr = 1e-13
I0312 14:34:38.374099 17663 solver.cpp:228] Iteration 105800, loss = 0.287856
I0312 14:34:38.374120 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 14:34:38.374127 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10557 (* 1 = 0.10557 loss)
I0312 14:34:38.374146 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.198124 (* 1 = 0.198124 loss)
I0312 14:34:38.374151 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166808 (* 1 = 0.0166808 loss)
I0312 14:34:38.374155 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0779391 (* 1 = 0.0779391 loss)
I0312 14:34:38.374161 17663 sgd_solver.cpp:106] Iteration 105800, lr = 1e-13
I0312 14:35:30.433689 17663 solver.cpp:228] Iteration 105900, loss = 0.765729
I0312 14:35:30.433712 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 14:35:30.433719 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.135745 (* 1 = 0.135745 loss)
I0312 14:35:30.433738 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.208876 (* 1 = 0.208876 loss)
I0312 14:35:30.433743 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173703 (* 1 = 0.0173703 loss)
I0312 14:35:30.433746 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474762 (* 1 = 0.0474762 loss)
I0312 14:35:30.433751 17663 sgd_solver.cpp:106] Iteration 105900, lr = 1e-13
speed: 0.525s / iter
I0312 14:36:22.303819 17663 solver.cpp:228] Iteration 106000, loss = 0.350543
I0312 14:36:22.303841 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 14:36:22.303848 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0663158 (* 1 = 0.0663158 loss)
I0312 14:36:22.303867 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.233827 (* 1 = 0.233827 loss)
I0312 14:36:22.303871 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192675 (* 1 = 0.0192675 loss)
I0312 14:36:22.303875 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117756 (* 1 = 0.117756 loss)
I0312 14:36:22.303880 17663 sgd_solver.cpp:106] Iteration 106000, lr = 1e-13
I0312 14:37:15.008182 17663 solver.cpp:228] Iteration 106100, loss = 0.466238
I0312 14:37:15.008203 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:37:15.008210 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0740102 (* 1 = 0.0740102 loss)
I0312 14:37:15.008229 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0748965 (* 1 = 0.0748965 loss)
I0312 14:37:15.008234 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0551125 (* 1 = 0.0551125 loss)
I0312 14:37:15.008237 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0963008 (* 1 = 0.0963008 loss)
I0312 14:37:15.008242 17663 sgd_solver.cpp:106] Iteration 106100, lr = 1e-13
I0312 14:38:08.139853 17663 solver.cpp:228] Iteration 106200, loss = 0.547892
I0312 14:38:08.139876 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0312 14:38:08.139883 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.191824 (* 1 = 0.191824 loss)
I0312 14:38:08.139902 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.372679 (* 1 = 0.372679 loss)
I0312 14:38:08.139907 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289685 (* 1 = 0.0289685 loss)
I0312 14:38:08.139911 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168802 (* 1 = 0.168802 loss)
I0312 14:38:08.139916 17663 sgd_solver.cpp:106] Iteration 106200, lr = 1e-13
I0312 14:39:00.654091 17663 solver.cpp:228] Iteration 106300, loss = 0.722571
I0312 14:39:00.654115 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0312 14:39:00.654122 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.344053 (* 1 = 0.344053 loss)
I0312 14:39:00.654140 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.542127 (* 1 = 0.542127 loss)
I0312 14:39:00.654145 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132139 (* 1 = 0.0132139 loss)
I0312 14:39:00.654150 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125769 (* 1 = 0.125769 loss)
I0312 14:39:00.654155 17663 sgd_solver.cpp:106] Iteration 106300, lr = 1e-13
I0312 14:39:53.451087 17663 solver.cpp:228] Iteration 106400, loss = 0.212097
I0312 14:39:53.451108 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:39:53.451115 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299093 (* 1 = 0.0299093 loss)
I0312 14:39:53.451119 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0998064 (* 1 = 0.0998064 loss)
I0312 14:39:53.451138 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00386448 (* 1 = 0.00386448 loss)
I0312 14:39:53.451143 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010877 (* 1 = 0.010877 loss)
I0312 14:39:53.451148 17663 sgd_solver.cpp:106] Iteration 106400, lr = 1e-13
I0312 14:40:44.924805 17663 solver.cpp:228] Iteration 106500, loss = 0.158859
I0312 14:40:44.924829 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:40:44.924836 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442748 (* 1 = 0.0442748 loss)
I0312 14:40:44.924841 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0883183 (* 1 = 0.0883183 loss)
I0312 14:40:44.924860 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114584 (* 1 = 0.0114584 loss)
I0312 14:40:44.924863 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.072624 (* 1 = 0.072624 loss)
I0312 14:40:44.924868 17663 sgd_solver.cpp:106] Iteration 106500, lr = 1e-13
I0312 14:41:37.272789 17663 solver.cpp:228] Iteration 106600, loss = 0.22838
I0312 14:41:37.272809 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 14:41:37.272816 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373167 (* 1 = 0.0373167 loss)
I0312 14:41:37.272836 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0839536 (* 1 = 0.0839536 loss)
I0312 14:41:37.272840 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101105 (* 1 = 0.00101105 loss)
I0312 14:41:37.272845 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00521518 (* 1 = 0.00521518 loss)
I0312 14:41:37.272850 17663 sgd_solver.cpp:106] Iteration 106600, lr = 1e-13
I0312 14:42:29.656060 17663 solver.cpp:228] Iteration 106700, loss = 0.207954
I0312 14:42:29.656083 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:42:29.656090 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272379 (* 1 = 0.0272379 loss)
I0312 14:42:29.656110 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0920772 (* 1 = 0.0920772 loss)
I0312 14:42:29.656114 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376459 (* 1 = 0.00376459 loss)
I0312 14:42:29.656119 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139436 (* 1 = 0.0139436 loss)
I0312 14:42:29.656123 17663 sgd_solver.cpp:106] Iteration 106700, lr = 1e-13
I0312 14:43:21.996765 17663 solver.cpp:228] Iteration 106800, loss = 0.139894
I0312 14:43:21.996788 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 14:43:21.996795 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.015643 (* 1 = 0.015643 loss)
I0312 14:43:21.996814 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0638608 (* 1 = 0.0638608 loss)
I0312 14:43:21.996819 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151545 (* 1 = 0.00151545 loss)
I0312 14:43:21.996821 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0486545 (* 1 = 0.0486545 loss)
I0312 14:43:21.996826 17663 sgd_solver.cpp:106] Iteration 106800, lr = 1e-13
I0312 14:44:13.860150 17663 solver.cpp:228] Iteration 106900, loss = 0.802123
I0312 14:44:13.860174 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 14:44:13.860182 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.04358 (* 1 = 0.04358 loss)
I0312 14:44:13.860201 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0932342 (* 1 = 0.0932342 loss)
I0312 14:44:13.860205 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123138 (* 1 = 0.0123138 loss)
I0312 14:44:13.860209 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00591452 (* 1 = 0.00591452 loss)
I0312 14:44:13.860214 17663 sgd_solver.cpp:106] Iteration 106900, lr = 1e-13
speed: 0.525s / iter
I0312 14:45:07.053658 17663 solver.cpp:228] Iteration 107000, loss = 0.734061
I0312 14:45:07.053681 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0312 14:45:07.053689 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.424673 (* 1 = 0.424673 loss)
I0312 14:45:07.053707 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.395163 (* 1 = 0.395163 loss)
I0312 14:45:07.053712 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0399578 (* 1 = 0.0399578 loss)
I0312 14:45:07.053730 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.321187 (* 1 = 0.321187 loss)
I0312 14:45:07.053735 17663 sgd_solver.cpp:106] Iteration 107000, lr = 1e-13
I0312 14:45:59.252135 17663 solver.cpp:228] Iteration 107100, loss = 0.529261
I0312 14:45:59.252156 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 14:45:59.252164 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676037 (* 1 = 0.0676037 loss)
I0312 14:45:59.252183 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.17432 (* 1 = 0.17432 loss)
I0312 14:45:59.252187 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.127654 (* 1 = 0.127654 loss)
I0312 14:45:59.252204 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.342908 (* 1 = 0.342908 loss)
I0312 14:45:59.252209 17663 sgd_solver.cpp:106] Iteration 107100, lr = 1e-13
I0312 14:46:52.298454 17663 solver.cpp:228] Iteration 107200, loss = 0.420258
I0312 14:46:52.298476 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 14:46:52.298483 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.241123 (* 1 = 0.241123 loss)
I0312 14:46:52.298503 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.315162 (* 1 = 0.315162 loss)
I0312 14:46:52.298507 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275013 (* 1 = 0.0275013 loss)
I0312 14:46:52.298526 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0629394 (* 1 = 0.0629394 loss)
I0312 14:46:52.298530 17663 sgd_solver.cpp:106] Iteration 107200, lr = 1e-13
I0312 14:47:44.838495 17663 solver.cpp:228] Iteration 107300, loss = 0.470963
I0312 14:47:44.838516 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 14:47:44.838523 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0828838 (* 1 = 0.0828838 loss)
I0312 14:47:44.838542 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.132139 (* 1 = 0.132139 loss)
I0312 14:47:44.838546 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0511356 (* 1 = 0.0511356 loss)
I0312 14:47:44.838551 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137236 (* 1 = 0.137236 loss)
I0312 14:47:44.838568 17663 sgd_solver.cpp:106] Iteration 107300, lr = 1e-13
I0312 14:48:37.608152 17663 solver.cpp:228] Iteration 107400, loss = 0.829467
I0312 14:48:37.608176 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0312 14:48:37.608184 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.366283 (* 1 = 0.366283 loss)
I0312 14:48:37.608202 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.62469 (* 1 = 0.62469 loss)
I0312 14:48:37.608207 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00788237 (* 1 = 0.00788237 loss)
I0312 14:48:37.608212 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150925 (* 1 = 0.150925 loss)
I0312 14:48:37.608217 17663 sgd_solver.cpp:106] Iteration 107400, lr = 1e-13
I0312 14:49:30.445564 17663 solver.cpp:228] Iteration 107500, loss = 0.250777
I0312 14:49:30.445587 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 14:49:30.445596 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472485 (* 1 = 0.0472485 loss)
I0312 14:49:30.445601 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157151 (* 1 = 0.157151 loss)
I0312 14:49:30.445605 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215729 (* 1 = 0.0215729 loss)
I0312 14:49:30.445610 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0573848 (* 1 = 0.0573848 loss)
I0312 14:49:30.445614 17663 sgd_solver.cpp:106] Iteration 107500, lr = 1e-13
I0312 14:50:23.922788 17663 solver.cpp:228] Iteration 107600, loss = 0.228083
I0312 14:50:23.922811 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:50:23.922818 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00775537 (* 1 = 0.00775537 loss)
I0312 14:50:23.922838 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0662141 (* 1 = 0.0662141 loss)
I0312 14:50:23.922842 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276095 (* 1 = 0.00276095 loss)
I0312 14:50:23.922859 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160686 (* 1 = 0.0160686 loss)
I0312 14:50:23.922864 17663 sgd_solver.cpp:106] Iteration 107600, lr = 1e-13
I0312 14:51:16.180714 17663 solver.cpp:228] Iteration 107700, loss = 0.482185
I0312 14:51:16.180735 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 14:51:16.180742 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.153993 (* 1 = 0.153993 loss)
I0312 14:51:16.180760 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.212822 (* 1 = 0.212822 loss)
I0312 14:51:16.180765 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016307 (* 1 = 0.016307 loss)
I0312 14:51:16.180769 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555599 (* 1 = 0.0555599 loss)
I0312 14:51:16.180774 17663 sgd_solver.cpp:106] Iteration 107700, lr = 1e-13
I0312 14:52:08.487207 17663 solver.cpp:228] Iteration 107800, loss = 0.203349
I0312 14:52:08.487236 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:52:08.487242 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0553545 (* 1 = 0.0553545 loss)
I0312 14:52:08.487247 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0690835 (* 1 = 0.0690835 loss)
I0312 14:52:08.487265 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00373678 (* 1 = 0.00373678 loss)
I0312 14:52:08.487283 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305962 (* 1 = 0.0305962 loss)
I0312 14:52:08.487289 17663 sgd_solver.cpp:106] Iteration 107800, lr = 1e-13
I0312 14:53:01.163159 17663 solver.cpp:228] Iteration 107900, loss = 0.516496
I0312 14:53:01.163182 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 14:53:01.163189 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385779 (* 1 = 0.0385779 loss)
I0312 14:53:01.163208 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.126843 (* 1 = 0.126843 loss)
I0312 14:53:01.163213 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0825989 (* 1 = 0.0825989 loss)
I0312 14:53:01.163229 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.324033 (* 1 = 0.324033 loss)
I0312 14:53:01.163234 17663 sgd_solver.cpp:106] Iteration 107900, lr = 1e-13
speed: 0.525s / iter
I0312 14:53:53.966675 17663 solver.cpp:228] Iteration 108000, loss = 0.486762
I0312 14:53:53.966697 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 14:53:53.966706 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226172 (* 1 = 0.0226172 loss)
I0312 14:53:53.966709 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0657538 (* 1 = 0.0657538 loss)
I0312 14:53:53.966728 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128338 (* 1 = 0.0128338 loss)
I0312 14:53:53.966732 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183145 (* 1 = 0.0183145 loss)
I0312 14:53:53.966737 17663 sgd_solver.cpp:106] Iteration 108000, lr = 1e-13
I0312 14:54:46.144280 17663 solver.cpp:228] Iteration 108100, loss = 0.398665
I0312 14:54:46.144304 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 14:54:46.144311 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.12803 (* 1 = 0.12803 loss)
I0312 14:54:46.144330 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.340899 (* 1 = 0.340899 loss)
I0312 14:54:46.144335 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.124945 (* 1 = 0.124945 loss)
I0312 14:54:46.144340 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337288 (* 1 = 0.0337288 loss)
I0312 14:54:46.144345 17663 sgd_solver.cpp:106] Iteration 108100, lr = 1e-13
I0312 14:55:38.833201 17663 solver.cpp:228] Iteration 108200, loss = 0.562935
I0312 14:55:38.833226 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 14:55:38.833235 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.283637 (* 1 = 0.283637 loss)
I0312 14:55:38.833238 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.436185 (* 1 = 0.436185 loss)
I0312 14:55:38.833256 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.101517 (* 1 = 0.101517 loss)
I0312 14:55:38.833261 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102312 (* 1 = 0.102312 loss)
I0312 14:55:38.833266 17663 sgd_solver.cpp:106] Iteration 108200, lr = 1e-13
I0312 14:56:32.219472 17663 solver.cpp:228] Iteration 108300, loss = 0.532961
I0312 14:56:32.219494 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 14:56:32.219501 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.197044 (* 1 = 0.197044 loss)
I0312 14:56:32.219521 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.195066 (* 1 = 0.195066 loss)
I0312 14:56:32.219524 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0391767 (* 1 = 0.0391767 loss)
I0312 14:56:32.219528 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191354 (* 1 = 0.191354 loss)
I0312 14:56:32.219533 17663 sgd_solver.cpp:106] Iteration 108300, lr = 1e-13
I0312 14:57:24.433297 17663 solver.cpp:228] Iteration 108400, loss = nan
I0312 14:57:24.433316 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 14:57:24.433324 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.172714 (* 1 = 0.172714 loss)
I0312 14:57:24.433343 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.251288 (* 1 = 0.251288 loss)
I0312 14:57:24.433347 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170125 (* 1 = 0.0170125 loss)
I0312 14:57:24.433351 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0426067 (* 1 = 0.0426067 loss)
I0312 14:57:24.433357 17663 sgd_solver.cpp:106] Iteration 108400, lr = 1e-13
I0312 14:58:16.792982 17663 solver.cpp:228] Iteration 108500, loss = 0.286412
I0312 14:58:16.793005 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 14:58:16.793014 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0577348 (* 1 = 0.0577348 loss)
I0312 14:58:16.793032 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.14139 (* 1 = 0.14139 loss)
I0312 14:58:16.793036 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296281 (* 1 = 0.0296281 loss)
I0312 14:58:16.793041 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162775 (* 1 = 0.0162775 loss)
I0312 14:58:16.793045 17663 sgd_solver.cpp:106] Iteration 108500, lr = 1e-13
I0312 14:59:09.321722 17663 solver.cpp:228] Iteration 108600, loss = 0.630876
I0312 14:59:09.321745 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 14:59:09.321753 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.112509 (* 1 = 0.112509 loss)
I0312 14:59:09.321771 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.186245 (* 1 = 0.186245 loss)
I0312 14:59:09.321775 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131189 (* 1 = 0.0131189 loss)
I0312 14:59:09.321779 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340705 (* 1 = 0.0340705 loss)
I0312 14:59:09.321784 17663 sgd_solver.cpp:106] Iteration 108600, lr = 1e-13
I0312 15:00:02.504961 17663 solver.cpp:228] Iteration 108700, loss = 0.335943
I0312 15:00:02.504983 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 15:00:02.504992 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0694011 (* 1 = 0.0694011 loss)
I0312 15:00:02.504997 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0777782 (* 1 = 0.0777782 loss)
I0312 15:00:02.505000 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008744 (* 1 = 0.008744 loss)
I0312 15:00:02.505004 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00508728 (* 1 = 0.00508728 loss)
I0312 15:00:02.505009 17663 sgd_solver.cpp:106] Iteration 108700, lr = 1e-13
I0312 15:00:55.306963 17663 solver.cpp:228] Iteration 108800, loss = 0.391393
I0312 15:00:55.306985 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 15:00:55.306993 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0773642 (* 1 = 0.0773642 loss)
I0312 15:00:55.306998 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146019 (* 1 = 0.146019 loss)
I0312 15:00:55.307001 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0084779 (* 1 = 0.0084779 loss)
I0312 15:00:55.307005 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0509937 (* 1 = 0.0509937 loss)
I0312 15:00:55.307010 17663 sgd_solver.cpp:106] Iteration 108800, lr = 1e-13
I0312 15:01:47.598641 17663 solver.cpp:228] Iteration 108900, loss = 0.302445
I0312 15:01:47.598664 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 15:01:47.598671 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691911 (* 1 = 0.0691911 loss)
I0312 15:01:47.598690 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219961 (* 1 = 0.219961 loss)
I0312 15:01:47.598695 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200676 (* 1 = 0.0200676 loss)
I0312 15:01:47.598698 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110731 (* 1 = 0.110731 loss)
I0312 15:01:47.598703 17663 sgd_solver.cpp:106] Iteration 108900, lr = 1e-13
speed: 0.525s / iter
I0312 15:02:39.439096 17663 solver.cpp:228] Iteration 109000, loss = 0.724283
I0312 15:02:39.439118 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 15:02:39.439126 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.271508 (* 1 = 0.271508 loss)
I0312 15:02:39.439129 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.482971 (* 1 = 0.482971 loss)
I0312 15:02:39.439147 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294154 (* 1 = 0.00294154 loss)
I0312 15:02:39.439152 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0463458 (* 1 = 0.0463458 loss)
I0312 15:02:39.439157 17663 sgd_solver.cpp:106] Iteration 109000, lr = 1e-13
I0312 15:03:31.904127 17663 solver.cpp:228] Iteration 109100, loss = 0.394766
I0312 15:03:31.904150 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 15:03:31.904157 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0723413 (* 1 = 0.0723413 loss)
I0312 15:03:31.904161 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.200112 (* 1 = 0.200112 loss)
I0312 15:03:31.904165 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0068793 (* 1 = 0.0068793 loss)
I0312 15:03:31.904170 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392557 (* 1 = 0.0392557 loss)
I0312 15:03:31.904175 17663 sgd_solver.cpp:106] Iteration 109100, lr = 1e-13
I0312 15:04:24.123414 17663 solver.cpp:228] Iteration 109200, loss = 0.227781
I0312 15:04:24.123435 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:04:24.123441 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729115 (* 1 = 0.0729115 loss)
I0312 15:04:24.123461 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147327 (* 1 = 0.147327 loss)
I0312 15:04:24.123466 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00506365 (* 1 = 0.00506365 loss)
I0312 15:04:24.123469 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681574 (* 1 = 0.0681574 loss)
I0312 15:04:24.123473 17663 sgd_solver.cpp:106] Iteration 109200, lr = 1e-13
I0312 15:05:16.552961 17663 solver.cpp:228] Iteration 109300, loss = 0.483367
I0312 15:05:16.552983 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 15:05:16.552991 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0778844 (* 1 = 0.0778844 loss)
I0312 15:05:16.553010 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.371111 (* 1 = 0.371111 loss)
I0312 15:05:16.553014 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153956 (* 1 = 0.0153956 loss)
I0312 15:05:16.553019 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0991676 (* 1 = 0.0991676 loss)
I0312 15:05:16.553023 17663 sgd_solver.cpp:106] Iteration 109300, lr = 1e-13
I0312 15:06:08.812245 17663 solver.cpp:228] Iteration 109400, loss = 0.404751
I0312 15:06:08.812266 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 15:06:08.812274 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0137677 (* 1 = 0.0137677 loss)
I0312 15:06:08.812294 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0726681 (* 1 = 0.0726681 loss)
I0312 15:06:08.812297 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0037841 (* 1 = 0.0037841 loss)
I0312 15:06:08.812301 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00754978 (* 1 = 0.00754978 loss)
I0312 15:06:08.812306 17663 sgd_solver.cpp:106] Iteration 109400, lr = 1e-13
I0312 15:07:01.113122 17663 solver.cpp:228] Iteration 109500, loss = 0.438866
I0312 15:07:01.113147 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 15:07:01.113154 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.166348 (* 1 = 0.166348 loss)
I0312 15:07:01.113158 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.233888 (* 1 = 0.233888 loss)
I0312 15:07:01.113178 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100419 (* 1 = 0.0100419 loss)
I0312 15:07:01.113181 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0558879 (* 1 = 0.0558879 loss)
I0312 15:07:01.113186 17663 sgd_solver.cpp:106] Iteration 109500, lr = 1e-13
I0312 15:07:53.435866 17663 solver.cpp:228] Iteration 109600, loss = 0.929839
I0312 15:07:53.435887 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 15:07:53.435895 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.142872 (* 1 = 0.142872 loss)
I0312 15:07:53.435914 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.251067 (* 1 = 0.251067 loss)
I0312 15:07:53.435919 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178054 (* 1 = 0.0178054 loss)
I0312 15:07:53.435922 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0460095 (* 1 = 0.0460095 loss)
I0312 15:07:53.435940 17663 sgd_solver.cpp:106] Iteration 109600, lr = 1e-13
I0312 15:08:46.582662 17663 solver.cpp:228] Iteration 109700, loss = 0.421529
I0312 15:08:46.582684 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:08:46.582690 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116991 (* 1 = 0.116991 loss)
I0312 15:08:46.582710 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.178982 (* 1 = 0.178982 loss)
I0312 15:08:46.582713 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0578304 (* 1 = 0.0578304 loss)
I0312 15:08:46.582717 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.302807 (* 1 = 0.302807 loss)
I0312 15:08:46.582736 17663 sgd_solver.cpp:106] Iteration 109700, lr = 1e-13
I0312 15:09:39.961897 17663 solver.cpp:228] Iteration 109800, loss = 0.417364
I0312 15:09:39.961949 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 15:09:39.961971 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321359 (* 1 = 0.0321359 loss)
I0312 15:09:39.961974 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0698026 (* 1 = 0.0698026 loss)
I0312 15:09:39.961992 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229108 (* 1 = 0.00229108 loss)
I0312 15:09:39.961997 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0696207 (* 1 = 0.0696207 loss)
I0312 15:09:39.962015 17663 sgd_solver.cpp:106] Iteration 109800, lr = 1e-13
I0312 15:10:32.534955 17663 solver.cpp:228] Iteration 109900, loss = 0.599866
I0312 15:10:32.534977 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 15:10:32.534986 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.13679 (* 1 = 0.13679 loss)
I0312 15:10:32.535004 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.256882 (* 1 = 0.256882 loss)
I0312 15:10:32.535009 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0649132 (* 1 = 0.0649132 loss)
I0312 15:10:32.535013 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0505582 (* 1 = 0.0505582 loss)
I0312 15:10:32.535018 17663 sgd_solver.cpp:106] Iteration 109900, lr = 1e-13
I0312 15:11:25.285686 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_110000.caffemodel
I0312 15:11:25.781797 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_110000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_110000.caffemodel
I0312 15:11:26.831598 17663 solver.cpp:228] Iteration 110000, loss = 0.294208
I0312 15:11:26.831619 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 15:11:26.831627 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0749031 (* 1 = 0.0749031 loss)
I0312 15:11:26.831646 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.146078 (* 1 = 0.146078 loss)
I0312 15:11:26.831650 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141148 (* 1 = 0.0141148 loss)
I0312 15:11:26.831655 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0772775 (* 1 = 0.0772775 loss)
I0312 15:11:26.831660 17663 sgd_solver.cpp:106] Iteration 110000, lr = 1e-14
I0312 15:12:19.330287 17663 solver.cpp:228] Iteration 110100, loss = 0.83959
I0312 15:12:19.330308 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 15:12:19.330317 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.262843 (* 1 = 0.262843 loss)
I0312 15:12:19.330320 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.273765 (* 1 = 0.273765 loss)
I0312 15:12:19.330324 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.13007 (* 1 = 0.13007 loss)
I0312 15:12:19.330328 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.318132 (* 1 = 0.318132 loss)
I0312 15:12:19.330333 17663 sgd_solver.cpp:106] Iteration 110100, lr = 1e-14
I0312 15:13:11.417672 17663 solver.cpp:228] Iteration 110200, loss = 0.202122
I0312 15:13:11.417695 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 15:13:11.417701 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183128 (* 1 = 0.0183128 loss)
I0312 15:13:11.417721 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0792664 (* 1 = 0.0792664 loss)
I0312 15:13:11.417724 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198996 (* 1 = 0.00198996 loss)
I0312 15:13:11.417728 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401132 (* 1 = 0.0401132 loss)
I0312 15:13:11.417733 17663 sgd_solver.cpp:106] Iteration 110200, lr = 1e-14
I0312 15:14:03.596848 17663 solver.cpp:228] Iteration 110300, loss = 0.198558
I0312 15:14:03.596870 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 15:14:03.596877 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0641149 (* 1 = 0.0641149 loss)
I0312 15:14:03.596895 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.152455 (* 1 = 0.152455 loss)
I0312 15:14:03.596899 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0310616 (* 1 = 0.0310616 loss)
I0312 15:14:03.596904 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0559576 (* 1 = 0.0559576 loss)
I0312 15:14:03.596921 17663 sgd_solver.cpp:106] Iteration 110300, lr = 1e-14
I0312 15:14:56.503079 17663 solver.cpp:228] Iteration 110400, loss = 0.126567
I0312 15:14:56.503103 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 15:14:56.503110 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226348 (* 1 = 0.0226348 loss)
I0312 15:14:56.503129 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0579774 (* 1 = 0.0579774 loss)
I0312 15:14:56.503134 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108268 (* 1 = 0.00108268 loss)
I0312 15:14:56.503137 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149987 (* 1 = 0.0149987 loss)
I0312 15:14:56.503142 17663 sgd_solver.cpp:106] Iteration 110400, lr = 1e-14
I0312 15:15:49.492882 17663 solver.cpp:228] Iteration 110500, loss = 0.23541
I0312 15:15:49.492907 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:15:49.492913 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393767 (* 1 = 0.0393767 loss)
I0312 15:15:49.492933 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112861 (* 1 = 0.112861 loss)
I0312 15:15:49.492938 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00146576 (* 1 = 0.00146576 loss)
I0312 15:15:49.492943 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153134 (* 1 = 0.0153134 loss)
I0312 15:15:49.492947 17663 sgd_solver.cpp:106] Iteration 110500, lr = 1e-14
I0312 15:16:41.495939 17663 solver.cpp:228] Iteration 110600, loss = 0.630876
I0312 15:16:41.495960 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 15:16:41.495967 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.282866 (* 1 = 0.282866 loss)
I0312 15:16:41.495971 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.491411 (* 1 = 0.491411 loss)
I0312 15:16:41.495975 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.127861 (* 1 = 0.127861 loss)
I0312 15:16:41.495980 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.224126 (* 1 = 0.224126 loss)
I0312 15:16:41.495997 17663 sgd_solver.cpp:106] Iteration 110600, lr = 1e-14
I0312 15:17:34.452239 17663 solver.cpp:228] Iteration 110700, loss = 0.414813
I0312 15:17:34.452260 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 15:17:34.452266 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.131765 (* 1 = 0.131765 loss)
I0312 15:17:34.452271 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.294123 (* 1 = 0.294123 loss)
I0312 15:17:34.452289 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117326 (* 1 = 0.0117326 loss)
I0312 15:17:34.452293 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120516 (* 1 = 0.120516 loss)
I0312 15:17:34.452298 17663 sgd_solver.cpp:106] Iteration 110700, lr = 1e-14
I0312 15:18:27.144187 17663 solver.cpp:228] Iteration 110800, loss = 0.302686
I0312 15:18:27.144209 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 15:18:27.144217 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.107525 (* 1 = 0.107525 loss)
I0312 15:18:27.144222 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.152937 (* 1 = 0.152937 loss)
I0312 15:18:27.144240 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00442313 (* 1 = 0.00442313 loss)
I0312 15:18:27.144244 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403112 (* 1 = 0.0403112 loss)
I0312 15:18:27.144250 17663 sgd_solver.cpp:106] Iteration 110800, lr = 1e-14
I0312 15:19:19.597815 17663 solver.cpp:228] Iteration 110900, loss = 0.340021
I0312 15:19:19.597836 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 15:19:19.597843 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0847131 (* 1 = 0.0847131 loss)
I0312 15:19:19.597862 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.209516 (* 1 = 0.209516 loss)
I0312 15:19:19.597867 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00639904 (* 1 = 0.00639904 loss)
I0312 15:19:19.597870 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434287 (* 1 = 0.0434287 loss)
I0312 15:19:19.597875 17663 sgd_solver.cpp:106] Iteration 110900, lr = 1e-14
speed: 0.525s / iter
I0312 15:20:13.101652 17663 solver.cpp:228] Iteration 111000, loss = 0.233974
I0312 15:20:13.101683 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 15:20:13.101691 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352162 (* 1 = 0.0352162 loss)
I0312 15:20:13.101711 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111255 (* 1 = 0.111255 loss)
I0312 15:20:13.101716 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233382 (* 1 = 0.00233382 loss)
I0312 15:20:13.101722 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0072587 (* 1 = 0.0072587 loss)
I0312 15:20:13.101727 17663 sgd_solver.cpp:106] Iteration 111000, lr = 1e-14
I0312 15:21:05.078445 17663 solver.cpp:228] Iteration 111100, loss = 0.390865
I0312 15:21:05.078469 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:21:05.078477 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0567847 (* 1 = 0.0567847 loss)
I0312 15:21:05.078496 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.205872 (* 1 = 0.205872 loss)
I0312 15:21:05.078500 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152414 (* 1 = 0.0152414 loss)
I0312 15:21:05.078505 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403898 (* 1 = 0.0403898 loss)
I0312 15:21:05.078510 17663 sgd_solver.cpp:106] Iteration 111100, lr = 1e-14
I0312 15:21:57.847789 17663 solver.cpp:228] Iteration 111200, loss = 1.06373
I0312 15:21:57.847810 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 15:21:57.847818 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.223576 (* 1 = 0.223576 loss)
I0312 15:21:57.847837 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.285666 (* 1 = 0.285666 loss)
I0312 15:21:57.847841 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.251605 (* 1 = 0.251605 loss)
I0312 15:21:57.847846 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.371227 (* 1 = 0.371227 loss)
I0312 15:21:57.847851 17663 sgd_solver.cpp:106] Iteration 111200, lr = 1e-14
I0312 15:22:49.953081 17663 solver.cpp:228] Iteration 111300, loss = 0.120304
I0312 15:22:49.953104 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 15:22:49.953110 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226769 (* 1 = 0.0226769 loss)
I0312 15:22:49.953114 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.048491 (* 1 = 0.048491 loss)
I0312 15:22:49.953133 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322868 (* 1 = 0.00322868 loss)
I0312 15:22:49.953137 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236369 (* 1 = 0.0236369 loss)
I0312 15:22:49.953142 17663 sgd_solver.cpp:106] Iteration 111300, lr = 1e-14
I0312 15:23:43.089629 17663 solver.cpp:228] Iteration 111400, loss = 0.191087
I0312 15:23:43.089650 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 15:23:43.089658 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347139 (* 1 = 0.0347139 loss)
I0312 15:23:43.089675 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.122392 (* 1 = 0.122392 loss)
I0312 15:23:43.089680 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0351683 (* 1 = 0.0351683 loss)
I0312 15:23:43.089684 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410738 (* 1 = 0.0410738 loss)
I0312 15:23:43.089689 17663 sgd_solver.cpp:106] Iteration 111400, lr = 1e-14
I0312 15:24:35.678280 17663 solver.cpp:228] Iteration 111500, loss = 0.407278
I0312 15:24:35.678300 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:24:35.678308 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299109 (* 1 = 0.0299109 loss)
I0312 15:24:35.678326 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.138527 (* 1 = 0.138527 loss)
I0312 15:24:35.678330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0084807 (* 1 = 0.0084807 loss)
I0312 15:24:35.678334 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0936452 (* 1 = 0.0936452 loss)
I0312 15:24:35.678339 17663 sgd_solver.cpp:106] Iteration 111500, lr = 1e-14
I0312 15:25:28.504179 17663 solver.cpp:228] Iteration 111600, loss = 0.647946
I0312 15:25:28.504202 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 15:25:28.504211 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0864472 (* 1 = 0.0864472 loss)
I0312 15:25:28.504215 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0781295 (* 1 = 0.0781295 loss)
I0312 15:25:28.504220 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0386839 (* 1 = 0.0386839 loss)
I0312 15:25:28.504223 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0533222 (* 1 = 0.0533222 loss)
I0312 15:25:28.504230 17663 sgd_solver.cpp:106] Iteration 111600, lr = 1e-14
I0312 15:26:21.324961 17663 solver.cpp:228] Iteration 111700, loss = 0.431429
I0312 15:26:21.324983 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 15:26:21.324990 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378282 (* 1 = 0.0378282 loss)
I0312 15:26:21.324995 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.065802 (* 1 = 0.065802 loss)
I0312 15:26:21.325013 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0049707 (* 1 = 0.0049707 loss)
I0312 15:26:21.325017 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185758 (* 1 = 0.0185758 loss)
I0312 15:26:21.325022 17663 sgd_solver.cpp:106] Iteration 111700, lr = 1e-14
I0312 15:27:13.478526 17663 solver.cpp:228] Iteration 111800, loss = 0.181487
I0312 15:27:13.478548 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 15:27:13.478554 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410588 (* 1 = 0.0410588 loss)
I0312 15:27:13.478559 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0345261 (* 1 = 0.0345261 loss)
I0312 15:27:13.478577 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135665 (* 1 = 0.0135665 loss)
I0312 15:27:13.478581 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560886 (* 1 = 0.0560886 loss)
I0312 15:27:13.478586 17663 sgd_solver.cpp:106] Iteration 111800, lr = 1e-14
I0312 15:28:05.597606 17663 solver.cpp:228] Iteration 111900, loss = 0.496548
I0312 15:28:05.597627 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 15:28:05.597635 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.223233 (* 1 = 0.223233 loss)
I0312 15:28:05.597653 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.357046 (* 1 = 0.357046 loss)
I0312 15:28:05.597657 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0471304 (* 1 = 0.0471304 loss)
I0312 15:28:05.597661 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10704 (* 1 = 0.10704 loss)
I0312 15:28:05.597678 17663 sgd_solver.cpp:106] Iteration 111900, lr = 1e-14
speed: 0.525s / iter
I0312 15:28:58.387182 17663 solver.cpp:228] Iteration 112000, loss = 0.135523
I0312 15:28:58.387204 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 15:28:58.387212 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228033 (* 1 = 0.0228033 loss)
I0312 15:28:58.387217 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0713198 (* 1 = 0.0713198 loss)
I0312 15:28:58.387235 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262662 (* 1 = 0.0262662 loss)
I0312 15:28:58.387239 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296083 (* 1 = 0.00296083 loss)
I0312 15:28:58.387245 17663 sgd_solver.cpp:106] Iteration 112000, lr = 1e-14
I0312 15:29:50.707234 17663 solver.cpp:228] Iteration 112100, loss = 0.600754
I0312 15:29:50.707255 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 15:29:50.707262 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383499 (* 1 = 0.0383499 loss)
I0312 15:29:50.707267 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.225263 (* 1 = 0.225263 loss)
I0312 15:29:50.707285 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00417838 (* 1 = 0.00417838 loss)
I0312 15:29:50.707289 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103415 (* 1 = 0.103415 loss)
I0312 15:29:50.707294 17663 sgd_solver.cpp:106] Iteration 112100, lr = 1e-14
I0312 15:30:42.990278 17663 solver.cpp:228] Iteration 112200, loss = 0.334668
I0312 15:30:42.990303 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 15:30:42.990310 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.114223 (* 1 = 0.114223 loss)
I0312 15:30:42.990329 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.15989 (* 1 = 0.15989 loss)
I0312 15:30:42.990334 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00651972 (* 1 = 0.00651972 loss)
I0312 15:30:42.990339 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120479 (* 1 = 0.0120479 loss)
I0312 15:30:42.990357 17663 sgd_solver.cpp:106] Iteration 112200, lr = 1e-14
I0312 15:31:34.673663 17663 solver.cpp:228] Iteration 112300, loss = 0.283015
I0312 15:31:34.673686 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 15:31:34.673694 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.063825 (* 1 = 0.063825 loss)
I0312 15:31:34.673713 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.104648 (* 1 = 0.104648 loss)
I0312 15:31:34.673717 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00973551 (* 1 = 0.00973551 loss)
I0312 15:31:34.673722 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.17697 (* 1 = 0.17697 loss)
I0312 15:31:34.673727 17663 sgd_solver.cpp:106] Iteration 112300, lr = 1e-14
I0312 15:32:27.853780 17663 solver.cpp:228] Iteration 112400, loss = 0.236801
I0312 15:32:27.853804 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:32:27.853812 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0782972 (* 1 = 0.0782972 loss)
I0312 15:32:27.853832 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.137977 (* 1 = 0.137977 loss)
I0312 15:32:27.853835 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0253635 (* 1 = 0.0253635 loss)
I0312 15:32:27.853839 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132707 (* 1 = 0.0132707 loss)
I0312 15:32:27.853845 17663 sgd_solver.cpp:106] Iteration 112400, lr = 1e-14
I0312 15:33:20.166404 17663 solver.cpp:228] Iteration 112500, loss = 0.221819
I0312 15:33:20.166425 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 15:33:20.166434 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605734 (* 1 = 0.0605734 loss)
I0312 15:33:20.166452 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.117303 (* 1 = 0.117303 loss)
I0312 15:33:20.166457 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00805396 (* 1 = 0.00805396 loss)
I0312 15:33:20.166462 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0876331 (* 1 = 0.0876331 loss)
I0312 15:33:20.166479 17663 sgd_solver.cpp:106] Iteration 112500, lr = 1e-14
I0312 15:34:12.319574 17663 solver.cpp:228] Iteration 112600, loss = 0.142706
I0312 15:34:12.319597 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 15:34:12.319604 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376325 (* 1 = 0.0376325 loss)
I0312 15:34:12.319623 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102291 (* 1 = 0.102291 loss)
I0312 15:34:12.319628 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144191 (* 1 = 0.0144191 loss)
I0312 15:34:12.319643 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00685766 (* 1 = 0.00685766 loss)
I0312 15:34:12.319649 17663 sgd_solver.cpp:106] Iteration 112600, lr = 1e-14
I0312 15:35:04.790177 17663 solver.cpp:228] Iteration 112700, loss = 0.61814
I0312 15:35:04.790199 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 15:35:04.790206 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0497866 (* 1 = 0.0497866 loss)
I0312 15:35:04.790211 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.1286 (* 1 = 0.1286 loss)
I0312 15:35:04.790230 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.12825 (* 1 = 0.12825 loss)
I0312 15:35:04.790235 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103641 (* 1 = 0.103641 loss)
I0312 15:35:04.790241 17663 sgd_solver.cpp:106] Iteration 112700, lr = 1e-14
I0312 15:35:57.624904 17663 solver.cpp:228] Iteration 112800, loss = 0.37404
I0312 15:35:57.624927 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0312 15:35:57.624933 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.223849 (* 1 = 0.223849 loss)
I0312 15:35:57.624953 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.343592 (* 1 = 0.343592 loss)
I0312 15:35:57.624958 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00802917 (* 1 = 0.00802917 loss)
I0312 15:35:57.624974 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034521 (* 1 = 0.034521 loss)
I0312 15:35:57.624979 17663 sgd_solver.cpp:106] Iteration 112800, lr = 1e-14
I0312 15:36:50.582998 17663 solver.cpp:228] Iteration 112900, loss = 0.408847
I0312 15:36:50.583019 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:36:50.583027 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817815 (* 1 = 0.0817815 loss)
I0312 15:36:50.583031 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.116091 (* 1 = 0.116091 loss)
I0312 15:36:50.583050 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152626 (* 1 = 0.0152626 loss)
I0312 15:36:50.583055 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0664604 (* 1 = 0.0664604 loss)
I0312 15:36:50.583060 17663 sgd_solver.cpp:106] Iteration 112900, lr = 1e-14
speed: 0.525s / iter
I0312 15:37:43.361843 17663 solver.cpp:228] Iteration 113000, loss = 0.320853
I0312 15:37:43.361866 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 15:37:43.361873 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614529 (* 1 = 0.0614529 loss)
I0312 15:37:43.361897 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0937061 (* 1 = 0.0937061 loss)
I0312 15:37:43.361902 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0283408 (* 1 = 0.0283408 loss)
I0312 15:37:43.361907 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116472 (* 1 = 0.116472 loss)
I0312 15:37:43.361925 17663 sgd_solver.cpp:106] Iteration 113000, lr = 1e-14
I0312 15:38:35.801597 17663 solver.cpp:228] Iteration 113100, loss = 0.255854
I0312 15:38:35.801627 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 15:38:35.801635 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232237 (* 1 = 0.0232237 loss)
I0312 15:38:35.801641 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0970719 (* 1 = 0.0970719 loss)
I0312 15:38:35.801646 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351388 (* 1 = 0.00351388 loss)
I0312 15:38:35.801651 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199471 (* 1 = 0.0199471 loss)
I0312 15:38:35.801668 17663 sgd_solver.cpp:106] Iteration 113100, lr = 1e-14
I0312 15:39:28.727026 17663 solver.cpp:228] Iteration 113200, loss = 0.306035
I0312 15:39:28.727047 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:39:28.727054 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0854516 (* 1 = 0.0854516 loss)
I0312 15:39:28.727073 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.143471 (* 1 = 0.143471 loss)
I0312 15:39:28.727077 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126144 (* 1 = 0.0126144 loss)
I0312 15:39:28.727082 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340749 (* 1 = 0.0340749 loss)
I0312 15:39:28.727087 17663 sgd_solver.cpp:106] Iteration 113200, lr = 1e-14
I0312 15:40:21.399987 17663 solver.cpp:228] Iteration 113300, loss = 0.16758
I0312 15:40:21.400010 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 15:40:21.400018 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186836 (* 1 = 0.0186836 loss)
I0312 15:40:21.400038 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0704556 (* 1 = 0.0704556 loss)
I0312 15:40:21.400041 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034066 (* 1 = 0.0034066 loss)
I0312 15:40:21.400045 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.081951 (* 1 = 0.081951 loss)
I0312 15:40:21.400063 17663 sgd_solver.cpp:106] Iteration 113300, lr = 1e-14
I0312 15:41:13.552151 17663 solver.cpp:228] Iteration 113400, loss = 0.275455
I0312 15:41:13.552175 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 15:41:13.552196 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793085 (* 1 = 0.0793085 loss)
I0312 15:41:13.552215 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.170219 (* 1 = 0.170219 loss)
I0312 15:41:13.552220 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676437 (* 1 = 0.00676437 loss)
I0312 15:41:13.552224 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271189 (* 1 = 0.0271189 loss)
I0312 15:41:13.552230 17663 sgd_solver.cpp:106] Iteration 113400, lr = 1e-14
I0312 15:42:05.691896 17663 solver.cpp:228] Iteration 113500, loss = 0.601623
I0312 15:42:05.691925 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 15:42:05.691932 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353374 (* 1 = 0.0353374 loss)
I0312 15:42:05.691951 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0635901 (* 1 = 0.0635901 loss)
I0312 15:42:05.691956 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00639184 (* 1 = 0.00639184 loss)
I0312 15:42:05.691961 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103808 (* 1 = 0.103808 loss)
I0312 15:42:05.691967 17663 sgd_solver.cpp:106] Iteration 113500, lr = 1e-14
I0312 15:42:57.565454 17663 solver.cpp:228] Iteration 113600, loss = 0.310265
I0312 15:42:57.565474 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 15:42:57.565482 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0307157 (* 1 = 0.0307157 loss)
I0312 15:42:57.565501 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.13013 (* 1 = 0.13013 loss)
I0312 15:42:57.565505 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183291 (* 1 = 0.0183291 loss)
I0312 15:42:57.565510 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0552642 (* 1 = 0.0552642 loss)
I0312 15:42:57.565515 17663 sgd_solver.cpp:106] Iteration 113600, lr = 1e-14
I0312 15:43:49.792623 17663 solver.cpp:228] Iteration 113700, loss = 0.986638
I0312 15:43:49.792644 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0312 15:43:49.792651 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.237254 (* 1 = 0.237254 loss)
I0312 15:43:49.792670 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.359201 (* 1 = 0.359201 loss)
I0312 15:43:49.792675 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00729 (* 1 = 0.00729 loss)
I0312 15:43:49.792678 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164694 (* 1 = 0.164694 loss)
I0312 15:43:49.792682 17663 sgd_solver.cpp:106] Iteration 113700, lr = 1e-14
I0312 15:44:42.268805 17663 solver.cpp:228] Iteration 113800, loss = 0.148005
I0312 15:44:42.268826 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 15:44:42.268834 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0705469 (* 1 = 0.0705469 loss)
I0312 15:44:42.268852 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0788889 (* 1 = 0.0788889 loss)
I0312 15:44:42.268857 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162325 (* 1 = 0.0162325 loss)
I0312 15:44:42.268862 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210276 (* 1 = 0.0210276 loss)
I0312 15:44:42.268865 17663 sgd_solver.cpp:106] Iteration 113800, lr = 1e-14
I0312 15:45:35.067818 17663 solver.cpp:228] Iteration 113900, loss = 0.314692
I0312 15:45:35.067842 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 15:45:35.067849 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.132272 (* 1 = 0.132272 loss)
I0312 15:45:35.067868 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.171343 (* 1 = 0.171343 loss)
I0312 15:45:35.067873 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687902 (* 1 = 0.00687902 loss)
I0312 15:45:35.067878 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0544498 (* 1 = 0.0544498 loss)
I0312 15:45:35.067883 17663 sgd_solver.cpp:106] Iteration 113900, lr = 1e-14
speed: 0.525s / iter
I0312 15:46:26.829144 17663 solver.cpp:228] Iteration 114000, loss = 0.269239
I0312 15:46:26.829298 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 15:46:26.829356 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.00181752 (* 1 = 0.00181752 loss)
I0312 15:46:26.829406 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.070684 (* 1 = 0.070684 loss)
I0312 15:46:26.829452 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.107658 (* 1 = 0.107658 loss)
I0312 15:46:26.829499 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280803 (* 1 = 0.0280803 loss)
I0312 15:46:26.829545 17663 sgd_solver.cpp:106] Iteration 114000, lr = 1e-14
I0312 15:47:19.093397 17663 solver.cpp:228] Iteration 114100, loss = 0.3049
I0312 15:47:19.093420 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:47:19.093426 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625933 (* 1 = 0.0625933 loss)
I0312 15:47:19.093446 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.102349 (* 1 = 0.102349 loss)
I0312 15:47:19.093449 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174334 (* 1 = 0.0174334 loss)
I0312 15:47:19.093453 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337578 (* 1 = 0.0337578 loss)
I0312 15:47:19.093458 17663 sgd_solver.cpp:106] Iteration 114100, lr = 1e-14
I0312 15:48:11.113184 17663 solver.cpp:228] Iteration 114200, loss = 0.176339
I0312 15:48:11.113206 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0312 15:48:11.113214 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355909 (* 1 = 0.0355909 loss)
I0312 15:48:11.113219 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0287424 (* 1 = 0.0287424 loss)
I0312 15:48:11.113224 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0099765 (* 1 = 0.0099765 loss)
I0312 15:48:11.113227 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0827766 (* 1 = 0.0827766 loss)
I0312 15:48:11.113246 17663 sgd_solver.cpp:106] Iteration 114200, lr = 1e-14
I0312 15:49:03.884992 17663 solver.cpp:228] Iteration 114300, loss = 0.288816
I0312 15:49:03.885015 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 15:49:03.885022 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.124096 (* 1 = 0.124096 loss)
I0312 15:49:03.885027 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.241845 (* 1 = 0.241845 loss)
I0312 15:49:03.885046 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00886287 (* 1 = 0.00886287 loss)
I0312 15:49:03.885051 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219659 (* 1 = 0.0219659 loss)
I0312 15:49:03.885056 17663 sgd_solver.cpp:106] Iteration 114300, lr = 1e-14
I0312 15:49:56.460746 17663 solver.cpp:228] Iteration 114400, loss = 0.396483
I0312 15:49:56.460767 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:49:56.460774 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.04679 (* 1 = 0.04679 loss)
I0312 15:49:56.460779 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.135734 (* 1 = 0.135734 loss)
I0312 15:49:56.460798 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051591 (* 1 = 0.0051591 loss)
I0312 15:49:56.460801 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433665 (* 1 = 0.0433665 loss)
I0312 15:49:56.460819 17663 sgd_solver.cpp:106] Iteration 114400, lr = 1e-14
I0312 15:50:48.900405 17663 solver.cpp:228] Iteration 114500, loss = 0.578692
I0312 15:50:48.900426 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 15:50:48.900434 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.241051 (* 1 = 0.241051 loss)
I0312 15:50:48.900452 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.26239 (* 1 = 0.26239 loss)
I0312 15:50:48.900456 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0658609 (* 1 = 0.0658609 loss)
I0312 15:50:48.900460 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.280228 (* 1 = 0.280228 loss)
I0312 15:50:48.900465 17663 sgd_solver.cpp:106] Iteration 114500, lr = 1e-14
I0312 15:51:41.611389 17663 solver.cpp:228] Iteration 114600, loss = 0.604084
I0312 15:51:41.611410 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:51:41.611418 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.11672 (* 1 = 0.11672 loss)
I0312 15:51:41.611436 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.121053 (* 1 = 0.121053 loss)
I0312 15:51:41.611440 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181054 (* 1 = 0.0181054 loss)
I0312 15:51:41.611457 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00529043 (* 1 = 0.00529043 loss)
I0312 15:51:41.611462 17663 sgd_solver.cpp:106] Iteration 114600, lr = 1e-14
I0312 15:52:34.264669 17663 solver.cpp:228] Iteration 114700, loss = 0.524705
I0312 15:52:34.264698 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0312 15:52:34.264706 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.165559 (* 1 = 0.165559 loss)
I0312 15:52:34.264725 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.479225 (* 1 = 0.479225 loss)
I0312 15:52:34.264729 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0333925 (* 1 = 0.0333925 loss)
I0312 15:52:34.264734 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.041654 (* 1 = 0.041654 loss)
I0312 15:52:34.264739 17663 sgd_solver.cpp:106] Iteration 114700, lr = 1e-14
I0312 15:53:27.046478 17663 solver.cpp:228] Iteration 114800, loss = 0.183265
I0312 15:53:27.046501 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 15:53:27.046509 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394472 (* 1 = 0.0394472 loss)
I0312 15:53:27.046528 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0837962 (* 1 = 0.0837962 loss)
I0312 15:53:27.046533 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0097651 (* 1 = 0.0097651 loss)
I0312 15:53:27.046537 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0531386 (* 1 = 0.0531386 loss)
I0312 15:53:27.046543 17663 sgd_solver.cpp:106] Iteration 114800, lr = 1e-14
I0312 15:54:19.279140 17663 solver.cpp:228] Iteration 114900, loss = 0.137575
I0312 15:54:19.279161 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:54:19.279168 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225813 (* 1 = 0.0225813 loss)
I0312 15:54:19.279186 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.100597 (* 1 = 0.100597 loss)
I0312 15:54:19.279191 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00437764 (* 1 = 0.00437764 loss)
I0312 15:54:19.279196 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131313 (* 1 = 0.0131313 loss)
I0312 15:54:19.279201 17663 sgd_solver.cpp:106] Iteration 114900, lr = 1e-14
speed: 0.525s / iter
I0312 15:55:12.038693 17663 solver.cpp:228] Iteration 115000, loss = 0.483832
I0312 15:55:12.038722 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:55:12.038731 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.116058 (* 1 = 0.116058 loss)
I0312 15:55:12.038738 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.231823 (* 1 = 0.231823 loss)
I0312 15:55:12.038743 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0470021 (* 1 = 0.0470021 loss)
I0312 15:55:12.038746 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.317328 (* 1 = 0.317328 loss)
I0312 15:55:12.038753 17663 sgd_solver.cpp:106] Iteration 115000, lr = 1e-14
I0312 15:56:04.582433 17663 solver.cpp:228] Iteration 115100, loss = 0.368524
I0312 15:56:04.582455 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:56:04.582463 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0420375 (* 1 = 0.0420375 loss)
I0312 15:56:04.582482 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.133591 (* 1 = 0.133591 loss)
I0312 15:56:04.582486 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205777 (* 1 = 0.0205777 loss)
I0312 15:56:04.582491 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00541337 (* 1 = 0.00541337 loss)
I0312 15:56:04.582496 17663 sgd_solver.cpp:106] Iteration 115100, lr = 1e-14
I0312 15:56:56.898263 17663 solver.cpp:228] Iteration 115200, loss = 0.313947
I0312 15:56:56.898285 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 15:56:56.898293 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541381 (* 1 = 0.0541381 loss)
I0312 15:56:56.898313 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157634 (* 1 = 0.157634 loss)
I0312 15:56:56.898316 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.002089 (* 1 = 0.002089 loss)
I0312 15:56:56.898320 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394634 (* 1 = 0.0394634 loss)
I0312 15:56:56.898325 17663 sgd_solver.cpp:106] Iteration 115200, lr = 1e-14
I0312 15:57:49.562429 17663 solver.cpp:228] Iteration 115300, loss = 0.61945
I0312 15:57:49.562453 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0312 15:57:49.562459 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.238534 (* 1 = 0.238534 loss)
I0312 15:57:49.562479 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.53289 (* 1 = 0.53289 loss)
I0312 15:57:49.562482 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0675993 (* 1 = 0.0675993 loss)
I0312 15:57:49.562486 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0976755 (* 1 = 0.0976755 loss)
I0312 15:57:49.562491 17663 sgd_solver.cpp:106] Iteration 115300, lr = 1e-14
I0312 15:58:42.184727 17663 solver.cpp:228] Iteration 115400, loss = 0.279116
I0312 15:58:42.184749 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 15:58:42.184756 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0606557 (* 1 = 0.0606557 loss)
I0312 15:58:42.184775 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.115411 (* 1 = 0.115411 loss)
I0312 15:58:42.184779 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0379641 (* 1 = 0.0379641 loss)
I0312 15:58:42.184783 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0676571 (* 1 = 0.0676571 loss)
I0312 15:58:42.184788 17663 sgd_solver.cpp:106] Iteration 115400, lr = 1e-14
I0312 15:59:34.133752 17663 solver.cpp:228] Iteration 115500, loss = 0.349826
I0312 15:59:34.133775 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 15:59:34.133783 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0796237 (* 1 = 0.0796237 loss)
I0312 15:59:34.133802 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.168312 (* 1 = 0.168312 loss)
I0312 15:59:34.133806 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695664 (* 1 = 0.00695664 loss)
I0312 15:59:34.133811 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0539054 (* 1 = 0.0539054 loss)
I0312 15:59:34.133816 17663 sgd_solver.cpp:106] Iteration 115500, lr = 1e-14
I0312 16:00:26.401311 17663 solver.cpp:228] Iteration 115600, loss = 0.576464
I0312 16:00:26.401334 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 16:00:26.401341 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0948601 (* 1 = 0.0948601 loss)
I0312 16:00:26.401360 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.22273 (* 1 = 0.22273 loss)
I0312 16:00:26.401363 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.128949 (* 1 = 0.128949 loss)
I0312 16:00:26.401381 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.393212 (* 1 = 0.393212 loss)
I0312 16:00:26.401386 17663 sgd_solver.cpp:106] Iteration 115600, lr = 1e-14
I0312 16:01:18.447062 17663 solver.cpp:228] Iteration 115700, loss = 0.560302
I0312 16:01:18.447084 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 16:01:18.447093 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.115974 (* 1 = 0.115974 loss)
I0312 16:01:18.447096 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.112698 (* 1 = 0.112698 loss)
I0312 16:01:18.447100 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00345802 (* 1 = 0.00345802 loss)
I0312 16:01:18.447104 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104236 (* 1 = 0.104236 loss)
I0312 16:01:18.447109 17663 sgd_solver.cpp:106] Iteration 115700, lr = 1e-14
I0312 16:02:11.942499 17663 solver.cpp:228] Iteration 115800, loss = 0.487762
I0312 16:02:11.942522 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 16:02:11.942529 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.055725 (* 1 = 0.055725 loss)
I0312 16:02:11.942534 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.245714 (* 1 = 0.245714 loss)
I0312 16:02:11.942538 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105104 (* 1 = 0.0105104 loss)
I0312 16:02:11.942541 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333101 (* 1 = 0.0333101 loss)
I0312 16:02:11.942546 17663 sgd_solver.cpp:106] Iteration 115800, lr = 1e-14
I0312 16:03:03.731168 17663 solver.cpp:228] Iteration 115900, loss = 0.363919
I0312 16:03:03.731189 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 16:03:03.731196 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.16074 (* 1 = 0.16074 loss)
I0312 16:03:03.731200 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.302916 (* 1 = 0.302916 loss)
I0312 16:03:03.731220 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015165 (* 1 = 0.015165 loss)
I0312 16:03:03.731223 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102435 (* 1 = 0.102435 loss)
I0312 16:03:03.731227 17663 sgd_solver.cpp:106] Iteration 115900, lr = 1e-14
speed: 0.525s / iter
I0312 16:03:56.184147 17663 solver.cpp:228] Iteration 116000, loss = 0.21098
I0312 16:03:56.184213 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 16:03:56.184237 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464311 (* 1 = 0.0464311 loss)
I0312 16:03:56.184242 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.156718 (* 1 = 0.156718 loss)
I0312 16:03:56.184259 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187675 (* 1 = 0.0187675 loss)
I0312 16:03:56.184264 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00652403 (* 1 = 0.00652403 loss)
I0312 16:03:56.184271 17663 sgd_solver.cpp:106] Iteration 116000, lr = 1e-14
I0312 16:04:49.081640 17663 solver.cpp:228] Iteration 116100, loss = 0.205816
I0312 16:04:49.081663 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 16:04:49.081671 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0194052 (* 1 = 0.0194052 loss)
I0312 16:04:49.081691 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0859294 (* 1 = 0.0859294 loss)
I0312 16:04:49.081694 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00696153 (* 1 = 0.00696153 loss)
I0312 16:04:49.081698 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387478 (* 1 = 0.0387478 loss)
I0312 16:04:49.081704 17663 sgd_solver.cpp:106] Iteration 116100, lr = 1e-14
I0312 16:05:41.319859 17663 solver.cpp:228] Iteration 116200, loss = 0.838124
I0312 16:05:41.319882 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0312 16:05:41.319890 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.137768 (* 1 = 0.137768 loss)
I0312 16:05:41.319893 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.234422 (* 1 = 0.234422 loss)
I0312 16:05:41.319897 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.253201 (* 1 = 0.253201 loss)
I0312 16:05:41.319901 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.652717 (* 1 = 0.652717 loss)
I0312 16:05:41.319906 17663 sgd_solver.cpp:106] Iteration 116200, lr = 1e-14
I0312 16:06:34.262403 17663 solver.cpp:228] Iteration 116300, loss = 0.302163
I0312 16:06:34.262425 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 16:06:34.262432 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0716581 (* 1 = 0.0716581 loss)
I0312 16:06:34.262450 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.197519 (* 1 = 0.197519 loss)
I0312 16:06:34.262455 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542052 (* 1 = 0.00542052 loss)
I0312 16:06:34.262472 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023257 (* 1 = 0.023257 loss)
I0312 16:06:34.262477 17663 sgd_solver.cpp:106] Iteration 116300, lr = 1e-14
I0312 16:07:27.243441 17663 solver.cpp:228] Iteration 116400, loss = 0.147136
I0312 16:07:27.243463 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0312 16:07:27.243469 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110054 (* 1 = 0.0110054 loss)
I0312 16:07:27.243487 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0769816 (* 1 = 0.0769816 loss)
I0312 16:07:27.243491 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115155 (* 1 = 0.0115155 loss)
I0312 16:07:27.243496 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00989575 (* 1 = 0.00989575 loss)
I0312 16:07:27.243500 17663 sgd_solver.cpp:106] Iteration 116400, lr = 1e-14
I0312 16:08:19.890514 17663 solver.cpp:228] Iteration 116500, loss = 0.468416
I0312 16:08:19.890554 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0312 16:08:19.890563 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.20771 (* 1 = 0.20771 loss)
I0312 16:08:19.890568 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.367325 (* 1 = 0.367325 loss)
I0312 16:08:19.890573 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.108965 (* 1 = 0.108965 loss)
I0312 16:08:19.890578 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0917723 (* 1 = 0.0917723 loss)
I0312 16:08:19.890584 17663 sgd_solver.cpp:106] Iteration 116500, lr = 1e-14
I0312 16:09:12.595108 17663 solver.cpp:228] Iteration 116600, loss = 0.32028
I0312 16:09:12.595129 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0312 16:09:12.595136 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.053911 (* 1 = 0.053911 loss)
I0312 16:09:12.595141 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.215691 (* 1 = 0.215691 loss)
I0312 16:09:12.595160 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126819 (* 1 = 0.0126819 loss)
I0312 16:09:12.595163 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.132692 (* 1 = 0.132692 loss)
I0312 16:09:12.595182 17663 sgd_solver.cpp:106] Iteration 116600, lr = 1e-14
I0312 16:10:05.491134 17663 solver.cpp:228] Iteration 116700, loss = 0.571477
I0312 16:10:05.491158 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 16:10:05.491165 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0831898 (* 1 = 0.0831898 loss)
I0312 16:10:05.491184 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.172194 (* 1 = 0.172194 loss)
I0312 16:10:05.491189 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0598974 (* 1 = 0.0598974 loss)
I0312 16:10:05.491194 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0945887 (* 1 = 0.0945887 loss)
I0312 16:10:05.491199 17663 sgd_solver.cpp:106] Iteration 116700, lr = 1e-14
I0312 16:10:58.395609 17663 solver.cpp:228] Iteration 116800, loss = 0.393427
I0312 16:10:58.395632 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0312 16:10:58.395638 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.161702 (* 1 = 0.161702 loss)
I0312 16:10:58.395658 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.265439 (* 1 = 0.265439 loss)
I0312 16:10:58.395661 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187474 (* 1 = 0.0187474 loss)
I0312 16:10:58.395666 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125633 (* 1 = 0.125633 loss)
I0312 16:10:58.395671 17663 sgd_solver.cpp:106] Iteration 116800, lr = 1e-14
I0312 16:11:50.536337 17663 solver.cpp:228] Iteration 116900, loss = 0.280939
I0312 16:11:50.536358 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 16:11:50.536366 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544876 (* 1 = 0.0544876 loss)
I0312 16:11:50.536370 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.144609 (* 1 = 0.144609 loss)
I0312 16:11:50.536375 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169625 (* 1 = 0.00169625 loss)
I0312 16:11:50.536378 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171786 (* 1 = 0.0171786 loss)
I0312 16:11:50.536383 17663 sgd_solver.cpp:106] Iteration 116900, lr = 1e-14
speed: 0.525s / iter
I0312 16:12:43.627482 17663 solver.cpp:228] Iteration 117000, loss = 0.278646
I0312 16:12:43.627506 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 16:12:43.627512 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0727921 (* 1 = 0.0727921 loss)
I0312 16:12:43.627532 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161964 (* 1 = 0.161964 loss)
I0312 16:12:43.627535 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171483 (* 1 = 0.0171483 loss)
I0312 16:12:43.627539 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.062206 (* 1 = 0.062206 loss)
I0312 16:12:43.627544 17663 sgd_solver.cpp:106] Iteration 117000, lr = 1e-14
I0312 16:13:36.122774 17663 solver.cpp:228] Iteration 117100, loss = 0.494664
I0312 16:13:36.122797 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 16:13:36.122804 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.122691 (* 1 = 0.122691 loss)
I0312 16:13:36.122808 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.202089 (* 1 = 0.202089 loss)
I0312 16:13:36.122828 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.025656 (* 1 = 0.025656 loss)
I0312 16:13:36.122833 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0757279 (* 1 = 0.0757279 loss)
I0312 16:13:36.122838 17663 sgd_solver.cpp:106] Iteration 117100, lr = 1e-14
I0312 16:14:28.235728 17663 solver.cpp:228] Iteration 117200, loss = 0.273675
I0312 16:14:28.235750 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 16:14:28.235759 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0267249 (* 1 = 0.0267249 loss)
I0312 16:14:28.235777 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0486688 (* 1 = 0.0486688 loss)
I0312 16:14:28.235782 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186944 (* 1 = 0.00186944 loss)
I0312 16:14:28.235786 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00468885 (* 1 = 0.00468885 loss)
I0312 16:14:28.235791 17663 sgd_solver.cpp:106] Iteration 117200, lr = 1e-14
I0312 16:15:21.502985 17663 solver.cpp:228] Iteration 117300, loss = 0.684988
I0312 16:15:21.503005 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 16:15:21.503012 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.153878 (* 1 = 0.153878 loss)
I0312 16:15:21.503031 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.157277 (* 1 = 0.157277 loss)
I0312 16:15:21.503036 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314067 (* 1 = 0.00314067 loss)
I0312 16:15:21.503041 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0580695 (* 1 = 0.0580695 loss)
I0312 16:15:21.503044 17663 sgd_solver.cpp:106] Iteration 117300, lr = 1e-14
I0312 16:16:14.645967 17663 solver.cpp:228] Iteration 117400, loss = 0.450345
I0312 16:16:14.645989 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0312 16:16:14.646008 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.167262 (* 1 = 0.167262 loss)
I0312 16:16:14.646013 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.363679 (* 1 = 0.363679 loss)
I0312 16:16:14.646030 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136777 (* 1 = 0.0136777 loss)
I0312 16:16:14.646034 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.158503 (* 1 = 0.158503 loss)
I0312 16:16:14.646052 17663 sgd_solver.cpp:106] Iteration 117400, lr = 1e-14
I0312 16:17:07.164939 17663 solver.cpp:228] Iteration 117500, loss = 0.6432
I0312 16:17:07.164961 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0312 16:17:07.164968 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.154294 (* 1 = 0.154294 loss)
I0312 16:17:07.164988 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.324861 (* 1 = 0.324861 loss)
I0312 16:17:07.164993 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00411115 (* 1 = 0.00411115 loss)
I0312 16:17:07.164996 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292157 (* 1 = 0.0292157 loss)
I0312 16:17:07.165001 17663 sgd_solver.cpp:106] Iteration 117500, lr = 1e-14
I0312 16:18:00.068084 17663 solver.cpp:228] Iteration 117600, loss = 0.406116
I0312 16:18:00.068107 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0312 16:18:00.068114 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279234 (* 1 = 0.0279234 loss)
I0312 16:18:00.068135 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.147583 (* 1 = 0.147583 loss)
I0312 16:18:00.068138 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188418 (* 1 = 0.0188418 loss)
I0312 16:18:00.068142 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0883221 (* 1 = 0.0883221 loss)
I0312 16:18:00.068147 17663 sgd_solver.cpp:106] Iteration 117600, lr = 1e-14
I0312 16:18:51.525329 17663 solver.cpp:228] Iteration 117700, loss = 0.594692
I0312 16:18:51.525354 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 16:18:51.525362 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.03206 (* 1 = 0.03206 loss)
I0312 16:18:51.525382 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.105096 (* 1 = 0.105096 loss)
I0312 16:18:51.525385 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183313 (* 1 = 0.0183313 loss)
I0312 16:18:51.525389 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0914124 (* 1 = 0.0914124 loss)
I0312 16:18:51.525394 17663 sgd_solver.cpp:106] Iteration 117700, lr = 1e-14
I0312 16:19:44.021332 17663 solver.cpp:228] Iteration 117800, loss = 0.185402
I0312 16:19:44.021354 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 16:19:44.021361 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481211 (* 1 = 0.0481211 loss)
I0312 16:19:44.021380 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.141312 (* 1 = 0.141312 loss)
I0312 16:19:44.021384 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249678 (* 1 = 0.00249678 loss)
I0312 16:19:44.021389 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226543 (* 1 = 0.0226543 loss)
I0312 16:19:44.021394 17663 sgd_solver.cpp:106] Iteration 117800, lr = 1e-14
I0312 16:20:36.611712 17663 solver.cpp:228] Iteration 117900, loss = 0.232776
I0312 16:20:36.611747 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 16:20:36.611755 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397431 (* 1 = 0.0397431 loss)
I0312 16:20:36.611759 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.108041 (* 1 = 0.108041 loss)
I0312 16:20:36.611783 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169723 (* 1 = 0.00169723 loss)
I0312 16:20:36.611788 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154868 (* 1 = 0.0154868 loss)
I0312 16:20:36.611805 17663 sgd_solver.cpp:106] Iteration 117900, lr = 1e-14
speed: 0.525s / iter
I0312 16:21:28.893652 17663 solver.cpp:228] Iteration 118000, loss = 0.273581
I0312 16:21:28.893811 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 16:21:28.893870 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.09015 (* 1 = 0.09015 loss)
I0312 16:21:28.893931 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.238199 (* 1 = 0.238199 loss)
I0312 16:21:28.893980 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00573108 (* 1 = 0.00573108 loss)
I0312 16:21:28.894026 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044311 (* 1 = 0.044311 loss)
I0312 16:21:28.894073 17663 sgd_solver.cpp:106] Iteration 118000, lr = 1e-14
I0312 16:22:20.963408 17663 solver.cpp:228] Iteration 118100, loss = 0.353682
I0312 16:22:20.963433 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 16:22:20.963439 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.104644 (* 1 = 0.104644 loss)
I0312 16:22:20.963459 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.107875 (* 1 = 0.107875 loss)
I0312 16:22:20.963464 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114343 (* 1 = 0.0114343 loss)
I0312 16:22:20.963467 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025445 (* 1 = 0.025445 loss)
I0312 16:22:20.963472 17663 sgd_solver.cpp:106] Iteration 118100, lr = 1e-14
I0312 16:23:13.870934 17663 solver.cpp:228] Iteration 118200, loss = 0.168681
I0312 16:23:13.870972 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0312 16:23:13.870980 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220877 (* 1 = 0.0220877 loss)
I0312 16:23:13.870985 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0554299 (* 1 = 0.0554299 loss)
I0312 16:23:13.871003 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00423849 (* 1 = 0.00423849 loss)
I0312 16:23:13.871007 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129994 (* 1 = 0.0129994 loss)
I0312 16:23:13.871012 17663 sgd_solver.cpp:106] Iteration 118200, lr = 1e-14
I0312 16:24:06.217247 17663 solver.cpp:228] Iteration 118300, loss = 0.348765
I0312 16:24:06.217268 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 16:24:06.217277 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498491 (* 1 = 0.0498491 loss)
I0312 16:24:06.217295 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.218496 (* 1 = 0.218496 loss)
I0312 16:24:06.217299 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0235391 (* 1 = 0.0235391 loss)
I0312 16:24:06.217303 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.194402 (* 1 = 0.194402 loss)
I0312 16:24:06.217308 17663 sgd_solver.cpp:106] Iteration 118300, lr = 1e-14
I0312 16:24:58.500010 17663 solver.cpp:228] Iteration 118400, loss = 0.31227
I0312 16:24:58.500031 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0312 16:24:58.500039 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0809494 (* 1 = 0.0809494 loss)
I0312 16:24:58.500058 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.154087 (* 1 = 0.154087 loss)
I0312 16:24:58.500062 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123922 (* 1 = 0.0123922 loss)
I0312 16:24:58.500066 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378564 (* 1 = 0.0378564 loss)
I0312 16:24:58.500072 17663 sgd_solver.cpp:106] Iteration 118400, lr = 1e-14
I0312 16:25:50.803282 17663 solver.cpp:228] Iteration 118500, loss = 0.193687
I0312 16:25:50.803305 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 16:25:50.803313 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0694022 (* 1 = 0.0694022 loss)
I0312 16:25:50.803333 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0691776 (* 1 = 0.0691776 loss)
I0312 16:25:50.803336 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118223 (* 1 = 0.0118223 loss)
I0312 16:25:50.803340 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473744 (* 1 = 0.0473744 loss)
I0312 16:25:50.803345 17663 sgd_solver.cpp:106] Iteration 118500, lr = 1e-14
I0312 16:26:42.513742 17663 solver.cpp:228] Iteration 118600, loss = 0.66651
I0312 16:26:42.513767 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 16:26:42.513773 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.112178 (* 1 = 0.112178 loss)
I0312 16:26:42.513778 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219819 (* 1 = 0.219819 loss)
I0312 16:26:42.513797 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0384442 (* 1 = 0.0384442 loss)
I0312 16:26:42.513801 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.228509 (* 1 = 0.228509 loss)
I0312 16:26:42.513806 17663 sgd_solver.cpp:106] Iteration 118600, lr = 1e-14
I0312 16:27:34.723162 17663 solver.cpp:228] Iteration 118700, loss = 0.339531
I0312 16:27:34.723184 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0312 16:27:34.723191 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.175644 (* 1 = 0.175644 loss)
I0312 16:27:34.723196 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.295986 (* 1 = 0.295986 loss)
I0312 16:27:34.723215 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00722635 (* 1 = 0.00722635 loss)
I0312 16:27:34.723220 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0489555 (* 1 = 0.0489555 loss)
I0312 16:27:34.723225 17663 sgd_solver.cpp:106] Iteration 118700, lr = 1e-14
I0312 16:28:27.897168 17663 solver.cpp:228] Iteration 118800, loss = 0.596237
I0312 16:28:27.897192 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0312 16:28:27.897198 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.248457 (* 1 = 0.248457 loss)
I0312 16:28:27.897217 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.562823 (* 1 = 0.562823 loss)
I0312 16:28:27.897222 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0462264 (* 1 = 0.0462264 loss)
I0312 16:28:27.897225 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371958 (* 1 = 0.0371958 loss)
I0312 16:28:27.897231 17663 sgd_solver.cpp:106] Iteration 118800, lr = 1e-14
I0312 16:29:20.572324 17663 solver.cpp:228] Iteration 118900, loss = 0.470128
I0312 16:29:20.572347 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 16:29:20.572355 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.10404 (* 1 = 0.10404 loss)
I0312 16:29:20.572374 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.219456 (* 1 = 0.219456 loss)
I0312 16:29:20.572378 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228632 (* 1 = 0.0228632 loss)
I0312 16:29:20.572382 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.226753 (* 1 = 0.226753 loss)
I0312 16:29:20.572388 17663 sgd_solver.cpp:106] Iteration 118900, lr = 1e-14
speed: 0.525s / iter
I0312 16:30:12.760583 17663 solver.cpp:228] Iteration 119000, loss = 0.209132
I0312 16:30:12.760785 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 16:30:12.760845 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0212292 (* 1 = 0.0212292 loss)
I0312 16:30:12.760895 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0914128 (* 1 = 0.0914128 loss)
I0312 16:30:12.760941 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029159 (* 1 = 0.0029159 loss)
I0312 16:30:12.760989 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00747131 (* 1 = 0.00747131 loss)
I0312 16:30:12.761037 17663 sgd_solver.cpp:106] Iteration 119000, lr = 1e-14
I0312 16:31:05.577044 17663 solver.cpp:228] Iteration 119100, loss = 0.296305
I0312 16:31:05.577065 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0312 16:31:05.577073 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611582 (* 1 = 0.0611582 loss)
I0312 16:31:05.577078 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0977354 (* 1 = 0.0977354 loss)
I0312 16:31:05.577082 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00892005 (* 1 = 0.00892005 loss)
I0312 16:31:05.577086 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020354 (* 1 = 0.020354 loss)
I0312 16:31:05.577108 17663 sgd_solver.cpp:106] Iteration 119100, lr = 1e-14
I0312 16:31:58.238490 17663 solver.cpp:228] Iteration 119200, loss = 0.368678
I0312 16:31:58.238512 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0312 16:31:58.238519 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443285 (* 1 = 0.0443285 loss)
I0312 16:31:58.238524 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.111617 (* 1 = 0.111617 loss)
I0312 16:31:58.238528 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.063842 (* 1 = 0.063842 loss)
I0312 16:31:58.238533 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.33586 (* 1 = 0.33586 loss)
I0312 16:31:58.238538 17663 sgd_solver.cpp:106] Iteration 119200, lr = 1e-14
I0312 16:32:50.617072 17663 solver.cpp:228] Iteration 119300, loss = 0.399209
I0312 16:32:50.617095 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0312 16:32:50.617103 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.12434 (* 1 = 0.12434 loss)
I0312 16:32:50.617122 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.227035 (* 1 = 0.227035 loss)
I0312 16:32:50.617127 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366652 (* 1 = 0.0366652 loss)
I0312 16:32:50.617131 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1833 (* 1 = 0.1833 loss)
I0312 16:32:50.617136 17663 sgd_solver.cpp:106] Iteration 119300, lr = 1e-14
I0312 16:33:43.896376 17663 solver.cpp:228] Iteration 119400, loss = 0.266537
I0312 16:33:43.896399 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0312 16:33:43.896405 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215827 (* 1 = 0.0215827 loss)
I0312 16:33:43.896425 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.0833146 (* 1 = 0.0833146 loss)
I0312 16:33:43.896428 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267435 (* 1 = 0.00267435 loss)
I0312 16:33:43.896432 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942539 (* 1 = 0.00942539 loss)
I0312 16:33:43.896437 17663 sgd_solver.cpp:106] Iteration 119400, lr = 1e-14
I0312 16:34:36.617734 17663 solver.cpp:228] Iteration 119500, loss = 0.645392
I0312 16:34:36.617763 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0312 16:34:36.617772 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415818 (* 1 = 0.0415818 loss)
I0312 16:34:36.617777 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.178335 (* 1 = 0.178335 loss)
I0312 16:34:36.617782 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00640372 (* 1 = 0.00640372 loss)
I0312 16:34:36.617787 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103978 (* 1 = 0.103978 loss)
I0312 16:34:36.617794 17663 sgd_solver.cpp:106] Iteration 119500, lr = 1e-14
I0312 16:35:29.476708 17663 solver.cpp:228] Iteration 119600, loss = 0.654911
I0312 16:35:29.476729 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 16:35:29.476737 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625243 (* 1 = 0.0625243 loss)
I0312 16:35:29.476742 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.165929 (* 1 = 0.165929 loss)
I0312 16:35:29.476760 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0824432 (* 1 = 0.0824432 loss)
I0312 16:35:29.476764 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488012 (* 1 = 0.0488012 loss)
I0312 16:35:29.476769 17663 sgd_solver.cpp:106] Iteration 119600, lr = 1e-14
I0312 16:36:22.292062 17663 solver.cpp:228] Iteration 119700, loss = 0.432228
I0312 16:36:22.292264 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0312 16:36:22.292323 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.130461 (* 1 = 0.130461 loss)
I0312 16:36:22.292371 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.25506 (* 1 = 0.25506 loss)
I0312 16:36:22.292418 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00874117 (* 1 = 0.00874117 loss)
I0312 16:36:22.292464 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225869 (* 1 = 0.0225869 loss)
I0312 16:36:22.292512 17663 sgd_solver.cpp:106] Iteration 119700, lr = 1e-14
I0312 16:37:14.968291 17663 solver.cpp:228] Iteration 119800, loss = 0.280672
I0312 16:37:14.968313 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0312 16:37:14.968322 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524887 (* 1 = 0.0524887 loss)
I0312 16:37:14.968327 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.161159 (* 1 = 0.161159 loss)
I0312 16:37:14.968330 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989325 (* 1 = 0.00989325 loss)
I0312 16:37:14.968334 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177478 (* 1 = 0.0177478 loss)
I0312 16:37:14.968339 17663 sgd_solver.cpp:106] Iteration 119800, lr = 1e-14
I0312 16:38:07.905439 17663 solver.cpp:228] Iteration 119900, loss = 0.426358
I0312 16:38:07.905460 17663 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0312 16:38:07.905467 17663 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199014 (* 1 = 0.0199014 loss)
I0312 16:38:07.905486 17663 solver.cpp:244]     Train net output #2: loss_cls = 0.239544 (* 1 = 0.239544 loss)
I0312 16:38:07.905490 17663 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.157084 (* 1 = 0.157084 loss)
I0312 16:38:07.905494 17663 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150571 (* 1 = 0.150571 loss)
I0312 16:38:07.905498 17663 sgd_solver.cpp:106] Iteration 119900, lr = 1e-14
I0312 16:38:59.561323 17663 solver.cpp:454] Snapshotting to binary proto file resnet50_rfcn_ohem_iter_120000.caffemodel
I0312 16:39:00.079144 17663 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet50_rfcn_ohem_iter_120000.solverstate
speed: 0.525s / iter
Wrote snapshot to: /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_120000.caffemodel
done solving

real	1051m48.364s
user	798m26.519s
sys	251m1.991s
+ set +x
+ ./tools/test_net.py --gpu 0 --def models/pascal_voc/ResNet-50/rfcn_end2end/test_agnostic.prototxt --net /home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_120000.caffemodel --imdb voc_2007_test --cfg experiments/cfgs/rfcn_end2end_ohem.yml
imagenet_train
<function <lambda> at 0x7fb9022ff6e0>
imagenet_val
<function <lambda> at 0x7fb9022ff758>
Called with args:
Namespace(caffemodel='/home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_120000.caffemodel', cfg_file='experiments/cfgs/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=0, imdb_name='voc_2007_test', max_per_image=400, prototxt='models/pascal_voc/ResNet-50/rfcn_end2end/test_agnostic.prototxt', rpn_file=None, set_cfgs=None, vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/fan/Rfcn/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'rfcn_end2end_ohem',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fan/Rfcn/models/pascal_voc',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/fan/Rfcn',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0312 16:39:04.311017 24897 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0312 16:39:04.311049 24897 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0312 16:39:04.311053 24897 _caffe.cpp:125] Net('models/pascal_voc/ResNet-50/rfcn_end2end/test_agnostic.prototxt', 1, weights='/home/fan/Rfcn/output/rfcn_end2end_ohem/voc_2007_trainval/resnet50_rfcn_ohem_iter_120000.caffemodel')
I0312 16:39:04.316889 24897 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: models/pascal_voc/ResNet-50/rfcn_end2end/test_agnostic.prototxt
I0312 16:39:04.316934 24897 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0312 16:39:04.316941 24897 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0312 16:39:04.319260 24897 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0312 16:39:04.320561 24897 layer_factory.hpp:77] Creating layer input
I0312 16:39:04.320578 24897 net.cpp:100] Creating Layer input
I0312 16:39:04.320585 24897 net.cpp:418] input -> data
I0312 16:39:04.320595 24897 net.cpp:418] input -> im_info
I0312 16:39:07.442100 24897 net.cpp:150] Setting up input
I0312 16:39:07.442158 24897 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0312 16:39:07.442164 24897 net.cpp:157] Top shape: 1 3 (3)
I0312 16:39:07.442167 24897 net.cpp:165] Memory required for data: 602124
I0312 16:39:07.442186 24897 layer_factory.hpp:77] Creating layer conv1
I0312 16:39:07.442200 24897 net.cpp:100] Creating Layer conv1
I0312 16:39:07.442206 24897 net.cpp:444] conv1 <- data
I0312 16:39:07.442224 24897 net.cpp:418] conv1 -> conv1
I0312 16:39:07.443089 24897 net.cpp:150] Setting up conv1
I0312 16:39:07.443099 24897 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0312 16:39:07.443101 24897 net.cpp:165] Memory required for data: 3813388
I0312 16:39:07.443109 24897 layer_factory.hpp:77] Creating layer bn_conv1
I0312 16:39:07.443115 24897 net.cpp:100] Creating Layer bn_conv1
I0312 16:39:07.443119 24897 net.cpp:444] bn_conv1 <- conv1
I0312 16:39:07.443122 24897 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0312 16:39:07.443282 24897 net.cpp:150] Setting up bn_conv1
I0312 16:39:07.443287 24897 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0312 16:39:07.443290 24897 net.cpp:165] Memory required for data: 7024652
I0312 16:39:07.443297 24897 layer_factory.hpp:77] Creating layer scale_conv1
I0312 16:39:07.443302 24897 net.cpp:100] Creating Layer scale_conv1
I0312 16:39:07.443305 24897 net.cpp:444] scale_conv1 <- conv1
I0312 16:39:07.443308 24897 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0312 16:39:07.443332 24897 layer_factory.hpp:77] Creating layer scale_conv1
I0312 16:39:07.443533 24897 net.cpp:150] Setting up scale_conv1
I0312 16:39:07.443538 24897 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0312 16:39:07.443541 24897 net.cpp:165] Memory required for data: 10235916
I0312 16:39:07.443545 24897 layer_factory.hpp:77] Creating layer conv1_relu
I0312 16:39:07.443549 24897 net.cpp:100] Creating Layer conv1_relu
I0312 16:39:07.443552 24897 net.cpp:444] conv1_relu <- conv1
I0312 16:39:07.443569 24897 net.cpp:405] conv1_relu -> conv1 (in-place)
I0312 16:39:07.443573 24897 net.cpp:150] Setting up conv1_relu
I0312 16:39:07.443576 24897 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0312 16:39:07.443591 24897 net.cpp:165] Memory required for data: 13447180
I0312 16:39:07.443593 24897 layer_factory.hpp:77] Creating layer pool1
I0312 16:39:07.443598 24897 net.cpp:100] Creating Layer pool1
I0312 16:39:07.443599 24897 net.cpp:444] pool1 <- conv1
I0312 16:39:07.443603 24897 net.cpp:418] pool1 -> pool1
I0312 16:39:07.443640 24897 net.cpp:150] Setting up pool1
I0312 16:39:07.443660 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.443661 24897 net.cpp:165] Memory required for data: 14249996
I0312 16:39:07.443663 24897 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0312 16:39:07.443681 24897 net.cpp:100] Creating Layer pool1_pool1_0_split
I0312 16:39:07.443682 24897 net.cpp:444] pool1_pool1_0_split <- pool1
I0312 16:39:07.443686 24897 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0312 16:39:07.443706 24897 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0312 16:39:07.443742 24897 net.cpp:150] Setting up pool1_pool1_0_split
I0312 16:39:07.443747 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.443749 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.443764 24897 net.cpp:165] Memory required for data: 15855628
I0312 16:39:07.443766 24897 layer_factory.hpp:77] Creating layer res2a_branch1
I0312 16:39:07.443771 24897 net.cpp:100] Creating Layer res2a_branch1
I0312 16:39:07.443791 24897 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0312 16:39:07.443794 24897 net.cpp:418] res2a_branch1 -> res2a_branch1
I0312 16:39:07.443964 24897 net.cpp:150] Setting up res2a_branch1
I0312 16:39:07.443969 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.443970 24897 net.cpp:165] Memory required for data: 19066892
I0312 16:39:07.443974 24897 layer_factory.hpp:77] Creating layer bn2a_branch1
I0312 16:39:07.443979 24897 net.cpp:100] Creating Layer bn2a_branch1
I0312 16:39:07.443996 24897 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0312 16:39:07.444000 24897 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0312 16:39:07.444723 24897 net.cpp:150] Setting up bn2a_branch1
I0312 16:39:07.444732 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.444735 24897 net.cpp:165] Memory required for data: 22278156
I0312 16:39:07.444742 24897 layer_factory.hpp:77] Creating layer scale2a_branch1
I0312 16:39:07.444762 24897 net.cpp:100] Creating Layer scale2a_branch1
I0312 16:39:07.444766 24897 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0312 16:39:07.444769 24897 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0312 16:39:07.444808 24897 layer_factory.hpp:77] Creating layer scale2a_branch1
I0312 16:39:07.444950 24897 net.cpp:150] Setting up scale2a_branch1
I0312 16:39:07.444955 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.444958 24897 net.cpp:165] Memory required for data: 25489420
I0312 16:39:07.444962 24897 layer_factory.hpp:77] Creating layer res2a_branch2a
I0312 16:39:07.444967 24897 net.cpp:100] Creating Layer res2a_branch2a
I0312 16:39:07.444972 24897 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0312 16:39:07.444975 24897 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0312 16:39:07.445108 24897 net.cpp:150] Setting up res2a_branch2a
I0312 16:39:07.445113 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.445116 24897 net.cpp:165] Memory required for data: 26292236
I0312 16:39:07.445119 24897 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0312 16:39:07.445124 24897 net.cpp:100] Creating Layer bn2a_branch2a
I0312 16:39:07.445127 24897 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0312 16:39:07.445132 24897 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0312 16:39:07.445268 24897 net.cpp:150] Setting up bn2a_branch2a
I0312 16:39:07.445273 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.445276 24897 net.cpp:165] Memory required for data: 27095052
I0312 16:39:07.445282 24897 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0312 16:39:07.445287 24897 net.cpp:100] Creating Layer scale2a_branch2a
I0312 16:39:07.445289 24897 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0312 16:39:07.445307 24897 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0312 16:39:07.445343 24897 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0312 16:39:07.445427 24897 net.cpp:150] Setting up scale2a_branch2a
I0312 16:39:07.445431 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.445433 24897 net.cpp:165] Memory required for data: 27897868
I0312 16:39:07.445437 24897 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0312 16:39:07.445441 24897 net.cpp:100] Creating Layer res2a_branch2a_relu
I0312 16:39:07.445443 24897 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0312 16:39:07.445462 24897 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0312 16:39:07.445466 24897 net.cpp:150] Setting up res2a_branch2a_relu
I0312 16:39:07.445482 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.445484 24897 net.cpp:165] Memory required for data: 28700684
I0312 16:39:07.445487 24897 layer_factory.hpp:77] Creating layer res2a_branch2b
I0312 16:39:07.445492 24897 net.cpp:100] Creating Layer res2a_branch2b
I0312 16:39:07.445494 24897 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0312 16:39:07.445497 24897 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0312 16:39:07.446267 24897 net.cpp:150] Setting up res2a_branch2b
I0312 16:39:07.446277 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.446280 24897 net.cpp:165] Memory required for data: 29503500
I0312 16:39:07.446283 24897 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0312 16:39:07.446288 24897 net.cpp:100] Creating Layer bn2a_branch2b
I0312 16:39:07.446306 24897 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0312 16:39:07.446310 24897 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0312 16:39:07.446480 24897 net.cpp:150] Setting up bn2a_branch2b
I0312 16:39:07.446485 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.446487 24897 net.cpp:165] Memory required for data: 30306316
I0312 16:39:07.446492 24897 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0312 16:39:07.446497 24897 net.cpp:100] Creating Layer scale2a_branch2b
I0312 16:39:07.446513 24897 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0312 16:39:07.446517 24897 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0312 16:39:07.446555 24897 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0312 16:39:07.446692 24897 net.cpp:150] Setting up scale2a_branch2b
I0312 16:39:07.446696 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.446699 24897 net.cpp:165] Memory required for data: 31109132
I0312 16:39:07.446703 24897 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0312 16:39:07.446707 24897 net.cpp:100] Creating Layer res2a_branch2b_relu
I0312 16:39:07.446709 24897 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0312 16:39:07.446727 24897 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0312 16:39:07.446730 24897 net.cpp:150] Setting up res2a_branch2b_relu
I0312 16:39:07.446733 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.446735 24897 net.cpp:165] Memory required for data: 31911948
I0312 16:39:07.446738 24897 layer_factory.hpp:77] Creating layer res2a_branch2c
I0312 16:39:07.446743 24897 net.cpp:100] Creating Layer res2a_branch2c
I0312 16:39:07.446744 24897 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0312 16:39:07.446763 24897 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0312 16:39:07.446931 24897 net.cpp:150] Setting up res2a_branch2c
I0312 16:39:07.446936 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.446938 24897 net.cpp:165] Memory required for data: 35123212
I0312 16:39:07.446941 24897 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0312 16:39:07.446945 24897 net.cpp:100] Creating Layer bn2a_branch2c
I0312 16:39:07.446949 24897 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0312 16:39:07.446965 24897 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0312 16:39:07.447114 24897 net.cpp:150] Setting up bn2a_branch2c
I0312 16:39:07.447119 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447121 24897 net.cpp:165] Memory required for data: 38334476
I0312 16:39:07.447126 24897 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0312 16:39:07.447130 24897 net.cpp:100] Creating Layer scale2a_branch2c
I0312 16:39:07.447145 24897 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0312 16:39:07.447149 24897 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0312 16:39:07.447185 24897 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0312 16:39:07.447345 24897 net.cpp:150] Setting up scale2a_branch2c
I0312 16:39:07.447350 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447352 24897 net.cpp:165] Memory required for data: 41545740
I0312 16:39:07.447356 24897 layer_factory.hpp:77] Creating layer res2a
I0312 16:39:07.447360 24897 net.cpp:100] Creating Layer res2a
I0312 16:39:07.447363 24897 net.cpp:444] res2a <- res2a_branch1
I0312 16:39:07.447366 24897 net.cpp:444] res2a <- res2a_branch2c
I0312 16:39:07.447369 24897 net.cpp:418] res2a -> res2a
I0312 16:39:07.447398 24897 net.cpp:150] Setting up res2a
I0312 16:39:07.447415 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447418 24897 net.cpp:165] Memory required for data: 44757004
I0312 16:39:07.447420 24897 layer_factory.hpp:77] Creating layer res2a_relu
I0312 16:39:07.447423 24897 net.cpp:100] Creating Layer res2a_relu
I0312 16:39:07.447427 24897 net.cpp:444] res2a_relu <- res2a
I0312 16:39:07.447432 24897 net.cpp:405] res2a_relu -> res2a (in-place)
I0312 16:39:07.447449 24897 net.cpp:150] Setting up res2a_relu
I0312 16:39:07.447453 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447468 24897 net.cpp:165] Memory required for data: 47968268
I0312 16:39:07.447470 24897 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0312 16:39:07.447474 24897 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0312 16:39:07.447476 24897 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0312 16:39:07.447492 24897 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0312 16:39:07.447497 24897 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0312 16:39:07.447531 24897 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0312 16:39:07.447536 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447540 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.447541 24897 net.cpp:165] Memory required for data: 54390796
I0312 16:39:07.447544 24897 layer_factory.hpp:77] Creating layer res2b_branch2a
I0312 16:39:07.447549 24897 net.cpp:100] Creating Layer res2b_branch2a
I0312 16:39:07.447552 24897 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0312 16:39:07.447556 24897 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0312 16:39:07.447690 24897 net.cpp:150] Setting up res2b_branch2a
I0312 16:39:07.447693 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.447696 24897 net.cpp:165] Memory required for data: 55193612
I0312 16:39:07.447713 24897 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0312 16:39:07.447717 24897 net.cpp:100] Creating Layer bn2b_branch2a
I0312 16:39:07.447719 24897 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0312 16:39:07.447723 24897 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0312 16:39:07.447857 24897 net.cpp:150] Setting up bn2b_branch2a
I0312 16:39:07.447861 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.447863 24897 net.cpp:165] Memory required for data: 55996428
I0312 16:39:07.447871 24897 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0312 16:39:07.447876 24897 net.cpp:100] Creating Layer scale2b_branch2a
I0312 16:39:07.447878 24897 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0312 16:39:07.447882 24897 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0312 16:39:07.447906 24897 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0312 16:39:07.447993 24897 net.cpp:150] Setting up scale2b_branch2a
I0312 16:39:07.447998 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.447999 24897 net.cpp:165] Memory required for data: 56799244
I0312 16:39:07.448004 24897 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0312 16:39:07.448007 24897 net.cpp:100] Creating Layer res2b_branch2a_relu
I0312 16:39:07.448009 24897 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0312 16:39:07.448012 24897 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0312 16:39:07.448016 24897 net.cpp:150] Setting up res2b_branch2a_relu
I0312 16:39:07.448020 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.448022 24897 net.cpp:165] Memory required for data: 57602060
I0312 16:39:07.448025 24897 layer_factory.hpp:77] Creating layer res2b_branch2b
I0312 16:39:07.448029 24897 net.cpp:100] Creating Layer res2b_branch2b
I0312 16:39:07.448032 24897 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0312 16:39:07.448036 24897 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0312 16:39:07.448179 24897 net.cpp:150] Setting up res2b_branch2b
I0312 16:39:07.448184 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.448187 24897 net.cpp:165] Memory required for data: 58404876
I0312 16:39:07.448190 24897 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0312 16:39:07.448194 24897 net.cpp:100] Creating Layer bn2b_branch2b
I0312 16:39:07.448197 24897 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0312 16:39:07.448200 24897 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0312 16:39:07.448350 24897 net.cpp:150] Setting up bn2b_branch2b
I0312 16:39:07.448354 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.448370 24897 net.cpp:165] Memory required for data: 59207692
I0312 16:39:07.448375 24897 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0312 16:39:07.448379 24897 net.cpp:100] Creating Layer scale2b_branch2b
I0312 16:39:07.448382 24897 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0312 16:39:07.448386 24897 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0312 16:39:07.448408 24897 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0312 16:39:07.448496 24897 net.cpp:150] Setting up scale2b_branch2b
I0312 16:39:07.448501 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.448503 24897 net.cpp:165] Memory required for data: 60010508
I0312 16:39:07.448508 24897 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0312 16:39:07.448524 24897 net.cpp:100] Creating Layer res2b_branch2b_relu
I0312 16:39:07.448527 24897 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0312 16:39:07.448530 24897 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0312 16:39:07.448534 24897 net.cpp:150] Setting up res2b_branch2b_relu
I0312 16:39:07.448537 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.448539 24897 net.cpp:165] Memory required for data: 60813324
I0312 16:39:07.448541 24897 layer_factory.hpp:77] Creating layer res2b_branch2c
I0312 16:39:07.448547 24897 net.cpp:100] Creating Layer res2b_branch2c
I0312 16:39:07.448549 24897 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0312 16:39:07.448554 24897 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0312 16:39:07.448686 24897 net.cpp:150] Setting up res2b_branch2c
I0312 16:39:07.448693 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.448694 24897 net.cpp:165] Memory required for data: 64024588
I0312 16:39:07.448698 24897 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0312 16:39:07.448715 24897 net.cpp:100] Creating Layer bn2b_branch2c
I0312 16:39:07.448717 24897 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0312 16:39:07.448721 24897 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0312 16:39:07.448849 24897 net.cpp:150] Setting up bn2b_branch2c
I0312 16:39:07.448853 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.448856 24897 net.cpp:165] Memory required for data: 67235852
I0312 16:39:07.448875 24897 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0312 16:39:07.448880 24897 net.cpp:100] Creating Layer scale2b_branch2c
I0312 16:39:07.448882 24897 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0312 16:39:07.448886 24897 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0312 16:39:07.448909 24897 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0312 16:39:07.448992 24897 net.cpp:150] Setting up scale2b_branch2c
I0312 16:39:07.448997 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.448999 24897 net.cpp:165] Memory required for data: 70447116
I0312 16:39:07.449003 24897 layer_factory.hpp:77] Creating layer res2b
I0312 16:39:07.449020 24897 net.cpp:100] Creating Layer res2b
I0312 16:39:07.449023 24897 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0312 16:39:07.449026 24897 net.cpp:444] res2b <- res2b_branch2c
I0312 16:39:07.449029 24897 net.cpp:418] res2b -> res2b
I0312 16:39:07.449044 24897 net.cpp:150] Setting up res2b
I0312 16:39:07.449049 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.449053 24897 net.cpp:165] Memory required for data: 73658380
I0312 16:39:07.449054 24897 layer_factory.hpp:77] Creating layer res2b_relu
I0312 16:39:07.449057 24897 net.cpp:100] Creating Layer res2b_relu
I0312 16:39:07.449060 24897 net.cpp:444] res2b_relu <- res2b
I0312 16:39:07.449064 24897 net.cpp:405] res2b_relu -> res2b (in-place)
I0312 16:39:07.449066 24897 net.cpp:150] Setting up res2b_relu
I0312 16:39:07.449069 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.449072 24897 net.cpp:165] Memory required for data: 76869644
I0312 16:39:07.449074 24897 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0312 16:39:07.449077 24897 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0312 16:39:07.449080 24897 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0312 16:39:07.449084 24897 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0312 16:39:07.449087 24897 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0312 16:39:07.449110 24897 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0312 16:39:07.449115 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.449117 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.449120 24897 net.cpp:165] Memory required for data: 83292172
I0312 16:39:07.449121 24897 layer_factory.hpp:77] Creating layer res2c_branch2a
I0312 16:39:07.449126 24897 net.cpp:100] Creating Layer res2c_branch2a
I0312 16:39:07.449129 24897 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0312 16:39:07.449133 24897 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0312 16:39:07.449252 24897 net.cpp:150] Setting up res2c_branch2a
I0312 16:39:07.449257 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449259 24897 net.cpp:165] Memory required for data: 84094988
I0312 16:39:07.449264 24897 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0312 16:39:07.449267 24897 net.cpp:100] Creating Layer bn2c_branch2a
I0312 16:39:07.449270 24897 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0312 16:39:07.449273 24897 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0312 16:39:07.449391 24897 net.cpp:150] Setting up bn2c_branch2a
I0312 16:39:07.449396 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449398 24897 net.cpp:165] Memory required for data: 84897804
I0312 16:39:07.449404 24897 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0312 16:39:07.449407 24897 net.cpp:100] Creating Layer scale2c_branch2a
I0312 16:39:07.449411 24897 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0312 16:39:07.449414 24897 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0312 16:39:07.449437 24897 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0312 16:39:07.449513 24897 net.cpp:150] Setting up scale2c_branch2a
I0312 16:39:07.449517 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449520 24897 net.cpp:165] Memory required for data: 85700620
I0312 16:39:07.449524 24897 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0312 16:39:07.449548 24897 net.cpp:100] Creating Layer res2c_branch2a_relu
I0312 16:39:07.449553 24897 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0312 16:39:07.449558 24897 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0312 16:39:07.449561 24897 net.cpp:150] Setting up res2c_branch2a_relu
I0312 16:39:07.449564 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449566 24897 net.cpp:165] Memory required for data: 86503436
I0312 16:39:07.449569 24897 layer_factory.hpp:77] Creating layer res2c_branch2b
I0312 16:39:07.449574 24897 net.cpp:100] Creating Layer res2c_branch2b
I0312 16:39:07.449578 24897 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0312 16:39:07.449581 24897 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0312 16:39:07.449717 24897 net.cpp:150] Setting up res2c_branch2b
I0312 16:39:07.449723 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449725 24897 net.cpp:165] Memory required for data: 87306252
I0312 16:39:07.449729 24897 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0312 16:39:07.449733 24897 net.cpp:100] Creating Layer bn2c_branch2b
I0312 16:39:07.449736 24897 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0312 16:39:07.449739 24897 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0312 16:39:07.449862 24897 net.cpp:150] Setting up bn2c_branch2b
I0312 16:39:07.449867 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.449868 24897 net.cpp:165] Memory required for data: 88109068
I0312 16:39:07.449873 24897 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0312 16:39:07.449878 24897 net.cpp:100] Creating Layer scale2c_branch2b
I0312 16:39:07.449882 24897 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0312 16:39:07.449884 24897 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0312 16:39:07.449913 24897 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0312 16:39:07.450004 24897 net.cpp:150] Setting up scale2c_branch2b
I0312 16:39:07.450009 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.450011 24897 net.cpp:165] Memory required for data: 88911884
I0312 16:39:07.450016 24897 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0312 16:39:07.450019 24897 net.cpp:100] Creating Layer res2c_branch2b_relu
I0312 16:39:07.450021 24897 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0312 16:39:07.450026 24897 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0312 16:39:07.450028 24897 net.cpp:150] Setting up res2c_branch2b_relu
I0312 16:39:07.450032 24897 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0312 16:39:07.450034 24897 net.cpp:165] Memory required for data: 89714700
I0312 16:39:07.450037 24897 layer_factory.hpp:77] Creating layer res2c_branch2c
I0312 16:39:07.450054 24897 net.cpp:100] Creating Layer res2c_branch2c
I0312 16:39:07.450057 24897 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0312 16:39:07.450060 24897 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0312 16:39:07.450196 24897 net.cpp:150] Setting up res2c_branch2c
I0312 16:39:07.450201 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450202 24897 net.cpp:165] Memory required for data: 92925964
I0312 16:39:07.450206 24897 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0312 16:39:07.450211 24897 net.cpp:100] Creating Layer bn2c_branch2c
I0312 16:39:07.450212 24897 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0312 16:39:07.450217 24897 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0312 16:39:07.450332 24897 net.cpp:150] Setting up bn2c_branch2c
I0312 16:39:07.450337 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450340 24897 net.cpp:165] Memory required for data: 96137228
I0312 16:39:07.450361 24897 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0312 16:39:07.450366 24897 net.cpp:100] Creating Layer scale2c_branch2c
I0312 16:39:07.450368 24897 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0312 16:39:07.450372 24897 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0312 16:39:07.450394 24897 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0312 16:39:07.450477 24897 net.cpp:150] Setting up scale2c_branch2c
I0312 16:39:07.450482 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450485 24897 net.cpp:165] Memory required for data: 99348492
I0312 16:39:07.450489 24897 layer_factory.hpp:77] Creating layer res2c
I0312 16:39:07.450492 24897 net.cpp:100] Creating Layer res2c
I0312 16:39:07.450508 24897 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0312 16:39:07.450512 24897 net.cpp:444] res2c <- res2c_branch2c
I0312 16:39:07.450515 24897 net.cpp:418] res2c -> res2c
I0312 16:39:07.450529 24897 net.cpp:150] Setting up res2c
I0312 16:39:07.450533 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450536 24897 net.cpp:165] Memory required for data: 102559756
I0312 16:39:07.450538 24897 layer_factory.hpp:77] Creating layer res2c_relu
I0312 16:39:07.450542 24897 net.cpp:100] Creating Layer res2c_relu
I0312 16:39:07.450544 24897 net.cpp:444] res2c_relu <- res2c
I0312 16:39:07.450547 24897 net.cpp:405] res2c_relu -> res2c (in-place)
I0312 16:39:07.450551 24897 net.cpp:150] Setting up res2c_relu
I0312 16:39:07.450554 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450556 24897 net.cpp:165] Memory required for data: 105771020
I0312 16:39:07.450558 24897 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0312 16:39:07.450562 24897 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0312 16:39:07.450564 24897 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0312 16:39:07.450567 24897 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0312 16:39:07.450572 24897 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0312 16:39:07.450593 24897 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0312 16:39:07.450598 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450601 24897 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0312 16:39:07.450603 24897 net.cpp:165] Memory required for data: 112193548
I0312 16:39:07.450605 24897 layer_factory.hpp:77] Creating layer res3a_branch1
I0312 16:39:07.450610 24897 net.cpp:100] Creating Layer res3a_branch1
I0312 16:39:07.450614 24897 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0312 16:39:07.450618 24897 net.cpp:418] res3a_branch1 -> res3a_branch1
I0312 16:39:07.451454 24897 net.cpp:150] Setting up res3a_branch1
I0312 16:39:07.451465 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.451467 24897 net.cpp:165] Memory required for data: 113799180
I0312 16:39:07.451472 24897 layer_factory.hpp:77] Creating layer bn3a_branch1
I0312 16:39:07.451478 24897 net.cpp:100] Creating Layer bn3a_branch1
I0312 16:39:07.451481 24897 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0312 16:39:07.451485 24897 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0312 16:39:07.452281 24897 net.cpp:150] Setting up bn3a_branch1
I0312 16:39:07.452291 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.452293 24897 net.cpp:165] Memory required for data: 115404812
I0312 16:39:07.452299 24897 layer_factory.hpp:77] Creating layer scale3a_branch1
I0312 16:39:07.452306 24897 net.cpp:100] Creating Layer scale3a_branch1
I0312 16:39:07.452323 24897 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0312 16:39:07.452327 24897 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0312 16:39:07.452356 24897 layer_factory.hpp:77] Creating layer scale3a_branch1
I0312 16:39:07.452452 24897 net.cpp:150] Setting up scale3a_branch1
I0312 16:39:07.452458 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.452461 24897 net.cpp:165] Memory required for data: 117010444
I0312 16:39:07.452464 24897 layer_factory.hpp:77] Creating layer res3a_branch2a
I0312 16:39:07.452471 24897 net.cpp:100] Creating Layer res3a_branch2a
I0312 16:39:07.452474 24897 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0312 16:39:07.452478 24897 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0312 16:39:07.452630 24897 net.cpp:150] Setting up res3a_branch2a
I0312 16:39:07.452635 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.452637 24897 net.cpp:165] Memory required for data: 117411852
I0312 16:39:07.452641 24897 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0312 16:39:07.452646 24897 net.cpp:100] Creating Layer bn3a_branch2a
I0312 16:39:07.452649 24897 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0312 16:39:07.452653 24897 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0312 16:39:07.452791 24897 net.cpp:150] Setting up bn3a_branch2a
I0312 16:39:07.452796 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.452798 24897 net.cpp:165] Memory required for data: 117813260
I0312 16:39:07.452803 24897 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0312 16:39:07.452807 24897 net.cpp:100] Creating Layer scale3a_branch2a
I0312 16:39:07.452824 24897 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0312 16:39:07.452828 24897 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0312 16:39:07.452852 24897 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0312 16:39:07.452946 24897 net.cpp:150] Setting up scale3a_branch2a
I0312 16:39:07.452951 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.452953 24897 net.cpp:165] Memory required for data: 118214668
I0312 16:39:07.452957 24897 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0312 16:39:07.452961 24897 net.cpp:100] Creating Layer res3a_branch2a_relu
I0312 16:39:07.452978 24897 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0312 16:39:07.452982 24897 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0312 16:39:07.452986 24897 net.cpp:150] Setting up res3a_branch2a_relu
I0312 16:39:07.452989 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.452991 24897 net.cpp:165] Memory required for data: 118616076
I0312 16:39:07.452994 24897 layer_factory.hpp:77] Creating layer res3a_branch2b
I0312 16:39:07.452998 24897 net.cpp:100] Creating Layer res3a_branch2b
I0312 16:39:07.453001 24897 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0312 16:39:07.453006 24897 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0312 16:39:07.453207 24897 net.cpp:150] Setting up res3a_branch2b
I0312 16:39:07.453212 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.453213 24897 net.cpp:165] Memory required for data: 119017484
I0312 16:39:07.453217 24897 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0312 16:39:07.453222 24897 net.cpp:100] Creating Layer bn3a_branch2b
I0312 16:39:07.453223 24897 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0312 16:39:07.453241 24897 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0312 16:39:07.453366 24897 net.cpp:150] Setting up bn3a_branch2b
I0312 16:39:07.453372 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.453373 24897 net.cpp:165] Memory required for data: 119418892
I0312 16:39:07.453378 24897 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0312 16:39:07.453382 24897 net.cpp:100] Creating Layer scale3a_branch2b
I0312 16:39:07.453398 24897 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0312 16:39:07.453402 24897 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0312 16:39:07.453438 24897 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0312 16:39:07.453532 24897 net.cpp:150] Setting up scale3a_branch2b
I0312 16:39:07.453537 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.453539 24897 net.cpp:165] Memory required for data: 119820300
I0312 16:39:07.453543 24897 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0312 16:39:07.453547 24897 net.cpp:100] Creating Layer res3a_branch2b_relu
I0312 16:39:07.453549 24897 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0312 16:39:07.453567 24897 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0312 16:39:07.453572 24897 net.cpp:150] Setting up res3a_branch2b_relu
I0312 16:39:07.453574 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.453577 24897 net.cpp:165] Memory required for data: 120221708
I0312 16:39:07.453579 24897 layer_factory.hpp:77] Creating layer res3a_branch2c
I0312 16:39:07.453584 24897 net.cpp:100] Creating Layer res3a_branch2c
I0312 16:39:07.453586 24897 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0312 16:39:07.453603 24897 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0312 16:39:07.453788 24897 net.cpp:150] Setting up res3a_branch2c
I0312 16:39:07.453794 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.453795 24897 net.cpp:165] Memory required for data: 121827340
I0312 16:39:07.453799 24897 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0312 16:39:07.453804 24897 net.cpp:100] Creating Layer bn3a_branch2c
I0312 16:39:07.453821 24897 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0312 16:39:07.453824 24897 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0312 16:39:07.454023 24897 net.cpp:150] Setting up bn3a_branch2c
I0312 16:39:07.454028 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454030 24897 net.cpp:165] Memory required for data: 123432972
I0312 16:39:07.454035 24897 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0312 16:39:07.454039 24897 net.cpp:100] Creating Layer scale3a_branch2c
I0312 16:39:07.454054 24897 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0312 16:39:07.454058 24897 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0312 16:39:07.454107 24897 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0312 16:39:07.454187 24897 net.cpp:150] Setting up scale3a_branch2c
I0312 16:39:07.454192 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454195 24897 net.cpp:165] Memory required for data: 125038604
I0312 16:39:07.454198 24897 layer_factory.hpp:77] Creating layer res3a
I0312 16:39:07.454203 24897 net.cpp:100] Creating Layer res3a
I0312 16:39:07.454206 24897 net.cpp:444] res3a <- res3a_branch1
I0312 16:39:07.454210 24897 net.cpp:444] res3a <- res3a_branch2c
I0312 16:39:07.454212 24897 net.cpp:418] res3a -> res3a
I0312 16:39:07.454241 24897 net.cpp:150] Setting up res3a
I0312 16:39:07.454244 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454246 24897 net.cpp:165] Memory required for data: 126644236
I0312 16:39:07.454262 24897 layer_factory.hpp:77] Creating layer res3a_relu
I0312 16:39:07.454264 24897 net.cpp:100] Creating Layer res3a_relu
I0312 16:39:07.454267 24897 net.cpp:444] res3a_relu <- res3a
I0312 16:39:07.454270 24897 net.cpp:405] res3a_relu -> res3a (in-place)
I0312 16:39:07.454288 24897 net.cpp:150] Setting up res3a_relu
I0312 16:39:07.454290 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454293 24897 net.cpp:165] Memory required for data: 128249868
I0312 16:39:07.454294 24897 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0312 16:39:07.454298 24897 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0312 16:39:07.454313 24897 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0312 16:39:07.454318 24897 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0312 16:39:07.454321 24897 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0312 16:39:07.454344 24897 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0312 16:39:07.454349 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454351 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.454354 24897 net.cpp:165] Memory required for data: 131461132
I0312 16:39:07.454355 24897 layer_factory.hpp:77] Creating layer res3b_branch2a
I0312 16:39:07.454361 24897 net.cpp:100] Creating Layer res3b_branch2a
I0312 16:39:07.454365 24897 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0312 16:39:07.454368 24897 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0312 16:39:07.454543 24897 net.cpp:150] Setting up res3b_branch2a
I0312 16:39:07.454550 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.454552 24897 net.cpp:165] Memory required for data: 131862540
I0312 16:39:07.454556 24897 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0312 16:39:07.454560 24897 net.cpp:100] Creating Layer bn3b_branch2a
I0312 16:39:07.454563 24897 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0312 16:39:07.454571 24897 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0312 16:39:07.454691 24897 net.cpp:150] Setting up bn3b_branch2a
I0312 16:39:07.454696 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.454712 24897 net.cpp:165] Memory required for data: 132263948
I0312 16:39:07.454717 24897 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0312 16:39:07.454721 24897 net.cpp:100] Creating Layer scale3b_branch2a
I0312 16:39:07.454723 24897 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0312 16:39:07.454727 24897 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0312 16:39:07.454751 24897 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0312 16:39:07.454820 24897 net.cpp:150] Setting up scale3b_branch2a
I0312 16:39:07.454825 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.454828 24897 net.cpp:165] Memory required for data: 132665356
I0312 16:39:07.454833 24897 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0312 16:39:07.454835 24897 net.cpp:100] Creating Layer res3b_branch2a_relu
I0312 16:39:07.454838 24897 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0312 16:39:07.454841 24897 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0312 16:39:07.454845 24897 net.cpp:150] Setting up res3b_branch2a_relu
I0312 16:39:07.454849 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.454851 24897 net.cpp:165] Memory required for data: 133066764
I0312 16:39:07.454854 24897 layer_factory.hpp:77] Creating layer res3b_branch2b
I0312 16:39:07.454859 24897 net.cpp:100] Creating Layer res3b_branch2b
I0312 16:39:07.454864 24897 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0312 16:39:07.454867 24897 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0312 16:39:07.455097 24897 net.cpp:150] Setting up res3b_branch2b
I0312 16:39:07.455116 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.455119 24897 net.cpp:165] Memory required for data: 133468172
I0312 16:39:07.455122 24897 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0312 16:39:07.455140 24897 net.cpp:100] Creating Layer bn3b_branch2b
I0312 16:39:07.455143 24897 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0312 16:39:07.455147 24897 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0312 16:39:07.455296 24897 net.cpp:150] Setting up bn3b_branch2b
I0312 16:39:07.455301 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.455303 24897 net.cpp:165] Memory required for data: 133869580
I0312 16:39:07.455307 24897 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0312 16:39:07.455313 24897 net.cpp:100] Creating Layer scale3b_branch2b
I0312 16:39:07.455317 24897 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0312 16:39:07.455319 24897 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0312 16:39:07.455343 24897 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0312 16:39:07.455418 24897 net.cpp:150] Setting up scale3b_branch2b
I0312 16:39:07.455423 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.455426 24897 net.cpp:165] Memory required for data: 134270988
I0312 16:39:07.455430 24897 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0312 16:39:07.455435 24897 net.cpp:100] Creating Layer res3b_branch2b_relu
I0312 16:39:07.455438 24897 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0312 16:39:07.455441 24897 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0312 16:39:07.455444 24897 net.cpp:150] Setting up res3b_branch2b_relu
I0312 16:39:07.455447 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.455451 24897 net.cpp:165] Memory required for data: 134672396
I0312 16:39:07.455452 24897 layer_factory.hpp:77] Creating layer res3b_branch2c
I0312 16:39:07.455459 24897 net.cpp:100] Creating Layer res3b_branch2c
I0312 16:39:07.455462 24897 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0312 16:39:07.455467 24897 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0312 16:39:07.455624 24897 net.cpp:150] Setting up res3b_branch2c
I0312 16:39:07.455631 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.455632 24897 net.cpp:165] Memory required for data: 136278028
I0312 16:39:07.455636 24897 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0312 16:39:07.455641 24897 net.cpp:100] Creating Layer bn3b_branch2c
I0312 16:39:07.455646 24897 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0312 16:39:07.455648 24897 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0312 16:39:07.455773 24897 net.cpp:150] Setting up bn3b_branch2c
I0312 16:39:07.455778 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.455781 24897 net.cpp:165] Memory required for data: 137883660
I0312 16:39:07.455785 24897 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0312 16:39:07.455790 24897 net.cpp:100] Creating Layer scale3b_branch2c
I0312 16:39:07.455793 24897 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0312 16:39:07.455797 24897 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0312 16:39:07.455823 24897 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0312 16:39:07.455899 24897 net.cpp:150] Setting up scale3b_branch2c
I0312 16:39:07.455904 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.455905 24897 net.cpp:165] Memory required for data: 139489292
I0312 16:39:07.455909 24897 layer_factory.hpp:77] Creating layer res3b
I0312 16:39:07.455914 24897 net.cpp:100] Creating Layer res3b
I0312 16:39:07.455916 24897 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0312 16:39:07.455919 24897 net.cpp:444] res3b <- res3b_branch2c
I0312 16:39:07.455924 24897 net.cpp:418] res3b -> res3b
I0312 16:39:07.455938 24897 net.cpp:150] Setting up res3b
I0312 16:39:07.455943 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.455945 24897 net.cpp:165] Memory required for data: 141094924
I0312 16:39:07.455947 24897 layer_factory.hpp:77] Creating layer res3b_relu
I0312 16:39:07.455952 24897 net.cpp:100] Creating Layer res3b_relu
I0312 16:39:07.455955 24897 net.cpp:444] res3b_relu <- res3b
I0312 16:39:07.455958 24897 net.cpp:405] res3b_relu -> res3b (in-place)
I0312 16:39:07.455961 24897 net.cpp:150] Setting up res3b_relu
I0312 16:39:07.455965 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.455967 24897 net.cpp:165] Memory required for data: 142700556
I0312 16:39:07.455970 24897 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0312 16:39:07.455974 24897 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0312 16:39:07.455978 24897 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0312 16:39:07.455981 24897 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0312 16:39:07.455986 24897 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0312 16:39:07.456010 24897 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0312 16:39:07.456014 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.456017 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.456020 24897 net.cpp:165] Memory required for data: 145911820
I0312 16:39:07.456022 24897 layer_factory.hpp:77] Creating layer res3c_branch2a
I0312 16:39:07.456027 24897 net.cpp:100] Creating Layer res3c_branch2a
I0312 16:39:07.456029 24897 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0312 16:39:07.456033 24897 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0312 16:39:07.456214 24897 net.cpp:150] Setting up res3c_branch2a
I0312 16:39:07.456219 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.456223 24897 net.cpp:165] Memory required for data: 146313228
I0312 16:39:07.456225 24897 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0312 16:39:07.456230 24897 net.cpp:100] Creating Layer bn3c_branch2a
I0312 16:39:07.456234 24897 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0312 16:39:07.456238 24897 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0312 16:39:07.456362 24897 net.cpp:150] Setting up bn3c_branch2a
I0312 16:39:07.456367 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.456369 24897 net.cpp:165] Memory required for data: 146714636
I0312 16:39:07.456374 24897 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0312 16:39:07.456378 24897 net.cpp:100] Creating Layer scale3c_branch2a
I0312 16:39:07.456382 24897 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0312 16:39:07.456387 24897 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0312 16:39:07.456409 24897 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0312 16:39:07.456509 24897 net.cpp:150] Setting up scale3c_branch2a
I0312 16:39:07.456516 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.456518 24897 net.cpp:165] Memory required for data: 147116044
I0312 16:39:07.456522 24897 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0312 16:39:07.456526 24897 net.cpp:100] Creating Layer res3c_branch2a_relu
I0312 16:39:07.456528 24897 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0312 16:39:07.456532 24897 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0312 16:39:07.456535 24897 net.cpp:150] Setting up res3c_branch2a_relu
I0312 16:39:07.456538 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.456540 24897 net.cpp:165] Memory required for data: 147517452
I0312 16:39:07.456542 24897 layer_factory.hpp:77] Creating layer res3c_branch2b
I0312 16:39:07.456547 24897 net.cpp:100] Creating Layer res3c_branch2b
I0312 16:39:07.456550 24897 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0312 16:39:07.456555 24897 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0312 16:39:07.457653 24897 net.cpp:150] Setting up res3c_branch2b
I0312 16:39:07.457681 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.457684 24897 net.cpp:165] Memory required for data: 147918860
I0312 16:39:07.457695 24897 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0312 16:39:07.457708 24897 net.cpp:100] Creating Layer bn3c_branch2b
I0312 16:39:07.457712 24897 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0312 16:39:07.457720 24897 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0312 16:39:07.457887 24897 net.cpp:150] Setting up bn3c_branch2b
I0312 16:39:07.457919 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.457922 24897 net.cpp:165] Memory required for data: 148320268
I0312 16:39:07.457928 24897 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0312 16:39:07.457949 24897 net.cpp:100] Creating Layer scale3c_branch2b
I0312 16:39:07.457952 24897 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0312 16:39:07.457955 24897 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0312 16:39:07.457985 24897 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0312 16:39:07.458081 24897 net.cpp:150] Setting up scale3c_branch2b
I0312 16:39:07.458086 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.458087 24897 net.cpp:165] Memory required for data: 148721676
I0312 16:39:07.458091 24897 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0312 16:39:07.458097 24897 net.cpp:100] Creating Layer res3c_branch2b_relu
I0312 16:39:07.458114 24897 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0312 16:39:07.458118 24897 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0312 16:39:07.458123 24897 net.cpp:150] Setting up res3c_branch2b_relu
I0312 16:39:07.458127 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.458129 24897 net.cpp:165] Memory required for data: 149123084
I0312 16:39:07.458132 24897 layer_factory.hpp:77] Creating layer res3c_branch2c
I0312 16:39:07.458151 24897 net.cpp:100] Creating Layer res3c_branch2c
I0312 16:39:07.458155 24897 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0312 16:39:07.458160 24897 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0312 16:39:07.458351 24897 net.cpp:150] Setting up res3c_branch2c
I0312 16:39:07.458359 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458360 24897 net.cpp:165] Memory required for data: 150728716
I0312 16:39:07.458364 24897 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0312 16:39:07.458369 24897 net.cpp:100] Creating Layer bn3c_branch2c
I0312 16:39:07.458372 24897 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0312 16:39:07.458376 24897 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0312 16:39:07.458534 24897 net.cpp:150] Setting up bn3c_branch2c
I0312 16:39:07.458539 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458541 24897 net.cpp:165] Memory required for data: 152334348
I0312 16:39:07.458546 24897 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0312 16:39:07.458550 24897 net.cpp:100] Creating Layer scale3c_branch2c
I0312 16:39:07.458569 24897 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0312 16:39:07.458571 24897 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0312 16:39:07.458612 24897 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0312 16:39:07.458689 24897 net.cpp:150] Setting up scale3c_branch2c
I0312 16:39:07.458694 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458696 24897 net.cpp:165] Memory required for data: 153939980
I0312 16:39:07.458700 24897 layer_factory.hpp:77] Creating layer res3c
I0312 16:39:07.458719 24897 net.cpp:100] Creating Layer res3c
I0312 16:39:07.458721 24897 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0312 16:39:07.458737 24897 net.cpp:444] res3c <- res3c_branch2c
I0312 16:39:07.458741 24897 net.cpp:418] res3c -> res3c
I0312 16:39:07.458773 24897 net.cpp:150] Setting up res3c
I0312 16:39:07.458778 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458781 24897 net.cpp:165] Memory required for data: 155545612
I0312 16:39:07.458783 24897 layer_factory.hpp:77] Creating layer res3c_relu
I0312 16:39:07.458787 24897 net.cpp:100] Creating Layer res3c_relu
I0312 16:39:07.458789 24897 net.cpp:444] res3c_relu <- res3c
I0312 16:39:07.458797 24897 net.cpp:405] res3c_relu -> res3c (in-place)
I0312 16:39:07.458802 24897 net.cpp:150] Setting up res3c_relu
I0312 16:39:07.458806 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458807 24897 net.cpp:165] Memory required for data: 157151244
I0312 16:39:07.458811 24897 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0312 16:39:07.458815 24897 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0312 16:39:07.458818 24897 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0312 16:39:07.458823 24897 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0312 16:39:07.458828 24897 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0312 16:39:07.458853 24897 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0312 16:39:07.458858 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458860 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.458874 24897 net.cpp:165] Memory required for data: 160362508
I0312 16:39:07.458878 24897 layer_factory.hpp:77] Creating layer res3d_branch2a
I0312 16:39:07.458896 24897 net.cpp:100] Creating Layer res3d_branch2a
I0312 16:39:07.458899 24897 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0312 16:39:07.458904 24897 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0312 16:39:07.460117 24897 net.cpp:150] Setting up res3d_branch2a
I0312 16:39:07.460147 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.460150 24897 net.cpp:165] Memory required for data: 160763916
I0312 16:39:07.460171 24897 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0312 16:39:07.460184 24897 net.cpp:100] Creating Layer bn3d_branch2a
I0312 16:39:07.460188 24897 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0312 16:39:07.460208 24897 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0312 16:39:07.460386 24897 net.cpp:150] Setting up bn3d_branch2a
I0312 16:39:07.460391 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.460393 24897 net.cpp:165] Memory required for data: 161165324
I0312 16:39:07.460433 24897 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0312 16:39:07.460443 24897 net.cpp:100] Creating Layer scale3d_branch2a
I0312 16:39:07.460460 24897 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0312 16:39:07.460465 24897 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0312 16:39:07.460526 24897 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0312 16:39:07.460608 24897 net.cpp:150] Setting up scale3d_branch2a
I0312 16:39:07.460628 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.460630 24897 net.cpp:165] Memory required for data: 161566732
I0312 16:39:07.460633 24897 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0312 16:39:07.460638 24897 net.cpp:100] Creating Layer res3d_branch2a_relu
I0312 16:39:07.460655 24897 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0312 16:39:07.460659 24897 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0312 16:39:07.460676 24897 net.cpp:150] Setting up res3d_branch2a_relu
I0312 16:39:07.460680 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.460681 24897 net.cpp:165] Memory required for data: 161968140
I0312 16:39:07.460683 24897 layer_factory.hpp:77] Creating layer res3d_branch2b
I0312 16:39:07.460706 24897 net.cpp:100] Creating Layer res3d_branch2b
I0312 16:39:07.460710 24897 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0312 16:39:07.460714 24897 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0312 16:39:07.460970 24897 net.cpp:150] Setting up res3d_branch2b
I0312 16:39:07.460976 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.460979 24897 net.cpp:165] Memory required for data: 162369548
I0312 16:39:07.460983 24897 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0312 16:39:07.460985 24897 net.cpp:100] Creating Layer bn3d_branch2b
I0312 16:39:07.460988 24897 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0312 16:39:07.461006 24897 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0312 16:39:07.461184 24897 net.cpp:150] Setting up bn3d_branch2b
I0312 16:39:07.461189 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.461190 24897 net.cpp:165] Memory required for data: 162770956
I0312 16:39:07.461195 24897 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0312 16:39:07.461215 24897 net.cpp:100] Creating Layer scale3d_branch2b
I0312 16:39:07.461216 24897 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0312 16:39:07.461220 24897 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0312 16:39:07.461272 24897 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0312 16:39:07.461416 24897 net.cpp:150] Setting up scale3d_branch2b
I0312 16:39:07.461433 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.461436 24897 net.cpp:165] Memory required for data: 163172364
I0312 16:39:07.461441 24897 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0312 16:39:07.461444 24897 net.cpp:100] Creating Layer res3d_branch2b_relu
I0312 16:39:07.461459 24897 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0312 16:39:07.461463 24897 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0312 16:39:07.461467 24897 net.cpp:150] Setting up res3d_branch2b_relu
I0312 16:39:07.461484 24897 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0312 16:39:07.461486 24897 net.cpp:165] Memory required for data: 163573772
I0312 16:39:07.461488 24897 layer_factory.hpp:77] Creating layer res3d_branch2c
I0312 16:39:07.461493 24897 net.cpp:100] Creating Layer res3d_branch2c
I0312 16:39:07.461495 24897 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0312 16:39:07.461500 24897 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0312 16:39:07.461685 24897 net.cpp:150] Setting up res3d_branch2c
I0312 16:39:07.461690 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.461694 24897 net.cpp:165] Memory required for data: 165179404
I0312 16:39:07.461696 24897 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0312 16:39:07.461701 24897 net.cpp:100] Creating Layer bn3d_branch2c
I0312 16:39:07.461716 24897 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0312 16:39:07.461719 24897 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0312 16:39:07.461869 24897 net.cpp:150] Setting up bn3d_branch2c
I0312 16:39:07.461874 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.461876 24897 net.cpp:165] Memory required for data: 166785036
I0312 16:39:07.461881 24897 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0312 16:39:07.461885 24897 net.cpp:100] Creating Layer scale3d_branch2c
I0312 16:39:07.461908 24897 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0312 16:39:07.461913 24897 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0312 16:39:07.461956 24897 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0312 16:39:07.462069 24897 net.cpp:150] Setting up scale3d_branch2c
I0312 16:39:07.462074 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.462076 24897 net.cpp:165] Memory required for data: 168390668
I0312 16:39:07.462080 24897 layer_factory.hpp:77] Creating layer res3d
I0312 16:39:07.462085 24897 net.cpp:100] Creating Layer res3d
I0312 16:39:07.462100 24897 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0312 16:39:07.462103 24897 net.cpp:444] res3d <- res3d_branch2c
I0312 16:39:07.462108 24897 net.cpp:418] res3d -> res3d
I0312 16:39:07.462126 24897 net.cpp:150] Setting up res3d
I0312 16:39:07.462128 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.462131 24897 net.cpp:165] Memory required for data: 169996300
I0312 16:39:07.462133 24897 layer_factory.hpp:77] Creating layer res3d_relu
I0312 16:39:07.462136 24897 net.cpp:100] Creating Layer res3d_relu
I0312 16:39:07.462139 24897 net.cpp:444] res3d_relu <- res3d
I0312 16:39:07.462142 24897 net.cpp:405] res3d_relu -> res3d (in-place)
I0312 16:39:07.462146 24897 net.cpp:150] Setting up res3d_relu
I0312 16:39:07.462148 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.462152 24897 net.cpp:165] Memory required for data: 171601932
I0312 16:39:07.462153 24897 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0312 16:39:07.462158 24897 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0312 16:39:07.462160 24897 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0312 16:39:07.462164 24897 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0312 16:39:07.462168 24897 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0312 16:39:07.462193 24897 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0312 16:39:07.462195 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.462199 24897 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0312 16:39:07.462201 24897 net.cpp:165] Memory required for data: 174813196
I0312 16:39:07.462203 24897 layer_factory.hpp:77] Creating layer res4a_branch1
I0312 16:39:07.462208 24897 net.cpp:100] Creating Layer res4a_branch1
I0312 16:39:07.462211 24897 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0312 16:39:07.462215 24897 net.cpp:418] res4a_branch1 -> res4a_branch1
I0312 16:39:07.463330 24897 net.cpp:150] Setting up res4a_branch1
I0312 16:39:07.463342 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.463344 24897 net.cpp:165] Memory required for data: 175616012
I0312 16:39:07.463349 24897 layer_factory.hpp:77] Creating layer bn4a_branch1
I0312 16:39:07.463354 24897 net.cpp:100] Creating Layer bn4a_branch1
I0312 16:39:07.463357 24897 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0312 16:39:07.463363 24897 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0312 16:39:07.463531 24897 net.cpp:150] Setting up bn4a_branch1
I0312 16:39:07.463536 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.463538 24897 net.cpp:165] Memory required for data: 176418828
I0312 16:39:07.463543 24897 layer_factory.hpp:77] Creating layer scale4a_branch1
I0312 16:39:07.463548 24897 net.cpp:100] Creating Layer scale4a_branch1
I0312 16:39:07.463563 24897 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0312 16:39:07.463567 24897 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0312 16:39:07.463591 24897 layer_factory.hpp:77] Creating layer scale4a_branch1
I0312 16:39:07.463709 24897 net.cpp:150] Setting up scale4a_branch1
I0312 16:39:07.463714 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.463716 24897 net.cpp:165] Memory required for data: 177221644
I0312 16:39:07.463721 24897 layer_factory.hpp:77] Creating layer res4a_branch2a
I0312 16:39:07.463726 24897 net.cpp:100] Creating Layer res4a_branch2a
I0312 16:39:07.463742 24897 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0312 16:39:07.463747 24897 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0312 16:39:07.463958 24897 net.cpp:150] Setting up res4a_branch2a
I0312 16:39:07.463964 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.463966 24897 net.cpp:165] Memory required for data: 177422348
I0312 16:39:07.463969 24897 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0312 16:39:07.463975 24897 net.cpp:100] Creating Layer bn4a_branch2a
I0312 16:39:07.463977 24897 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0312 16:39:07.463981 24897 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0312 16:39:07.464134 24897 net.cpp:150] Setting up bn4a_branch2a
I0312 16:39:07.464139 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.464143 24897 net.cpp:165] Memory required for data: 177623052
I0312 16:39:07.464148 24897 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0312 16:39:07.464151 24897 net.cpp:100] Creating Layer scale4a_branch2a
I0312 16:39:07.464154 24897 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0312 16:39:07.464159 24897 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0312 16:39:07.464184 24897 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0312 16:39:07.464282 24897 net.cpp:150] Setting up scale4a_branch2a
I0312 16:39:07.464287 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.464301 24897 net.cpp:165] Memory required for data: 177823756
I0312 16:39:07.464305 24897 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0312 16:39:07.464309 24897 net.cpp:100] Creating Layer res4a_branch2a_relu
I0312 16:39:07.464324 24897 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0312 16:39:07.464329 24897 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0312 16:39:07.464334 24897 net.cpp:150] Setting up res4a_branch2a_relu
I0312 16:39:07.464336 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.464339 24897 net.cpp:165] Memory required for data: 178024460
I0312 16:39:07.464341 24897 layer_factory.hpp:77] Creating layer res4a_branch2b
I0312 16:39:07.464345 24897 net.cpp:100] Creating Layer res4a_branch2b
I0312 16:39:07.464349 24897 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0312 16:39:07.464354 24897 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0312 16:39:07.465543 24897 net.cpp:150] Setting up res4a_branch2b
I0312 16:39:07.465556 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.465559 24897 net.cpp:165] Memory required for data: 178225164
I0312 16:39:07.465564 24897 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0312 16:39:07.465571 24897 net.cpp:100] Creating Layer bn4a_branch2b
I0312 16:39:07.465574 24897 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0312 16:39:07.465579 24897 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0312 16:39:07.465742 24897 net.cpp:150] Setting up bn4a_branch2b
I0312 16:39:07.465747 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.465749 24897 net.cpp:165] Memory required for data: 178425868
I0312 16:39:07.465767 24897 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0312 16:39:07.465772 24897 net.cpp:100] Creating Layer scale4a_branch2b
I0312 16:39:07.465775 24897 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0312 16:39:07.465780 24897 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0312 16:39:07.465806 24897 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0312 16:39:07.465919 24897 net.cpp:150] Setting up scale4a_branch2b
I0312 16:39:07.465925 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.465927 24897 net.cpp:165] Memory required for data: 178626572
I0312 16:39:07.465932 24897 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0312 16:39:07.465936 24897 net.cpp:100] Creating Layer res4a_branch2b_relu
I0312 16:39:07.465939 24897 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0312 16:39:07.465943 24897 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0312 16:39:07.465948 24897 net.cpp:150] Setting up res4a_branch2b_relu
I0312 16:39:07.465952 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.465955 24897 net.cpp:165] Memory required for data: 178827276
I0312 16:39:07.465956 24897 layer_factory.hpp:77] Creating layer res4a_branch2c
I0312 16:39:07.465962 24897 net.cpp:100] Creating Layer res4a_branch2c
I0312 16:39:07.465965 24897 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0312 16:39:07.465970 24897 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0312 16:39:07.466939 24897 net.cpp:150] Setting up res4a_branch2c
I0312 16:39:07.466951 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.466954 24897 net.cpp:165] Memory required for data: 179630092
I0312 16:39:07.466958 24897 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0312 16:39:07.466979 24897 net.cpp:100] Creating Layer bn4a_branch2c
I0312 16:39:07.466981 24897 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0312 16:39:07.466986 24897 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0312 16:39:07.467149 24897 net.cpp:150] Setting up bn4a_branch2c
I0312 16:39:07.467154 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467155 24897 net.cpp:165] Memory required for data: 180432908
I0312 16:39:07.467160 24897 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0312 16:39:07.467181 24897 net.cpp:100] Creating Layer scale4a_branch2c
I0312 16:39:07.467183 24897 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0312 16:39:07.467187 24897 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0312 16:39:07.467226 24897 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0312 16:39:07.467315 24897 net.cpp:150] Setting up scale4a_branch2c
I0312 16:39:07.467320 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467322 24897 net.cpp:165] Memory required for data: 181235724
I0312 16:39:07.467326 24897 layer_factory.hpp:77] Creating layer res4a
I0312 16:39:07.467331 24897 net.cpp:100] Creating Layer res4a
I0312 16:39:07.467348 24897 net.cpp:444] res4a <- res4a_branch1
I0312 16:39:07.467351 24897 net.cpp:444] res4a <- res4a_branch2c
I0312 16:39:07.467355 24897 net.cpp:418] res4a -> res4a
I0312 16:39:07.467384 24897 net.cpp:150] Setting up res4a
I0312 16:39:07.467388 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467391 24897 net.cpp:165] Memory required for data: 182038540
I0312 16:39:07.467393 24897 layer_factory.hpp:77] Creating layer res4a_relu
I0312 16:39:07.467397 24897 net.cpp:100] Creating Layer res4a_relu
I0312 16:39:07.467399 24897 net.cpp:444] res4a_relu <- res4a
I0312 16:39:07.467403 24897 net.cpp:405] res4a_relu -> res4a (in-place)
I0312 16:39:07.467408 24897 net.cpp:150] Setting up res4a_relu
I0312 16:39:07.467411 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467413 24897 net.cpp:165] Memory required for data: 182841356
I0312 16:39:07.467416 24897 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0312 16:39:07.467419 24897 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0312 16:39:07.467422 24897 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0312 16:39:07.467425 24897 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0312 16:39:07.467429 24897 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0312 16:39:07.467454 24897 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0312 16:39:07.467458 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467461 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.467463 24897 net.cpp:165] Memory required for data: 184446988
I0312 16:39:07.467466 24897 layer_factory.hpp:77] Creating layer res4b_branch2a
I0312 16:39:07.467478 24897 net.cpp:100] Creating Layer res4b_branch2a
I0312 16:39:07.467480 24897 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0312 16:39:07.467484 24897 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0312 16:39:07.467743 24897 net.cpp:150] Setting up res4b_branch2a
I0312 16:39:07.467749 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.467751 24897 net.cpp:165] Memory required for data: 184647692
I0312 16:39:07.467756 24897 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0312 16:39:07.467759 24897 net.cpp:100] Creating Layer bn4b_branch2a
I0312 16:39:07.467777 24897 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0312 16:39:07.467780 24897 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0312 16:39:07.467933 24897 net.cpp:150] Setting up bn4b_branch2a
I0312 16:39:07.467938 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.467941 24897 net.cpp:165] Memory required for data: 184848396
I0312 16:39:07.467944 24897 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0312 16:39:07.467948 24897 net.cpp:100] Creating Layer scale4b_branch2a
I0312 16:39:07.467967 24897 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0312 16:39:07.467969 24897 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0312 16:39:07.467994 24897 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0312 16:39:07.468104 24897 net.cpp:150] Setting up scale4b_branch2a
I0312 16:39:07.468109 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.468112 24897 net.cpp:165] Memory required for data: 185049100
I0312 16:39:07.468116 24897 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0312 16:39:07.468122 24897 net.cpp:100] Creating Layer res4b_branch2a_relu
I0312 16:39:07.468138 24897 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0312 16:39:07.468142 24897 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0312 16:39:07.468145 24897 net.cpp:150] Setting up res4b_branch2a_relu
I0312 16:39:07.468148 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.468150 24897 net.cpp:165] Memory required for data: 185249804
I0312 16:39:07.468152 24897 layer_factory.hpp:77] Creating layer res4b_branch2b
I0312 16:39:07.468158 24897 net.cpp:100] Creating Layer res4b_branch2b
I0312 16:39:07.468160 24897 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0312 16:39:07.468166 24897 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0312 16:39:07.469393 24897 net.cpp:150] Setting up res4b_branch2b
I0312 16:39:07.469408 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.469409 24897 net.cpp:165] Memory required for data: 185450508
I0312 16:39:07.469415 24897 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0312 16:39:07.469421 24897 net.cpp:100] Creating Layer bn4b_branch2b
I0312 16:39:07.469425 24897 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0312 16:39:07.469431 24897 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0312 16:39:07.469593 24897 net.cpp:150] Setting up bn4b_branch2b
I0312 16:39:07.469597 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.469600 24897 net.cpp:165] Memory required for data: 185651212
I0312 16:39:07.469604 24897 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0312 16:39:07.469610 24897 net.cpp:100] Creating Layer scale4b_branch2b
I0312 16:39:07.469627 24897 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0312 16:39:07.469631 24897 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0312 16:39:07.469671 24897 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0312 16:39:07.469771 24897 net.cpp:150] Setting up scale4b_branch2b
I0312 16:39:07.469777 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.469779 24897 net.cpp:165] Memory required for data: 185851916
I0312 16:39:07.469784 24897 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0312 16:39:07.469787 24897 net.cpp:100] Creating Layer res4b_branch2b_relu
I0312 16:39:07.469805 24897 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0312 16:39:07.469807 24897 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0312 16:39:07.469811 24897 net.cpp:150] Setting up res4b_branch2b_relu
I0312 16:39:07.469815 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.469816 24897 net.cpp:165] Memory required for data: 186052620
I0312 16:39:07.469820 24897 layer_factory.hpp:77] Creating layer res4b_branch2c
I0312 16:39:07.469825 24897 net.cpp:100] Creating Layer res4b_branch2c
I0312 16:39:07.469827 24897 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0312 16:39:07.469832 24897 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0312 16:39:07.470942 24897 net.cpp:150] Setting up res4b_branch2c
I0312 16:39:07.470957 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.470960 24897 net.cpp:165] Memory required for data: 186855436
I0312 16:39:07.470964 24897 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0312 16:39:07.470986 24897 net.cpp:100] Creating Layer bn4b_branch2c
I0312 16:39:07.470990 24897 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0312 16:39:07.470995 24897 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0312 16:39:07.471181 24897 net.cpp:150] Setting up bn4b_branch2c
I0312 16:39:07.471186 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471189 24897 net.cpp:165] Memory required for data: 187658252
I0312 16:39:07.471194 24897 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0312 16:39:07.471199 24897 net.cpp:100] Creating Layer scale4b_branch2c
I0312 16:39:07.471200 24897 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0312 16:39:07.471218 24897 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0312 16:39:07.471244 24897 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0312 16:39:07.471351 24897 net.cpp:150] Setting up scale4b_branch2c
I0312 16:39:07.471356 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471359 24897 net.cpp:165] Memory required for data: 188461068
I0312 16:39:07.471362 24897 layer_factory.hpp:77] Creating layer res4b
I0312 16:39:07.471367 24897 net.cpp:100] Creating Layer res4b
I0312 16:39:07.471369 24897 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0312 16:39:07.471385 24897 net.cpp:444] res4b <- res4b_branch2c
I0312 16:39:07.471391 24897 net.cpp:418] res4b -> res4b
I0312 16:39:07.471406 24897 net.cpp:150] Setting up res4b
I0312 16:39:07.471412 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471415 24897 net.cpp:165] Memory required for data: 189263884
I0312 16:39:07.471416 24897 layer_factory.hpp:77] Creating layer res4b_relu
I0312 16:39:07.471434 24897 net.cpp:100] Creating Layer res4b_relu
I0312 16:39:07.471436 24897 net.cpp:444] res4b_relu <- res4b
I0312 16:39:07.471439 24897 net.cpp:405] res4b_relu -> res4b (in-place)
I0312 16:39:07.471443 24897 net.cpp:150] Setting up res4b_relu
I0312 16:39:07.471446 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471448 24897 net.cpp:165] Memory required for data: 190066700
I0312 16:39:07.471451 24897 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0312 16:39:07.471457 24897 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0312 16:39:07.471459 24897 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0312 16:39:07.471462 24897 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0312 16:39:07.471467 24897 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0312 16:39:07.471491 24897 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0312 16:39:07.471496 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471499 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.471501 24897 net.cpp:165] Memory required for data: 191672332
I0312 16:39:07.471504 24897 layer_factory.hpp:77] Creating layer res4c_branch2a
I0312 16:39:07.471509 24897 net.cpp:100] Creating Layer res4c_branch2a
I0312 16:39:07.471511 24897 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0312 16:39:07.471518 24897 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0312 16:39:07.471799 24897 net.cpp:150] Setting up res4c_branch2a
I0312 16:39:07.471806 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.471807 24897 net.cpp:165] Memory required for data: 191873036
I0312 16:39:07.471812 24897 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0312 16:39:07.471817 24897 net.cpp:100] Creating Layer bn4c_branch2a
I0312 16:39:07.471832 24897 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0312 16:39:07.471835 24897 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0312 16:39:07.471992 24897 net.cpp:150] Setting up bn4c_branch2a
I0312 16:39:07.471997 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.471998 24897 net.cpp:165] Memory required for data: 192073740
I0312 16:39:07.472003 24897 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0312 16:39:07.472007 24897 net.cpp:100] Creating Layer scale4c_branch2a
I0312 16:39:07.472023 24897 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0312 16:39:07.472028 24897 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0312 16:39:07.472069 24897 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0312 16:39:07.472163 24897 net.cpp:150] Setting up scale4c_branch2a
I0312 16:39:07.472168 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.472170 24897 net.cpp:165] Memory required for data: 192274444
I0312 16:39:07.472174 24897 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0312 16:39:07.472178 24897 net.cpp:100] Creating Layer res4c_branch2a_relu
I0312 16:39:07.472182 24897 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0312 16:39:07.472185 24897 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0312 16:39:07.472189 24897 net.cpp:150] Setting up res4c_branch2a_relu
I0312 16:39:07.472193 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.472208 24897 net.cpp:165] Memory required for data: 192475148
I0312 16:39:07.472210 24897 layer_factory.hpp:77] Creating layer res4c_branch2b
I0312 16:39:07.472215 24897 net.cpp:100] Creating Layer res4c_branch2b
I0312 16:39:07.472218 24897 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0312 16:39:07.472223 24897 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0312 16:39:07.473479 24897 net.cpp:150] Setting up res4c_branch2b
I0312 16:39:07.473492 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.473495 24897 net.cpp:165] Memory required for data: 192675852
I0312 16:39:07.473501 24897 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0312 16:39:07.473510 24897 net.cpp:100] Creating Layer bn4c_branch2b
I0312 16:39:07.473512 24897 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0312 16:39:07.473517 24897 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0312 16:39:07.473688 24897 net.cpp:150] Setting up bn4c_branch2b
I0312 16:39:07.473693 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.473696 24897 net.cpp:165] Memory required for data: 192876556
I0312 16:39:07.473701 24897 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0312 16:39:07.473706 24897 net.cpp:100] Creating Layer scale4c_branch2b
I0312 16:39:07.473709 24897 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0312 16:39:07.473713 24897 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0312 16:39:07.473752 24897 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0312 16:39:07.473845 24897 net.cpp:150] Setting up scale4c_branch2b
I0312 16:39:07.473851 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.473855 24897 net.cpp:165] Memory required for data: 193077260
I0312 16:39:07.473858 24897 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0312 16:39:07.473863 24897 net.cpp:100] Creating Layer res4c_branch2b_relu
I0312 16:39:07.473865 24897 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0312 16:39:07.473868 24897 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0312 16:39:07.473872 24897 net.cpp:150] Setting up res4c_branch2b_relu
I0312 16:39:07.473875 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.473901 24897 net.cpp:165] Memory required for data: 193277964
I0312 16:39:07.473903 24897 layer_factory.hpp:77] Creating layer res4c_branch2c
I0312 16:39:07.473911 24897 net.cpp:100] Creating Layer res4c_branch2c
I0312 16:39:07.473913 24897 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0312 16:39:07.473918 24897 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0312 16:39:07.475154 24897 net.cpp:150] Setting up res4c_branch2c
I0312 16:39:07.475178 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475180 24897 net.cpp:165] Memory required for data: 194080780
I0312 16:39:07.475201 24897 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0312 16:39:07.475225 24897 net.cpp:100] Creating Layer bn4c_branch2c
I0312 16:39:07.475230 24897 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0312 16:39:07.475236 24897 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0312 16:39:07.475420 24897 net.cpp:150] Setting up bn4c_branch2c
I0312 16:39:07.475425 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475427 24897 net.cpp:165] Memory required for data: 194883596
I0312 16:39:07.475433 24897 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0312 16:39:07.475455 24897 net.cpp:100] Creating Layer scale4c_branch2c
I0312 16:39:07.475457 24897 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0312 16:39:07.475461 24897 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0312 16:39:07.475500 24897 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0312 16:39:07.475582 24897 net.cpp:150] Setting up scale4c_branch2c
I0312 16:39:07.475589 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475590 24897 net.cpp:165] Memory required for data: 195686412
I0312 16:39:07.475594 24897 layer_factory.hpp:77] Creating layer res4c
I0312 16:39:07.475600 24897 net.cpp:100] Creating Layer res4c
I0312 16:39:07.475601 24897 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0312 16:39:07.475605 24897 net.cpp:444] res4c <- res4c_branch2c
I0312 16:39:07.475610 24897 net.cpp:418] res4c -> res4c
I0312 16:39:07.475627 24897 net.cpp:150] Setting up res4c
I0312 16:39:07.475632 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475636 24897 net.cpp:165] Memory required for data: 196489228
I0312 16:39:07.475637 24897 layer_factory.hpp:77] Creating layer res4c_relu
I0312 16:39:07.475641 24897 net.cpp:100] Creating Layer res4c_relu
I0312 16:39:07.475644 24897 net.cpp:444] res4c_relu <- res4c
I0312 16:39:07.475647 24897 net.cpp:405] res4c_relu -> res4c (in-place)
I0312 16:39:07.475656 24897 net.cpp:150] Setting up res4c_relu
I0312 16:39:07.475659 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475661 24897 net.cpp:165] Memory required for data: 197292044
I0312 16:39:07.475663 24897 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0312 16:39:07.475667 24897 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0312 16:39:07.475670 24897 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0312 16:39:07.475673 24897 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0312 16:39:07.475678 24897 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0312 16:39:07.475705 24897 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0312 16:39:07.475709 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475713 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.475714 24897 net.cpp:165] Memory required for data: 198897676
I0312 16:39:07.475716 24897 layer_factory.hpp:77] Creating layer res4d_branch2a
I0312 16:39:07.475723 24897 net.cpp:100] Creating Layer res4d_branch2a
I0312 16:39:07.475725 24897 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0312 16:39:07.475729 24897 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0312 16:39:07.475993 24897 net.cpp:150] Setting up res4d_branch2a
I0312 16:39:07.475999 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.476001 24897 net.cpp:165] Memory required for data: 199098380
I0312 16:39:07.476004 24897 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0312 16:39:07.476011 24897 net.cpp:100] Creating Layer bn4d_branch2a
I0312 16:39:07.476028 24897 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0312 16:39:07.476032 24897 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0312 16:39:07.476184 24897 net.cpp:150] Setting up bn4d_branch2a
I0312 16:39:07.476189 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.476191 24897 net.cpp:165] Memory required for data: 199299084
I0312 16:39:07.476197 24897 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0312 16:39:07.476200 24897 net.cpp:100] Creating Layer scale4d_branch2a
I0312 16:39:07.476217 24897 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0312 16:39:07.476222 24897 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0312 16:39:07.476261 24897 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0312 16:39:07.476336 24897 net.cpp:150] Setting up scale4d_branch2a
I0312 16:39:07.476354 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.476356 24897 net.cpp:165] Memory required for data: 199499788
I0312 16:39:07.476361 24897 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0312 16:39:07.476363 24897 net.cpp:100] Creating Layer res4d_branch2a_relu
I0312 16:39:07.476366 24897 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0312 16:39:07.476385 24897 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0312 16:39:07.476389 24897 net.cpp:150] Setting up res4d_branch2a_relu
I0312 16:39:07.476405 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.476408 24897 net.cpp:165] Memory required for data: 199700492
I0312 16:39:07.476409 24897 layer_factory.hpp:77] Creating layer res4d_branch2b
I0312 16:39:07.476415 24897 net.cpp:100] Creating Layer res4d_branch2b
I0312 16:39:07.476418 24897 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0312 16:39:07.476421 24897 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0312 16:39:07.477579 24897 net.cpp:150] Setting up res4d_branch2b
I0312 16:39:07.477592 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.477594 24897 net.cpp:165] Memory required for data: 199901196
I0312 16:39:07.477599 24897 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0312 16:39:07.477607 24897 net.cpp:100] Creating Layer bn4d_branch2b
I0312 16:39:07.477624 24897 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0312 16:39:07.477628 24897 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0312 16:39:07.477794 24897 net.cpp:150] Setting up bn4d_branch2b
I0312 16:39:07.477799 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.477802 24897 net.cpp:165] Memory required for data: 200101900
I0312 16:39:07.477807 24897 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0312 16:39:07.477828 24897 net.cpp:100] Creating Layer scale4d_branch2b
I0312 16:39:07.477829 24897 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0312 16:39:07.477833 24897 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0312 16:39:07.477874 24897 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0312 16:39:07.477990 24897 net.cpp:150] Setting up scale4d_branch2b
I0312 16:39:07.477996 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.477998 24897 net.cpp:165] Memory required for data: 200302604
I0312 16:39:07.478003 24897 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0312 16:39:07.478006 24897 net.cpp:100] Creating Layer res4d_branch2b_relu
I0312 16:39:07.478024 24897 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0312 16:39:07.478027 24897 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0312 16:39:07.478045 24897 net.cpp:150] Setting up res4d_branch2b_relu
I0312 16:39:07.478049 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.478050 24897 net.cpp:165] Memory required for data: 200503308
I0312 16:39:07.478052 24897 layer_factory.hpp:77] Creating layer res4d_branch2c
I0312 16:39:07.478058 24897 net.cpp:100] Creating Layer res4d_branch2c
I0312 16:39:07.478061 24897 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0312 16:39:07.478065 24897 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0312 16:39:07.479027 24897 net.cpp:150] Setting up res4d_branch2c
I0312 16:39:07.479038 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479040 24897 net.cpp:165] Memory required for data: 201306124
I0312 16:39:07.479045 24897 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0312 16:39:07.479064 24897 net.cpp:100] Creating Layer bn4d_branch2c
I0312 16:39:07.479068 24897 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0312 16:39:07.479073 24897 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0312 16:39:07.479240 24897 net.cpp:150] Setting up bn4d_branch2c
I0312 16:39:07.479245 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479248 24897 net.cpp:165] Memory required for data: 202108940
I0312 16:39:07.479254 24897 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0312 16:39:07.479274 24897 net.cpp:100] Creating Layer scale4d_branch2c
I0312 16:39:07.479276 24897 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0312 16:39:07.479279 24897 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0312 16:39:07.479320 24897 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0312 16:39:07.479414 24897 net.cpp:150] Setting up scale4d_branch2c
I0312 16:39:07.479419 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479421 24897 net.cpp:165] Memory required for data: 202911756
I0312 16:39:07.479425 24897 layer_factory.hpp:77] Creating layer res4d
I0312 16:39:07.479430 24897 net.cpp:100] Creating Layer res4d
I0312 16:39:07.479446 24897 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0312 16:39:07.479449 24897 net.cpp:444] res4d <- res4d_branch2c
I0312 16:39:07.479454 24897 net.cpp:418] res4d -> res4d
I0312 16:39:07.479483 24897 net.cpp:150] Setting up res4d
I0312 16:39:07.479487 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479490 24897 net.cpp:165] Memory required for data: 203714572
I0312 16:39:07.479492 24897 layer_factory.hpp:77] Creating layer res4d_relu
I0312 16:39:07.479496 24897 net.cpp:100] Creating Layer res4d_relu
I0312 16:39:07.479498 24897 net.cpp:444] res4d_relu <- res4d
I0312 16:39:07.479502 24897 net.cpp:405] res4d_relu -> res4d (in-place)
I0312 16:39:07.479507 24897 net.cpp:150] Setting up res4d_relu
I0312 16:39:07.479511 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479512 24897 net.cpp:165] Memory required for data: 204517388
I0312 16:39:07.479514 24897 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0312 16:39:07.479518 24897 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0312 16:39:07.479521 24897 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0312 16:39:07.479524 24897 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0312 16:39:07.479528 24897 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0312 16:39:07.479554 24897 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0312 16:39:07.479558 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479562 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.479563 24897 net.cpp:165] Memory required for data: 206123020
I0312 16:39:07.479565 24897 layer_factory.hpp:77] Creating layer res4e_branch2a
I0312 16:39:07.479573 24897 net.cpp:100] Creating Layer res4e_branch2a
I0312 16:39:07.479574 24897 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0312 16:39:07.479578 24897 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0312 16:39:07.479846 24897 net.cpp:150] Setting up res4e_branch2a
I0312 16:39:07.479851 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.479853 24897 net.cpp:165] Memory required for data: 206323724
I0312 16:39:07.479857 24897 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0312 16:39:07.479861 24897 net.cpp:100] Creating Layer bn4e_branch2a
I0312 16:39:07.479863 24897 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0312 16:39:07.479879 24897 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0312 16:39:07.480036 24897 net.cpp:150] Setting up bn4e_branch2a
I0312 16:39:07.480041 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.480042 24897 net.cpp:165] Memory required for data: 206524428
I0312 16:39:07.480047 24897 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0312 16:39:07.480052 24897 net.cpp:100] Creating Layer scale4e_branch2a
I0312 16:39:07.480067 24897 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0312 16:39:07.480072 24897 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0312 16:39:07.480098 24897 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0312 16:39:07.480213 24897 net.cpp:150] Setting up scale4e_branch2a
I0312 16:39:07.480218 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.480221 24897 net.cpp:165] Memory required for data: 206725132
I0312 16:39:07.480224 24897 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0312 16:39:07.480228 24897 net.cpp:100] Creating Layer res4e_branch2a_relu
I0312 16:39:07.480244 24897 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0312 16:39:07.480247 24897 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0312 16:39:07.480252 24897 net.cpp:150] Setting up res4e_branch2a_relu
I0312 16:39:07.480254 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.480257 24897 net.cpp:165] Memory required for data: 206925836
I0312 16:39:07.480259 24897 layer_factory.hpp:77] Creating layer res4e_branch2b
I0312 16:39:07.480264 24897 net.cpp:100] Creating Layer res4e_branch2b
I0312 16:39:07.480268 24897 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0312 16:39:07.480273 24897 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0312 16:39:07.481499 24897 net.cpp:150] Setting up res4e_branch2b
I0312 16:39:07.481513 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.481514 24897 net.cpp:165] Memory required for data: 207126540
I0312 16:39:07.481519 24897 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0312 16:39:07.481525 24897 net.cpp:100] Creating Layer bn4e_branch2b
I0312 16:39:07.481528 24897 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0312 16:39:07.481532 24897 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0312 16:39:07.481672 24897 net.cpp:150] Setting up bn4e_branch2b
I0312 16:39:07.481676 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.481678 24897 net.cpp:165] Memory required for data: 207327244
I0312 16:39:07.481683 24897 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0312 16:39:07.481690 24897 net.cpp:100] Creating Layer scale4e_branch2b
I0312 16:39:07.481705 24897 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0312 16:39:07.481709 24897 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0312 16:39:07.481735 24897 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0312 16:39:07.481829 24897 net.cpp:150] Setting up scale4e_branch2b
I0312 16:39:07.481834 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.481837 24897 net.cpp:165] Memory required for data: 207527948
I0312 16:39:07.481840 24897 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0312 16:39:07.481847 24897 net.cpp:100] Creating Layer res4e_branch2b_relu
I0312 16:39:07.481849 24897 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0312 16:39:07.481853 24897 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0312 16:39:07.481856 24897 net.cpp:150] Setting up res4e_branch2b_relu
I0312 16:39:07.481873 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.481875 24897 net.cpp:165] Memory required for data: 207728652
I0312 16:39:07.481878 24897 layer_factory.hpp:77] Creating layer res4e_branch2c
I0312 16:39:07.481884 24897 net.cpp:100] Creating Layer res4e_branch2c
I0312 16:39:07.481886 24897 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0312 16:39:07.481902 24897 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0312 16:39:07.482884 24897 net.cpp:150] Setting up res4e_branch2c
I0312 16:39:07.482897 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.482899 24897 net.cpp:165] Memory required for data: 208531468
I0312 16:39:07.482903 24897 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0312 16:39:07.482909 24897 net.cpp:100] Creating Layer bn4e_branch2c
I0312 16:39:07.482926 24897 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0312 16:39:07.482933 24897 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0312 16:39:07.483104 24897 net.cpp:150] Setting up bn4e_branch2c
I0312 16:39:07.483109 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483111 24897 net.cpp:165] Memory required for data: 209334284
I0312 16:39:07.483116 24897 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0312 16:39:07.483121 24897 net.cpp:100] Creating Layer scale4e_branch2c
I0312 16:39:07.483139 24897 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0312 16:39:07.483142 24897 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0312 16:39:07.483181 24897 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0312 16:39:07.483260 24897 net.cpp:150] Setting up scale4e_branch2c
I0312 16:39:07.483265 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483268 24897 net.cpp:165] Memory required for data: 210137100
I0312 16:39:07.483284 24897 layer_factory.hpp:77] Creating layer res4e
I0312 16:39:07.483289 24897 net.cpp:100] Creating Layer res4e
I0312 16:39:07.483307 24897 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0312 16:39:07.483311 24897 net.cpp:444] res4e <- res4e_branch2c
I0312 16:39:07.483315 24897 net.cpp:418] res4e -> res4e
I0312 16:39:07.483343 24897 net.cpp:150] Setting up res4e
I0312 16:39:07.483347 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483350 24897 net.cpp:165] Memory required for data: 210939916
I0312 16:39:07.483352 24897 layer_factory.hpp:77] Creating layer res4e_relu
I0312 16:39:07.483357 24897 net.cpp:100] Creating Layer res4e_relu
I0312 16:39:07.483361 24897 net.cpp:444] res4e_relu <- res4e
I0312 16:39:07.483363 24897 net.cpp:405] res4e_relu -> res4e (in-place)
I0312 16:39:07.483367 24897 net.cpp:150] Setting up res4e_relu
I0312 16:39:07.483371 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483373 24897 net.cpp:165] Memory required for data: 211742732
I0312 16:39:07.483376 24897 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0312 16:39:07.483379 24897 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0312 16:39:07.483381 24897 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0312 16:39:07.483384 24897 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0312 16:39:07.483391 24897 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0312 16:39:07.483414 24897 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0312 16:39:07.483418 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483422 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.483423 24897 net.cpp:165] Memory required for data: 213348364
I0312 16:39:07.483427 24897 layer_factory.hpp:77] Creating layer res4f_branch2a
I0312 16:39:07.483433 24897 net.cpp:100] Creating Layer res4f_branch2a
I0312 16:39:07.483435 24897 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0312 16:39:07.483439 24897 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0312 16:39:07.483702 24897 net.cpp:150] Setting up res4f_branch2a
I0312 16:39:07.483707 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.483709 24897 net.cpp:165] Memory required for data: 213549068
I0312 16:39:07.483713 24897 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0312 16:39:07.483717 24897 net.cpp:100] Creating Layer bn4f_branch2a
I0312 16:39:07.483734 24897 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0312 16:39:07.483739 24897 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0312 16:39:07.483897 24897 net.cpp:150] Setting up bn4f_branch2a
I0312 16:39:07.483902 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.483904 24897 net.cpp:165] Memory required for data: 213749772
I0312 16:39:07.483909 24897 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0312 16:39:07.483913 24897 net.cpp:100] Creating Layer scale4f_branch2a
I0312 16:39:07.483930 24897 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0312 16:39:07.483934 24897 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0312 16:39:07.483959 24897 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0312 16:39:07.484064 24897 net.cpp:150] Setting up scale4f_branch2a
I0312 16:39:07.484069 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.484072 24897 net.cpp:165] Memory required for data: 213950476
I0312 16:39:07.484076 24897 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0312 16:39:07.484079 24897 net.cpp:100] Creating Layer res4f_branch2a_relu
I0312 16:39:07.484082 24897 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0312 16:39:07.484102 24897 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0312 16:39:07.484107 24897 net.cpp:150] Setting up res4f_branch2a_relu
I0312 16:39:07.484109 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.484112 24897 net.cpp:165] Memory required for data: 214151180
I0312 16:39:07.484113 24897 layer_factory.hpp:77] Creating layer res4f_branch2b
I0312 16:39:07.484118 24897 net.cpp:100] Creating Layer res4f_branch2b
I0312 16:39:07.484120 24897 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0312 16:39:07.484125 24897 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0312 16:39:07.485347 24897 net.cpp:150] Setting up res4f_branch2b
I0312 16:39:07.485363 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.485365 24897 net.cpp:165] Memory required for data: 214351884
I0312 16:39:07.485388 24897 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0312 16:39:07.485399 24897 net.cpp:100] Creating Layer bn4f_branch2b
I0312 16:39:07.485405 24897 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0312 16:39:07.485426 24897 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0312 16:39:07.485591 24897 net.cpp:150] Setting up bn4f_branch2b
I0312 16:39:07.485599 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.485600 24897 net.cpp:165] Memory required for data: 214552588
I0312 16:39:07.485606 24897 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0312 16:39:07.485613 24897 net.cpp:100] Creating Layer scale4f_branch2b
I0312 16:39:07.485615 24897 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0312 16:39:07.485620 24897 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0312 16:39:07.485651 24897 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0312 16:39:07.485793 24897 net.cpp:150] Setting up scale4f_branch2b
I0312 16:39:07.485798 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.485800 24897 net.cpp:165] Memory required for data: 214753292
I0312 16:39:07.485805 24897 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0312 16:39:07.485810 24897 net.cpp:100] Creating Layer res4f_branch2b_relu
I0312 16:39:07.485813 24897 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0312 16:39:07.485832 24897 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0312 16:39:07.485837 24897 net.cpp:150] Setting up res4f_branch2b_relu
I0312 16:39:07.485841 24897 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0312 16:39:07.485843 24897 net.cpp:165] Memory required for data: 214953996
I0312 16:39:07.485846 24897 layer_factory.hpp:77] Creating layer res4f_branch2c
I0312 16:39:07.485854 24897 net.cpp:100] Creating Layer res4f_branch2c
I0312 16:39:07.485858 24897 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0312 16:39:07.485862 24897 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0312 16:39:07.487181 24897 net.cpp:150] Setting up res4f_branch2c
I0312 16:39:07.487195 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487198 24897 net.cpp:165] Memory required for data: 215756812
I0312 16:39:07.487224 24897 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0312 16:39:07.487246 24897 net.cpp:100] Creating Layer bn4f_branch2c
I0312 16:39:07.487249 24897 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0312 16:39:07.487254 24897 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0312 16:39:07.487426 24897 net.cpp:150] Setting up bn4f_branch2c
I0312 16:39:07.487431 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487432 24897 net.cpp:165] Memory required for data: 216559628
I0312 16:39:07.487449 24897 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0312 16:39:07.487455 24897 net.cpp:100] Creating Layer scale4f_branch2c
I0312 16:39:07.487458 24897 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0312 16:39:07.487462 24897 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0312 16:39:07.487510 24897 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0312 16:39:07.487591 24897 net.cpp:150] Setting up scale4f_branch2c
I0312 16:39:07.487597 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487599 24897 net.cpp:165] Memory required for data: 217362444
I0312 16:39:07.487604 24897 layer_factory.hpp:77] Creating layer res4f
I0312 16:39:07.487608 24897 net.cpp:100] Creating Layer res4f
I0312 16:39:07.487612 24897 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0312 16:39:07.487614 24897 net.cpp:444] res4f <- res4f_branch2c
I0312 16:39:07.487618 24897 net.cpp:418] res4f -> res4f
I0312 16:39:07.487649 24897 net.cpp:150] Setting up res4f
I0312 16:39:07.487653 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487655 24897 net.cpp:165] Memory required for data: 218165260
I0312 16:39:07.487658 24897 layer_factory.hpp:77] Creating layer res4f_relu
I0312 16:39:07.487664 24897 net.cpp:100] Creating Layer res4f_relu
I0312 16:39:07.487668 24897 net.cpp:444] res4f_relu <- res4f
I0312 16:39:07.487670 24897 net.cpp:405] res4f_relu -> res4f (in-place)
I0312 16:39:07.487674 24897 net.cpp:150] Setting up res4f_relu
I0312 16:39:07.487677 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487679 24897 net.cpp:165] Memory required for data: 218968076
I0312 16:39:07.487681 24897 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0312 16:39:07.487686 24897 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0312 16:39:07.487689 24897 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0312 16:39:07.487694 24897 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0312 16:39:07.487697 24897 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0312 16:39:07.487704 24897 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0312 16:39:07.487736 24897 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0312 16:39:07.487740 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487743 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487746 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.487748 24897 net.cpp:165] Memory required for data: 221376524
I0312 16:39:07.487751 24897 layer_factory.hpp:77] Creating layer res5a_branch1
I0312 16:39:07.487756 24897 net.cpp:100] Creating Layer res5a_branch1
I0312 16:39:07.487759 24897 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0312 16:39:07.487764 24897 net.cpp:418] res5a_branch1 -> res5a_branch1
I0312 16:39:07.493077 24897 net.cpp:150] Setting up res5a_branch1
I0312 16:39:07.493130 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.493134 24897 net.cpp:165] Memory required for data: 222982156
I0312 16:39:07.493155 24897 layer_factory.hpp:77] Creating layer bn5a_branch1
I0312 16:39:07.493170 24897 net.cpp:100] Creating Layer bn5a_branch1
I0312 16:39:07.493175 24897 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0312 16:39:07.493180 24897 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0312 16:39:07.493387 24897 net.cpp:150] Setting up bn5a_branch1
I0312 16:39:07.493393 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.493396 24897 net.cpp:165] Memory required for data: 224587788
I0312 16:39:07.493413 24897 layer_factory.hpp:77] Creating layer scale5a_branch1
I0312 16:39:07.493420 24897 net.cpp:100] Creating Layer scale5a_branch1
I0312 16:39:07.493423 24897 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0312 16:39:07.493427 24897 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0312 16:39:07.493459 24897 layer_factory.hpp:77] Creating layer scale5a_branch1
I0312 16:39:07.493546 24897 net.cpp:150] Setting up scale5a_branch1
I0312 16:39:07.493551 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.493553 24897 net.cpp:165] Memory required for data: 226193420
I0312 16:39:07.493557 24897 layer_factory.hpp:77] Creating layer res5a_branch2a
I0312 16:39:07.493572 24897 net.cpp:100] Creating Layer res5a_branch2a
I0312 16:39:07.493576 24897 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0312 16:39:07.493580 24897 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0312 16:39:07.494973 24897 net.cpp:150] Setting up res5a_branch2a
I0312 16:39:07.495021 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.495025 24897 net.cpp:165] Memory required for data: 226594828
I0312 16:39:07.495038 24897 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0312 16:39:07.495055 24897 net.cpp:100] Creating Layer bn5a_branch2a
I0312 16:39:07.495074 24897 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0312 16:39:07.495080 24897 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0312 16:39:07.495271 24897 net.cpp:150] Setting up bn5a_branch2a
I0312 16:39:07.495290 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.495292 24897 net.cpp:165] Memory required for data: 226996236
I0312 16:39:07.495297 24897 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0312 16:39:07.495321 24897 net.cpp:100] Creating Layer scale5a_branch2a
I0312 16:39:07.495337 24897 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0312 16:39:07.495342 24897 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0312 16:39:07.495370 24897 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0312 16:39:07.495458 24897 net.cpp:150] Setting up scale5a_branch2a
I0312 16:39:07.495466 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.495468 24897 net.cpp:165] Memory required for data: 227397644
I0312 16:39:07.495472 24897 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0312 16:39:07.495478 24897 net.cpp:100] Creating Layer res5a_branch2a_relu
I0312 16:39:07.495482 24897 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0312 16:39:07.495498 24897 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0312 16:39:07.495503 24897 net.cpp:150] Setting up res5a_branch2a_relu
I0312 16:39:07.495522 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.495523 24897 net.cpp:165] Memory required for data: 227799052
I0312 16:39:07.495525 24897 layer_factory.hpp:77] Creating layer res5a_branch2b
I0312 16:39:07.495533 24897 net.cpp:100] Creating Layer res5a_branch2b
I0312 16:39:07.495537 24897 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0312 16:39:07.495543 24897 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0312 16:39:07.500632 24897 net.cpp:150] Setting up res5a_branch2b
I0312 16:39:07.500660 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.500663 24897 net.cpp:165] Memory required for data: 228200460
I0312 16:39:07.500672 24897 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0312 16:39:07.500684 24897 net.cpp:100] Creating Layer bn5a_branch2b
I0312 16:39:07.500689 24897 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0312 16:39:07.500696 24897 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0312 16:39:07.500870 24897 net.cpp:150] Setting up bn5a_branch2b
I0312 16:39:07.500875 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.500877 24897 net.cpp:165] Memory required for data: 228601868
I0312 16:39:07.500882 24897 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0312 16:39:07.500888 24897 net.cpp:100] Creating Layer scale5a_branch2b
I0312 16:39:07.500891 24897 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0312 16:39:07.500902 24897 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0312 16:39:07.500931 24897 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0312 16:39:07.501018 24897 net.cpp:150] Setting up scale5a_branch2b
I0312 16:39:07.501024 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.501026 24897 net.cpp:165] Memory required for data: 229003276
I0312 16:39:07.501030 24897 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0312 16:39:07.501034 24897 net.cpp:100] Creating Layer res5a_branch2b_relu
I0312 16:39:07.501039 24897 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0312 16:39:07.501042 24897 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0312 16:39:07.501046 24897 net.cpp:150] Setting up res5a_branch2b_relu
I0312 16:39:07.501050 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.501052 24897 net.cpp:165] Memory required for data: 229404684
I0312 16:39:07.501055 24897 layer_factory.hpp:77] Creating layer res5a_branch2c
I0312 16:39:07.501062 24897 net.cpp:100] Creating Layer res5a_branch2c
I0312 16:39:07.501066 24897 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0312 16:39:07.501071 24897 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0312 16:39:07.502929 24897 net.cpp:150] Setting up res5a_branch2c
I0312 16:39:07.502950 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.502954 24897 net.cpp:165] Memory required for data: 231010316
I0312 16:39:07.502959 24897 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0312 16:39:07.502967 24897 net.cpp:100] Creating Layer bn5a_branch2c
I0312 16:39:07.502971 24897 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0312 16:39:07.502979 24897 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0312 16:39:07.503145 24897 net.cpp:150] Setting up bn5a_branch2c
I0312 16:39:07.503151 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503154 24897 net.cpp:165] Memory required for data: 232615948
I0312 16:39:07.503159 24897 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0312 16:39:07.503165 24897 net.cpp:100] Creating Layer scale5a_branch2c
I0312 16:39:07.503167 24897 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0312 16:39:07.503171 24897 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0312 16:39:07.503199 24897 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0312 16:39:07.503288 24897 net.cpp:150] Setting up scale5a_branch2c
I0312 16:39:07.503293 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503296 24897 net.cpp:165] Memory required for data: 234221580
I0312 16:39:07.503300 24897 layer_factory.hpp:77] Creating layer res5a
I0312 16:39:07.503304 24897 net.cpp:100] Creating Layer res5a
I0312 16:39:07.503307 24897 net.cpp:444] res5a <- res5a_branch1
I0312 16:39:07.503310 24897 net.cpp:444] res5a <- res5a_branch2c
I0312 16:39:07.503315 24897 net.cpp:418] res5a -> res5a
I0312 16:39:07.503334 24897 net.cpp:150] Setting up res5a
I0312 16:39:07.503338 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503340 24897 net.cpp:165] Memory required for data: 235827212
I0312 16:39:07.503343 24897 layer_factory.hpp:77] Creating layer res5a_relu
I0312 16:39:07.503347 24897 net.cpp:100] Creating Layer res5a_relu
I0312 16:39:07.503351 24897 net.cpp:444] res5a_relu <- res5a
I0312 16:39:07.503355 24897 net.cpp:405] res5a_relu -> res5a (in-place)
I0312 16:39:07.503360 24897 net.cpp:150] Setting up res5a_relu
I0312 16:39:07.503362 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503365 24897 net.cpp:165] Memory required for data: 237432844
I0312 16:39:07.503367 24897 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0312 16:39:07.503371 24897 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0312 16:39:07.503373 24897 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0312 16:39:07.503376 24897 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0312 16:39:07.503382 24897 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0312 16:39:07.503409 24897 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0312 16:39:07.503414 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503417 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.503419 24897 net.cpp:165] Memory required for data: 240644108
I0312 16:39:07.503422 24897 layer_factory.hpp:77] Creating layer res5b_branch2a
I0312 16:39:07.503427 24897 net.cpp:100] Creating Layer res5b_branch2a
I0312 16:39:07.503432 24897 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0312 16:39:07.503437 24897 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0312 16:39:07.505338 24897 net.cpp:150] Setting up res5b_branch2a
I0312 16:39:07.505360 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.505362 24897 net.cpp:165] Memory required for data: 241045516
I0312 16:39:07.505368 24897 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0312 16:39:07.505395 24897 net.cpp:100] Creating Layer bn5b_branch2a
I0312 16:39:07.505399 24897 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0312 16:39:07.505406 24897 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0312 16:39:07.505595 24897 net.cpp:150] Setting up bn5b_branch2a
I0312 16:39:07.505600 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.505602 24897 net.cpp:165] Memory required for data: 241446924
I0312 16:39:07.505607 24897 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0312 16:39:07.505625 24897 net.cpp:100] Creating Layer scale5b_branch2a
I0312 16:39:07.505628 24897 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0312 16:39:07.505632 24897 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0312 16:39:07.505662 24897 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0312 16:39:07.505766 24897 net.cpp:150] Setting up scale5b_branch2a
I0312 16:39:07.505785 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.505789 24897 net.cpp:165] Memory required for data: 241848332
I0312 16:39:07.505792 24897 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0312 16:39:07.505797 24897 net.cpp:100] Creating Layer res5b_branch2a_relu
I0312 16:39:07.505801 24897 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0312 16:39:07.505805 24897 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0312 16:39:07.505810 24897 net.cpp:150] Setting up res5b_branch2a_relu
I0312 16:39:07.505828 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.505831 24897 net.cpp:165] Memory required for data: 242249740
I0312 16:39:07.505832 24897 layer_factory.hpp:77] Creating layer res5b_branch2b
I0312 16:39:07.505838 24897 net.cpp:100] Creating Layer res5b_branch2b
I0312 16:39:07.505841 24897 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0312 16:39:07.505847 24897 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0312 16:39:07.511224 24897 net.cpp:150] Setting up res5b_branch2b
I0312 16:39:07.511317 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.511320 24897 net.cpp:165] Memory required for data: 242651148
I0312 16:39:07.511337 24897 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0312 16:39:07.511358 24897 net.cpp:100] Creating Layer bn5b_branch2b
I0312 16:39:07.511365 24897 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0312 16:39:07.511379 24897 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0312 16:39:07.511660 24897 net.cpp:150] Setting up bn5b_branch2b
I0312 16:39:07.511667 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.511669 24897 net.cpp:165] Memory required for data: 243052556
I0312 16:39:07.511675 24897 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0312 16:39:07.511683 24897 net.cpp:100] Creating Layer scale5b_branch2b
I0312 16:39:07.511685 24897 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0312 16:39:07.511688 24897 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0312 16:39:07.511723 24897 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0312 16:39:07.511816 24897 net.cpp:150] Setting up scale5b_branch2b
I0312 16:39:07.511821 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.511823 24897 net.cpp:165] Memory required for data: 243453964
I0312 16:39:07.511828 24897 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0312 16:39:07.511834 24897 net.cpp:100] Creating Layer res5b_branch2b_relu
I0312 16:39:07.511837 24897 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0312 16:39:07.511842 24897 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0312 16:39:07.511847 24897 net.cpp:150] Setting up res5b_branch2b_relu
I0312 16:39:07.511850 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.511852 24897 net.cpp:165] Memory required for data: 243855372
I0312 16:39:07.511854 24897 layer_factory.hpp:77] Creating layer res5b_branch2c
I0312 16:39:07.511864 24897 net.cpp:100] Creating Layer res5b_branch2c
I0312 16:39:07.511868 24897 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0312 16:39:07.511873 24897 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0312 16:39:07.514082 24897 net.cpp:150] Setting up res5b_branch2c
I0312 16:39:07.514120 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514124 24897 net.cpp:165] Memory required for data: 245461004
I0312 16:39:07.514135 24897 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0312 16:39:07.514150 24897 net.cpp:100] Creating Layer bn5b_branch2c
I0312 16:39:07.514156 24897 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0312 16:39:07.514164 24897 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0312 16:39:07.514344 24897 net.cpp:150] Setting up bn5b_branch2c
I0312 16:39:07.514350 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514353 24897 net.cpp:165] Memory required for data: 247066636
I0312 16:39:07.514358 24897 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0312 16:39:07.514364 24897 net.cpp:100] Creating Layer scale5b_branch2c
I0312 16:39:07.514369 24897 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0312 16:39:07.514374 24897 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0312 16:39:07.514405 24897 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0312 16:39:07.514497 24897 net.cpp:150] Setting up scale5b_branch2c
I0312 16:39:07.514503 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514506 24897 net.cpp:165] Memory required for data: 248672268
I0312 16:39:07.514510 24897 layer_factory.hpp:77] Creating layer res5b
I0312 16:39:07.514516 24897 net.cpp:100] Creating Layer res5b
I0312 16:39:07.514520 24897 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0312 16:39:07.514523 24897 net.cpp:444] res5b <- res5b_branch2c
I0312 16:39:07.514529 24897 net.cpp:418] res5b -> res5b
I0312 16:39:07.514549 24897 net.cpp:150] Setting up res5b
I0312 16:39:07.514554 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514556 24897 net.cpp:165] Memory required for data: 250277900
I0312 16:39:07.514559 24897 layer_factory.hpp:77] Creating layer res5b_relu
I0312 16:39:07.514564 24897 net.cpp:100] Creating Layer res5b_relu
I0312 16:39:07.514569 24897 net.cpp:444] res5b_relu <- res5b
I0312 16:39:07.514572 24897 net.cpp:405] res5b_relu -> res5b (in-place)
I0312 16:39:07.514576 24897 net.cpp:150] Setting up res5b_relu
I0312 16:39:07.514581 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514583 24897 net.cpp:165] Memory required for data: 251883532
I0312 16:39:07.514585 24897 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0312 16:39:07.514590 24897 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0312 16:39:07.514592 24897 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0312 16:39:07.514597 24897 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0312 16:39:07.514603 24897 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0312 16:39:07.514632 24897 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0312 16:39:07.514637 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514641 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.514642 24897 net.cpp:165] Memory required for data: 255094796
I0312 16:39:07.514645 24897 layer_factory.hpp:77] Creating layer res5c_branch2a
I0312 16:39:07.514652 24897 net.cpp:100] Creating Layer res5c_branch2a
I0312 16:39:07.514655 24897 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0312 16:39:07.514659 24897 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0312 16:39:07.516789 24897 net.cpp:150] Setting up res5c_branch2a
I0312 16:39:07.516834 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.516836 24897 net.cpp:165] Memory required for data: 255496204
I0312 16:39:07.516849 24897 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0312 16:39:07.516863 24897 net.cpp:100] Creating Layer bn5c_branch2a
I0312 16:39:07.516870 24897 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0312 16:39:07.516876 24897 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0312 16:39:07.517058 24897 net.cpp:150] Setting up bn5c_branch2a
I0312 16:39:07.517065 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.517066 24897 net.cpp:165] Memory required for data: 255897612
I0312 16:39:07.517071 24897 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0312 16:39:07.517078 24897 net.cpp:100] Creating Layer scale5c_branch2a
I0312 16:39:07.517082 24897 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0312 16:39:07.517086 24897 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0312 16:39:07.517119 24897 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0312 16:39:07.517216 24897 net.cpp:150] Setting up scale5c_branch2a
I0312 16:39:07.517222 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.517225 24897 net.cpp:165] Memory required for data: 256299020
I0312 16:39:07.517228 24897 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0312 16:39:07.517236 24897 net.cpp:100] Creating Layer res5c_branch2a_relu
I0312 16:39:07.517241 24897 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0312 16:39:07.517243 24897 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0312 16:39:07.517248 24897 net.cpp:150] Setting up res5c_branch2a_relu
I0312 16:39:07.517251 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.517254 24897 net.cpp:165] Memory required for data: 256700428
I0312 16:39:07.517256 24897 layer_factory.hpp:77] Creating layer res5c_branch2b
I0312 16:39:07.517264 24897 net.cpp:100] Creating Layer res5c_branch2b
I0312 16:39:07.517267 24897 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0312 16:39:07.517271 24897 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0312 16:39:07.523362 24897 net.cpp:150] Setting up res5c_branch2b
I0312 16:39:07.523402 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.523406 24897 net.cpp:165] Memory required for data: 257101836
I0312 16:39:07.523416 24897 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0312 16:39:07.523432 24897 net.cpp:100] Creating Layer bn5c_branch2b
I0312 16:39:07.523437 24897 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0312 16:39:07.523443 24897 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0312 16:39:07.523632 24897 net.cpp:150] Setting up bn5c_branch2b
I0312 16:39:07.523638 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.523639 24897 net.cpp:165] Memory required for data: 257503244
I0312 16:39:07.523645 24897 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0312 16:39:07.523654 24897 net.cpp:100] Creating Layer scale5c_branch2b
I0312 16:39:07.523658 24897 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0312 16:39:07.523660 24897 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0312 16:39:07.523691 24897 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0312 16:39:07.523787 24897 net.cpp:150] Setting up scale5c_branch2b
I0312 16:39:07.523792 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.523794 24897 net.cpp:165] Memory required for data: 257904652
I0312 16:39:07.523798 24897 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0312 16:39:07.523807 24897 net.cpp:100] Creating Layer res5c_branch2b_relu
I0312 16:39:07.523809 24897 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0312 16:39:07.523813 24897 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0312 16:39:07.523818 24897 net.cpp:150] Setting up res5c_branch2b_relu
I0312 16:39:07.523820 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.523823 24897 net.cpp:165] Memory required for data: 258306060
I0312 16:39:07.523825 24897 layer_factory.hpp:77] Creating layer res5c_branch2c
I0312 16:39:07.523833 24897 net.cpp:100] Creating Layer res5c_branch2c
I0312 16:39:07.523836 24897 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0312 16:39:07.523843 24897 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0312 16:39:07.526222 24897 net.cpp:150] Setting up res5c_branch2c
I0312 16:39:07.526253 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.526257 24897 net.cpp:165] Memory required for data: 259911692
I0312 16:39:07.526270 24897 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0312 16:39:07.526283 24897 net.cpp:100] Creating Layer bn5c_branch2c
I0312 16:39:07.526286 24897 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0312 16:39:07.526294 24897 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0312 16:39:07.526500 24897 net.cpp:150] Setting up bn5c_branch2c
I0312 16:39:07.526507 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.526510 24897 net.cpp:165] Memory required for data: 261517324
I0312 16:39:07.526516 24897 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0312 16:39:07.526522 24897 net.cpp:100] Creating Layer scale5c_branch2c
I0312 16:39:07.526525 24897 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0312 16:39:07.526528 24897 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0312 16:39:07.526569 24897 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0312 16:39:07.526669 24897 net.cpp:150] Setting up scale5c_branch2c
I0312 16:39:07.526674 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.526677 24897 net.cpp:165] Memory required for data: 263122956
I0312 16:39:07.526684 24897 layer_factory.hpp:77] Creating layer res5c
I0312 16:39:07.526687 24897 net.cpp:100] Creating Layer res5c
I0312 16:39:07.526690 24897 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0312 16:39:07.526693 24897 net.cpp:444] res5c <- res5c_branch2c
I0312 16:39:07.526698 24897 net.cpp:418] res5c -> res5c
I0312 16:39:07.526716 24897 net.cpp:150] Setting up res5c
I0312 16:39:07.526721 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.526722 24897 net.cpp:165] Memory required for data: 264728588
I0312 16:39:07.526726 24897 layer_factory.hpp:77] Creating layer res5c_relu
I0312 16:39:07.526731 24897 net.cpp:100] Creating Layer res5c_relu
I0312 16:39:07.526733 24897 net.cpp:444] res5c_relu <- res5c
I0312 16:39:07.526736 24897 net.cpp:405] res5c_relu -> res5c (in-place)
I0312 16:39:07.526741 24897 net.cpp:150] Setting up res5c_relu
I0312 16:39:07.526744 24897 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0312 16:39:07.526746 24897 net.cpp:165] Memory required for data: 266334220
I0312 16:39:07.526748 24897 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0312 16:39:07.526758 24897 net.cpp:100] Creating Layer rpn_conv/3x3
I0312 16:39:07.526762 24897 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0312 16:39:07.526767 24897 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0312 16:39:07.571204 24897 net.cpp:150] Setting up rpn_conv/3x3
I0312 16:39:07.571234 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.571238 24897 net.cpp:165] Memory required for data: 266735628
I0312 16:39:07.571260 24897 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0312 16:39:07.571272 24897 net.cpp:100] Creating Layer rpn_relu/3x3
I0312 16:39:07.571277 24897 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0312 16:39:07.571283 24897 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0312 16:39:07.571293 24897 net.cpp:150] Setting up rpn_relu/3x3
I0312 16:39:07.571296 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.571298 24897 net.cpp:165] Memory required for data: 267137036
I0312 16:39:07.571301 24897 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0312 16:39:07.571319 24897 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0312 16:39:07.571323 24897 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0312 16:39:07.571328 24897 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0312 16:39:07.571334 24897 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0312 16:39:07.571377 24897 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0312 16:39:07.571382 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.571385 24897 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0312 16:39:07.571388 24897 net.cpp:165] Memory required for data: 267939852
I0312 16:39:07.571389 24897 layer_factory.hpp:77] Creating layer rpn_cls_score
I0312 16:39:07.571398 24897 net.cpp:100] Creating Layer rpn_cls_score
I0312 16:39:07.571403 24897 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0312 16:39:07.571408 24897 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0312 16:39:07.571691 24897 net.cpp:150] Setting up rpn_cls_score
I0312 16:39:07.571696 24897 net.cpp:157] Top shape: 1 18 14 14 (3528)
I0312 16:39:07.571697 24897 net.cpp:165] Memory required for data: 267953964
I0312 16:39:07.571702 24897 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0312 16:39:07.571724 24897 net.cpp:100] Creating Layer rpn_bbox_pred
I0312 16:39:07.571727 24897 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0312 16:39:07.571745 24897 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0312 16:39:07.572101 24897 net.cpp:150] Setting up rpn_bbox_pred
I0312 16:39:07.572106 24897 net.cpp:157] Top shape: 1 36 14 14 (7056)
I0312 16:39:07.572108 24897 net.cpp:165] Memory required for data: 267982188
I0312 16:39:07.572113 24897 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0312 16:39:07.572134 24897 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0312 16:39:07.572136 24897 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0312 16:39:07.572140 24897 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0312 16:39:07.572178 24897 net.cpp:150] Setting up rpn_cls_score_reshape
I0312 16:39:07.572196 24897 net.cpp:157] Top shape: 1 2 126 14 (3528)
I0312 16:39:07.572197 24897 net.cpp:165] Memory required for data: 267996300
I0312 16:39:07.572201 24897 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0312 16:39:07.572219 24897 net.cpp:100] Creating Layer rpn_cls_prob
I0312 16:39:07.572222 24897 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0312 16:39:07.572227 24897 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0312 16:39:07.572288 24897 net.cpp:150] Setting up rpn_cls_prob
I0312 16:39:07.572293 24897 net.cpp:157] Top shape: 1 2 126 14 (3528)
I0312 16:39:07.572295 24897 net.cpp:165] Memory required for data: 268010412
I0312 16:39:07.572298 24897 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0312 16:39:07.572302 24897 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0312 16:39:07.572305 24897 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0312 16:39:07.572324 24897 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0312 16:39:07.572340 24897 net.cpp:150] Setting up rpn_cls_prob_reshape
I0312 16:39:07.572345 24897 net.cpp:157] Top shape: 1 18 14 14 (3528)
I0312 16:39:07.572347 24897 net.cpp:165] Memory required for data: 268024524
I0312 16:39:07.572350 24897 layer_factory.hpp:77] Creating layer proposal
I0312 16:39:07.573464 24897 net.cpp:100] Creating Layer proposal
I0312 16:39:07.573473 24897 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0312 16:39:07.573477 24897 net.cpp:444] proposal <- rpn_bbox_pred
I0312 16:39:07.573480 24897 net.cpp:444] proposal <- im_info
I0312 16:39:07.573484 24897 net.cpp:418] proposal -> rois
I0312 16:39:07.574168 24897 net.cpp:150] Setting up proposal
I0312 16:39:07.574179 24897 net.cpp:157] Top shape: 1 5 (5)
I0312 16:39:07.574182 24897 net.cpp:165] Memory required for data: 268024544
I0312 16:39:07.574184 24897 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0312 16:39:07.574189 24897 net.cpp:100] Creating Layer rois_proposal_0_split
I0312 16:39:07.574208 24897 net.cpp:444] rois_proposal_0_split <- rois
I0312 16:39:07.574211 24897 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0312 16:39:07.574230 24897 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0312 16:39:07.574290 24897 net.cpp:150] Setting up rois_proposal_0_split
I0312 16:39:07.574309 24897 net.cpp:157] Top shape: 1 5 (5)
I0312 16:39:07.574312 24897 net.cpp:157] Top shape: 1 5 (5)
I0312 16:39:07.574314 24897 net.cpp:165] Memory required for data: 268024584
I0312 16:39:07.574329 24897 layer_factory.hpp:77] Creating layer conv_new_1
I0312 16:39:07.574337 24897 net.cpp:100] Creating Layer conv_new_1
I0312 16:39:07.574354 24897 net.cpp:444] conv_new_1 <- res5c
I0312 16:39:07.574358 24897 net.cpp:418] conv_new_1 -> conv_new_1
I0312 16:39:07.594636 24897 net.cpp:150] Setting up conv_new_1
I0312 16:39:07.594660 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.594662 24897 net.cpp:165] Memory required for data: 268827400
I0312 16:39:07.594671 24897 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0312 16:39:07.594694 24897 net.cpp:100] Creating Layer conv_new_1_relu
I0312 16:39:07.594698 24897 net.cpp:444] conv_new_1_relu <- conv_new_1
I0312 16:39:07.594717 24897 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0312 16:39:07.594727 24897 net.cpp:150] Setting up conv_new_1_relu
I0312 16:39:07.594743 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.594745 24897 net.cpp:165] Memory required for data: 269630216
I0312 16:39:07.594748 24897 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0312 16:39:07.594751 24897 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0312 16:39:07.594768 24897 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0312 16:39:07.594774 24897 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0312 16:39:07.594780 24897 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0312 16:39:07.594830 24897 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0312 16:39:07.594837 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.594841 24897 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0312 16:39:07.594844 24897 net.cpp:165] Memory required for data: 271235848
I0312 16:39:07.594846 24897 layer_factory.hpp:77] Creating layer rfcn_cls
I0312 16:39:07.594867 24897 net.cpp:100] Creating Layer rfcn_cls
I0312 16:39:07.594884 24897 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0312 16:39:07.594889 24897 net.cpp:418] rfcn_cls -> rfcn_cls
I0312 16:39:07.595914 24897 net.cpp:150] Setting up rfcn_cls
I0312 16:39:07.595927 24897 net.cpp:157] Top shape: 1 98 14 14 (19208)
I0312 16:39:07.595929 24897 net.cpp:165] Memory required for data: 271312680
I0312 16:39:07.595935 24897 layer_factory.hpp:77] Creating layer rfcn_bbox
I0312 16:39:07.595984 24897 net.cpp:100] Creating Layer rfcn_bbox
I0312 16:39:07.596004 24897 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0312 16:39:07.596009 24897 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0312 16:39:07.600481 24897 net.cpp:150] Setting up rfcn_bbox
I0312 16:39:07.600505 24897 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0312 16:39:07.600508 24897 net.cpp:165] Memory required for data: 271620008
I0312 16:39:07.600519 24897 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0312 16:39:07.600533 24897 net.cpp:100] Creating Layer psroipooled_cls_rois
I0312 16:39:07.600538 24897 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0312 16:39:07.600544 24897 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0312 16:39:07.600550 24897 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0312 16:39:07.600564 24897 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0312 16:39:07.600615 24897 net.cpp:150] Setting up psroipooled_cls_rois
I0312 16:39:07.600633 24897 net.cpp:157] Top shape: 1 2 7 7 (98)
I0312 16:39:07.600636 24897 net.cpp:165] Memory required for data: 271620400
I0312 16:39:07.600638 24897 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0312 16:39:07.600656 24897 net.cpp:100] Creating Layer ave_cls_score_rois
I0312 16:39:07.600658 24897 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0312 16:39:07.600664 24897 net.cpp:418] ave_cls_score_rois -> cls_score
I0312 16:39:07.600682 24897 net.cpp:150] Setting up ave_cls_score_rois
I0312 16:39:07.600685 24897 net.cpp:157] Top shape: 1 2 1 1 (2)
I0312 16:39:07.600688 24897 net.cpp:165] Memory required for data: 271620408
I0312 16:39:07.600690 24897 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0312 16:39:07.600694 24897 net.cpp:100] Creating Layer psroipooled_loc_rois
I0312 16:39:07.600697 24897 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0312 16:39:07.600700 24897 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0312 16:39:07.600708 24897 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0312 16:39:07.600713 24897 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0312 16:39:07.600740 24897 net.cpp:150] Setting up psroipooled_loc_rois
I0312 16:39:07.600744 24897 net.cpp:157] Top shape: 1 8 7 7 (392)
I0312 16:39:07.600747 24897 net.cpp:165] Memory required for data: 271621976
I0312 16:39:07.600749 24897 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0312 16:39:07.600754 24897 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0312 16:39:07.600756 24897 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0312 16:39:07.600761 24897 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0312 16:39:07.600777 24897 net.cpp:150] Setting up ave_bbox_pred_rois
I0312 16:39:07.600782 24897 net.cpp:157] Top shape: 1 8 1 1 (8)
I0312 16:39:07.600785 24897 net.cpp:165] Memory required for data: 271622008
I0312 16:39:07.600787 24897 layer_factory.hpp:77] Creating layer cls_prob
I0312 16:39:07.600792 24897 net.cpp:100] Creating Layer cls_prob
I0312 16:39:07.600795 24897 net.cpp:444] cls_prob <- cls_score
I0312 16:39:07.600798 24897 net.cpp:418] cls_prob -> cls_prob_pre
I0312 16:39:07.600888 24897 net.cpp:150] Setting up cls_prob
I0312 16:39:07.600893 24897 net.cpp:157] Top shape: 1 2 1 1 (2)
I0312 16:39:07.600908 24897 net.cpp:165] Memory required for data: 271622016
I0312 16:39:07.600910 24897 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0312 16:39:07.600931 24897 net.cpp:100] Creating Layer cls_prob_reshape
I0312 16:39:07.600934 24897 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0312 16:39:07.600937 24897 net.cpp:418] cls_prob_reshape -> cls_prob
I0312 16:39:07.600970 24897 net.cpp:150] Setting up cls_prob_reshape
I0312 16:39:07.600975 24897 net.cpp:157] Top shape: 1 2 (2)
I0312 16:39:07.600976 24897 net.cpp:165] Memory required for data: 271622024
I0312 16:39:07.600978 24897 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0312 16:39:07.600983 24897 net.cpp:100] Creating Layer bbox_pred_reshape
I0312 16:39:07.600987 24897 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0312 16:39:07.600991 24897 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0312 16:39:07.601007 24897 net.cpp:150] Setting up bbox_pred_reshape
I0312 16:39:07.601012 24897 net.cpp:157] Top shape: 1 8 (8)
I0312 16:39:07.601014 24897 net.cpp:165] Memory required for data: 271622056
I0312 16:39:07.601017 24897 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0312 16:39:07.601019 24897 net.cpp:228] cls_prob_reshape does not need backward computation.
I0312 16:39:07.601022 24897 net.cpp:228] cls_prob does not need backward computation.
I0312 16:39:07.601024 24897 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0312 16:39:07.601027 24897 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0312 16:39:07.601029 24897 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0312 16:39:07.601032 24897 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0312 16:39:07.601035 24897 net.cpp:228] rfcn_bbox does not need backward computation.
I0312 16:39:07.601038 24897 net.cpp:228] rfcn_cls does not need backward computation.
I0312 16:39:07.601042 24897 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0312 16:39:07.601045 24897 net.cpp:228] conv_new_1_relu does not need backward computation.
I0312 16:39:07.601048 24897 net.cpp:228] conv_new_1 does not need backward computation.
I0312 16:39:07.601052 24897 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0312 16:39:07.601055 24897 net.cpp:228] proposal does not need backward computation.
I0312 16:39:07.601058 24897 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0312 16:39:07.601063 24897 net.cpp:228] rpn_cls_prob does not need backward computation.
I0312 16:39:07.601065 24897 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0312 16:39:07.601068 24897 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0312 16:39:07.601071 24897 net.cpp:228] rpn_cls_score does not need backward computation.
I0312 16:39:07.601074 24897 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0312 16:39:07.601078 24897 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0312 16:39:07.601080 24897 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0312 16:39:07.601083 24897 net.cpp:228] res5c_relu does not need backward computation.
I0312 16:39:07.601086 24897 net.cpp:228] res5c does not need backward computation.
I0312 16:39:07.601089 24897 net.cpp:228] scale5c_branch2c does not need backward computation.
I0312 16:39:07.601092 24897 net.cpp:228] bn5c_branch2c does not need backward computation.
I0312 16:39:07.601094 24897 net.cpp:228] res5c_branch2c does not need backward computation.
I0312 16:39:07.601097 24897 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0312 16:39:07.601099 24897 net.cpp:228] scale5c_branch2b does not need backward computation.
I0312 16:39:07.601102 24897 net.cpp:228] bn5c_branch2b does not need backward computation.
I0312 16:39:07.601104 24897 net.cpp:228] res5c_branch2b does not need backward computation.
I0312 16:39:07.601107 24897 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0312 16:39:07.601109 24897 net.cpp:228] scale5c_branch2a does not need backward computation.
I0312 16:39:07.601112 24897 net.cpp:228] bn5c_branch2a does not need backward computation.
I0312 16:39:07.601114 24897 net.cpp:228] res5c_branch2a does not need backward computation.
I0312 16:39:07.601117 24897 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0312 16:39:07.601120 24897 net.cpp:228] res5b_relu does not need backward computation.
I0312 16:39:07.601125 24897 net.cpp:228] res5b does not need backward computation.
I0312 16:39:07.601127 24897 net.cpp:228] scale5b_branch2c does not need backward computation.
I0312 16:39:07.601130 24897 net.cpp:228] bn5b_branch2c does not need backward computation.
I0312 16:39:07.601132 24897 net.cpp:228] res5b_branch2c does not need backward computation.
I0312 16:39:07.601135 24897 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0312 16:39:07.601138 24897 net.cpp:228] scale5b_branch2b does not need backward computation.
I0312 16:39:07.601140 24897 net.cpp:228] bn5b_branch2b does not need backward computation.
I0312 16:39:07.601143 24897 net.cpp:228] res5b_branch2b does not need backward computation.
I0312 16:39:07.601145 24897 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0312 16:39:07.601148 24897 net.cpp:228] scale5b_branch2a does not need backward computation.
I0312 16:39:07.601151 24897 net.cpp:228] bn5b_branch2a does not need backward computation.
I0312 16:39:07.601153 24897 net.cpp:228] res5b_branch2a does not need backward computation.
I0312 16:39:07.601156 24897 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0312 16:39:07.601158 24897 net.cpp:228] res5a_relu does not need backward computation.
I0312 16:39:07.601161 24897 net.cpp:228] res5a does not need backward computation.
I0312 16:39:07.601164 24897 net.cpp:228] scale5a_branch2c does not need backward computation.
I0312 16:39:07.601167 24897 net.cpp:228] bn5a_branch2c does not need backward computation.
I0312 16:39:07.601169 24897 net.cpp:228] res5a_branch2c does not need backward computation.
I0312 16:39:07.601172 24897 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0312 16:39:07.601176 24897 net.cpp:228] scale5a_branch2b does not need backward computation.
I0312 16:39:07.601177 24897 net.cpp:228] bn5a_branch2b does not need backward computation.
I0312 16:39:07.601179 24897 net.cpp:228] res5a_branch2b does not need backward computation.
I0312 16:39:07.601182 24897 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0312 16:39:07.601186 24897 net.cpp:228] scale5a_branch2a does not need backward computation.
I0312 16:39:07.601187 24897 net.cpp:228] bn5a_branch2a does not need backward computation.
I0312 16:39:07.601189 24897 net.cpp:228] res5a_branch2a does not need backward computation.
I0312 16:39:07.601192 24897 net.cpp:228] scale5a_branch1 does not need backward computation.
I0312 16:39:07.601197 24897 net.cpp:228] bn5a_branch1 does not need backward computation.
I0312 16:39:07.601199 24897 net.cpp:228] res5a_branch1 does not need backward computation.
I0312 16:39:07.601202 24897 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0312 16:39:07.601205 24897 net.cpp:228] res4f_relu does not need backward computation.
I0312 16:39:07.601207 24897 net.cpp:228] res4f does not need backward computation.
I0312 16:39:07.601210 24897 net.cpp:228] scale4f_branch2c does not need backward computation.
I0312 16:39:07.601213 24897 net.cpp:228] bn4f_branch2c does not need backward computation.
I0312 16:39:07.601217 24897 net.cpp:228] res4f_branch2c does not need backward computation.
I0312 16:39:07.601219 24897 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0312 16:39:07.601222 24897 net.cpp:228] scale4f_branch2b does not need backward computation.
I0312 16:39:07.601224 24897 net.cpp:228] bn4f_branch2b does not need backward computation.
I0312 16:39:07.601227 24897 net.cpp:228] res4f_branch2b does not need backward computation.
I0312 16:39:07.601229 24897 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0312 16:39:07.601233 24897 net.cpp:228] scale4f_branch2a does not need backward computation.
I0312 16:39:07.601234 24897 net.cpp:228] bn4f_branch2a does not need backward computation.
I0312 16:39:07.601238 24897 net.cpp:228] res4f_branch2a does not need backward computation.
I0312 16:39:07.601240 24897 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0312 16:39:07.601243 24897 net.cpp:228] res4e_relu does not need backward computation.
I0312 16:39:07.601245 24897 net.cpp:228] res4e does not need backward computation.
I0312 16:39:07.601248 24897 net.cpp:228] scale4e_branch2c does not need backward computation.
I0312 16:39:07.601253 24897 net.cpp:228] bn4e_branch2c does not need backward computation.
I0312 16:39:07.601254 24897 net.cpp:228] res4e_branch2c does not need backward computation.
I0312 16:39:07.601256 24897 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0312 16:39:07.601259 24897 net.cpp:228] scale4e_branch2b does not need backward computation.
I0312 16:39:07.601261 24897 net.cpp:228] bn4e_branch2b does not need backward computation.
I0312 16:39:07.601264 24897 net.cpp:228] res4e_branch2b does not need backward computation.
I0312 16:39:07.601266 24897 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0312 16:39:07.601269 24897 net.cpp:228] scale4e_branch2a does not need backward computation.
I0312 16:39:07.601271 24897 net.cpp:228] bn4e_branch2a does not need backward computation.
I0312 16:39:07.601274 24897 net.cpp:228] res4e_branch2a does not need backward computation.
I0312 16:39:07.601277 24897 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0312 16:39:07.601280 24897 net.cpp:228] res4d_relu does not need backward computation.
I0312 16:39:07.601282 24897 net.cpp:228] res4d does not need backward computation.
I0312 16:39:07.601287 24897 net.cpp:228] scale4d_branch2c does not need backward computation.
I0312 16:39:07.601291 24897 net.cpp:228] bn4d_branch2c does not need backward computation.
I0312 16:39:07.601294 24897 net.cpp:228] res4d_branch2c does not need backward computation.
I0312 16:39:07.601295 24897 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0312 16:39:07.601299 24897 net.cpp:228] scale4d_branch2b does not need backward computation.
I0312 16:39:07.601300 24897 net.cpp:228] bn4d_branch2b does not need backward computation.
I0312 16:39:07.601303 24897 net.cpp:228] res4d_branch2b does not need backward computation.
I0312 16:39:07.601305 24897 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0312 16:39:07.601308 24897 net.cpp:228] scale4d_branch2a does not need backward computation.
I0312 16:39:07.601323 24897 net.cpp:228] bn4d_branch2a does not need backward computation.
I0312 16:39:07.601326 24897 net.cpp:228] res4d_branch2a does not need backward computation.
I0312 16:39:07.601330 24897 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0312 16:39:07.601331 24897 net.cpp:228] res4c_relu does not need backward computation.
I0312 16:39:07.601335 24897 net.cpp:228] res4c does not need backward computation.
I0312 16:39:07.601337 24897 net.cpp:228] scale4c_branch2c does not need backward computation.
I0312 16:39:07.601341 24897 net.cpp:228] bn4c_branch2c does not need backward computation.
I0312 16:39:07.601342 24897 net.cpp:228] res4c_branch2c does not need backward computation.
I0312 16:39:07.601344 24897 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0312 16:39:07.601347 24897 net.cpp:228] scale4c_branch2b does not need backward computation.
I0312 16:39:07.601351 24897 net.cpp:228] bn4c_branch2b does not need backward computation.
I0312 16:39:07.601366 24897 net.cpp:228] res4c_branch2b does not need backward computation.
I0312 16:39:07.601367 24897 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0312 16:39:07.601371 24897 net.cpp:228] scale4c_branch2a does not need backward computation.
I0312 16:39:07.601372 24897 net.cpp:228] bn4c_branch2a does not need backward computation.
I0312 16:39:07.601374 24897 net.cpp:228] res4c_branch2a does not need backward computation.
I0312 16:39:07.601378 24897 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0312 16:39:07.601380 24897 net.cpp:228] res4b_relu does not need backward computation.
I0312 16:39:07.601383 24897 net.cpp:228] res4b does not need backward computation.
I0312 16:39:07.601387 24897 net.cpp:228] scale4b_branch2c does not need backward computation.
I0312 16:39:07.601388 24897 net.cpp:228] bn4b_branch2c does not need backward computation.
I0312 16:39:07.601392 24897 net.cpp:228] res4b_branch2c does not need backward computation.
I0312 16:39:07.601393 24897 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0312 16:39:07.601397 24897 net.cpp:228] scale4b_branch2b does not need backward computation.
I0312 16:39:07.601398 24897 net.cpp:228] bn4b_branch2b does not need backward computation.
I0312 16:39:07.601402 24897 net.cpp:228] res4b_branch2b does not need backward computation.
I0312 16:39:07.601403 24897 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0312 16:39:07.601406 24897 net.cpp:228] scale4b_branch2a does not need backward computation.
I0312 16:39:07.601408 24897 net.cpp:228] bn4b_branch2a does not need backward computation.
I0312 16:39:07.601410 24897 net.cpp:228] res4b_branch2a does not need backward computation.
I0312 16:39:07.601413 24897 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0312 16:39:07.601416 24897 net.cpp:228] res4a_relu does not need backward computation.
I0312 16:39:07.601418 24897 net.cpp:228] res4a does not need backward computation.
I0312 16:39:07.601421 24897 net.cpp:228] scale4a_branch2c does not need backward computation.
I0312 16:39:07.601424 24897 net.cpp:228] bn4a_branch2c does not need backward computation.
I0312 16:39:07.601426 24897 net.cpp:228] res4a_branch2c does not need backward computation.
I0312 16:39:07.601428 24897 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0312 16:39:07.601433 24897 net.cpp:228] scale4a_branch2b does not need backward computation.
I0312 16:39:07.601436 24897 net.cpp:228] bn4a_branch2b does not need backward computation.
I0312 16:39:07.601438 24897 net.cpp:228] res4a_branch2b does not need backward computation.
I0312 16:39:07.601440 24897 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0312 16:39:07.601444 24897 net.cpp:228] scale4a_branch2a does not need backward computation.
I0312 16:39:07.601445 24897 net.cpp:228] bn4a_branch2a does not need backward computation.
I0312 16:39:07.601449 24897 net.cpp:228] res4a_branch2a does not need backward computation.
I0312 16:39:07.601451 24897 net.cpp:228] scale4a_branch1 does not need backward computation.
I0312 16:39:07.601454 24897 net.cpp:228] bn4a_branch1 does not need backward computation.
I0312 16:39:07.601456 24897 net.cpp:228] res4a_branch1 does not need backward computation.
I0312 16:39:07.601459 24897 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0312 16:39:07.601462 24897 net.cpp:228] res3d_relu does not need backward computation.
I0312 16:39:07.601477 24897 net.cpp:228] res3d does not need backward computation.
I0312 16:39:07.601481 24897 net.cpp:228] scale3d_branch2c does not need backward computation.
I0312 16:39:07.601483 24897 net.cpp:228] bn3d_branch2c does not need backward computation.
I0312 16:39:07.601486 24897 net.cpp:228] res3d_branch2c does not need backward computation.
I0312 16:39:07.601488 24897 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0312 16:39:07.601491 24897 net.cpp:228] scale3d_branch2b does not need backward computation.
I0312 16:39:07.601493 24897 net.cpp:228] bn3d_branch2b does not need backward computation.
I0312 16:39:07.601495 24897 net.cpp:228] res3d_branch2b does not need backward computation.
I0312 16:39:07.601498 24897 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0312 16:39:07.601501 24897 net.cpp:228] scale3d_branch2a does not need backward computation.
I0312 16:39:07.601503 24897 net.cpp:228] bn3d_branch2a does not need backward computation.
I0312 16:39:07.601506 24897 net.cpp:228] res3d_branch2a does not need backward computation.
I0312 16:39:07.601510 24897 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0312 16:39:07.601511 24897 net.cpp:228] res3c_relu does not need backward computation.
I0312 16:39:07.601513 24897 net.cpp:228] res3c does not need backward computation.
I0312 16:39:07.601516 24897 net.cpp:228] scale3c_branch2c does not need backward computation.
I0312 16:39:07.601519 24897 net.cpp:228] bn3c_branch2c does not need backward computation.
I0312 16:39:07.601521 24897 net.cpp:228] res3c_branch2c does not need backward computation.
I0312 16:39:07.601524 24897 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0312 16:39:07.601526 24897 net.cpp:228] scale3c_branch2b does not need backward computation.
I0312 16:39:07.601529 24897 net.cpp:228] bn3c_branch2b does not need backward computation.
I0312 16:39:07.601531 24897 net.cpp:228] res3c_branch2b does not need backward computation.
I0312 16:39:07.601534 24897 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0312 16:39:07.601536 24897 net.cpp:228] scale3c_branch2a does not need backward computation.
I0312 16:39:07.601539 24897 net.cpp:228] bn3c_branch2a does not need backward computation.
I0312 16:39:07.601541 24897 net.cpp:228] res3c_branch2a does not need backward computation.
I0312 16:39:07.601544 24897 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0312 16:39:07.601547 24897 net.cpp:228] res3b_relu does not need backward computation.
I0312 16:39:07.601549 24897 net.cpp:228] res3b does not need backward computation.
I0312 16:39:07.601552 24897 net.cpp:228] scale3b_branch2c does not need backward computation.
I0312 16:39:07.601557 24897 net.cpp:228] bn3b_branch2c does not need backward computation.
I0312 16:39:07.601558 24897 net.cpp:228] res3b_branch2c does not need backward computation.
I0312 16:39:07.601562 24897 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0312 16:39:07.601563 24897 net.cpp:228] scale3b_branch2b does not need backward computation.
I0312 16:39:07.601567 24897 net.cpp:228] bn3b_branch2b does not need backward computation.
I0312 16:39:07.601568 24897 net.cpp:228] res3b_branch2b does not need backward computation.
I0312 16:39:07.601572 24897 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0312 16:39:07.601573 24897 net.cpp:228] scale3b_branch2a does not need backward computation.
I0312 16:39:07.601577 24897 net.cpp:228] bn3b_branch2a does not need backward computation.
I0312 16:39:07.601578 24897 net.cpp:228] res3b_branch2a does not need backward computation.
I0312 16:39:07.601582 24897 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0312 16:39:07.601584 24897 net.cpp:228] res3a_relu does not need backward computation.
I0312 16:39:07.601586 24897 net.cpp:228] res3a does not need backward computation.
I0312 16:39:07.601590 24897 net.cpp:228] scale3a_branch2c does not need backward computation.
I0312 16:39:07.601594 24897 net.cpp:228] bn3a_branch2c does not need backward computation.
I0312 16:39:07.601596 24897 net.cpp:228] res3a_branch2c does not need backward computation.
I0312 16:39:07.601599 24897 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0312 16:39:07.601601 24897 net.cpp:228] scale3a_branch2b does not need backward computation.
I0312 16:39:07.601604 24897 net.cpp:228] bn3a_branch2b does not need backward computation.
I0312 16:39:07.601606 24897 net.cpp:228] res3a_branch2b does not need backward computation.
I0312 16:39:07.601609 24897 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0312 16:39:07.601611 24897 net.cpp:228] scale3a_branch2a does not need backward computation.
I0312 16:39:07.601614 24897 net.cpp:228] bn3a_branch2a does not need backward computation.
I0312 16:39:07.601616 24897 net.cpp:228] res3a_branch2a does not need backward computation.
I0312 16:39:07.601619 24897 net.cpp:228] scale3a_branch1 does not need backward computation.
I0312 16:39:07.601621 24897 net.cpp:228] bn3a_branch1 does not need backward computation.
I0312 16:39:07.601624 24897 net.cpp:228] res3a_branch1 does not need backward computation.
I0312 16:39:07.601626 24897 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0312 16:39:07.601629 24897 net.cpp:228] res2c_relu does not need backward computation.
I0312 16:39:07.601631 24897 net.cpp:228] res2c does not need backward computation.
I0312 16:39:07.601635 24897 net.cpp:228] scale2c_branch2c does not need backward computation.
I0312 16:39:07.601639 24897 net.cpp:228] bn2c_branch2c does not need backward computation.
I0312 16:39:07.601641 24897 net.cpp:228] res2c_branch2c does not need backward computation.
I0312 16:39:07.601657 24897 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0312 16:39:07.601660 24897 net.cpp:228] scale2c_branch2b does not need backward computation.
I0312 16:39:07.601662 24897 net.cpp:228] bn2c_branch2b does not need backward computation.
I0312 16:39:07.601665 24897 net.cpp:228] res2c_branch2b does not need backward computation.
I0312 16:39:07.601667 24897 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0312 16:39:07.601670 24897 net.cpp:228] scale2c_branch2a does not need backward computation.
I0312 16:39:07.601672 24897 net.cpp:228] bn2c_branch2a does not need backward computation.
I0312 16:39:07.601675 24897 net.cpp:228] res2c_branch2a does not need backward computation.
I0312 16:39:07.601677 24897 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0312 16:39:07.601680 24897 net.cpp:228] res2b_relu does not need backward computation.
I0312 16:39:07.601682 24897 net.cpp:228] res2b does not need backward computation.
I0312 16:39:07.601686 24897 net.cpp:228] scale2b_branch2c does not need backward computation.
I0312 16:39:07.601688 24897 net.cpp:228] bn2b_branch2c does not need backward computation.
I0312 16:39:07.601691 24897 net.cpp:228] res2b_branch2c does not need backward computation.
I0312 16:39:07.601693 24897 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0312 16:39:07.601696 24897 net.cpp:228] scale2b_branch2b does not need backward computation.
I0312 16:39:07.601697 24897 net.cpp:228] bn2b_branch2b does not need backward computation.
I0312 16:39:07.601701 24897 net.cpp:228] res2b_branch2b does not need backward computation.
I0312 16:39:07.601702 24897 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0312 16:39:07.601706 24897 net.cpp:228] scale2b_branch2a does not need backward computation.
I0312 16:39:07.601721 24897 net.cpp:228] bn2b_branch2a does not need backward computation.
I0312 16:39:07.601723 24897 net.cpp:228] res2b_branch2a does not need backward computation.
I0312 16:39:07.601725 24897 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0312 16:39:07.601728 24897 net.cpp:228] res2a_relu does not need backward computation.
I0312 16:39:07.601730 24897 net.cpp:228] res2a does not need backward computation.
I0312 16:39:07.601733 24897 net.cpp:228] scale2a_branch2c does not need backward computation.
I0312 16:39:07.601737 24897 net.cpp:228] bn2a_branch2c does not need backward computation.
I0312 16:39:07.601739 24897 net.cpp:228] res2a_branch2c does not need backward computation.
I0312 16:39:07.601742 24897 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0312 16:39:07.601744 24897 net.cpp:228] scale2a_branch2b does not need backward computation.
I0312 16:39:07.601760 24897 net.cpp:228] bn2a_branch2b does not need backward computation.
I0312 16:39:07.601763 24897 net.cpp:228] res2a_branch2b does not need backward computation.
I0312 16:39:07.601765 24897 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0312 16:39:07.601768 24897 net.cpp:228] scale2a_branch2a does not need backward computation.
I0312 16:39:07.601770 24897 net.cpp:228] bn2a_branch2a does not need backward computation.
I0312 16:39:07.601773 24897 net.cpp:228] res2a_branch2a does not need backward computation.
I0312 16:39:07.601775 24897 net.cpp:228] scale2a_branch1 does not need backward computation.
I0312 16:39:07.601778 24897 net.cpp:228] bn2a_branch1 does not need backward computation.
I0312 16:39:07.601780 24897 net.cpp:228] res2a_branch1 does not need backward computation.
I0312 16:39:07.601783 24897 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0312 16:39:07.601786 24897 net.cpp:228] pool1 does not need backward computation.
I0312 16:39:07.601789 24897 net.cpp:228] conv1_relu does not need backward computation.
I0312 16:39:07.601794 24897 net.cpp:228] scale_conv1 does not need backward computation.
I0312 16:39:07.601795 24897 net.cpp:228] bn_conv1 does not need backward computation.
I0312 16:39:07.601799 24897 net.cpp:228] conv1 does not need backward computation.
I0312 16:39:07.601801 24897 net.cpp:228] input does not need backward computation.
I0312 16:39:07.601804 24897 net.cpp:270] This network produces output bbox_pred
I0312 16:39:07.601806 24897 net.cpp:270] This network produces output cls_prob
I0312 16:39:07.601938 24897 net.cpp:283] Network initialization done.
I0312 16:39:07.685217 24897 net.cpp:771] Ignoring source layer input-data
I0312 16:39:07.685238 24897 net.cpp:771] Ignoring source layer data_input-data_0_split
I0312 16:39:07.685241 24897 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0312 16:39:07.685243 24897 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0312 16:39:07.685246 24897 net.cpp:774] Copying source layer conv1
I0312 16:39:07.685258 24897 net.cpp:774] Copying source layer bn_conv1
I0312 16:39:07.685262 24897 net.cpp:774] Copying source layer scale_conv1
I0312 16:39:07.685266 24897 net.cpp:774] Copying source layer conv1_relu
I0312 16:39:07.685269 24897 net.cpp:774] Copying source layer pool1
I0312 16:39:07.685271 24897 net.cpp:774] Copying source layer pool1_pool1_0_split
I0312 16:39:07.685273 24897 net.cpp:774] Copying source layer res2a_branch1
I0312 16:39:07.685297 24897 net.cpp:774] Copying source layer bn2a_branch1
I0312 16:39:07.685305 24897 net.cpp:774] Copying source layer scale2a_branch1
I0312 16:39:07.685312 24897 net.cpp:774] Copying source layer res2a_branch2a
I0312 16:39:07.685322 24897 net.cpp:774] Copying source layer bn2a_branch2a
I0312 16:39:07.685328 24897 net.cpp:774] Copying source layer scale2a_branch2a
I0312 16:39:07.685331 24897 net.cpp:774] Copying source layer res2a_branch2a_relu
I0312 16:39:07.685334 24897 net.cpp:774] Copying source layer res2a_branch2b
I0312 16:39:07.685379 24897 net.cpp:774] Copying source layer bn2a_branch2b
I0312 16:39:07.685384 24897 net.cpp:774] Copying source layer scale2a_branch2b
I0312 16:39:07.685387 24897 net.cpp:774] Copying source layer res2a_branch2b_relu
I0312 16:39:07.685390 24897 net.cpp:774] Copying source layer res2a_branch2c
I0312 16:39:07.685406 24897 net.cpp:774] Copying source layer bn2a_branch2c
I0312 16:39:07.685411 24897 net.cpp:774] Copying source layer scale2a_branch2c
I0312 16:39:07.685415 24897 net.cpp:774] Copying source layer res2a
I0312 16:39:07.685418 24897 net.cpp:774] Copying source layer res2a_relu
I0312 16:39:07.685420 24897 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0312 16:39:07.685422 24897 net.cpp:774] Copying source layer res2b_branch2a
I0312 16:39:07.685446 24897 net.cpp:774] Copying source layer bn2b_branch2a
I0312 16:39:07.685451 24897 net.cpp:774] Copying source layer scale2b_branch2a
I0312 16:39:07.685456 24897 net.cpp:774] Copying source layer res2b_branch2a_relu
I0312 16:39:07.685457 24897 net.cpp:774] Copying source layer res2b_branch2b
I0312 16:39:07.685500 24897 net.cpp:774] Copying source layer bn2b_branch2b
I0312 16:39:07.685505 24897 net.cpp:774] Copying source layer scale2b_branch2b
I0312 16:39:07.685508 24897 net.cpp:774] Copying source layer res2b_branch2b_relu
I0312 16:39:07.685511 24897 net.cpp:774] Copying source layer res2b_branch2c
I0312 16:39:07.685528 24897 net.cpp:774] Copying source layer bn2b_branch2c
I0312 16:39:07.685531 24897 net.cpp:774] Copying source layer scale2b_branch2c
I0312 16:39:07.685535 24897 net.cpp:774] Copying source layer res2b
I0312 16:39:07.685539 24897 net.cpp:774] Copying source layer res2b_relu
I0312 16:39:07.685541 24897 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0312 16:39:07.685544 24897 net.cpp:774] Copying source layer res2c_branch2a
I0312 16:39:07.685559 24897 net.cpp:774] Copying source layer bn2c_branch2a
I0312 16:39:07.685564 24897 net.cpp:774] Copying source layer scale2c_branch2a
I0312 16:39:07.685567 24897 net.cpp:774] Copying source layer res2c_branch2a_relu
I0312 16:39:07.685571 24897 net.cpp:774] Copying source layer res2c_branch2b
I0312 16:39:07.685607 24897 net.cpp:774] Copying source layer bn2c_branch2b
I0312 16:39:07.685613 24897 net.cpp:774] Copying source layer scale2c_branch2b
I0312 16:39:07.685616 24897 net.cpp:774] Copying source layer res2c_branch2b_relu
I0312 16:39:07.685619 24897 net.cpp:774] Copying source layer res2c_branch2c
I0312 16:39:07.685636 24897 net.cpp:774] Copying source layer bn2c_branch2c
I0312 16:39:07.685642 24897 net.cpp:774] Copying source layer scale2c_branch2c
I0312 16:39:07.685647 24897 net.cpp:774] Copying source layer res2c
I0312 16:39:07.685649 24897 net.cpp:774] Copying source layer res2c_relu
I0312 16:39:07.685652 24897 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0312 16:39:07.685654 24897 net.cpp:774] Copying source layer res3a_branch1
I0312 16:39:07.685765 24897 net.cpp:774] Copying source layer bn3a_branch1
I0312 16:39:07.685772 24897 net.cpp:774] Copying source layer scale3a_branch1
I0312 16:39:07.685777 24897 net.cpp:774] Copying source layer res3a_branch2a
I0312 16:39:07.685808 24897 net.cpp:774] Copying source layer bn3a_branch2a
I0312 16:39:07.685814 24897 net.cpp:774] Copying source layer scale3a_branch2a
I0312 16:39:07.685818 24897 net.cpp:774] Copying source layer res3a_branch2a_relu
I0312 16:39:07.685822 24897 net.cpp:774] Copying source layer res3a_branch2b
I0312 16:39:07.685950 24897 net.cpp:774] Copying source layer bn3a_branch2b
I0312 16:39:07.685957 24897 net.cpp:774] Copying source layer scale3a_branch2b
I0312 16:39:07.685961 24897 net.cpp:774] Copying source layer res3a_branch2b_relu
I0312 16:39:07.685963 24897 net.cpp:774] Copying source layer res3a_branch2c
I0312 16:39:07.686020 24897 net.cpp:774] Copying source layer bn3a_branch2c
I0312 16:39:07.686028 24897 net.cpp:774] Copying source layer scale3a_branch2c
I0312 16:39:07.686031 24897 net.cpp:774] Copying source layer res3a
I0312 16:39:07.686035 24897 net.cpp:774] Copying source layer res3a_relu
I0312 16:39:07.686038 24897 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0312 16:39:07.686040 24897 net.cpp:774] Copying source layer res3b_branch2a
I0312 16:39:07.686094 24897 net.cpp:774] Copying source layer bn3b_branch2a
I0312 16:39:07.686100 24897 net.cpp:774] Copying source layer scale3b_branch2a
I0312 16:39:07.686105 24897 net.cpp:774] Copying source layer res3b_branch2a_relu
I0312 16:39:07.686106 24897 net.cpp:774] Copying source layer res3b_branch2b
I0312 16:39:07.686228 24897 net.cpp:774] Copying source layer bn3b_branch2b
I0312 16:39:07.686233 24897 net.cpp:774] Copying source layer scale3b_branch2b
I0312 16:39:07.686236 24897 net.cpp:774] Copying source layer res3b_branch2b_relu
I0312 16:39:07.686239 24897 net.cpp:774] Copying source layer res3b_branch2c
I0312 16:39:07.686295 24897 net.cpp:774] Copying source layer bn3b_branch2c
I0312 16:39:07.686301 24897 net.cpp:774] Copying source layer scale3b_branch2c
I0312 16:39:07.686305 24897 net.cpp:774] Copying source layer res3b
I0312 16:39:07.686308 24897 net.cpp:774] Copying source layer res3b_relu
I0312 16:39:07.686311 24897 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0312 16:39:07.686313 24897 net.cpp:774] Copying source layer res3c_branch2a
I0312 16:39:07.686369 24897 net.cpp:774] Copying source layer bn3c_branch2a
I0312 16:39:07.686375 24897 net.cpp:774] Copying source layer scale3c_branch2a
I0312 16:39:07.686379 24897 net.cpp:774] Copying source layer res3c_branch2a_relu
I0312 16:39:07.686383 24897 net.cpp:774] Copying source layer res3c_branch2b
I0312 16:39:07.686506 24897 net.cpp:774] Copying source layer bn3c_branch2b
I0312 16:39:07.686511 24897 net.cpp:774] Copying source layer scale3c_branch2b
I0312 16:39:07.686516 24897 net.cpp:774] Copying source layer res3c_branch2b_relu
I0312 16:39:07.686517 24897 net.cpp:774] Copying source layer res3c_branch2c
I0312 16:39:07.686573 24897 net.cpp:774] Copying source layer bn3c_branch2c
I0312 16:39:07.686579 24897 net.cpp:774] Copying source layer scale3c_branch2c
I0312 16:39:07.686599 24897 net.cpp:774] Copying source layer res3c
I0312 16:39:07.686600 24897 net.cpp:774] Copying source layer res3c_relu
I0312 16:39:07.686604 24897 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0312 16:39:07.686606 24897 net.cpp:774] Copying source layer res3d_branch2a
I0312 16:39:07.686663 24897 net.cpp:774] Copying source layer bn3d_branch2a
I0312 16:39:07.686668 24897 net.cpp:774] Copying source layer scale3d_branch2a
I0312 16:39:07.686672 24897 net.cpp:774] Copying source layer res3d_branch2a_relu
I0312 16:39:07.686676 24897 net.cpp:774] Copying source layer res3d_branch2b
I0312 16:39:07.686797 24897 net.cpp:774] Copying source layer bn3d_branch2b
I0312 16:39:07.686802 24897 net.cpp:774] Copying source layer scale3d_branch2b
I0312 16:39:07.686806 24897 net.cpp:774] Copying source layer res3d_branch2b_relu
I0312 16:39:07.686810 24897 net.cpp:774] Copying source layer res3d_branch2c
I0312 16:39:07.686864 24897 net.cpp:774] Copying source layer bn3d_branch2c
I0312 16:39:07.686872 24897 net.cpp:774] Copying source layer scale3d_branch2c
I0312 16:39:07.686875 24897 net.cpp:774] Copying source layer res3d
I0312 16:39:07.686878 24897 net.cpp:774] Copying source layer res3d_relu
I0312 16:39:07.686882 24897 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0312 16:39:07.686884 24897 net.cpp:774] Copying source layer res4a_branch1
I0312 16:39:07.687381 24897 net.cpp:774] Copying source layer bn4a_branch1
I0312 16:39:07.687389 24897 net.cpp:774] Copying source layer scale4a_branch1
I0312 16:39:07.687396 24897 net.cpp:774] Copying source layer res4a_branch2a
I0312 16:39:07.687507 24897 net.cpp:774] Copying source layer bn4a_branch2a
I0312 16:39:07.687515 24897 net.cpp:774] Copying source layer scale4a_branch2a
I0312 16:39:07.687518 24897 net.cpp:774] Copying source layer res4a_branch2a_relu
I0312 16:39:07.687521 24897 net.cpp:774] Copying source layer res4a_branch2b
I0312 16:39:07.687986 24897 net.cpp:774] Copying source layer bn4a_branch2b
I0312 16:39:07.687994 24897 net.cpp:774] Copying source layer scale4a_branch2b
I0312 16:39:07.687997 24897 net.cpp:774] Copying source layer res4a_branch2b_relu
I0312 16:39:07.688001 24897 net.cpp:774] Copying source layer res4a_branch2c
I0312 16:39:07.688221 24897 net.cpp:774] Copying source layer bn4a_branch2c
I0312 16:39:07.688230 24897 net.cpp:774] Copying source layer scale4a_branch2c
I0312 16:39:07.688236 24897 net.cpp:774] Copying source layer res4a
I0312 16:39:07.688239 24897 net.cpp:774] Copying source layer res4a_relu
I0312 16:39:07.688242 24897 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0312 16:39:07.688246 24897 net.cpp:774] Copying source layer res4b_branch2a
I0312 16:39:07.688452 24897 net.cpp:774] Copying source layer bn4b_branch2a
I0312 16:39:07.688458 24897 net.cpp:774] Copying source layer scale4b_branch2a
I0312 16:39:07.688462 24897 net.cpp:774] Copying source layer res4b_branch2a_relu
I0312 16:39:07.688465 24897 net.cpp:774] Copying source layer res4b_branch2b
I0312 16:39:07.688948 24897 net.cpp:774] Copying source layer bn4b_branch2b
I0312 16:39:07.688956 24897 net.cpp:774] Copying source layer scale4b_branch2b
I0312 16:39:07.688959 24897 net.cpp:774] Copying source layer res4b_branch2b_relu
I0312 16:39:07.688962 24897 net.cpp:774] Copying source layer res4b_branch2c
I0312 16:39:07.689172 24897 net.cpp:774] Copying source layer bn4b_branch2c
I0312 16:39:07.689180 24897 net.cpp:774] Copying source layer scale4b_branch2c
I0312 16:39:07.689185 24897 net.cpp:774] Copying source layer res4b
I0312 16:39:07.689188 24897 net.cpp:774] Copying source layer res4b_relu
I0312 16:39:07.689191 24897 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0312 16:39:07.689193 24897 net.cpp:774] Copying source layer res4c_branch2a
I0312 16:39:07.689420 24897 net.cpp:774] Copying source layer bn4c_branch2a
I0312 16:39:07.689427 24897 net.cpp:774] Copying source layer scale4c_branch2a
I0312 16:39:07.689432 24897 net.cpp:774] Copying source layer res4c_branch2a_relu
I0312 16:39:07.689435 24897 net.cpp:774] Copying source layer res4c_branch2b
I0312 16:39:07.689908 24897 net.cpp:774] Copying source layer bn4c_branch2b
I0312 16:39:07.689915 24897 net.cpp:774] Copying source layer scale4c_branch2b
I0312 16:39:07.689920 24897 net.cpp:774] Copying source layer res4c_branch2b_relu
I0312 16:39:07.689923 24897 net.cpp:774] Copying source layer res4c_branch2c
I0312 16:39:07.690138 24897 net.cpp:774] Copying source layer bn4c_branch2c
I0312 16:39:07.690145 24897 net.cpp:774] Copying source layer scale4c_branch2c
I0312 16:39:07.690151 24897 net.cpp:774] Copying source layer res4c
I0312 16:39:07.690153 24897 net.cpp:774] Copying source layer res4c_relu
I0312 16:39:07.690156 24897 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0312 16:39:07.690160 24897 net.cpp:774] Copying source layer res4d_branch2a
I0312 16:39:07.690366 24897 net.cpp:774] Copying source layer bn4d_branch2a
I0312 16:39:07.690371 24897 net.cpp:774] Copying source layer scale4d_branch2a
I0312 16:39:07.690376 24897 net.cpp:774] Copying source layer res4d_branch2a_relu
I0312 16:39:07.690378 24897 net.cpp:774] Copying source layer res4d_branch2b
I0312 16:39:07.690865 24897 net.cpp:774] Copying source layer bn4d_branch2b
I0312 16:39:07.690871 24897 net.cpp:774] Copying source layer scale4d_branch2b
I0312 16:39:07.690876 24897 net.cpp:774] Copying source layer res4d_branch2b_relu
I0312 16:39:07.690878 24897 net.cpp:774] Copying source layer res4d_branch2c
I0312 16:39:07.691087 24897 net.cpp:774] Copying source layer bn4d_branch2c
I0312 16:39:07.691094 24897 net.cpp:774] Copying source layer scale4d_branch2c
I0312 16:39:07.691099 24897 net.cpp:774] Copying source layer res4d
I0312 16:39:07.691102 24897 net.cpp:774] Copying source layer res4d_relu
I0312 16:39:07.691105 24897 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0312 16:39:07.691108 24897 net.cpp:774] Copying source layer res4e_branch2a
I0312 16:39:07.691323 24897 net.cpp:774] Copying source layer bn4e_branch2a
I0312 16:39:07.691329 24897 net.cpp:774] Copying source layer scale4e_branch2a
I0312 16:39:07.691334 24897 net.cpp:774] Copying source layer res4e_branch2a_relu
I0312 16:39:07.691336 24897 net.cpp:774] Copying source layer res4e_branch2b
I0312 16:39:07.691798 24897 net.cpp:774] Copying source layer bn4e_branch2b
I0312 16:39:07.691804 24897 net.cpp:774] Copying source layer scale4e_branch2b
I0312 16:39:07.691809 24897 net.cpp:774] Copying source layer res4e_branch2b_relu
I0312 16:39:07.691812 24897 net.cpp:774] Copying source layer res4e_branch2c
I0312 16:39:07.692034 24897 net.cpp:774] Copying source layer bn4e_branch2c
I0312 16:39:07.692041 24897 net.cpp:774] Copying source layer scale4e_branch2c
I0312 16:39:07.692047 24897 net.cpp:774] Copying source layer res4e
I0312 16:39:07.692050 24897 net.cpp:774] Copying source layer res4e_relu
I0312 16:39:07.692054 24897 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0312 16:39:07.692056 24897 net.cpp:774] Copying source layer res4f_branch2a
I0312 16:39:07.692271 24897 net.cpp:774] Copying source layer bn4f_branch2a
I0312 16:39:07.692277 24897 net.cpp:774] Copying source layer scale4f_branch2a
I0312 16:39:07.692282 24897 net.cpp:774] Copying source layer res4f_branch2a_relu
I0312 16:39:07.692284 24897 net.cpp:774] Copying source layer res4f_branch2b
I0312 16:39:07.692764 24897 net.cpp:774] Copying source layer bn4f_branch2b
I0312 16:39:07.692771 24897 net.cpp:774] Copying source layer scale4f_branch2b
I0312 16:39:07.692775 24897 net.cpp:774] Copying source layer res4f_branch2b_relu
I0312 16:39:07.692778 24897 net.cpp:774] Copying source layer res4f_branch2c
I0312 16:39:07.692991 24897 net.cpp:774] Copying source layer bn4f_branch2c
I0312 16:39:07.692997 24897 net.cpp:774] Copying source layer scale4f_branch2c
I0312 16:39:07.693002 24897 net.cpp:774] Copying source layer res4f
I0312 16:39:07.693006 24897 net.cpp:774] Copying source layer res4f_relu
I0312 16:39:07.693009 24897 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0312 16:39:07.693012 24897 net.cpp:774] Copying source layer res5a_branch1
I0312 16:39:07.694730 24897 net.cpp:774] Copying source layer bn5a_branch1
I0312 16:39:07.694741 24897 net.cpp:774] Copying source layer scale5a_branch1
I0312 16:39:07.694747 24897 net.cpp:774] Copying source layer res5a_branch2a
I0312 16:39:07.695169 24897 net.cpp:774] Copying source layer bn5a_branch2a
I0312 16:39:07.695176 24897 net.cpp:774] Copying source layer scale5a_branch2a
I0312 16:39:07.695181 24897 net.cpp:774] Copying source layer res5a_branch2a_relu
I0312 16:39:07.695185 24897 net.cpp:774] Copying source layer res5a_branch2b
I0312 16:39:07.697124 24897 net.cpp:774] Copying source layer bn5a_branch2b
I0312 16:39:07.697134 24897 net.cpp:774] Copying source layer scale5a_branch2b
I0312 16:39:07.697139 24897 net.cpp:774] Copying source layer res5a_branch2b_relu
I0312 16:39:07.697141 24897 net.cpp:774] Copying source layer res5a_branch2c
I0312 16:39:07.698076 24897 net.cpp:774] Copying source layer bn5a_branch2c
I0312 16:39:07.698087 24897 net.cpp:774] Copying source layer scale5a_branch2c
I0312 16:39:07.698096 24897 net.cpp:774] Copying source layer res5a
I0312 16:39:07.698099 24897 net.cpp:774] Copying source layer res5a_relu
I0312 16:39:07.698102 24897 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0312 16:39:07.698105 24897 net.cpp:774] Copying source layer res5b_branch2a
I0312 16:39:07.699237 24897 net.cpp:774] Copying source layer bn5b_branch2a
I0312 16:39:07.699250 24897 net.cpp:774] Copying source layer scale5b_branch2a
I0312 16:39:07.699255 24897 net.cpp:774] Copying source layer res5b_branch2a_relu
I0312 16:39:07.699259 24897 net.cpp:774] Copying source layer res5b_branch2b
I0312 16:39:07.701704 24897 net.cpp:774] Copying source layer bn5b_branch2b
I0312 16:39:07.701726 24897 net.cpp:774] Copying source layer scale5b_branch2b
I0312 16:39:07.701732 24897 net.cpp:774] Copying source layer res5b_branch2b_relu
I0312 16:39:07.701735 24897 net.cpp:774] Copying source layer res5b_branch2c
I0312 16:39:07.703197 24897 net.cpp:774] Copying source layer bn5b_branch2c
I0312 16:39:07.703222 24897 net.cpp:774] Copying source layer scale5b_branch2c
I0312 16:39:07.703233 24897 net.cpp:774] Copying source layer res5b
I0312 16:39:07.703235 24897 net.cpp:774] Copying source layer res5b_relu
I0312 16:39:07.703240 24897 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0312 16:39:07.703244 24897 net.cpp:774] Copying source layer res5c_branch2a
I0312 16:39:07.704886 24897 net.cpp:774] Copying source layer bn5c_branch2a
I0312 16:39:07.704903 24897 net.cpp:774] Copying source layer scale5c_branch2a
I0312 16:39:07.704910 24897 net.cpp:774] Copying source layer res5c_branch2a_relu
I0312 16:39:07.704915 24897 net.cpp:774] Copying source layer res5c_branch2b
I0312 16:39:07.708199 24897 net.cpp:774] Copying source layer bn5c_branch2b
I0312 16:39:07.708214 24897 net.cpp:774] Copying source layer scale5c_branch2b
I0312 16:39:07.708220 24897 net.cpp:774] Copying source layer res5c_branch2b_relu
I0312 16:39:07.708225 24897 net.cpp:774] Copying source layer res5c_branch2c
I0312 16:39:07.709178 24897 net.cpp:774] Copying source layer bn5c_branch2c
I0312 16:39:07.709195 24897 net.cpp:774] Copying source layer scale5c_branch2c
I0312 16:39:07.709203 24897 net.cpp:774] Copying source layer res5c
I0312 16:39:07.709206 24897 net.cpp:774] Copying source layer res5c_relu
I0312 16:39:07.709209 24897 net.cpp:774] Copying source layer rpn_conv/3x3
I0312 16:39:07.713832 24897 net.cpp:774] Copying source layer rpn_relu/3x3
I0312 16:39:07.713846 24897 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0312 16:39:07.713850 24897 net.cpp:774] Copying source layer rpn_cls_score
I0312 16:39:07.713863 24897 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0312 16:39:07.713866 24897 net.cpp:774] Copying source layer rpn_bbox_pred
I0312 16:39:07.713902 24897 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0312 16:39:07.713907 24897 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0312 16:39:07.713910 24897 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0312 16:39:07.713912 24897 net.cpp:771] Ignoring source layer rpn-data
I0312 16:39:07.713915 24897 net.cpp:771] Ignoring source layer rpn_loss_cls
I0312 16:39:07.713919 24897 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0312 16:39:07.713922 24897 net.cpp:774] Copying source layer rpn_cls_prob
I0312 16:39:07.713924 24897 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0312 16:39:07.713927 24897 net.cpp:774] Copying source layer proposal
I0312 16:39:07.713930 24897 net.cpp:771] Ignoring source layer roi-data
I0312 16:39:07.713933 24897 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0312 16:39:07.713937 24897 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0312 16:39:07.713938 24897 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0312 16:39:07.713941 24897 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0312 16:39:07.713944 24897 net.cpp:774] Copying source layer conv_new_1
I0312 16:39:07.716127 24897 net.cpp:774] Copying source layer conv_new_1_relu
I0312 16:39:07.716136 24897 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0312 16:39:07.716140 24897 net.cpp:774] Copying source layer rfcn_cls
I0312 16:39:07.716243 24897 net.cpp:774] Copying source layer rfcn_bbox
I0312 16:39:07.716622 24897 net.cpp:774] Copying source layer psroipooled_cls_rois
I0312 16:39:07.716627 24897 net.cpp:774] Copying source layer ave_cls_score_rois
I0312 16:39:07.716630 24897 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0312 16:39:07.716634 24897 net.cpp:774] Copying source layer psroipooled_loc_rois
I0312 16:39:07.716636 24897 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0312 16:39:07.716639 24897 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0312 16:39:07.716645 24897 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0312 16:39:07.716647 24897 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0312 16:39:07.716650 24897 net.cpp:771] Ignoring source layer per_roi_loss
I0312 16:39:07.716652 24897 net.cpp:771] Ignoring source layer annotator_detector
I0312 16:39:07.716655 24897 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0312 16:39:07.716658 24897 net.cpp:771] Ignoring source layer silence
I0312 16:39:07.716660 24897 net.cpp:771] Ignoring source layer loss
I0312 16:39:07.716663 24897 net.cpp:771] Ignoring source layer accuarcy
I0312 16:39:07.716666 24897 net.cpp:771] Ignoring source layer loss_bbox
im_detect: 1/1297 0.759s 0.000s
im_detect: 2/1297 0.444s 0.000s
im_detect: 3/1297 0.342s 0.000s
im_detect: 4/1297 0.312s 0.000s
im_detect: 5/1297 0.274s 0.000s
im_detect: 6/1297 0.251s 0.000s
im_detect: 7/1297 0.235s 0.000s
im_detect: 8/1297 0.223s 0.000s
im_detect: 9/1297 0.214s 0.000s
im_detect: 10/1297 0.207s 0.000s
im_detect: 11/1297 0.200s 0.000s
im_detect: 12/1297 0.195s 0.000s
im_detect: 13/1297 0.191s 0.000s
im_detect: 14/1297 0.187s 0.000s
im_detect: 15/1297 0.183s 0.000s
im_detect: 16/1297 0.180s 0.000s
im_detect: 17/1297 0.178s 0.000s
im_detect: 18/1297 0.175s 0.000s
im_detect: 19/1297 0.173s 0.000s
im_detect: 20/1297 0.172s 0.000s
im_detect: 21/1297 0.170s 0.000s
im_detect: 22/1297 0.169s 0.000s
im_detect: 23/1297 0.168s 0.000s
im_detect: 24/1297 0.166s 0.000s
im_detect: 25/1297 0.165s 0.000s
im_detect: 26/1297 0.164s 0.000s
im_detect: 27/1297 0.163s 0.000s
im_detect: 28/1297 0.162s 0.000s
im_detect: 29/1297 0.161s 0.000s
im_detect: 30/1297 0.160s 0.000s
im_detect: 31/1297 0.159s 0.000s
im_detect: 32/1297 0.158s 0.000s
im_detect: 33/1297 0.158s 0.000s
im_detect: 34/1297 0.157s 0.000s
im_detect: 35/1297 0.157s 0.000s
im_detect: 36/1297 0.156s 0.000s
im_detect: 37/1297 0.155s 0.000s
im_detect: 38/1297 0.155s 0.000s
im_detect: 39/1297 0.154s 0.000s
im_detect: 40/1297 0.154s 0.000s
im_detect: 41/1297 0.154s 0.000s
im_detect: 42/1297 0.153s 0.000s
im_detect: 43/1297 0.153s 0.000s
im_detect: 44/1297 0.152s 0.000s
im_detect: 45/1297 0.152s 0.000s
im_detect: 46/1297 0.152s 0.000s
im_detect: 47/1297 0.151s 0.000s
im_detect: 48/1297 0.151s 0.000s
im_detect: 49/1297 0.151s 0.000s
im_detect: 50/1297 0.151s 0.000s
im_detect: 51/1297 0.150s 0.000s
im_detect: 52/1297 0.150s 0.000s
im_detect: 53/1297 0.150s 0.000s
im_detect: 54/1297 0.149s 0.000s
im_detect: 55/1297 0.149s 0.000s
im_detect: 56/1297 0.149s 0.000s
im_detect: 57/1297 0.149s 0.000s
im_detect: 58/1297 0.148s 0.000s
im_detect: 59/1297 0.148s 0.000s
im_detect: 60/1297 0.148s 0.000s
im_detect: 61/1297 0.148s 0.000s
im_detect: 62/1297 0.148s 0.000s
im_detect: 63/1297 0.147s 0.000s
im_detect: 64/1297 0.147s 0.000s
im_detect: 65/1297 0.147s 0.000s
im_detect: 66/1297 0.147s 0.000s
im_detect: 67/1297 0.146s 0.000s
im_detect: 68/1297 0.146s 0.000s
im_detect: 69/1297 0.146s 0.000s
im_detect: 70/1297 0.146s 0.000s
im_detect: 71/1297 0.146s 0.000s
im_detect: 72/1297 0.146s 0.000s
im_detect: 73/1297 0.146s 0.000s
im_detect: 74/1297 0.145s 0.000s
im_detect: 75/1297 0.145s 0.000s
im_detect: 76/1297 0.145s 0.000s
im_detect: 77/1297 0.145s 0.000s
im_detect: 78/1297 0.145s 0.000s
im_detect: 79/1297 0.145s 0.000s
im_detect: 80/1297 0.145s 0.000s
im_detect: 81/1297 0.145s 0.000s
im_detect: 82/1297 0.144s 0.000s
im_detect: 83/1297 0.144s 0.000s
im_detect: 84/1297 0.144s 0.000s
im_detect: 85/1297 0.144s 0.000s
im_detect: 86/1297 0.144s 0.000s
im_detect: 87/1297 0.144s 0.000s
im_detect: 88/1297 0.144s 0.000s
im_detect: 89/1297 0.144s 0.000s
im_detect: 90/1297 0.144s 0.000s
im_detect: 91/1297 0.144s 0.000s
im_detect: 92/1297 0.144s 0.000s
im_detect: 93/1297 0.144s 0.000s
im_detect: 94/1297 0.143s 0.000s
im_detect: 95/1297 0.143s 0.000s
im_detect: 96/1297 0.143s 0.000s
im_detect: 97/1297 0.143s 0.000s
im_detect: 98/1297 0.143s 0.000s
im_detect: 99/1297 0.143s 0.000s
im_detect: 100/1297 0.143s 0.000s
im_detect: 101/1297 0.143s 0.000s
im_detect: 102/1297 0.143s 0.000s
im_detect: 103/1297 0.143s 0.000s
im_detect: 104/1297 0.143s 0.000s
im_detect: 105/1297 0.143s 0.000s
im_detect: 106/1297 0.142s 0.000s
im_detect: 107/1297 0.142s 0.000s
im_detect: 108/1297 0.142s 0.000s
im_detect: 109/1297 0.142s 0.000s
im_detect: 110/1297 0.142s 0.000s
im_detect: 111/1297 0.142s 0.000s
im_detect: 112/1297 0.142s 0.000s
im_detect: 113/1297 0.142s 0.000s
im_detect: 114/1297 0.142s 0.000s
im_detect: 115/1297 0.142s 0.000s
im_detect: 116/1297 0.142s 0.000s
im_detect: 117/1297 0.142s 0.000s
im_detect: 118/1297 0.142s 0.000s
im_detect: 119/1297 0.142s 0.000s
im_detect: 120/1297 0.142s 0.000s
im_detect: 121/1297 0.142s 0.000s
im_detect: 122/1297 0.141s 0.000s
im_detect: 123/1297 0.141s 0.000s
im_detect: 124/1297 0.141s 0.000s
im_detect: 125/1297 0.141s 0.000s
im_detect: 126/1297 0.141s 0.000s
im_detect: 127/1297 0.141s 0.000s
im_detect: 128/1297 0.141s 0.000s
im_detect: 129/1297 0.141s 0.000s
im_detect: 130/1297 0.141s 0.000s
im_detect: 131/1297 0.141s 0.000s
im_detect: 132/1297 0.141s 0.000s
im_detect: 133/1297 0.141s 0.000s
im_detect: 134/1297 0.141s 0.000s
im_detect: 135/1297 0.141s 0.000s
im_detect: 136/1297 0.141s 0.000s
im_detect: 137/1297 0.141s 0.000s
im_detect: 138/1297 0.141s 0.000s
im_detect: 139/1297 0.141s 0.000s
im_detect: 140/1297 0.141s 0.000s
im_detect: 141/1297 0.141s 0.000s
im_detect: 142/1297 0.141s 0.000s
im_detect: 143/1297 0.141s 0.000s
im_detect: 144/1297 0.141s 0.000s
im_detect: 145/1297 0.141s 0.000s
im_detect: 146/1297 0.141s 0.000s
im_detect: 147/1297 0.141s 0.000s
im_detect: 148/1297 0.141s 0.000s
im_detect: 149/1297 0.141s 0.000s
im_detect: 150/1297 0.141s 0.000s
im_detect: 151/1297 0.141s 0.000s
im_detect: 152/1297 0.140s 0.000s
im_detect: 153/1297 0.140s 0.000s
im_detect: 154/1297 0.140s 0.000s
im_detect: 155/1297 0.140s 0.000s
im_detect: 156/1297 0.140s 0.000s
im_detect: 157/1297 0.140s 0.000s
im_detect: 158/1297 0.140s 0.000s
im_detect: 159/1297 0.140s 0.000s
im_detect: 160/1297 0.140s 0.000s
im_detect: 161/1297 0.140s 0.000s
im_detect: 162/1297 0.140s 0.000s
im_detect: 163/1297 0.140s 0.000s
im_detect: 164/1297 0.140s 0.000s
im_detect: 165/1297 0.140s 0.000s
im_detect: 166/1297 0.140s 0.000s
im_detect: 167/1297 0.140s 0.000s
im_detect: 168/1297 0.140s 0.000s
im_detect: 169/1297 0.140s 0.000s
im_detect: 170/1297 0.140s 0.000s
im_detect: 171/1297 0.140s 0.000s
im_detect: 172/1297 0.140s 0.000s
im_detect: 173/1297 0.140s 0.000s
im_detect: 174/1297 0.140s 0.000s
im_detect: 175/1297 0.140s 0.000s
im_detect: 176/1297 0.139s 0.000s
im_detect: 177/1297 0.139s 0.000s
im_detect: 178/1297 0.139s 0.000s
im_detect: 179/1297 0.139s 0.000s
im_detect: 180/1297 0.139s 0.000s
im_detect: 181/1297 0.139s 0.000s
im_detect: 182/1297 0.139s 0.000s
im_detect: 183/1297 0.139s 0.000s
im_detect: 184/1297 0.139s 0.000s
im_detect: 185/1297 0.139s 0.000s
im_detect: 186/1297 0.139s 0.000s
im_detect: 187/1297 0.139s 0.000s
im_detect: 188/1297 0.139s 0.000s
im_detect: 189/1297 0.139s 0.000s
im_detect: 190/1297 0.139s 0.000s
im_detect: 191/1297 0.139s 0.000s
im_detect: 192/1297 0.139s 0.000s
im_detect: 193/1297 0.139s 0.000s
im_detect: 194/1297 0.139s 0.000s
im_detect: 195/1297 0.139s 0.000s
im_detect: 196/1297 0.139s 0.000s
im_detect: 197/1297 0.139s 0.000s
im_detect: 198/1297 0.139s 0.000s
im_detect: 199/1297 0.139s 0.000s
im_detect: 200/1297 0.139s 0.000s
im_detect: 201/1297 0.139s 0.000s
im_detect: 202/1297 0.139s 0.000s
im_detect: 203/1297 0.139s 0.000s
im_detect: 204/1297 0.139s 0.000s
im_detect: 205/1297 0.139s 0.000s
im_detect: 206/1297 0.139s 0.000s
im_detect: 207/1297 0.139s 0.000s
im_detect: 208/1297 0.139s 0.000s
im_detect: 209/1297 0.139s 0.000s
im_detect: 210/1297 0.139s 0.000s
im_detect: 211/1297 0.139s 0.000s
im_detect: 212/1297 0.139s 0.000s
im_detect: 213/1297 0.139s 0.000s
im_detect: 214/1297 0.139s 0.000s
im_detect: 215/1297 0.139s 0.000s
im_detect: 216/1297 0.139s 0.000s
im_detect: 217/1297 0.139s 0.000s
im_detect: 218/1297 0.139s 0.000s
im_detect: 219/1297 0.139s 0.000s
im_detect: 220/1297 0.139s 0.000s
im_detect: 221/1297 0.139s 0.000s
im_detect: 222/1297 0.139s 0.000s
im_detect: 223/1297 0.139s 0.000s
im_detect: 224/1297 0.139s 0.000s
im_detect: 225/1297 0.139s 0.000s
im_detect: 226/1297 0.139s 0.000s
im_detect: 227/1297 0.139s 0.000s
im_detect: 228/1297 0.139s 0.000s
im_detect: 229/1297 0.139s 0.000s
im_detect: 230/1297 0.139s 0.000s
im_detect: 231/1297 0.139s 0.000s
im_detect: 232/1297 0.139s 0.000s
im_detect: 233/1297 0.139s 0.000s
im_detect: 234/1297 0.139s 0.000s
im_detect: 235/1297 0.139s 0.000s
im_detect: 236/1297 0.139s 0.000s
im_detect: 237/1297 0.139s 0.000s
im_detect: 238/1297 0.139s 0.000s
im_detect: 239/1297 0.139s 0.000s
im_detect: 240/1297 0.138s 0.000s
im_detect: 241/1297 0.138s 0.000s
im_detect: 242/1297 0.139s 0.000s
im_detect: 243/1297 0.139s 0.000s
im_detect: 244/1297 0.139s 0.000s
im_detect: 245/1297 0.138s 0.000s
im_detect: 246/1297 0.138s 0.000s
im_detect: 247/1297 0.138s 0.000s
im_detect: 248/1297 0.138s 0.000s
im_detect: 249/1297 0.138s 0.000s
im_detect: 250/1297 0.138s 0.000s
im_detect: 251/1297 0.138s 0.000s
im_detect: 252/1297 0.138s 0.000s
im_detect: 253/1297 0.138s 0.000s
im_detect: 254/1297 0.138s 0.000s
im_detect: 255/1297 0.138s 0.000s
im_detect: 256/1297 0.138s 0.000s
im_detect: 257/1297 0.138s 0.000s
im_detect: 258/1297 0.138s 0.000s
im_detect: 259/1297 0.138s 0.000s
im_detect: 260/1297 0.138s 0.000s
im_detect: 261/1297 0.138s 0.000s
im_detect: 262/1297 0.138s 0.000s
im_detect: 263/1297 0.138s 0.000s
im_detect: 264/1297 0.138s 0.000s
im_detect: 265/1297 0.138s 0.000s
im_detect: 266/1297 0.138s 0.000s
im_detect: 267/1297 0.138s 0.000s
im_detect: 268/1297 0.138s 0.000s
im_detect: 269/1297 0.138s 0.000s
im_detect: 270/1297 0.138s 0.000s
im_detect: 271/1297 0.138s 0.000s
im_detect: 272/1297 0.138s 0.000s
im_detect: 273/1297 0.138s 0.000s
im_detect: 274/1297 0.138s 0.000s
im_detect: 275/1297 0.138s 0.000s
im_detect: 276/1297 0.138s 0.000s
im_detect: 277/1297 0.138s 0.000s
im_detect: 278/1297 0.138s 0.000s
im_detect: 279/1297 0.138s 0.000s
im_detect: 280/1297 0.138s 0.000s
im_detect: 281/1297 0.138s 0.000s
im_detect: 282/1297 0.138s 0.000s
im_detect: 283/1297 0.138s 0.000s
im_detect: 284/1297 0.138s 0.000s
im_detect: 285/1297 0.138s 0.000s
im_detect: 286/1297 0.138s 0.000s
im_detect: 287/1297 0.138s 0.000s
im_detect: 288/1297 0.138s 0.000s
im_detect: 289/1297 0.138s 0.000s
im_detect: 290/1297 0.138s 0.000s
im_detect: 291/1297 0.138s 0.000s
im_detect: 292/1297 0.138s 0.000s
im_detect: 293/1297 0.138s 0.000s
im_detect: 294/1297 0.138s 0.000s
im_detect: 295/1297 0.138s 0.000s
im_detect: 296/1297 0.138s 0.000s
im_detect: 297/1297 0.138s 0.000s
im_detect: 298/1297 0.138s 0.000s
im_detect: 299/1297 0.138s 0.000s
im_detect: 300/1297 0.138s 0.000s
im_detect: 301/1297 0.138s 0.000s
im_detect: 302/1297 0.138s 0.000s
im_detect: 303/1297 0.138s 0.000s
im_detect: 304/1297 0.138s 0.000s
im_detect: 305/1297 0.138s 0.000s
im_detect: 306/1297 0.138s 0.000s
im_detect: 307/1297 0.138s 0.000s
im_detect: 308/1297 0.138s 0.000s
im_detect: 309/1297 0.138s 0.000s
im_detect: 310/1297 0.138s 0.000s
im_detect: 311/1297 0.138s 0.000s
im_detect: 312/1297 0.138s 0.000s
im_detect: 313/1297 0.138s 0.000s
im_detect: 314/1297 0.138s 0.000s
im_detect: 315/1297 0.138s 0.000s
im_detect: 316/1297 0.138s 0.000s
im_detect: 317/1297 0.138s 0.000s
im_detect: 318/1297 0.138s 0.000s
im_detect: 319/1297 0.138s 0.000s
im_detect: 320/1297 0.138s 0.000s
im_detect: 321/1297 0.138s 0.000s
im_detect: 322/1297 0.138s 0.000s
im_detect: 323/1297 0.138s 0.000s
im_detect: 324/1297 0.138s 0.000s
im_detect: 325/1297 0.138s 0.000s
im_detect: 326/1297 0.138s 0.000s
im_detect: 327/1297 0.138s 0.000s
im_detect: 328/1297 0.138s 0.000s
im_detect: 329/1297 0.138s 0.000s
im_detect: 330/1297 0.138s 0.000s
im_detect: 331/1297 0.138s 0.000s
im_detect: 332/1297 0.138s 0.000s
im_detect: 333/1297 0.138s 0.000s
im_detect: 334/1297 0.138s 0.000s
im_detect: 335/1297 0.138s 0.000s
im_detect: 336/1297 0.138s 0.000s
im_detect: 337/1297 0.138s 0.000s
im_detect: 338/1297 0.138s 0.000s
im_detect: 339/1297 0.138s 0.000s
im_detect: 340/1297 0.138s 0.000s
im_detect: 341/1297 0.138s 0.000s
im_detect: 342/1297 0.138s 0.000s
im_detect: 343/1297 0.138s 0.000s
im_detect: 344/1297 0.138s 0.000s
im_detect: 345/1297 0.138s 0.000s
im_detect: 346/1297 0.138s 0.000s
im_detect: 347/1297 0.138s 0.000s
im_detect: 348/1297 0.138s 0.000s
im_detect: 349/1297 0.138s 0.000s
im_detect: 350/1297 0.138s 0.000s
im_detect: 351/1297 0.138s 0.000s
im_detect: 352/1297 0.138s 0.000s
im_detect: 353/1297 0.138s 0.000s
im_detect: 354/1297 0.138s 0.000s
im_detect: 355/1297 0.138s 0.000s
im_detect: 356/1297 0.138s 0.000s
im_detect: 357/1297 0.138s 0.000s
im_detect: 358/1297 0.138s 0.000s
im_detect: 359/1297 0.138s 0.000s
im_detect: 360/1297 0.138s 0.000s
im_detect: 361/1297 0.138s 0.000s
im_detect: 362/1297 0.138s 0.000s
im_detect: 363/1297 0.138s 0.000s
im_detect: 364/1297 0.138s 0.000s
im_detect: 365/1297 0.138s 0.000s
im_detect: 366/1297 0.138s 0.000s
im_detect: 367/1297 0.138s 0.000s
im_detect: 368/1297 0.138s 0.000s
im_detect: 369/1297 0.138s 0.000s
im_detect: 370/1297 0.138s 0.000s
im_detect: 371/1297 0.138s 0.000s
im_detect: 372/1297 0.138s 0.000s
im_detect: 373/1297 0.138s 0.000s
im_detect: 374/1297 0.138s 0.000s
im_detect: 375/1297 0.138s 0.000s
im_detect: 376/1297 0.138s 0.000s
im_detect: 377/1297 0.138s 0.000s
im_detect: 378/1297 0.138s 0.000s
im_detect: 379/1297 0.138s 0.000s
im_detect: 380/1297 0.138s 0.000s
im_detect: 381/1297 0.138s 0.000s
im_detect: 382/1297 0.138s 0.000s
im_detect: 383/1297 0.138s 0.000s
im_detect: 384/1297 0.138s 0.000s
im_detect: 385/1297 0.138s 0.000s
im_detect: 386/1297 0.138s 0.000s
im_detect: 387/1297 0.138s 0.000s
im_detect: 388/1297 0.138s 0.000s
im_detect: 389/1297 0.138s 0.000s
im_detect: 390/1297 0.138s 0.000s
im_detect: 391/1297 0.138s 0.000s
im_detect: 392/1297 0.138s 0.000s
im_detect: 393/1297 0.138s 0.000s
im_detect: 394/1297 0.138s 0.000s
im_detect: 395/1297 0.138s 0.000s
im_detect: 396/1297 0.138s 0.000s
im_detect: 397/1297 0.138s 0.000s
im_detect: 398/1297 0.138s 0.000s
im_detect: 399/1297 0.138s 0.000s
im_detect: 400/1297 0.138s 0.000s
im_detect: 401/1297 0.138s 0.000s
im_detect: 402/1297 0.138s 0.000s
im_detect: 403/1297 0.138s 0.000s
im_detect: 404/1297 0.138s 0.000s
im_detect: 405/1297 0.138s 0.000s
im_detect: 406/1297 0.138s 0.000s
im_detect: 407/1297 0.138s 0.000s
im_detect: 408/1297 0.138s 0.000s
im_detect: 409/1297 0.137s 0.000s
im_detect: 410/1297 0.137s 0.000s
im_detect: 411/1297 0.137s 0.000s
im_detect: 412/1297 0.137s 0.000s
im_detect: 413/1297 0.137s 0.000s
im_detect: 414/1297 0.137s 0.000s
im_detect: 415/1297 0.137s 0.000s
im_detect: 416/1297 0.137s 0.000s
im_detect: 417/1297 0.137s 0.000s
im_detect: 418/1297 0.137s 0.000s
im_detect: 419/1297 0.137s 0.000s
im_detect: 420/1297 0.137s 0.000s
im_detect: 421/1297 0.137s 0.000s
im_detect: 422/1297 0.137s 0.000s
im_detect: 423/1297 0.137s 0.000s
im_detect: 424/1297 0.137s 0.000s
im_detect: 425/1297 0.137s 0.000s
im_detect: 426/1297 0.137s 0.000s
im_detect: 427/1297 0.137s 0.000s
im_detect: 428/1297 0.137s 0.000s
im_detect: 429/1297 0.137s 0.000s
im_detect: 430/1297 0.137s 0.000s
im_detect: 431/1297 0.137s 0.000s
im_detect: 432/1297 0.137s 0.000s
im_detect: 433/1297 0.137s 0.000s
im_detect: 434/1297 0.137s 0.000s
im_detect: 435/1297 0.137s 0.000s
im_detect: 436/1297 0.137s 0.000s
im_detect: 437/1297 0.137s 0.000s
im_detect: 438/1297 0.137s 0.000s
im_detect: 439/1297 0.137s 0.000s
im_detect: 440/1297 0.137s 0.000s
im_detect: 441/1297 0.137s 0.000s
im_detect: 442/1297 0.137s 0.000s
im_detect: 443/1297 0.137s 0.000s
im_detect: 444/1297 0.137s 0.000s
im_detect: 445/1297 0.137s 0.000s
im_detect: 446/1297 0.137s 0.000s
im_detect: 447/1297 0.137s 0.000s
im_detect: 448/1297 0.137s 0.000s
im_detect: 449/1297 0.137s 0.000s
im_detect: 450/1297 0.137s 0.000s
im_detect: 451/1297 0.137s 0.000s
im_detect: 452/1297 0.137s 0.000s
im_detect: 453/1297 0.137s 0.000s
im_detect: 454/1297 0.137s 0.000s
im_detect: 455/1297 0.137s 0.000s
im_detect: 456/1297 0.137s 0.000s
im_detect: 457/1297 0.137s 0.000s
im_detect: 458/1297 0.137s 0.000s
im_detect: 459/1297 0.137s 0.000s
im_detect: 460/1297 0.137s 0.000s
im_detect: 461/1297 0.137s 0.000s
im_detect: 462/1297 0.137s 0.000s
im_detect: 463/1297 0.137s 0.000s
im_detect: 464/1297 0.137s 0.000s
im_detect: 465/1297 0.137s 0.000s
im_detect: 466/1297 0.137s 0.000s
im_detect: 467/1297 0.137s 0.000s
im_detect: 468/1297 0.137s 0.000s
im_detect: 469/1297 0.137s 0.000s
im_detect: 470/1297 0.137s 0.000s
im_detect: 471/1297 0.137s 0.000s
im_detect: 472/1297 0.137s 0.000s
im_detect: 473/1297 0.137s 0.000s
im_detect: 474/1297 0.137s 0.000s
im_detect: 475/1297 0.137s 0.000s
im_detect: 476/1297 0.137s 0.000s
im_detect: 477/1297 0.137s 0.000s
im_detect: 478/1297 0.137s 0.000s
im_detect: 479/1297 0.137s 0.000s
im_detect: 480/1297 0.137s 0.000s
im_detect: 481/1297 0.137s 0.000s
im_detect: 482/1297 0.137s 0.000s
im_detect: 483/1297 0.137s 0.000s
im_detect: 484/1297 0.137s 0.000s
im_detect: 485/1297 0.137s 0.000s
im_detect: 486/1297 0.137s 0.000s
im_detect: 487/1297 0.137s 0.000s
im_detect: 488/1297 0.137s 0.000s
im_detect: 489/1297 0.137s 0.000s
im_detect: 490/1297 0.137s 0.000s
im_detect: 491/1297 0.137s 0.000s
im_detect: 492/1297 0.137s 0.000s
im_detect: 493/1297 0.137s 0.000s
im_detect: 494/1297 0.137s 0.000s
im_detect: 495/1297 0.137s 0.000s
im_detect: 496/1297 0.137s 0.000s
im_detect: 497/1297 0.137s 0.000s
im_detect: 498/1297 0.137s 0.000s
im_detect: 499/1297 0.137s 0.000s
im_detect: 500/1297 0.137s 0.000s
im_detect: 501/1297 0.137s 0.000s
im_detect: 502/1297 0.137s 0.000s
im_detect: 503/1297 0.137s 0.000s
im_detect: 504/1297 0.137s 0.000s
im_detect: 505/1297 0.137s 0.000s
im_detect: 506/1297 0.137s 0.000s
im_detect: 507/1297 0.137s 0.000s
im_detect: 508/1297 0.137s 0.000s
im_detect: 509/1297 0.137s 0.000s
im_detect: 510/1297 0.137s 0.000s
im_detect: 511/1297 0.137s 0.000s
im_detect: 512/1297 0.137s 0.000s
im_detect: 513/1297 0.137s 0.000s
im_detect: 514/1297 0.137s 0.000s
im_detect: 515/1297 0.137s 0.000s
im_detect: 516/1297 0.137s 0.000s
im_detect: 517/1297 0.137s 0.000s
im_detect: 518/1297 0.137s 0.000s
im_detect: 519/1297 0.137s 0.000s
im_detect: 520/1297 0.137s 0.000s
im_detect: 521/1297 0.137s 0.000s
im_detect: 522/1297 0.137s 0.000s
im_detect: 523/1297 0.137s 0.000s
im_detect: 524/1297 0.137s 0.000s
im_detect: 525/1297 0.137s 0.000s
im_detect: 526/1297 0.137s 0.000s
im_detect: 527/1297 0.137s 0.000s
im_detect: 528/1297 0.137s 0.000s
im_detect: 529/1297 0.137s 0.000s
im_detect: 530/1297 0.137s 0.000s
im_detect: 531/1297 0.137s 0.000s
im_detect: 532/1297 0.137s 0.000s
im_detect: 533/1297 0.137s 0.000s
im_detect: 534/1297 0.137s 0.000s
im_detect: 535/1297 0.137s 0.000s
im_detect: 536/1297 0.137s 0.000s
im_detect: 537/1297 0.137s 0.000s
im_detect: 538/1297 0.137s 0.000s
im_detect: 539/1297 0.137s 0.000s
im_detect: 540/1297 0.137s 0.000s
im_detect: 541/1297 0.137s 0.000s
im_detect: 542/1297 0.137s 0.000s
im_detect: 543/1297 0.137s 0.000s
im_detect: 544/1297 0.137s 0.000s
im_detect: 545/1297 0.137s 0.000s
im_detect: 546/1297 0.137s 0.000s
im_detect: 547/1297 0.137s 0.000s
im_detect: 548/1297 0.137s 0.000s
im_detect: 549/1297 0.137s 0.000s
im_detect: 550/1297 0.137s 0.000s
im_detect: 551/1297 0.137s 0.000s
im_detect: 552/1297 0.137s 0.000s
im_detect: 553/1297 0.137s 0.000s
im_detect: 554/1297 0.137s 0.000s
im_detect: 555/1297 0.137s 0.000s
im_detect: 556/1297 0.137s 0.000s
im_detect: 557/1297 0.137s 0.000s
im_detect: 558/1297 0.137s 0.000s
im_detect: 559/1297 0.137s 0.000s
im_detect: 560/1297 0.137s 0.000s
im_detect: 561/1297 0.137s 0.000s
im_detect: 562/1297 0.137s 0.000s
im_detect: 563/1297 0.137s 0.000s
im_detect: 564/1297 0.137s 0.000s
im_detect: 565/1297 0.137s 0.000s
im_detect: 566/1297 0.137s 0.000s
im_detect: 567/1297 0.137s 0.000s
im_detect: 568/1297 0.137s 0.000s
im_detect: 569/1297 0.137s 0.000s
im_detect: 570/1297 0.137s 0.000s
im_detect: 571/1297 0.137s 0.000s
im_detect: 572/1297 0.137s 0.000s
im_detect: 573/1297 0.137s 0.000s
im_detect: 574/1297 0.137s 0.000s
im_detect: 575/1297 0.137s 0.000s
im_detect: 576/1297 0.137s 0.000s
im_detect: 577/1297 0.137s 0.000s
im_detect: 578/1297 0.137s 0.000s
im_detect: 579/1297 0.137s 0.000s
im_detect: 580/1297 0.137s 0.000s
im_detect: 581/1297 0.137s 0.000s
im_detect: 582/1297 0.137s 0.000s
im_detect: 583/1297 0.137s 0.000s
im_detect: 584/1297 0.137s 0.000s
im_detect: 585/1297 0.137s 0.000s
im_detect: 586/1297 0.137s 0.000s
im_detect: 587/1297 0.137s 0.000s
im_detect: 588/1297 0.137s 0.000s
im_detect: 589/1297 0.137s 0.000s
im_detect: 590/1297 0.137s 0.000s
im_detect: 591/1297 0.137s 0.000s
im_detect: 592/1297 0.137s 0.000s
im_detect: 593/1297 0.137s 0.000s
im_detect: 594/1297 0.137s 0.000s
im_detect: 595/1297 0.137s 0.000s
im_detect: 596/1297 0.137s 0.000s
im_detect: 597/1297 0.137s 0.000s
im_detect: 598/1297 0.137s 0.000s
im_detect: 599/1297 0.137s 0.000s
im_detect: 600/1297 0.137s 0.000s
im_detect: 601/1297 0.137s 0.000s
im_detect: 602/1297 0.137s 0.000s
im_detect: 603/1297 0.137s 0.000s
im_detect: 604/1297 0.137s 0.000s
im_detect: 605/1297 0.137s 0.000s
im_detect: 606/1297 0.137s 0.000s
im_detect: 607/1297 0.137s 0.000s
im_detect: 608/1297 0.137s 0.000s
im_detect: 609/1297 0.137s 0.000s
im_detect: 610/1297 0.137s 0.000s
im_detect: 611/1297 0.137s 0.000s
im_detect: 612/1297 0.137s 0.000s
im_detect: 613/1297 0.137s 0.000s
im_detect: 614/1297 0.137s 0.000s
im_detect: 615/1297 0.137s 0.000s
im_detect: 616/1297 0.137s 0.000s
im_detect: 617/1297 0.137s 0.000s
im_detect: 618/1297 0.137s 0.000s
im_detect: 619/1297 0.137s 0.000s
im_detect: 620/1297 0.137s 0.000s
im_detect: 621/1297 0.137s 0.000s
im_detect: 622/1297 0.137s 0.000s
im_detect: 623/1297 0.137s 0.000s
im_detect: 624/1297 0.137s 0.000s
im_detect: 625/1297 0.137s 0.000s
im_detect: 626/1297 0.137s 0.000s
im_detect: 627/1297 0.137s 0.000s
im_detect: 628/1297 0.137s 0.000s
im_detect: 629/1297 0.137s 0.000s
im_detect: 630/1297 0.137s 0.000s
im_detect: 631/1297 0.137s 0.000s
im_detect: 632/1297 0.137s 0.000s
im_detect: 633/1297 0.137s 0.000s
im_detect: 634/1297 0.137s 0.000s
im_detect: 635/1297 0.137s 0.000s
im_detect: 636/1297 0.137s 0.000s
im_detect: 637/1297 0.137s 0.000s
im_detect: 638/1297 0.137s 0.000s
im_detect: 639/1297 0.137s 0.000s
im_detect: 640/1297 0.137s 0.000s
im_detect: 641/1297 0.137s 0.000s
im_detect: 642/1297 0.137s 0.000s
im_detect: 643/1297 0.137s 0.000s
im_detect: 644/1297 0.137s 0.000s
im_detect: 645/1297 0.137s 0.000s
im_detect: 646/1297 0.137s 0.000s
im_detect: 647/1297 0.137s 0.000s
im_detect: 648/1297 0.137s 0.000s
im_detect: 649/1297 0.137s 0.000s
im_detect: 650/1297 0.137s 0.000s
im_detect: 651/1297 0.137s 0.000s
im_detect: 652/1297 0.137s 0.000s
im_detect: 653/1297 0.137s 0.000s
im_detect: 654/1297 0.137s 0.000s
im_detect: 655/1297 0.137s 0.000s
im_detect: 656/1297 0.137s 0.000s
im_detect: 657/1297 0.137s 0.000s
im_detect: 658/1297 0.137s 0.000s
im_detect: 659/1297 0.137s 0.000s
im_detect: 660/1297 0.137s 0.000s
im_detect: 661/1297 0.137s 0.000s
im_detect: 662/1297 0.137s 0.000s
im_detect: 663/1297 0.137s 0.000s
im_detect: 664/1297 0.137s 0.000s
im_detect: 665/1297 0.137s 0.000s
im_detect: 666/1297 0.137s 0.000s
im_detect: 667/1297 0.137s 0.000s
im_detect: 668/1297 0.137s 0.000s
im_detect: 669/1297 0.137s 0.000s
im_detect: 670/1297 0.137s 0.000s
im_detect: 671/1297 0.137s 0.000s
im_detect: 672/1297 0.137s 0.000s
im_detect: 673/1297 0.137s 0.000s
im_detect: 674/1297 0.137s 0.000s
im_detect: 675/1297 0.137s 0.000s
im_detect: 676/1297 0.137s 0.000s
im_detect: 677/1297 0.137s 0.000s
im_detect: 678/1297 0.137s 0.000s
im_detect: 679/1297 0.137s 0.000s
im_detect: 680/1297 0.137s 0.000s
im_detect: 681/1297 0.137s 0.000s
im_detect: 682/1297 0.137s 0.000s
im_detect: 683/1297 0.137s 0.000s
im_detect: 684/1297 0.137s 0.000s
im_detect: 685/1297 0.137s 0.000s
im_detect: 686/1297 0.137s 0.000s
im_detect: 687/1297 0.137s 0.000s
im_detect: 688/1297 0.137s 0.000s
im_detect: 689/1297 0.137s 0.000s
im_detect: 690/1297 0.137s 0.000s
im_detect: 691/1297 0.137s 0.000s
im_detect: 692/1297 0.137s 0.000s
im_detect: 693/1297 0.137s 0.000s
im_detect: 694/1297 0.137s 0.000s
im_detect: 695/1297 0.137s 0.000s
im_detect: 696/1297 0.137s 0.000s
im_detect: 697/1297 0.137s 0.000s
im_detect: 698/1297 0.137s 0.000s
im_detect: 699/1297 0.137s 0.000s
im_detect: 700/1297 0.137s 0.000s
im_detect: 701/1297 0.137s 0.000s
im_detect: 702/1297 0.137s 0.000s
im_detect: 703/1297 0.137s 0.000s
im_detect: 704/1297 0.137s 0.000s
im_detect: 705/1297 0.137s 0.000s
im_detect: 706/1297 0.137s 0.000s
im_detect: 707/1297 0.137s 0.000s
im_detect: 708/1297 0.137s 0.000s
im_detect: 709/1297 0.137s 0.000s
im_detect: 710/1297 0.137s 0.000s
im_detect: 711/1297 0.137s 0.000s
im_detect: 712/1297 0.137s 0.000s
im_detect: 713/1297 0.137s 0.000s
im_detect: 714/1297 0.137s 0.000s
im_detect: 715/1297 0.137s 0.000s
im_detect: 716/1297 0.137s 0.000s
im_detect: 717/1297 0.137s 0.000s
im_detect: 718/1297 0.137s 0.000s
im_detect: 719/1297 0.137s 0.000s
im_detect: 720/1297 0.137s 0.000s
im_detect: 721/1297 0.137s 0.000s
im_detect: 722/1297 0.137s 0.000s
im_detect: 723/1297 0.137s 0.000s
im_detect: 724/1297 0.137s 0.000s
im_detect: 725/1297 0.137s 0.000s
im_detect: 726/1297 0.137s 0.000s
im_detect: 727/1297 0.137s 0.000s
im_detect: 728/1297 0.137s 0.000s
im_detect: 729/1297 0.137s 0.000s
im_detect: 730/1297 0.137s 0.000s
im_detect: 731/1297 0.137s 0.000s
im_detect: 732/1297 0.137s 0.000s
im_detect: 733/1297 0.137s 0.000s
im_detect: 734/1297 0.137s 0.000s
im_detect: 735/1297 0.137s 0.000s
im_detect: 736/1297 0.137s 0.000s
im_detect: 737/1297 0.137s 0.000s
im_detect: 738/1297 0.137s 0.000s
im_detect: 739/1297 0.137s 0.000s
im_detect: 740/1297 0.137s 0.000s
im_detect: 741/1297 0.137s 0.000s
im_detect: 742/1297 0.137s 0.000s
im_detect: 743/1297 0.137s 0.000s
im_detect: 744/1297 0.137s 0.000s
im_detect: 745/1297 0.137s 0.000s
im_detect: 746/1297 0.137s 0.000s
im_detect: 747/1297 0.137s 0.000s
im_detect: 748/1297 0.137s 0.000s
im_detect: 749/1297 0.137s 0.000s
im_detect: 750/1297 0.137s 0.000s
im_detect: 751/1297 0.137s 0.000s
im_detect: 752/1297 0.137s 0.000s
im_detect: 753/1297 0.137s 0.000s
im_detect: 754/1297 0.137s 0.000s
im_detect: 755/1297 0.137s 0.000s
im_detect: 756/1297 0.137s 0.000s
im_detect: 757/1297 0.137s 0.000s
im_detect: 758/1297 0.137s 0.000s
im_detect: 759/1297 0.137s 0.000s
im_detect: 760/1297 0.137s 0.000s
im_detect: 761/1297 0.137s 0.000s
im_detect: 762/1297 0.137s 0.000s
im_detect: 763/1297 0.137s 0.000s
im_detect: 764/1297 0.137s 0.000s
im_detect: 765/1297 0.137s 0.000s
im_detect: 766/1297 0.137s 0.000s
im_detect: 767/1297 0.137s 0.000s
im_detect: 768/1297 0.137s 0.000s
im_detect: 769/1297 0.137s 0.000s
im_detect: 770/1297 0.137s 0.000s
im_detect: 771/1297 0.137s 0.000s
im_detect: 772/1297 0.137s 0.000s
im_detect: 773/1297 0.137s 0.000s
im_detect: 774/1297 0.137s 0.000s
im_detect: 775/1297 0.137s 0.000s
im_detect: 776/1297 0.137s 0.000s
im_detect: 777/1297 0.137s 0.000s
im_detect: 778/1297 0.137s 0.000s
im_detect: 779/1297 0.137s 0.000s
im_detect: 780/1297 0.137s 0.000s
im_detect: 781/1297 0.137s 0.000s
im_detect: 782/1297 0.137s 0.000s
im_detect: 783/1297 0.137s 0.000s
im_detect: 784/1297 0.137s 0.000s
im_detect: 785/1297 0.137s 0.000s
im_detect: 786/1297 0.137s 0.000s
im_detect: 787/1297 0.137s 0.000s
im_detect: 788/1297 0.137s 0.000s
im_detect: 789/1297 0.137s 0.000s
im_detect: 790/1297 0.137s 0.000s
im_detect: 791/1297 0.137s 0.000s
im_detect: 792/1297 0.137s 0.000s
im_detect: 793/1297 0.137s 0.000s
im_detect: 794/1297 0.137s 0.000s
im_detect: 795/1297 0.137s 0.000s
im_detect: 796/1297 0.137s 0.000s
im_detect: 797/1297 0.137s 0.000s
im_detect: 798/1297 0.137s 0.000s
im_detect: 799/1297 0.137s 0.000s
im_detect: 800/1297 0.137s 0.000s
im_detect: 801/1297 0.137s 0.000s
im_detect: 802/1297 0.137s 0.000s
im_detect: 803/1297 0.137s 0.000s
im_detect: 804/1297 0.137s 0.000s
im_detect: 805/1297 0.137s 0.000s
im_detect: 806/1297 0.137s 0.000s
im_detect: 807/1297 0.137s 0.000s
im_detect: 808/1297 0.137s 0.000s
im_detect: 809/1297 0.137s 0.000s
im_detect: 810/1297 0.136s 0.000s
im_detect: 811/1297 0.137s 0.000s
im_detect: 812/1297 0.136s 0.000s
im_detect: 813/1297 0.136s 0.000s
im_detect: 814/1297 0.136s 0.000s
im_detect: 815/1297 0.136s 0.000s
im_detect: 816/1297 0.136s 0.000s
im_detect: 817/1297 0.136s 0.000s
im_detect: 818/1297 0.136s 0.000s
im_detect: 819/1297 0.136s 0.000s
im_detect: 820/1297 0.136s 0.000s
im_detect: 821/1297 0.136s 0.000s
im_detect: 822/1297 0.136s 0.000s
im_detect: 823/1297 0.136s 0.000s
im_detect: 824/1297 0.136s 0.000s
im_detect: 825/1297 0.136s 0.000s
im_detect: 826/1297 0.136s 0.000s
im_detect: 827/1297 0.136s 0.000s
im_detect: 828/1297 0.136s 0.000s
im_detect: 829/1297 0.136s 0.000s
im_detect: 830/1297 0.136s 0.000s
im_detect: 831/1297 0.137s 0.000s
im_detect: 832/1297 0.137s 0.000s
im_detect: 833/1297 0.136s 0.000s
im_detect: 834/1297 0.137s 0.000s
im_detect: 835/1297 0.137s 0.000s
im_detect: 836/1297 0.137s 0.000s
im_detect: 837/1297 0.137s 0.000s
im_detect: 838/1297 0.136s 0.000s
im_detect: 839/1297 0.136s 0.000s
im_detect: 840/1297 0.136s 0.000s
im_detect: 841/1297 0.136s 0.000s
im_detect: 842/1297 0.136s 0.000s
im_detect: 843/1297 0.136s 0.000s
im_detect: 844/1297 0.136s 0.000s
im_detect: 845/1297 0.136s 0.000s
im_detect: 846/1297 0.136s 0.000s
im_detect: 847/1297 0.136s 0.000s
im_detect: 848/1297 0.136s 0.000s
im_detect: 849/1297 0.136s 0.000s
im_detect: 850/1297 0.136s 0.000s
im_detect: 851/1297 0.136s 0.000s
im_detect: 852/1297 0.136s 0.000s
im_detect: 853/1297 0.136s 0.000s
im_detect: 854/1297 0.136s 0.000s
im_detect: 855/1297 0.136s 0.000s
im_detect: 856/1297 0.136s 0.000s
im_detect: 857/1297 0.136s 0.000s
im_detect: 858/1297 0.136s 0.000s
im_detect: 859/1297 0.136s 0.000s
im_detect: 860/1297 0.136s 0.000s
im_detect: 861/1297 0.136s 0.000s
im_detect: 862/1297 0.136s 0.000s
im_detect: 863/1297 0.136s 0.000s
im_detect: 864/1297 0.136s 0.000s
im_detect: 865/1297 0.136s 0.000s
im_detect: 866/1297 0.136s 0.000s
im_detect: 867/1297 0.136s 0.000s
im_detect: 868/1297 0.136s 0.000s
im_detect: 869/1297 0.136s 0.000s
im_detect: 870/1297 0.136s 0.000s
im_detect: 871/1297 0.136s 0.000s
im_detect: 872/1297 0.136s 0.000s
im_detect: 873/1297 0.136s 0.000s
im_detect: 874/1297 0.136s 0.000s
im_detect: 875/1297 0.136s 0.000s
im_detect: 876/1297 0.136s 0.000s
im_detect: 877/1297 0.136s 0.000s
im_detect: 878/1297 0.136s 0.000s
im_detect: 879/1297 0.136s 0.000s
im_detect: 880/1297 0.136s 0.000s
im_detect: 881/1297 0.136s 0.000s
im_detect: 882/1297 0.136s 0.000s
im_detect: 883/1297 0.136s 0.000s
im_detect: 884/1297 0.136s 0.000s
im_detect: 885/1297 0.136s 0.000s
im_detect: 886/1297 0.136s 0.000s
im_detect: 887/1297 0.136s 0.000s
im_detect: 888/1297 0.136s 0.000s
im_detect: 889/1297 0.136s 0.000s
im_detect: 890/1297 0.136s 0.000s
im_detect: 891/1297 0.136s 0.000s
im_detect: 892/1297 0.136s 0.000s
im_detect: 893/1297 0.136s 0.000s
im_detect: 894/1297 0.136s 0.000s
im_detect: 895/1297 0.136s 0.000s
im_detect: 896/1297 0.136s 0.000s
im_detect: 897/1297 0.136s 0.000s
im_detect: 898/1297 0.136s 0.000s
im_detect: 899/1297 0.136s 0.000s
im_detect: 900/1297 0.136s 0.000s
im_detect: 901/1297 0.136s 0.000s
im_detect: 902/1297 0.136s 0.000s
im_detect: 903/1297 0.136s 0.000s
im_detect: 904/1297 0.136s 0.000s
im_detect: 905/1297 0.136s 0.000s
im_detect: 906/1297 0.136s 0.000s
im_detect: 907/1297 0.136s 0.000s
im_detect: 908/1297 0.136s 0.000s
im_detect: 909/1297 0.136s 0.000s
im_detect: 910/1297 0.136s 0.000s
im_detect: 911/1297 0.136s 0.000s
im_detect: 912/1297 0.136s 0.000s
im_detect: 913/1297 0.136s 0.000s
im_detect: 914/1297 0.136s 0.000s
im_detect: 915/1297 0.136s 0.000s
im_detect: 916/1297 0.136s 0.000s
im_detect: 917/1297 0.136s 0.000s
im_detect: 918/1297 0.136s 0.000s
im_detect: 919/1297 0.136s 0.000s
im_detect: 920/1297 0.136s 0.000s
im_detect: 921/1297 0.136s 0.000s
im_detect: 922/1297 0.136s 0.000s
im_detect: 923/1297 0.136s 0.000s
im_detect: 924/1297 0.136s 0.000s
im_detect: 925/1297 0.136s 0.000s
im_detect: 926/1297 0.136s 0.000s
im_detect: 927/1297 0.136s 0.000s
im_detect: 928/1297 0.136s 0.000s
im_detect: 929/1297 0.136s 0.000s
im_detect: 930/1297 0.136s 0.000s
im_detect: 931/1297 0.136s 0.000s
im_detect: 932/1297 0.136s 0.000s
im_detect: 933/1297 0.136s 0.000s
im_detect: 934/1297 0.136s 0.000s
im_detect: 935/1297 0.136s 0.000s
im_detect: 936/1297 0.136s 0.000s
im_detect: 937/1297 0.136s 0.000s
im_detect: 938/1297 0.136s 0.000s
im_detect: 939/1297 0.136s 0.000s
im_detect: 940/1297 0.136s 0.000s
im_detect: 941/1297 0.136s 0.000s
im_detect: 942/1297 0.136s 0.000s
im_detect: 943/1297 0.136s 0.000s
im_detect: 944/1297 0.136s 0.000s
im_detect: 945/1297 0.136s 0.000s
im_detect: 946/1297 0.136s 0.000s
im_detect: 947/1297 0.136s 0.000s
im_detect: 948/1297 0.136s 0.000s
im_detect: 949/1297 0.136s 0.000s
im_detect: 950/1297 0.136s 0.000s
im_detect: 951/1297 0.136s 0.000s
im_detect: 952/1297 0.136s 0.000s
im_detect: 953/1297 0.136s 0.000s
im_detect: 954/1297 0.136s 0.000s
im_detect: 955/1297 0.136s 0.000s
im_detect: 956/1297 0.136s 0.000s
im_detect: 957/1297 0.136s 0.000s
im_detect: 958/1297 0.136s 0.000s
im_detect: 959/1297 0.136s 0.000s
im_detect: 960/1297 0.136s 0.000s
im_detect: 961/1297 0.136s 0.000s
im_detect: 962/1297 0.136s 0.000s
im_detect: 963/1297 0.136s 0.000s
im_detect: 964/1297 0.136s 0.000s
im_detect: 965/1297 0.136s 0.000s
im_detect: 966/1297 0.136s 0.000s
im_detect: 967/1297 0.136s 0.000s
im_detect: 968/1297 0.136s 0.000s
im_detect: 969/1297 0.136s 0.000s
im_detect: 970/1297 0.136s 0.000s
im_detect: 971/1297 0.136s 0.000s
im_detect: 972/1297 0.136s 0.000s
im_detect: 973/1297 0.136s 0.000s
im_detect: 974/1297 0.136s 0.000s
im_detect: 975/1297 0.136s 0.000s
im_detect: 976/1297 0.136s 0.000s
im_detect: 977/1297 0.136s 0.000s
im_detect: 978/1297 0.136s 0.000s
im_detect: 979/1297 0.136s 0.000s
im_detect: 980/1297 0.136s 0.000s
im_detect: 981/1297 0.136s 0.000s
im_detect: 982/1297 0.136s 0.000s
im_detect: 983/1297 0.136s 0.000s
im_detect: 984/1297 0.136s 0.000s
im_detect: 985/1297 0.136s 0.000s
im_detect: 986/1297 0.136s 0.000s
im_detect: 987/1297 0.136s 0.000s
im_detect: 988/1297 0.136s 0.000s
im_detect: 989/1297 0.136s 0.000s
im_detect: 990/1297 0.136s 0.000s
im_detect: 991/1297 0.136s 0.000s
im_detect: 992/1297 0.136s 0.000s
im_detect: 993/1297 0.136s 0.000s
im_detect: 994/1297 0.136s 0.000s
im_detect: 995/1297 0.136s 0.000s
im_detect: 996/1297 0.136s 0.000s
im_detect: 997/1297 0.136s 0.000s
im_detect: 998/1297 0.136s 0.000s
im_detect: 999/1297 0.136s 0.000s
im_detect: 1000/1297 0.136s 0.000s
im_detect: 1001/1297 0.136s 0.000s
im_detect: 1002/1297 0.136s 0.000s
im_detect: 1003/1297 0.136s 0.000s
im_detect: 1004/1297 0.136s 0.000s
im_detect: 1005/1297 0.136s 0.000s
im_detect: 1006/1297 0.136s 0.000s
im_detect: 1007/1297 0.136s 0.000s
im_detect: 1008/1297 0.136s 0.000s
im_detect: 1009/1297 0.136s 0.000s
im_detect: 1010/1297 0.136s 0.000s
im_detect: 1011/1297 0.136s 0.000s
im_detect: 1012/1297 0.136s 0.000s
im_detect: 1013/1297 0.136s 0.000s
im_detect: 1014/1297 0.136s 0.000s
im_detect: 1015/1297 0.136s 0.000s
im_detect: 1016/1297 0.136s 0.000s
im_detect: 1017/1297 0.136s 0.000s
im_detect: 1018/1297 0.136s 0.000s
im_detect: 1019/1297 0.136s 0.000s
im_detect: 1020/1297 0.136s 0.000s
im_detect: 1021/1297 0.136s 0.000s
im_detect: 1022/1297 0.136s 0.000s
im_detect: 1023/1297 0.136s 0.000s
im_detect: 1024/1297 0.136s 0.000s
im_detect: 1025/1297 0.136s 0.000s
im_detect: 1026/1297 0.136s 0.000s
im_detect: 1027/1297 0.136s 0.000s
im_detect: 1028/1297 0.136s 0.000s
im_detect: 1029/1297 0.136s 0.000s
im_detect: 1030/1297 0.136s 0.000s
im_detect: 1031/1297 0.136s 0.000s
im_detect: 1032/1297 0.136s 0.000s
im_detect: 1033/1297 0.136s 0.000s
im_detect: 1034/1297 0.136s 0.000s
im_detect: 1035/1297 0.136s 0.000s
im_detect: 1036/1297 0.136s 0.000s
im_detect: 1037/1297 0.136s 0.000s
im_detect: 1038/1297 0.136s 0.000s
im_detect: 1039/1297 0.136s 0.000s
im_detect: 1040/1297 0.136s 0.000s
im_detect: 1041/1297 0.136s 0.000s
im_detect: 1042/1297 0.136s 0.000s
im_detect: 1043/1297 0.136s 0.000s
im_detect: 1044/1297 0.136s 0.000s
im_detect: 1045/1297 0.136s 0.000s
im_detect: 1046/1297 0.136s 0.000s
im_detect: 1047/1297 0.136s 0.000s
im_detect: 1048/1297 0.136s 0.000s
im_detect: 1049/1297 0.136s 0.000s
im_detect: 1050/1297 0.136s 0.000s
im_detect: 1051/1297 0.136s 0.000s
im_detect: 1052/1297 0.136s 0.000s
im_detect: 1053/1297 0.136s 0.000s
im_detect: 1054/1297 0.136s 0.000s
im_detect: 1055/1297 0.136s 0.000s
im_detect: 1056/1297 0.136s 0.000s
im_detect: 1057/1297 0.136s 0.000s
im_detect: 1058/1297 0.136s 0.000s
im_detect: 1059/1297 0.136s 0.000s
im_detect: 1060/1297 0.136s 0.000s
im_detect: 1061/1297 0.136s 0.000s
im_detect: 1062/1297 0.136s 0.000s
im_detect: 1063/1297 0.136s 0.000s
im_detect: 1064/1297 0.136s 0.000s
im_detect: 1065/1297 0.136s 0.000s
im_detect: 1066/1297 0.136s 0.000s
im_detect: 1067/1297 0.136s 0.000s
im_detect: 1068/1297 0.136s 0.000s
im_detect: 1069/1297 0.136s 0.000s
im_detect: 1070/1297 0.136s 0.000s
im_detect: 1071/1297 0.136s 0.000s
im_detect: 1072/1297 0.136s 0.000s
im_detect: 1073/1297 0.136s 0.000s
im_detect: 1074/1297 0.136s 0.000s
im_detect: 1075/1297 0.136s 0.000s
im_detect: 1076/1297 0.136s 0.000s
im_detect: 1077/1297 0.136s 0.000s
im_detect: 1078/1297 0.136s 0.000s
im_detect: 1079/1297 0.136s 0.000s
im_detect: 1080/1297 0.136s 0.000s
im_detect: 1081/1297 0.136s 0.000s
im_detect: 1082/1297 0.136s 0.000s
im_detect: 1083/1297 0.136s 0.000s
im_detect: 1084/1297 0.136s 0.000s
im_detect: 1085/1297 0.136s 0.000s
im_detect: 1086/1297 0.136s 0.000s
im_detect: 1087/1297 0.136s 0.000s
im_detect: 1088/1297 0.136s 0.000s
im_detect: 1089/1297 0.136s 0.000s
im_detect: 1090/1297 0.136s 0.000s
im_detect: 1091/1297 0.136s 0.000s
im_detect: 1092/1297 0.136s 0.000s
im_detect: 1093/1297 0.136s 0.000s
im_detect: 1094/1297 0.136s 0.000s
im_detect: 1095/1297 0.136s 0.000s
im_detect: 1096/1297 0.136s 0.000s
im_detect: 1097/1297 0.136s 0.000s
im_detect: 1098/1297 0.136s 0.000s
im_detect: 1099/1297 0.136s 0.000s
im_detect: 1100/1297 0.136s 0.000s
im_detect: 1101/1297 0.136s 0.000s
im_detect: 1102/1297 0.136s 0.000s
im_detect: 1103/1297 0.136s 0.000s
im_detect: 1104/1297 0.136s 0.000s
im_detect: 1105/1297 0.136s 0.000s
im_detect: 1106/1297 0.136s 0.000s
im_detect: 1107/1297 0.136s 0.000s
im_detect: 1108/1297 0.136s 0.000s
im_detect: 1109/1297 0.136s 0.000s
im_detect: 1110/1297 0.136s 0.000s
im_detect: 1111/1297 0.136s 0.000s
im_detect: 1112/1297 0.136s 0.000s
im_detect: 1113/1297 0.136s 0.000s
im_detect: 1114/1297 0.136s 0.000s
im_detect: 1115/1297 0.136s 0.000s
im_detect: 1116/1297 0.136s 0.000s
im_detect: 1117/1297 0.136s 0.000s
im_detect: 1118/1297 0.136s 0.000s
im_detect: 1119/1297 0.136s 0.000s
im_detect: 1120/1297 0.136s 0.000s
im_detect: 1121/1297 0.136s 0.000s
im_detect: 1122/1297 0.136s 0.000s
im_detect: 1123/1297 0.136s 0.000s
im_detect: 1124/1297 0.136s 0.000s
im_detect: 1125/1297 0.136s 0.000s
im_detect: 1126/1297 0.136s 0.000s
im_detect: 1127/1297 0.136s 0.000s
im_detect: 1128/1297 0.136s 0.000s
im_detect: 1129/1297 0.136s 0.000s
im_detect: 1130/1297 0.136s 0.000s
im_detect: 1131/1297 0.136s 0.000s
im_detect: 1132/1297 0.136s 0.000s
im_detect: 1133/1297 0.136s 0.000s
im_detect: 1134/1297 0.136s 0.000s
im_detect: 1135/1297 0.136s 0.000s
im_detect: 1136/1297 0.136s 0.000s
im_detect: 1137/1297 0.136s 0.000s
im_detect: 1138/1297 0.136s 0.000s
im_detect: 1139/1297 0.136s 0.000s
im_detect: 1140/1297 0.136s 0.000s
im_detect: 1141/1297 0.136s 0.000s
im_detect: 1142/1297 0.136s 0.000s
im_detect: 1143/1297 0.136s 0.000s
im_detect: 1144/1297 0.136s 0.000s
im_detect: 1145/1297 0.136s 0.000s
im_detect: 1146/1297 0.136s 0.000s
im_detect: 1147/1297 0.136s 0.000s
im_detect: 1148/1297 0.136s 0.000s
im_detect: 1149/1297 0.136s 0.000s
im_detect: 1150/1297 0.136s 0.000s
im_detect: 1151/1297 0.136s 0.000s
im_detect: 1152/1297 0.136s 0.000s
im_detect: 1153/1297 0.136s 0.000s
im_detect: 1154/1297 0.136s 0.000s
im_detect: 1155/1297 0.136s 0.000s
im_detect: 1156/1297 0.136s 0.000s
im_detect: 1157/1297 0.136s 0.000s
im_detect: 1158/1297 0.136s 0.000s
im_detect: 1159/1297 0.136s 0.000s
im_detect: 1160/1297 0.136s 0.000s
im_detect: 1161/1297 0.136s 0.000s
im_detect: 1162/1297 0.136s 0.000s
im_detect: 1163/1297 0.136s 0.000s
im_detect: 1164/1297 0.136s 0.000s
im_detect: 1165/1297 0.136s 0.000s
im_detect: 1166/1297 0.136s 0.000s
im_detect: 1167/1297 0.136s 0.000s
im_detect: 1168/1297 0.136s 0.000s
im_detect: 1169/1297 0.136s 0.000s
im_detect: 1170/1297 0.136s 0.000s
im_detect: 1171/1297 0.136s 0.000s
im_detect: 1172/1297 0.136s 0.000s
im_detect: 1173/1297 0.136s 0.000s
im_detect: 1174/1297 0.136s 0.000s
im_detect: 1175/1297 0.136s 0.000s
im_detect: 1176/1297 0.136s 0.000s
im_detect: 1177/1297 0.136s 0.000s
im_detect: 1178/1297 0.136s 0.000s
im_detect: 1179/1297 0.136s 0.000s
im_detect: 1180/1297 0.136s 0.000s
im_detect: 1181/1297 0.136s 0.000s
im_detect: 1182/1297 0.136s 0.000s
im_detect: 1183/1297 0.136s 0.000s
im_detect: 1184/1297 0.136s 0.000s
im_detect: 1185/1297 0.136s 0.000s
im_detect: 1186/1297 0.136s 0.000s
im_detect: 1187/1297 0.136s 0.000s
im_detect: 1188/1297 0.136s 0.000s
im_detect: 1189/1297 0.136s 0.000s
im_detect: 1190/1297 0.136s 0.000s
im_detect: 1191/1297 0.136s 0.000s
im_detect: 1192/1297 0.136s 0.000s
im_detect: 1193/1297 0.136s 0.000s
im_detect: 1194/1297 0.136s 0.000s
im_detect: 1195/1297 0.136s 0.000s
im_detect: 1196/1297 0.136s 0.000s
im_detect: 1197/1297 0.136s 0.000s
im_detect: 1198/1297 0.136s 0.000s
im_detect: 1199/1297 0.136s 0.000s
im_detect: 1200/1297 0.136s 0.000s
im_detect: 1201/1297 0.136s 0.000s
im_detect: 1202/1297 0.136s 0.000s
im_detect: 1203/1297 0.136s 0.000s
im_detect: 1204/1297 0.136s 0.000s
im_detect: 1205/1297 0.136s 0.000s
im_detect: 1206/1297 0.136s 0.000s
im_detect: 1207/1297 0.136s 0.000s
im_detect: 1208/1297 0.136s 0.000s
im_detect: 1209/1297 0.136s 0.000s
im_detect: 1210/1297 0.136s 0.000s
im_detect: 1211/1297 0.136s 0.000s
im_detect: 1212/1297 0.136s 0.000s
im_detect: 1213/1297 0.136s 0.000s
im_detect: 1214/1297 0.136s 0.000s
im_detect: 1215/1297 0.136s 0.000s
im_detect: 1216/1297 0.136s 0.000s
im_detect: 1217/1297 0.136s 0.000s
im_detect: 1218/1297 0.136s 0.000s
im_detect: 1219/1297 0.136s 0.000s
im_detect: 1220/1297 0.136s 0.000s
im_detect: 1221/1297 0.136s 0.000s
im_detect: 1222/1297 0.136s 0.000s
im_detect: 1223/1297 0.136s 0.000s
im_detect: 1224/1297 0.136s 0.000s
im_detect: 1225/1297 0.136s 0.000s
im_detect: 1226/1297 0.136s 0.000s
im_detect: 1227/1297 0.136s 0.000s
im_detect: 1228/1297 0.136s 0.000s
im_detect: 1229/1297 0.136s 0.000s
im_detect: 1230/1297 0.136s 0.000s
im_detect: 1231/1297 0.136s 0.000s
im_detect: 1232/1297 0.136s 0.000s
im_detect: 1233/1297 0.136s 0.000s
im_detect: 1234/1297 0.136s 0.000s
im_detect: 1235/1297 0.136s 0.000s
im_detect: 1236/1297 0.136s 0.000s
im_detect: 1237/1297 0.136s 0.000s
im_detect: 1238/1297 0.136s 0.000s
im_detect: 1239/1297 0.136s 0.000s
im_detect: 1240/1297 0.136s 0.000s
im_detect: 1241/1297 0.136s 0.000s
im_detect: 1242/1297 0.136s 0.000s
im_detect: 1243/1297 0.136s 0.000s
im_detect: 1244/1297 0.136s 0.000s
im_detect: 1245/1297 0.136s 0.000s
im_detect: 1246/1297 0.136s 0.000s
im_detect: 1247/1297 0.136s 0.000s
im_detect: 1248/1297 0.136s 0.000s
im_detect: 1249/1297 0.136s 0.000s
im_detect: 1250/1297 0.136s 0.000s
im_detect: 1251/1297 0.136s 0.000s
im_detect: 1252/1297 0.136s 0.000s
im_detect: 1253/1297 0.136s 0.000s
im_detect: 1254/1297 0.136s 0.000s
im_detect: 1255/1297 0.136s 0.000s
im_detect: 1256/1297 0.136s 0.000s
im_detect: 1257/1297 0.136s 0.000s
im_detect: 1258/1297 0.136s 0.000s
im_detect: 1259/1297 0.136s 0.000s
im_detect: 1260/1297 0.136s 0.000s
im_detect: 1261/1297 0.136s 0.000s
im_detect: 1262/1297 0.136s 0.000s
im_detect: 1263/1297 0.136s 0.000s
im_detect: 1264/1297 0.136s 0.000s
im_detect: 1265/1297 0.136s 0.000s
im_detect: 1266/1297 0.136s 0.000s
im_detect: 1267/1297 0.136s 0.000s
im_detect: 1268/1297 0.136s 0.000s
im_detect: 1269/1297 0.136s 0.000s
im_detect: 1270/1297 0.136s 0.000s
im_detect: 1271/1297 0.136s 0.000s
im_detect: 1272/1297 0.136s 0.000s
im_detect: 1273/1297 0.136s 0.000s
im_detect: 1274/1297 0.136s 0.000s
im_detect: 1275/1297 0.136s 0.000s
im_detect: 1276/1297 0.136s 0.000s
im_detect: 1277/1297 0.136s 0.000s
im_detect: 1278/1297 0.136s 0.000s
im_detect: 1279/1297 0.136s 0.000s
im_detect: 1280/1297 0.136s 0.000s
im_detect: 1281/1297 0.136s 0.000s
im_detect: 1282/1297 0.136s 0.000s
im_detect: 1283/1297 0.136s 0.000s
im_detect: 1284/1297 0.136s 0.000s
im_detect: 1285/1297 0.136s 0.000s
im_detect: 1286/1297 0.136s 0.000s
im_detect: 1287/1297 0.136s 0.000s
im_detect: 1288/1297 0.136s 0.000s
im_detect: 1289/1297 0.136s 0.000s
im_detect: 1290/1297 0.136s 0.000s
im_detect: 1291/1297 0.136s 0.000s
im_detect: 1292/1297 0.136s 0.000s
im_detect: 1293/1297 0.136s 0.000s
im_detect: 1294/1297 0.136s 0.000s
im_detect: 1295/1297 0.136s 0.000s
im_detect: 1296/1297 0.136s 0.000s
im_detect: 1297/1297 0.136s 0.000s
Evaluating detections
Writing head VOC results file
VOC07 metric? Yes
AP for head = 0.8093
Mean AP = 0.8093
~~~~~~~~
Results:
0.809
0.809
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	3m8.156s
user	2m22.036s
sys	0m46.802s
